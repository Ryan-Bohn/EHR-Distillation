==========================================
SLURM_JOB_ID = 18882278
SLURM_JOB_NODELIST = a01-01
TMPDIR = /tmp/SLURM_18882278
==========================================
Restoring modules from user's default
Using device: cuda
Loading dataset from "../data/mimic3/benchmark/multitask/train/saves/20240130-023352.pkl"...
Dataset loaded. Info: {'sr': 1.0, 'one_hot': False}
Loading dataset from "../data/mimic3/benchmark/multitask/test/saves/20240130-022843.pkl"...
Dataset loaded. Info: {'sr': 1.0, 'one_hot': False}
Datasets loaded.
Train set size: 35571
Test set size: 6273
Epoch 1 training...
Epoch 1 evaluating...
Epoch [1/100], Train Loss: 2.3496, Eval Loss: 2.4751
Epoch 2 training...
Epoch 2 evaluating...
Epoch [2/100], Train Loss: 2.1599, Eval Loss: 2.2115
Epoch 3 training...
Epoch 3 evaluating...
Epoch [3/100], Train Loss: 1.9636, Eval Loss: 2.0184
Epoch 4 training...
Epoch 4 evaluating...
Epoch [4/100], Train Loss: 1.8042, Eval Loss: 1.8849
Epoch 5 training...
Epoch 5 evaluating...
Epoch [5/100], Train Loss: 1.6572, Eval Loss: 1.7386
Epoch 6 training...
Epoch 6 evaluating...
Epoch [6/100], Train Loss: 1.5608, Eval Loss: 1.6629
Epoch 7 training...
Epoch 7 evaluating...
Epoch [7/100], Train Loss: 1.4869, Eval Loss: 1.6575
Epoch 8 training...
Epoch 8 evaluating...
Epoch [8/100], Train Loss: 1.4389, Eval Loss: 1.5618
Epoch 9 training...
Epoch 9 evaluating...
Epoch [9/100], Train Loss: 1.4076, Eval Loss: 1.5405
Epoch 10 training...
Epoch 10 evaluating...
Epoch [10/100], Train Loss: 1.4119, Eval Loss: 1.5816
Epoch 11 training...
Epoch 11 evaluating...
Epoch [11/100], Train Loss: 1.3812, Eval Loss: 1.5494
Epoch 12 training...
Epoch 12 evaluating...
Epoch [12/100], Train Loss: 1.3890, Eval Loss: 1.5986
Epoch 13 training...
Epoch 13 evaluating...
Epoch [13/100], Train Loss: 1.3718, Eval Loss: 1.5864
Epoch 14 training...
Epoch 14 evaluating...
Epoch [14/100], Train Loss: 1.3715, Eval Loss: 1.5949
Epoch 15 training...
Epoch 15 evaluating...
Epoch [15/100], Train Loss: 1.3672, Eval Loss: 1.7376
Epoch 16 training...
Epoch 16 evaluating...
Epoch [16/100], Train Loss: 1.3553, Eval Loss: 1.6406
Epoch 17 training...
Epoch 17 evaluating...
Epoch [17/100], Train Loss: 1.3419, Eval Loss: 1.5905
Epoch 18 training...
Epoch 18 evaluating...
Epoch [18/100], Train Loss: 1.3382, Eval Loss: 1.6442
Epoch 19 training...
Epoch 19 evaluating...
Epoch [19/100], Train Loss: 1.3348, Eval Loss: 1.6013
Epoch 20 training...
Epoch 20 evaluating...
Epoch [20/100], Train Loss: 1.3288, Eval Loss: 1.6003
Epoch 21 training...
Epoch 21 evaluating...
Epoch [21/100], Train Loss: 1.3175, Eval Loss: 1.6582
Epoch 22 training...
Epoch 22 evaluating...
Epoch [22/100], Train Loss: 1.3185, Eval Loss: 1.7444
Epoch 23 training...
Epoch 23 evaluating...
Epoch [23/100], Train Loss: 1.2961, Eval Loss: 1.6588
Epoch 24 training...
Epoch 24 evaluating...
Epoch [24/100], Train Loss: 1.2994, Eval Loss: 1.6350
Epoch 25 training...
Epoch 25 evaluating...
Epoch [25/100], Train Loss: 1.3029, Eval Loss: 1.6433
Epoch 26 training...
Epoch 26 evaluating...
Epoch [26/100], Train Loss: 1.2839, Eval Loss: 1.6790
Epoch 27 training...
Epoch 27 evaluating...
Epoch [27/100], Train Loss: 1.2916, Eval Loss: 1.7069
Epoch 28 training...
Epoch 28 evaluating...
Epoch [28/100], Train Loss: 1.2692, Eval Loss: 1.7375
Epoch 29 training...
Epoch 29 evaluating...
Epoch [29/100], Train Loss: 1.2644, Eval Loss: 1.6687
Epoch 30 training...
Epoch 30 evaluating...
Epoch [30/100], Train Loss: 1.2629, Eval Loss: 1.7324
Epoch 31 training...
Epoch 31 evaluating...
Epoch [31/100], Train Loss: 1.2565, Eval Loss: 1.6954
Epoch 32 training...
Epoch 32 evaluating...
Epoch [32/100], Train Loss: 1.2397, Eval Loss: 1.7253
Epoch 33 training...
Epoch 33 evaluating...
Epoch [33/100], Train Loss: 1.2271, Eval Loss: 1.7376
Epoch 34 training...
Epoch 34 evaluating...
Epoch [34/100], Train Loss: 1.2254, Eval Loss: 1.7237
Epoch 35 training...
Epoch 35 evaluating...
Epoch [35/100], Train Loss: 1.2087, Eval Loss: 1.7860
Epoch 36 training...
Epoch 36 evaluating...
Epoch [36/100], Train Loss: 1.1845, Eval Loss: 1.7362
Epoch 37 training...
Epoch 37 evaluating...
Epoch [37/100], Train Loss: 1.1796, Eval Loss: 1.7847
Epoch 38 training...
Epoch 38 evaluating...
Epoch [38/100], Train Loss: 1.1730, Eval Loss: 1.8774
Epoch 39 training...
Epoch 39 evaluating...
Epoch [39/100], Train Loss: 1.1525, Eval Loss: 1.8416
Epoch 40 training...
Epoch 40 evaluating...
Epoch [40/100], Train Loss: 1.1310, Eval Loss: 1.8354
Epoch 41 training...
Epoch 41 evaluating...
Epoch [41/100], Train Loss: 1.1458, Eval Loss: 1.8324
Epoch 42 training...
Epoch 42 evaluating...
Epoch [42/100], Train Loss: 1.1130, Eval Loss: 1.8230
Epoch 43 training...
Epoch 43 evaluating...
Epoch [43/100], Train Loss: 1.1074, Eval Loss: 1.8794
Epoch 44 training...
Epoch 44 evaluating...
Epoch [44/100], Train Loss: 1.0656, Eval Loss: 1.8668
Epoch 45 training...
Epoch 45 evaluating...
Epoch [45/100], Train Loss: 1.0693, Eval Loss: 1.9825
Epoch 46 training...
Epoch 46 evaluating...
Epoch [46/100], Train Loss: 1.0354, Eval Loss: 1.9001
Epoch 47 training...
Epoch 47 evaluating...
Epoch [47/100], Train Loss: 1.0495, Eval Loss: 1.8478
Epoch 48 training...
Epoch 48 evaluating...
Epoch [48/100], Train Loss: 1.0770, Eval Loss: 1.8122
Epoch 49 training...
Epoch 49 evaluating...
Epoch [49/100], Train Loss: 1.0595, Eval Loss: 1.8931
Epoch 50 training...
Epoch 50 evaluating...
Epoch [50/100], Train Loss: 0.9913, Eval Loss: 1.9785
Epoch 51 training...
Epoch 51 evaluating...
Epoch [51/100], Train Loss: 0.9628, Eval Loss: 2.1108
Epoch 52 training...
Epoch 52 evaluating...
Epoch [52/100], Train Loss: 0.9760, Eval Loss: 1.8842
Epoch 53 training...
Epoch 53 evaluating...
Epoch [53/100], Train Loss: 0.9363, Eval Loss: 1.9574
Epoch 54 training...
Epoch 54 evaluating...
Epoch [54/100], Train Loss: 0.9223, Eval Loss: 2.2037
Epoch 55 training...
Epoch 55 evaluating...
Epoch [55/100], Train Loss: 0.9214, Eval Loss: 1.9033
Epoch 56 training...
Epoch 56 evaluating...
Epoch [56/100], Train Loss: 0.9612, Eval Loss: 2.0332
Epoch 57 training...
Epoch 57 evaluating...
Epoch [57/100], Train Loss: 0.9034, Eval Loss: 2.0617
Epoch 58 training...
Epoch 58 evaluating...
Epoch [58/100], Train Loss: 0.8658, Eval Loss: 1.8717
Epoch 59 training...
Epoch 59 evaluating...
Epoch [59/100], Train Loss: 0.8320, Eval Loss: 2.1134
Epoch 60 training...
Epoch 60 evaluating...
Epoch [60/100], Train Loss: 0.8230, Eval Loss: 1.9539
Epoch 61 training...
Epoch 61 evaluating...
Epoch [61/100], Train Loss: 0.8253, Eval Loss: 2.1450
Epoch 62 training...
Epoch 62 evaluating...
Epoch [62/100], Train Loss: 0.8126, Eval Loss: 2.0795
Epoch 63 training...
Epoch 63 evaluating...
Epoch [63/100], Train Loss: 0.8268, Eval Loss: 2.1260
Epoch 64 training...
Epoch 64 evaluating...
Epoch [64/100], Train Loss: 0.7972, Eval Loss: 1.9971
Epoch 65 training...
Epoch 65 evaluating...
Epoch [65/100], Train Loss: 0.7704, Eval Loss: 2.1231
Epoch 66 training...
Epoch 66 evaluating...
Epoch [66/100], Train Loss: 0.7996, Eval Loss: 2.3540
Epoch 67 training...
Epoch 67 evaluating...
Epoch [67/100], Train Loss: 0.7810, Eval Loss: 1.9733
Epoch 68 training...
Epoch 68 evaluating...
Epoch [68/100], Train Loss: 0.7777, Eval Loss: 1.9596
Epoch 69 training...
Epoch 69 evaluating...
Epoch [69/100], Train Loss: 0.7486, Eval Loss: 2.0717
Epoch 70 training...
Epoch 70 evaluating...
Epoch [70/100], Train Loss: 0.7415, Eval Loss: 2.0156
Epoch 71 training...
Epoch 71 evaluating...
Epoch [71/100], Train Loss: 0.7271, Eval Loss: 2.0770
Epoch 72 training...
Epoch 72 evaluating...
Epoch [72/100], Train Loss: 0.7395, Eval Loss: 2.3138
Epoch 73 training...
Epoch 73 evaluating...
Epoch [73/100], Train Loss: 0.7118, Eval Loss: 1.9590
Epoch 74 training...
Epoch 74 evaluating...
Epoch [74/100], Train Loss: 0.6979, Eval Loss: 2.0230
Epoch 75 training...
Epoch 75 evaluating...
Epoch [75/100], Train Loss: 0.6905, Eval Loss: 2.0929
Epoch 76 training...
Epoch 76 evaluating...
Epoch [76/100], Train Loss: 0.7051, Eval Loss: 2.0301
Epoch 77 training...
Epoch 77 evaluating...
Epoch [77/100], Train Loss: 0.7097, Eval Loss: 2.0443
Epoch 78 training...
Epoch 78 evaluating...
Epoch [78/100], Train Loss: 0.6852, Eval Loss: 2.0787
Epoch 79 training...
Epoch 79 evaluating...
Epoch [79/100], Train Loss: 0.6966, Eval Loss: 2.2469
Epoch 80 training...
Epoch 80 evaluating...
Epoch [80/100], Train Loss: 0.6814, Eval Loss: 2.1888
Epoch 81 training...
Epoch 81 evaluating...
Epoch [81/100], Train Loss: 0.6631, Eval Loss: 1.9965
Epoch 82 training...
Epoch 82 evaluating...
Epoch [82/100], Train Loss: 0.7338, Eval Loss: 2.1347
Epoch 83 training...
Epoch 83 evaluating...
Epoch [83/100], Train Loss: 0.7015, Eval Loss: 2.0747
Epoch 84 training...
Epoch 84 evaluating...
Epoch [84/100], Train Loss: 0.6703, Eval Loss: 2.3147
Epoch 85 training...
Epoch 85 evaluating...
Epoch [85/100], Train Loss: 0.6377, Eval Loss: 2.1226
Epoch 86 training...
Epoch 86 evaluating...
Epoch [86/100], Train Loss: 0.6190, Eval Loss: 2.1973
Epoch 87 training...
Epoch 87 evaluating...
Epoch [87/100], Train Loss: 0.6070, Eval Loss: 2.3325
Epoch 88 training...
Epoch 88 evaluating...
Epoch [88/100], Train Loss: 0.6284, Eval Loss: 2.1561
Epoch 89 training...
Epoch 89 evaluating...
Epoch [89/100], Train Loss: 0.6090, Eval Loss: 2.1099
Epoch 90 training...
Epoch 90 evaluating...
Epoch [90/100], Train Loss: 0.5985, Eval Loss: 2.1540
Epoch 91 training...
Epoch 91 evaluating...
Epoch [91/100], Train Loss: 0.5803, Eval Loss: 2.0397
Epoch 92 training...
Epoch 92 evaluating...
Epoch [92/100], Train Loss: 0.5961, Eval Loss: 2.1980
Epoch 93 training...
Epoch 93 evaluating...
Epoch [93/100], Train Loss: 0.5954, Eval Loss: 2.2298
Epoch 94 training...
Epoch 94 evaluating...
Epoch [94/100], Train Loss: 0.5997, Eval Loss: 2.1491
Epoch 95 training...
Epoch 95 evaluating...
Epoch [95/100], Train Loss: 0.5912, Eval Loss: 2.0281
Epoch 96 training...
Epoch 96 evaluating...
Epoch [96/100], Train Loss: 0.5824, Eval Loss: 2.0355
Epoch 97 training...
Epoch 97 evaluating...
Epoch [97/100], Train Loss: 0.5701, Eval Loss: 2.0772
Epoch 98 training...
Epoch 98 evaluating...
Epoch [98/100], Train Loss: 0.5499, Eval Loss: 2.1083
Epoch 99 training...
Epoch 99 evaluating...
Epoch [99/100], Train Loss: 0.5403, Eval Loss: 2.2055
Epoch 100 training...
Epoch 100 evaluating...
Epoch [100/100], Train Loss: 0.5724, Eval Loss: 2.0934
Training done, all data saved to "../saved_data/20240130-061945".
