==========================================
SLURM_JOB_ID = 18480117
SLURM_JOB_NODELIST = a02-15
TMPDIR = /tmp/SLURM_18480117
==========================================
Restoring modules from user's default
All data will be output to ./saved_data/20240110-050655
Running on device: CUDA
Objective has been set to ihm
Initializing train set for ihm objective...
Loading dataset to RAM...
Loading from file ./data/mimic3/multitask_preliminary/train/all.pkl, skipping individuals...
Preprocessing dataset...
Computing dataset statistics...
First item in the dataset: 
(tensor([[ 1.0000,  0.0000,  0.1069,  ...,  0.0000,  0.0000,  0.0000],
        [ 1.0000,  0.0000,  0.0802,  ...,  0.0000,  0.0000,  0.0000],
        [ 1.0000,  0.0000,  0.0980,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 1.0000,  0.0000, -0.0583,  ...,  0.1849, -0.2451,  0.0219],
        [ 1.0000,  0.0000, -0.0672,  ...,  0.2056, -0.2451,  0.0219],
        [ 1.0000,  0.0000, -0.0806,  ...,  0.2159, -0.2451,  0.0219]]), tensor(1))
Feature tensor shape: torch.Size([48, 42])
Objective has been set to ihm
Initializing test set for ihm objective...
Loading dataset to RAM...
Loading from file ./data/mimic3/multitask_preliminary/test/all.pkl, skipping individuals...
Preprocessing dataset...
Computing dataset statistics...
First item in the dataset: 
(tensor([[ 1.0000,  0.0000, -0.0538,  ...,  0.0000,  0.0000,  0.0000],
        [ 1.0000,  0.0000, -0.0806,  ..., -0.0698,  0.0000,  0.0000],
        [ 1.0000,  0.0000, -0.0717,  ..., -0.0698,  0.0000, -0.3360],
        ...,
        [ 1.0000,  0.0000, -0.0627,  ..., -0.0698,  0.0000,  0.0823],
        [ 1.0000,  0.0000, -0.0627,  ..., -0.0698,  0.0000,  0.0823],
        [ 1.0000,  0.0000, -0.0627,  ..., -0.0698,  0.0000,  0.0823]]), tensor(1))
Feature tensor shape: torch.Size([48, 42])
Input tensor shape: torch.Size([48, 42])
Initializing synthetic dataset. Number of samples in total = 1
Objective has been set to los
Objective has been set to los
Synthetic feature shape: torch.Size([1, 48, 42])
Synthetic label shape: torch.Size([1])
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Ready for training

Training iteration:   0%|          | 0/1001 [00:00<?, ?it/s]Optimization iteration 0 evaluation begins...
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
A new evaluation visualization has been saved: ./saved_data/20240110-050655/it0.png
Training network 0 for evaluation...
Training network 1 for evaluation...
Training network 2 for evaluation...
Training network 3 for evaluation...
Testing network 0 on real datasets for evaluation...
Testing network 1 on real datasets for evaluation...
Testing network 2 on real datasets for evaluation...
Testing network 3 on real datasets for evaluation...
Optimization iteration 0, eval auroc score (train): 27681.6226, eval auroc score (test): 28827.1973
Checkpoint at iteration 0 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = None
/home1/dingyini/.conda/envs/playground/lib/python3.11/site-packages/torch/nn/utils/clip_grad.py:39: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /opt/conda/conda-bld/pytorch_1695392026823/work/build/aten/src/ATen/core/TensorBody.h:489.)
  grads = [p.grad for p in parameters if p.grad is not None]

Training iteration:   0%|          | 0/1001 [00:45<?, ?it/s, avg loss=172.7294]New best at iteratoin 0!

Training iteration:   0%|          | 1/1001 [00:45<12:45:23, 45.92s/it, avg loss=172.7294]Checkpoint at iteration 1 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 172.72935104370117

Training iteration:   0%|          | 1/1001 [00:46<12:45:23, 45.92s/it, avg loss=191.9162]
Training iteration:   0%|          | 2/1001 [00:46<5:22:19, 19.36s/it, avg loss=191.9162] Checkpoint at iteration 2 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 191.91616668701172

Training iteration:   0%|          | 2/1001 [00:47<5:22:19, 19.36s/it, avg loss=205.3019]
Training iteration:   0%|          | 3/1001 [00:47<3:00:46, 10.87s/it, avg loss=205.3019]Checkpoint at iteration 3 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 205.30190887451172

Training iteration:   0%|          | 3/1001 [00:48<3:00:46, 10.87s/it, avg loss=248.6524]
Training iteration:   0%|          | 4/1001 [00:48<1:54:18,  6.88s/it, avg loss=248.6524]Checkpoint at iteration 4 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 248.65244903564454

Training iteration:   0%|          | 4/1001 [00:48<1:54:18,  6.88s/it, avg loss=228.8372]
Training iteration:   0%|          | 5/1001 [00:48<1:17:35,  4.67s/it, avg loss=228.8372]Checkpoint at iteration 5 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 228.83716354370117

Training iteration:   0%|          | 5/1001 [00:49<1:17:35,  4.67s/it, avg loss=252.0668]
Training iteration:   1%|          | 6/1001 [00:49<55:27,  3.34s/it, avg loss=252.0668]  Checkpoint at iteration 6 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 252.06683425903321

Training iteration:   1%|          | 6/1001 [00:50<55:27,  3.34s/it, avg loss=251.5549]
Training iteration:   1%|          | 7/1001 [00:50<41:25,  2.50s/it, avg loss=251.5549]Checkpoint at iteration 7 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 251.5548843383789

Training iteration:   1%|          | 7/1001 [00:51<41:25,  2.50s/it, avg loss=230.9667]
Training iteration:   1%|          | 8/1001 [00:51<32:12,  1.95s/it, avg loss=230.9667]Checkpoint at iteration 8 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 230.9667205810547

Training iteration:   1%|          | 8/1001 [00:52<32:12,  1.95s/it, avg loss=266.5036]
Training iteration:   1%|          | 9/1001 [00:52<26:03,  1.58s/it, avg loss=266.5036]Checkpoint at iteration 9 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 266.5036224365234

Training iteration:   1%|          | 9/1001 [00:52<26:03,  1.58s/it, avg loss=264.0245]
Training iteration:   1%|          | 10/1001 [00:52<21:53,  1.33s/it, avg loss=264.0245]Checkpoint at iteration 10 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 264.0244766235352

Training iteration:   1%|          | 10/1001 [00:53<21:53,  1.33s/it, avg loss=266.7262]
Training iteration:   1%|          | 11/1001 [00:53<19:01,  1.15s/it, avg loss=266.7262]Checkpoint at iteration 11 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 266.7261901855469

Training iteration:   1%|          | 11/1001 [00:54<19:01,  1.15s/it, avg loss=204.7308]
Training iteration:   1%|          | 12/1001 [00:54<17:03,  1.03s/it, avg loss=204.7308]Checkpoint at iteration 12 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 204.73083038330077

Training iteration:   1%|          | 12/1001 [00:55<17:03,  1.03s/it, avg loss=203.5553]
Training iteration:   1%|▏         | 13/1001 [00:55<15:40,  1.05it/s, avg loss=203.5553]Checkpoint at iteration 13 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 203.55531463623046

Training iteration:   1%|▏         | 13/1001 [00:55<15:40,  1.05it/s, avg loss=196.1530]
Training iteration:   1%|▏         | 14/1001 [00:55<14:43,  1.12it/s, avg loss=196.1530]Checkpoint at iteration 14 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 196.1529510498047

Training iteration:   1%|▏         | 14/1001 [00:56<14:43,  1.12it/s, avg loss=152.7986]New best at iteratoin 14!

Training iteration:   1%|▏         | 15/1001 [00:56<14:03,  1.17it/s, avg loss=152.7986]Checkpoint at iteration 15 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 152.7986083984375

Training iteration:   1%|▏         | 15/1001 [00:57<14:03,  1.17it/s, avg loss=249.7056]
Training iteration:   2%|▏         | 16/1001 [00:57<13:35,  1.21it/s, avg loss=249.7056]Checkpoint at iteration 16 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 249.7056411743164

Training iteration:   2%|▏         | 16/1001 [00:58<13:35,  1.21it/s, avg loss=287.1933]
Training iteration:   2%|▏         | 17/1001 [00:58<13:15,  1.24it/s, avg loss=287.1933]Checkpoint at iteration 17 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 287.19333419799807

Training iteration:   2%|▏         | 17/1001 [00:58<13:15,  1.24it/s, avg loss=154.2643]
Training iteration:   2%|▏         | 18/1001 [00:58<13:02,  1.26it/s, avg loss=154.2643]Checkpoint at iteration 18 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 154.26428604125977

Training iteration:   2%|▏         | 18/1001 [00:59<13:02,  1.26it/s, avg loss=132.9786]New best at iteratoin 18!

Training iteration:   2%|▏         | 19/1001 [00:59<12:52,  1.27it/s, avg loss=132.9786]Checkpoint at iteration 19 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 132.97855224609376

Training iteration:   2%|▏         | 19/1001 [01:00<12:52,  1.27it/s, avg loss=113.8546]New best at iteratoin 19!

Training iteration:   2%|▏         | 20/1001 [01:00<12:44,  1.28it/s, avg loss=113.8546]Checkpoint at iteration 20 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 113.854638671875

Training iteration:   2%|▏         | 20/1001 [01:01<12:44,  1.28it/s, avg loss=140.9547]
Training iteration:   2%|▏         | 21/1001 [01:01<12:38,  1.29it/s, avg loss=140.9547]Checkpoint at iteration 21 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 140.95469436645507

Training iteration:   2%|▏         | 21/1001 [01:01<12:38,  1.29it/s, avg loss=254.6475]
Training iteration:   2%|▏         | 22/1001 [01:01<12:29,  1.31it/s, avg loss=254.6475]Checkpoint at iteration 22 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 254.64746551513673

Training iteration:   2%|▏         | 22/1001 [01:02<12:29,  1.31it/s, avg loss=112.5504]New best at iteratoin 22!

Training iteration:   2%|▏         | 23/1001 [01:02<12:11,  1.34it/s, avg loss=112.5504]Checkpoint at iteration 23 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 112.5503761291504

Training iteration:   2%|▏         | 23/1001 [01:03<12:11,  1.34it/s, avg loss=253.4118]
Training iteration:   2%|▏         | 24/1001 [01:03<11:57,  1.36it/s, avg loss=253.4118]Checkpoint at iteration 24 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 253.41177978515626

Training iteration:   2%|▏         | 24/1001 [01:04<11:57,  1.36it/s, avg loss=183.5910]
Training iteration:   2%|▏         | 25/1001 [01:04<11:47,  1.38it/s, avg loss=183.5910]Checkpoint at iteration 25 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 183.59097900390626

Training iteration:   2%|▏         | 25/1001 [01:04<11:47,  1.38it/s, avg loss=111.8644]New best at iteratoin 25!

Training iteration:   3%|▎         | 26/1001 [01:04<11:40,  1.39it/s, avg loss=111.8644]Checkpoint at iteration 26 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 111.86440582275391

Training iteration:   3%|▎         | 26/1001 [01:05<11:40,  1.39it/s, avg loss=286.5540]
Training iteration:   3%|▎         | 27/1001 [01:05<11:35,  1.40it/s, avg loss=286.5540]Checkpoint at iteration 27 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 286.5540489196777

Training iteration:   3%|▎         | 27/1001 [01:06<11:35,  1.40it/s, avg loss=118.7727]
Training iteration:   3%|▎         | 28/1001 [01:06<11:31,  1.41it/s, avg loss=118.7727]Checkpoint at iteration 28 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 118.77268676757812

Training iteration:   3%|▎         | 28/1001 [01:06<11:31,  1.41it/s, avg loss=298.8271]
Training iteration:   3%|▎         | 29/1001 [01:06<11:28,  1.41it/s, avg loss=298.8271]Checkpoint at iteration 29 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 298.8270622253418

Training iteration:   3%|▎         | 29/1001 [01:07<11:28,  1.41it/s, avg loss=138.4114]
Training iteration:   3%|▎         | 30/1001 [01:07<11:27,  1.41it/s, avg loss=138.4114]Checkpoint at iteration 30 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 138.41135787963867

Training iteration:   3%|▎         | 30/1001 [01:08<11:27,  1.41it/s, avg loss=300.9463]
Training iteration:   3%|▎         | 31/1001 [01:08<11:25,  1.41it/s, avg loss=300.9463]Checkpoint at iteration 31 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 300.9463195800781

Training iteration:   3%|▎         | 31/1001 [01:08<11:25,  1.41it/s, avg loss=113.7826]
Training iteration:   3%|▎         | 32/1001 [01:08<11:24,  1.42it/s, avg loss=113.7826]Checkpoint at iteration 32 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 113.78261184692383

Training iteration:   3%|▎         | 32/1001 [01:09<11:24,  1.42it/s, avg loss=290.8843]
Training iteration:   3%|▎         | 33/1001 [01:09<11:22,  1.42it/s, avg loss=290.8843]Checkpoint at iteration 33 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 290.88426818847654

Training iteration:   3%|▎         | 33/1001 [01:10<11:22,  1.42it/s, avg loss=228.6772]
Training iteration:   3%|▎         | 34/1001 [01:10<11:21,  1.42it/s, avg loss=228.6772]Checkpoint at iteration 34 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 228.6772262573242

Training iteration:   3%|▎         | 34/1001 [01:11<11:21,  1.42it/s, avg loss=290.9955]
Training iteration:   3%|▎         | 35/1001 [01:11<11:20,  1.42it/s, avg loss=290.9955]Checkpoint at iteration 35 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 290.99547424316404

Training iteration:   3%|▎         | 35/1001 [01:11<11:20,  1.42it/s, avg loss=276.6717]
Training iteration:   4%|▎         | 36/1001 [01:11<11:19,  1.42it/s, avg loss=276.6717]Checkpoint at iteration 36 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 276.671728515625

Training iteration:   4%|▎         | 36/1001 [01:12<11:19,  1.42it/s, avg loss=207.8338]
Training iteration:   4%|▎         | 37/1001 [01:12<11:19,  1.42it/s, avg loss=207.8338]Checkpoint at iteration 37 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 207.83376235961913

Training iteration:   4%|▎         | 37/1001 [01:13<11:19,  1.42it/s, avg loss=218.0234]
Training iteration:   4%|▍         | 38/1001 [01:13<11:18,  1.42it/s, avg loss=218.0234]Checkpoint at iteration 38 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 218.0234375

Training iteration:   4%|▍         | 38/1001 [01:13<11:18,  1.42it/s, avg loss=138.7266]
Training iteration:   4%|▍         | 39/1001 [01:13<11:17,  1.42it/s, avg loss=138.7266]Checkpoint at iteration 39 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 138.72661590576172

Training iteration:   4%|▍         | 39/1001 [01:14<11:17,  1.42it/s, avg loss=110.4108]New best at iteratoin 39!

Training iteration:   4%|▍         | 40/1001 [01:14<11:17,  1.42it/s, avg loss=110.4108]Checkpoint at iteration 40 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 110.41080627441406

Training iteration:   4%|▍         | 40/1001 [01:15<11:17,  1.42it/s, avg loss=308.4619]
Training iteration:   4%|▍         | 41/1001 [01:15<11:17,  1.42it/s, avg loss=308.4619]Checkpoint at iteration 41 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 308.46192321777346

Training iteration:   4%|▍         | 41/1001 [01:16<11:17,  1.42it/s, avg loss=118.6245]
Training iteration:   4%|▍         | 42/1001 [01:16<11:16,  1.42it/s, avg loss=118.6245]Checkpoint at iteration 42 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 118.62452621459961

Training iteration:   4%|▍         | 42/1001 [01:16<11:16,  1.42it/s, avg loss=115.3483]
Training iteration:   4%|▍         | 43/1001 [01:16<11:16,  1.42it/s, avg loss=115.3483]Checkpoint at iteration 43 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 115.34830932617187

Training iteration:   4%|▍         | 43/1001 [01:17<11:16,  1.42it/s, avg loss=110.8156]
Training iteration:   4%|▍         | 44/1001 [01:17<11:16,  1.42it/s, avg loss=110.8156]Checkpoint at iteration 44 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 110.81560974121093

Training iteration:   4%|▍         | 44/1001 [01:18<11:16,  1.42it/s, avg loss=115.5566]
Training iteration:   4%|▍         | 45/1001 [01:18<11:15,  1.42it/s, avg loss=115.5566]Checkpoint at iteration 45 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 115.5566390991211

Training iteration:   4%|▍         | 45/1001 [01:18<11:15,  1.42it/s, avg loss=113.9705]
Training iteration:   5%|▍         | 46/1001 [01:18<11:14,  1.42it/s, avg loss=113.9705]Checkpoint at iteration 46 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 113.97049255371094

Training iteration:   5%|▍         | 46/1001 [01:19<11:14,  1.42it/s, avg loss=184.2064]
Training iteration:   5%|▍         | 47/1001 [01:19<11:13,  1.42it/s, avg loss=184.2064]Checkpoint at iteration 47 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 184.20640182495117

Training iteration:   5%|▍         | 47/1001 [01:20<11:13,  1.42it/s, avg loss=315.8778]
Training iteration:   5%|▍         | 48/1001 [01:20<11:13,  1.42it/s, avg loss=315.8778]Checkpoint at iteration 48 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 315.87781677246096

Training iteration:   5%|▍         | 48/1001 [01:20<11:13,  1.42it/s, avg loss=320.2337]
Training iteration:   5%|▍         | 49/1001 [01:20<11:12,  1.42it/s, avg loss=320.2337]Checkpoint at iteration 49 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 320.23366088867186

Training iteration:   5%|▍         | 49/1001 [01:21<11:12,  1.42it/s, avg loss=318.1429]
Training iteration:   5%|▍         | 50/1001 [01:21<11:11,  1.42it/s, avg loss=318.1429]Checkpoint at iteration 50 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 318.14290618896484

Training iteration:   5%|▍         | 50/1001 [01:22<11:11,  1.42it/s, avg loss=108.5360]New best at iteratoin 50!

Training iteration:   5%|▌         | 51/1001 [01:22<11:10,  1.42it/s, avg loss=108.5360]Checkpoint at iteration 51 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 108.53600006103515

Training iteration:   5%|▌         | 51/1001 [01:23<11:10,  1.42it/s, avg loss=316.4553]
Training iteration:   5%|▌         | 52/1001 [01:23<11:10,  1.42it/s, avg loss=316.4553]Checkpoint at iteration 52 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 316.45525817871095

Training iteration:   5%|▌         | 52/1001 [01:23<11:10,  1.42it/s, avg loss=315.1954]
Training iteration:   5%|▌         | 53/1001 [01:23<11:09,  1.42it/s, avg loss=315.1954]Checkpoint at iteration 53 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 315.195378112793

Training iteration:   5%|▌         | 53/1001 [01:24<11:09,  1.42it/s, avg loss=111.8418]
Training iteration:   5%|▌         | 54/1001 [01:24<11:08,  1.42it/s, avg loss=111.8418]Checkpoint at iteration 54 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 111.84183731079102

Training iteration:   5%|▌         | 54/1001 [01:25<11:08,  1.42it/s, avg loss=318.2580]
Training iteration:   5%|▌         | 55/1001 [01:25<11:08,  1.41it/s, avg loss=318.2580]Checkpoint at iteration 55 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 318.2580001831055

Training iteration:   5%|▌         | 55/1001 [01:25<11:08,  1.41it/s, avg loss=119.2013]
Training iteration:   6%|▌         | 56/1001 [01:25<11:08,  1.41it/s, avg loss=119.2013]Checkpoint at iteration 56 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 119.20133056640626

Training iteration:   6%|▌         | 56/1001 [01:26<11:08,  1.41it/s, avg loss=319.5611]
Training iteration:   6%|▌         | 57/1001 [01:26<11:08,  1.41it/s, avg loss=319.5611]Checkpoint at iteration 57 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 319.56109313964845

Training iteration:   6%|▌         | 57/1001 [01:27<11:08,  1.41it/s, avg loss=314.1748]
Training iteration:   6%|▌         | 58/1001 [01:27<11:07,  1.41it/s, avg loss=314.1748]Checkpoint at iteration 58 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 314.1748336791992

Training iteration:   6%|▌         | 58/1001 [01:28<11:07,  1.41it/s, avg loss=309.0697]
Training iteration:   6%|▌         | 59/1001 [01:28<11:06,  1.41it/s, avg loss=309.0697]Checkpoint at iteration 59 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 309.06969146728517

Training iteration:   6%|▌         | 59/1001 [01:28<11:06,  1.41it/s, avg loss=302.6570]
Training iteration:   6%|▌         | 60/1001 [01:28<11:05,  1.41it/s, avg loss=302.6570]Checkpoint at iteration 60 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 302.6569763183594

Training iteration:   6%|▌         | 60/1001 [01:29<11:05,  1.41it/s, avg loss=273.0179]
Training iteration:   6%|▌         | 61/1001 [01:29<11:04,  1.41it/s, avg loss=273.0179]Checkpoint at iteration 61 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 273.0179275512695

Training iteration:   6%|▌         | 61/1001 [01:30<11:04,  1.41it/s, avg loss=244.7837]
Training iteration:   6%|▌         | 62/1001 [01:30<11:03,  1.41it/s, avg loss=244.7837]Checkpoint at iteration 62 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 244.7837371826172

Training iteration:   6%|▌         | 62/1001 [01:30<11:03,  1.41it/s, avg loss=133.1542]
Training iteration:   6%|▋         | 63/1001 [01:30<11:03,  1.41it/s, avg loss=133.1542]Checkpoint at iteration 63 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 133.15421142578126

Training iteration:   6%|▋         | 63/1001 [01:31<11:03,  1.41it/s, avg loss=252.2082]
Training iteration:   6%|▋         | 64/1001 [01:31<11:02,  1.41it/s, avg loss=252.2082]Checkpoint at iteration 64 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 252.20821990966797

Training iteration:   6%|▋         | 64/1001 [01:32<11:02,  1.41it/s, avg loss=255.2717]
Training iteration:   6%|▋         | 65/1001 [01:32<11:01,  1.42it/s, avg loss=255.2717]Checkpoint at iteration 65 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 255.27171173095704

Training iteration:   6%|▋         | 65/1001 [01:32<11:01,  1.42it/s, avg loss=237.8083]
Training iteration:   7%|▋         | 66/1001 [01:32<11:00,  1.42it/s, avg loss=237.8083]Checkpoint at iteration 66 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 237.8082733154297

Training iteration:   7%|▋         | 66/1001 [01:33<11:00,  1.42it/s, avg loss=240.8962]
Training iteration:   7%|▋         | 67/1001 [01:33<11:00,  1.41it/s, avg loss=240.8962]Checkpoint at iteration 67 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 240.8961624145508

Training iteration:   7%|▋         | 67/1001 [01:34<11:00,  1.41it/s, avg loss=240.6877]
Training iteration:   7%|▋         | 68/1001 [01:34<10:59,  1.41it/s, avg loss=240.6877]Checkpoint at iteration 68 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 240.6877471923828

Training iteration:   7%|▋         | 68/1001 [01:35<10:59,  1.41it/s, avg loss=156.5572]
Training iteration:   7%|▋         | 69/1001 [01:35<10:58,  1.41it/s, avg loss=156.5572]Checkpoint at iteration 69 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 156.55724639892577

Training iteration:   7%|▋         | 69/1001 [01:35<10:58,  1.41it/s, avg loss=247.9883]
Training iteration:   7%|▋         | 70/1001 [01:35<10:58,  1.41it/s, avg loss=247.9883]Checkpoint at iteration 70 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 247.98833618164062

Training iteration:   7%|▋         | 70/1001 [01:36<10:58,  1.41it/s, avg loss=250.0055]
Training iteration:   7%|▋         | 71/1001 [01:36<10:59,  1.41it/s, avg loss=250.0055]Checkpoint at iteration 71 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 250.00545654296874

Training iteration:   7%|▋         | 71/1001 [01:37<10:59,  1.41it/s, avg loss=271.1450]
Training iteration:   7%|▋         | 72/1001 [01:37<10:57,  1.41it/s, avg loss=271.1450]Checkpoint at iteration 72 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 271.14503173828126

Training iteration:   7%|▋         | 72/1001 [01:37<10:57,  1.41it/s, avg loss=156.5174]
Training iteration:   7%|▋         | 73/1001 [01:37<10:56,  1.41it/s, avg loss=156.5174]Checkpoint at iteration 73 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 156.51740570068358

Training iteration:   7%|▋         | 73/1001 [01:38<10:56,  1.41it/s, avg loss=268.3086]
Training iteration:   7%|▋         | 74/1001 [01:38<10:55,  1.41it/s, avg loss=268.3086]Checkpoint at iteration 74 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 268.3085601806641

Training iteration:   7%|▋         | 74/1001 [01:39<10:55,  1.41it/s, avg loss=150.1724]
Training iteration:   7%|▋         | 75/1001 [01:39<10:54,  1.42it/s, avg loss=150.1724]Checkpoint at iteration 75 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 150.17241668701172

Training iteration:   7%|▋         | 75/1001 [01:40<10:54,  1.42it/s, avg loss=146.6482]
Training iteration:   8%|▊         | 76/1001 [01:40<10:53,  1.42it/s, avg loss=146.6482]Checkpoint at iteration 76 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 146.64818572998047

Training iteration:   8%|▊         | 76/1001 [01:40<10:53,  1.42it/s, avg loss=152.5543]
Training iteration:   8%|▊         | 77/1001 [01:40<10:52,  1.42it/s, avg loss=152.5543]Checkpoint at iteration 77 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 152.55428161621094

Training iteration:   8%|▊         | 77/1001 [01:41<10:52,  1.42it/s, avg loss=259.2600]
Training iteration:   8%|▊         | 78/1001 [01:41<10:51,  1.42it/s, avg loss=259.2600]Checkpoint at iteration 78 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 259.2599838256836

Training iteration:   8%|▊         | 78/1001 [01:42<10:51,  1.42it/s, avg loss=264.6679]
Training iteration:   8%|▊         | 79/1001 [01:42<10:51,  1.42it/s, avg loss=264.6679]Checkpoint at iteration 79 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 264.66790466308595

Training iteration:   8%|▊         | 79/1001 [01:42<10:51,  1.42it/s, avg loss=149.2342]
Training iteration:   8%|▊         | 80/1001 [01:42<10:50,  1.42it/s, avg loss=149.2342]Checkpoint at iteration 80 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 149.23424072265624

Training iteration:   8%|▊         | 80/1001 [01:43<10:50,  1.42it/s, avg loss=276.0215]
Training iteration:   8%|▊         | 81/1001 [01:43<10:50,  1.42it/s, avg loss=276.0215]Checkpoint at iteration 81 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 276.0215087890625

Training iteration:   8%|▊         | 81/1001 [01:44<10:50,  1.42it/s, avg loss=148.5348]
Training iteration:   8%|▊         | 82/1001 [01:44<10:49,  1.42it/s, avg loss=148.5348]Checkpoint at iteration 82 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 148.53480834960936

Training iteration:   8%|▊         | 82/1001 [01:45<10:49,  1.42it/s, avg loss=254.7631]
Training iteration:   8%|▊         | 83/1001 [01:45<10:48,  1.42it/s, avg loss=254.7631]Checkpoint at iteration 83 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 254.7631408691406

Training iteration:   8%|▊         | 83/1001 [01:45<10:48,  1.42it/s, avg loss=158.4806]
Training iteration:   8%|▊         | 84/1001 [01:45<10:47,  1.42it/s, avg loss=158.4806]Checkpoint at iteration 84 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 158.4806365966797

Training iteration:   8%|▊         | 84/1001 [01:46<10:47,  1.42it/s, avg loss=142.5068]
Training iteration:   8%|▊         | 85/1001 [01:46<10:47,  1.42it/s, avg loss=142.5068]Checkpoint at iteration 85 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 142.50675506591796

Training iteration:   8%|▊         | 85/1001 [01:47<10:47,  1.42it/s, avg loss=146.4114]
Training iteration:   9%|▊         | 86/1001 [01:47<10:46,  1.42it/s, avg loss=146.4114]Checkpoint at iteration 86 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 146.41138610839843

Training iteration:   9%|▊         | 86/1001 [01:47<10:46,  1.42it/s, avg loss=145.5376]
Training iteration:   9%|▊         | 87/1001 [01:47<10:45,  1.42it/s, avg loss=145.5376]Checkpoint at iteration 87 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 145.53759155273437

Training iteration:   9%|▊         | 87/1001 [01:48<10:45,  1.42it/s, avg loss=296.2878]
Training iteration:   9%|▉         | 88/1001 [01:48<10:44,  1.42it/s, avg loss=296.2878]Checkpoint at iteration 88 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 296.28779754638674

Training iteration:   9%|▉         | 88/1001 [01:49<10:44,  1.42it/s, avg loss=144.8594]
Training iteration:   9%|▉         | 89/1001 [01:49<10:44,  1.42it/s, avg loss=144.8594]Checkpoint at iteration 89 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 144.85936737060547

Training iteration:   9%|▉         | 89/1001 [01:49<10:44,  1.42it/s, avg loss=139.8302]
Training iteration:   9%|▉         | 90/1001 [01:49<10:43,  1.42it/s, avg loss=139.8302]Checkpoint at iteration 90 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 139.83020477294923

Training iteration:   9%|▉         | 90/1001 [01:50<10:43,  1.42it/s, avg loss=295.2183]
Training iteration:   9%|▉         | 91/1001 [01:50<10:42,  1.42it/s, avg loss=295.2183]Checkpoint at iteration 91 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 295.2182952880859

Training iteration:   9%|▉         | 91/1001 [01:51<10:42,  1.42it/s, avg loss=144.9557]
Training iteration:   9%|▉         | 92/1001 [01:51<10:41,  1.42it/s, avg loss=144.9557]Checkpoint at iteration 92 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 144.95572204589843

Training iteration:   9%|▉         | 92/1001 [01:52<10:41,  1.42it/s, avg loss=288.9999]
Training iteration:   9%|▉         | 93/1001 [01:52<10:41,  1.42it/s, avg loss=288.9999]Checkpoint at iteration 93 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 288.9998519897461

Training iteration:   9%|▉         | 93/1001 [01:52<10:41,  1.42it/s, avg loss=279.9266]
Training iteration:   9%|▉         | 94/1001 [01:52<10:40,  1.42it/s, avg loss=279.9266]Checkpoint at iteration 94 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 279.9266357421875

Training iteration:   9%|▉         | 94/1001 [01:53<10:40,  1.42it/s, avg loss=156.9262]
Training iteration:   9%|▉         | 95/1001 [01:53<10:39,  1.42it/s, avg loss=156.9262]Checkpoint at iteration 95 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 156.92620239257812

Training iteration:   9%|▉         | 95/1001 [01:54<10:39,  1.42it/s, avg loss=132.0490]
Training iteration:  10%|▉         | 96/1001 [01:54<10:38,  1.42it/s, avg loss=132.0490]Checkpoint at iteration 96 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 132.04904022216797

Training iteration:  10%|▉         | 96/1001 [01:54<10:38,  1.42it/s, avg loss=132.2573]
Training iteration:  10%|▉         | 97/1001 [01:54<10:38,  1.42it/s, avg loss=132.2573]Checkpoint at iteration 97 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 132.25730056762694

Training iteration:  10%|▉         | 97/1001 [01:55<10:38,  1.42it/s, avg loss=129.2713]
Training iteration:  10%|▉         | 98/1001 [01:55<10:37,  1.42it/s, avg loss=129.2713]Checkpoint at iteration 98 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 129.2712631225586

Training iteration:  10%|▉         | 98/1001 [01:56<10:37,  1.42it/s, avg loss=129.7400]
Training iteration:  10%|▉         | 99/1001 [01:56<10:36,  1.42it/s, avg loss=129.7400]Checkpoint at iteration 99 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 129.73999557495117

Training iteration:  10%|▉         | 99/1001 [01:57<10:36,  1.42it/s, avg loss=307.5538]
Training iteration:  10%|▉         | 100/1001 [01:57<10:35,  1.42it/s, avg loss=307.5538]Optimization iteration 100 evaluation begins...
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
A new evaluation visualization has been saved: ./saved_data/20240110-050655/it100.png
Training network 0 for evaluation...
Training network 1 for evaluation...
Training network 2 for evaluation...
Training network 3 for evaluation...
Testing network 0 on real datasets for evaluation...
Testing network 1 on real datasets for evaluation...
Testing network 2 on real datasets for evaluation...
Testing network 3 on real datasets for evaluation...
Optimization iteration 100, eval auroc score (train): 28972.6637, eval auroc score (test): 30270.7189
Checkpoint at iteration 100 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 307.5537933349609

Training iteration:  10%|▉         | 100/1001 [02:39<10:35,  1.42it/s, avg loss=308.1835]
Training iteration:  10%|█         | 101/1001 [02:39<3:17:40, 13.18s/it, avg loss=308.1835]Checkpoint at iteration 101 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 308.1835021972656

Training iteration:  10%|█         | 101/1001 [02:40<3:17:40, 13.18s/it, avg loss=123.1107]
Training iteration:  10%|█         | 102/1001 [02:40<2:22:16,  9.50s/it, avg loss=123.1107]Checkpoint at iteration 102 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 123.1106674194336

Training iteration:  10%|█         | 102/1001 [02:41<2:22:16,  9.50s/it, avg loss=214.6342]
Training iteration:  10%|█         | 103/1001 [02:41<1:43:31,  6.92s/it, avg loss=214.6342]Checkpoint at iteration 103 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 214.6341552734375

Training iteration:  10%|█         | 103/1001 [02:41<1:43:31,  6.92s/it, avg loss=129.4172]
Training iteration:  10%|█         | 104/1001 [02:41<1:16:25,  5.11s/it, avg loss=129.4172]Checkpoint at iteration 104 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 129.41722869873047

Training iteration:  10%|█         | 104/1001 [02:42<1:16:25,  5.11s/it, avg loss=128.0723]
Training iteration:  10%|█         | 105/1001 [02:42<57:28,  3.85s/it, avg loss=128.0723]  Checkpoint at iteration 105 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 128.07232284545898

Training iteration:  10%|█         | 105/1001 [02:43<57:28,  3.85s/it, avg loss=303.0191]
Training iteration:  11%|█         | 106/1001 [02:43<44:12,  2.96s/it, avg loss=303.0191]Checkpoint at iteration 106 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 303.0191360473633

Training iteration:  11%|█         | 106/1001 [02:44<44:12,  2.96s/it, avg loss=130.3310]
Training iteration:  11%|█         | 107/1001 [02:44<34:55,  2.34s/it, avg loss=130.3310]Checkpoint at iteration 107 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 130.3310119628906

Training iteration:  11%|█         | 107/1001 [02:45<34:55,  2.34s/it, avg loss=304.7510]
Training iteration:  11%|█         | 108/1001 [02:45<28:26,  1.91s/it, avg loss=304.7510]Checkpoint at iteration 108 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 304.75101165771486

Training iteration:  11%|█         | 108/1001 [02:46<28:26,  1.91s/it, avg loss=302.8068]
Training iteration:  11%|█         | 109/1001 [02:46<23:53,  1.61s/it, avg loss=302.8068]Checkpoint at iteration 109 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 302.80679779052736

Training iteration:  11%|█         | 109/1001 [02:47<23:53,  1.61s/it, avg loss=123.2800]
Training iteration:  11%|█         | 110/1001 [02:47<20:42,  1.39s/it, avg loss=123.2800]Checkpoint at iteration 110 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 123.28001174926757

Training iteration:  11%|█         | 110/1001 [02:48<20:42,  1.39s/it, avg loss=127.2319]
Training iteration:  11%|█         | 111/1001 [02:48<18:28,  1.25s/it, avg loss=127.2319]Checkpoint at iteration 111 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 127.23188552856445

Training iteration:  11%|█         | 111/1001 [02:49<18:28,  1.25s/it, avg loss=123.2844]
Training iteration:  11%|█         | 112/1001 [02:49<16:55,  1.14s/it, avg loss=123.2844]Checkpoint at iteration 112 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 123.28442459106445

Training iteration:  11%|█         | 112/1001 [02:50<16:55,  1.14s/it, avg loss=126.5414]
Training iteration:  11%|█▏        | 113/1001 [02:50<15:49,  1.07s/it, avg loss=126.5414]Checkpoint at iteration 113 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 126.54144897460938

Training iteration:  11%|█▏        | 113/1001 [02:50<15:49,  1.07s/it, avg loss=305.7739]
Training iteration:  11%|█▏        | 114/1001 [02:50<15:02,  1.02s/it, avg loss=305.7739]Checkpoint at iteration 114 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 305.7738754272461

Training iteration:  11%|█▏        | 114/1001 [02:51<15:02,  1.02s/it, avg loss=304.4458]
Training iteration:  11%|█▏        | 115/1001 [02:51<14:30,  1.02it/s, avg loss=304.4458]Checkpoint at iteration 115 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 304.4457580566406

Training iteration:  11%|█▏        | 115/1001 [02:52<14:30,  1.02it/s, avg loss=125.7925]
Training iteration:  12%|█▏        | 116/1001 [02:52<14:07,  1.04it/s, avg loss=125.7925]Checkpoint at iteration 116 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 125.79251251220703

Training iteration:  12%|█▏        | 116/1001 [02:53<14:07,  1.04it/s, avg loss=304.1028]
Training iteration:  12%|█▏        | 117/1001 [02:53<13:50,  1.06it/s, avg loss=304.1028]Checkpoint at iteration 117 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 304.1028121948242

Training iteration:  12%|█▏        | 117/1001 [02:54<13:50,  1.06it/s, avg loss=129.8657]
Training iteration:  12%|█▏        | 118/1001 [02:54<13:39,  1.08it/s, avg loss=129.8657]Checkpoint at iteration 118 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 129.8656867980957

Training iteration:  12%|█▏        | 118/1001 [02:55<13:39,  1.08it/s, avg loss=303.5167]
Training iteration:  12%|█▏        | 119/1001 [02:55<13:30,  1.09it/s, avg loss=303.5167]Checkpoint at iteration 119 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 303.516650390625

Training iteration:  12%|█▏        | 119/1001 [02:56<13:30,  1.09it/s, avg loss=119.2515]
Training iteration:  12%|█▏        | 120/1001 [02:56<13:24,  1.10it/s, avg loss=119.2515]Checkpoint at iteration 120 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 119.25146865844727

Training iteration:  12%|█▏        | 120/1001 [02:57<13:24,  1.10it/s, avg loss=133.2827]
Training iteration:  12%|█▏        | 121/1001 [02:57<13:19,  1.10it/s, avg loss=133.2827]Checkpoint at iteration 121 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 133.28265380859375

Training iteration:  12%|█▏        | 121/1001 [02:58<13:19,  1.10it/s, avg loss=124.2415]
Training iteration:  12%|█▏        | 122/1001 [02:58<13:16,  1.10it/s, avg loss=124.2415]Checkpoint at iteration 122 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 124.24146423339843

Training iteration:  12%|█▏        | 122/1001 [02:59<13:16,  1.10it/s, avg loss=302.9792]
Training iteration:  12%|█▏        | 123/1001 [02:59<13:14,  1.11it/s, avg loss=302.9792]Checkpoint at iteration 123 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 302.979248046875

Training iteration:  12%|█▏        | 123/1001 [02:59<13:14,  1.11it/s, avg loss=304.0191]
Training iteration:  12%|█▏        | 124/1001 [02:59<13:12,  1.11it/s, avg loss=304.0191]Checkpoint at iteration 124 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 304.0191177368164

Training iteration:  12%|█▏        | 124/1001 [03:00<13:12,  1.11it/s, avg loss=116.3552]
Training iteration:  12%|█▏        | 125/1001 [03:00<13:10,  1.11it/s, avg loss=116.3552]Checkpoint at iteration 125 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 116.35516586303712

Training iteration:  12%|█▏        | 125/1001 [03:01<13:10,  1.11it/s, avg loss=304.3941]
Training iteration:  13%|█▎        | 126/1001 [03:01<13:08,  1.11it/s, avg loss=304.3941]Checkpoint at iteration 126 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 304.39413299560545

Training iteration:  13%|█▎        | 126/1001 [03:02<13:08,  1.11it/s, avg loss=125.6278]
Training iteration:  13%|█▎        | 127/1001 [03:02<13:07,  1.11it/s, avg loss=125.6278]Checkpoint at iteration 127 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 125.6278091430664

Training iteration:  13%|█▎        | 127/1001 [03:03<13:07,  1.11it/s, avg loss=303.7084]
Training iteration:  13%|█▎        | 128/1001 [03:03<13:06,  1.11it/s, avg loss=303.7084]Checkpoint at iteration 128 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 303.70836639404297

Training iteration:  13%|█▎        | 128/1001 [03:04<13:06,  1.11it/s, avg loss=131.1718]
Training iteration:  13%|█▎        | 129/1001 [03:04<13:05,  1.11it/s, avg loss=131.1718]Checkpoint at iteration 129 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 131.17181854248048

Training iteration:  13%|█▎        | 129/1001 [03:05<13:05,  1.11it/s, avg loss=303.7624]
Training iteration:  13%|█▎        | 130/1001 [03:05<13:04,  1.11it/s, avg loss=303.7624]Checkpoint at iteration 130 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 303.76238403320315

Training iteration:  13%|█▎        | 130/1001 [03:06<13:04,  1.11it/s, avg loss=127.7582]
Training iteration:  13%|█▎        | 131/1001 [03:06<13:03,  1.11it/s, avg loss=127.7582]Checkpoint at iteration 131 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 127.75819625854493

Training iteration:  13%|█▎        | 131/1001 [03:07<13:03,  1.11it/s, avg loss=304.5152]
Training iteration:  13%|█▎        | 132/1001 [03:07<13:02,  1.11it/s, avg loss=304.5152]Checkpoint at iteration 132 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 304.51516876220705

Training iteration:  13%|█▎        | 132/1001 [03:08<13:02,  1.11it/s, avg loss=128.4627]
Training iteration:  13%|█▎        | 133/1001 [03:08<13:00,  1.11it/s, avg loss=128.4627]Checkpoint at iteration 133 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 128.46272354125978

Training iteration:  13%|█▎        | 133/1001 [03:08<13:00,  1.11it/s, avg loss=313.4010]
Training iteration:  13%|█▎        | 134/1001 [03:08<12:59,  1.11it/s, avg loss=313.4010]Checkpoint at iteration 134 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 313.4010269165039

Training iteration:  13%|█▎        | 134/1001 [03:09<12:59,  1.11it/s, avg loss=310.8762]
Training iteration:  13%|█▎        | 135/1001 [03:09<12:59,  1.11it/s, avg loss=310.8762]Checkpoint at iteration 135 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 310.8761688232422

Training iteration:  13%|█▎        | 135/1001 [03:10<12:59,  1.11it/s, avg loss=126.5066]
Training iteration:  14%|█▎        | 136/1001 [03:10<12:58,  1.11it/s, avg loss=126.5066]Checkpoint at iteration 136 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 126.50662460327149

Training iteration:  14%|█▎        | 136/1001 [03:11<12:58,  1.11it/s, avg loss=311.5235]
Training iteration:  14%|█▎        | 137/1001 [03:11<12:57,  1.11it/s, avg loss=311.5235]Checkpoint at iteration 137 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 311.5235336303711

Training iteration:  14%|█▎        | 137/1001 [03:12<12:57,  1.11it/s, avg loss=127.3746]
Training iteration:  14%|█▍        | 138/1001 [03:12<12:56,  1.11it/s, avg loss=127.3746]Checkpoint at iteration 138 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 127.37455978393555

Training iteration:  14%|█▍        | 138/1001 [03:13<12:56,  1.11it/s, avg loss=305.3468]
Training iteration:  14%|█▍        | 139/1001 [03:13<12:55,  1.11it/s, avg loss=305.3468]Checkpoint at iteration 139 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 305.34681701660156

Training iteration:  14%|█▍        | 139/1001 [03:14<12:55,  1.11it/s, avg loss=308.7186]
Training iteration:  14%|█▍        | 140/1001 [03:14<12:55,  1.11it/s, avg loss=308.7186]Checkpoint at iteration 140 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 308.7186477661133

Training iteration:  14%|█▍        | 140/1001 [03:15<12:55,  1.11it/s, avg loss=300.4100]
Training iteration:  14%|█▍        | 141/1001 [03:15<12:54,  1.11it/s, avg loss=300.4100]Checkpoint at iteration 141 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 300.4099884033203

Training iteration:  14%|█▍        | 141/1001 [03:16<12:54,  1.11it/s, avg loss=307.4826]
Training iteration:  14%|█▍        | 142/1001 [03:16<12:53,  1.11it/s, avg loss=307.4826]Checkpoint at iteration 142 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 307.482568359375

Training iteration:  14%|█▍        | 142/1001 [03:17<12:53,  1.11it/s, avg loss=123.5769]
Training iteration:  14%|█▍        | 143/1001 [03:17<12:52,  1.11it/s, avg loss=123.5769]Checkpoint at iteration 143 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 123.5769172668457

Training iteration:  14%|█▍        | 143/1001 [03:17<12:52,  1.11it/s, avg loss=296.9284]
Training iteration:  14%|█▍        | 144/1001 [03:17<12:51,  1.11it/s, avg loss=296.9284]Checkpoint at iteration 144 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 296.92842254638674

Training iteration:  14%|█▍        | 144/1001 [03:18<12:51,  1.11it/s, avg loss=295.6361]
Training iteration:  14%|█▍        | 145/1001 [03:18<12:50,  1.11it/s, avg loss=295.6361]Checkpoint at iteration 145 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 295.63609771728517

Training iteration:  14%|█▍        | 145/1001 [03:19<12:50,  1.11it/s, avg loss=130.7914]
Training iteration:  15%|█▍        | 146/1001 [03:19<12:49,  1.11it/s, avg loss=130.7914]Checkpoint at iteration 146 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 130.79137496948243

Training iteration:  15%|█▍        | 146/1001 [03:20<12:49,  1.11it/s, avg loss=303.5214]
Training iteration:  15%|█▍        | 147/1001 [03:20<12:48,  1.11it/s, avg loss=303.5214]Checkpoint at iteration 147 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 303.5213790893555

Training iteration:  15%|█▍        | 147/1001 [03:21<12:48,  1.11it/s, avg loss=134.1015]
Training iteration:  15%|█▍        | 148/1001 [03:21<12:47,  1.11it/s, avg loss=134.1015]Checkpoint at iteration 148 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 134.10146789550782

Training iteration:  15%|█▍        | 148/1001 [03:22<12:47,  1.11it/s, avg loss=298.3435]
Training iteration:  15%|█▍        | 149/1001 [03:22<12:46,  1.11it/s, avg loss=298.3435]Checkpoint at iteration 149 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 298.3434631347656

Training iteration:  15%|█▍        | 149/1001 [03:23<12:46,  1.11it/s, avg loss=124.8142]
Training iteration:  15%|█▍        | 150/1001 [03:23<12:45,  1.11it/s, avg loss=124.8142]Checkpoint at iteration 150 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 124.81422805786133

Training iteration:  15%|█▍        | 150/1001 [03:24<12:45,  1.11it/s, avg loss=117.0214]
Training iteration:  15%|█▌        | 151/1001 [03:24<12:43,  1.11it/s, avg loss=117.0214]Checkpoint at iteration 151 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 117.02136764526367

Training iteration:  15%|█▌        | 151/1001 [03:25<12:43,  1.11it/s, avg loss=130.1970]
Training iteration:  15%|█▌        | 152/1001 [03:25<12:43,  1.11it/s, avg loss=130.1970]Checkpoint at iteration 152 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 130.1969772338867

Training iteration:  15%|█▌        | 152/1001 [03:26<12:43,  1.11it/s, avg loss=294.1062]
Training iteration:  15%|█▌        | 153/1001 [03:26<12:42,  1.11it/s, avg loss=294.1062]Checkpoint at iteration 153 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 294.1062347412109

Training iteration:  15%|█▌        | 153/1001 [03:26<12:42,  1.11it/s, avg loss=124.6790]
Training iteration:  15%|█▌        | 154/1001 [03:26<12:41,  1.11it/s, avg loss=124.6790]Checkpoint at iteration 154 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 124.67900619506835

Training iteration:  15%|█▌        | 154/1001 [03:27<12:41,  1.11it/s, avg loss=133.4758]
Training iteration:  15%|█▌        | 155/1001 [03:27<12:40,  1.11it/s, avg loss=133.4758]Checkpoint at iteration 155 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 133.47584075927733

Training iteration:  15%|█▌        | 155/1001 [03:28<12:40,  1.11it/s, avg loss=122.0862]
Training iteration:  16%|█▌        | 156/1001 [03:28<12:40,  1.11it/s, avg loss=122.0862]Checkpoint at iteration 156 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 122.08617324829102

Training iteration:  16%|█▌        | 156/1001 [03:29<12:40,  1.11it/s, avg loss=306.5575]
Training iteration:  16%|█▌        | 157/1001 [03:29<12:39,  1.11it/s, avg loss=306.5575]Checkpoint at iteration 157 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 306.55748443603517

Training iteration:  16%|█▌        | 157/1001 [03:30<12:39,  1.11it/s, avg loss=301.8524]
Training iteration:  16%|█▌        | 158/1001 [03:30<12:38,  1.11it/s, avg loss=301.8524]Checkpoint at iteration 158 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 301.8523681640625

Training iteration:  16%|█▌        | 158/1001 [03:31<12:38,  1.11it/s, avg loss=296.6918]
Training iteration:  16%|█▌        | 159/1001 [03:31<12:37,  1.11it/s, avg loss=296.6918]Checkpoint at iteration 159 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 296.69175872802737

Training iteration:  16%|█▌        | 159/1001 [03:32<12:37,  1.11it/s, avg loss=122.1313]
Training iteration:  16%|█▌        | 160/1001 [03:32<12:36,  1.11it/s, avg loss=122.1313]Checkpoint at iteration 160 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 122.13132171630859

Training iteration:  16%|█▌        | 160/1001 [03:33<12:36,  1.11it/s, avg loss=307.5301]
Training iteration:  16%|█▌        | 161/1001 [03:33<12:35,  1.11it/s, avg loss=307.5301]Checkpoint at iteration 161 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 307.5301177978516

Training iteration:  16%|█▌        | 161/1001 [03:34<12:35,  1.11it/s, avg loss=130.4803]
Training iteration:  16%|█▌        | 162/1001 [03:34<12:34,  1.11it/s, avg loss=130.4803]Checkpoint at iteration 162 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 130.48025436401366

Training iteration:  16%|█▌        | 162/1001 [03:35<12:34,  1.11it/s, avg loss=128.0284]
Training iteration:  16%|█▋        | 163/1001 [03:35<12:33,  1.11it/s, avg loss=128.0284]Checkpoint at iteration 163 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 128.02842483520507

Training iteration:  16%|█▋        | 163/1001 [03:35<12:33,  1.11it/s, avg loss=129.5781]
Training iteration:  16%|█▋        | 164/1001 [03:35<12:33,  1.11it/s, avg loss=129.5781]Checkpoint at iteration 164 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 129.57813034057617

Training iteration:  16%|█▋        | 164/1001 [03:36<12:33,  1.11it/s, avg loss=302.4931]
Training iteration:  16%|█▋        | 165/1001 [03:36<12:32,  1.11it/s, avg loss=302.4931]Checkpoint at iteration 165 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 302.49307403564455

Training iteration:  16%|█▋        | 165/1001 [03:37<12:32,  1.11it/s, avg loss=123.2547]
Training iteration:  17%|█▋        | 166/1001 [03:37<12:31,  1.11it/s, avg loss=123.2547]Checkpoint at iteration 166 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 123.25471801757813

Training iteration:  17%|█▋        | 166/1001 [03:38<12:31,  1.11it/s, avg loss=307.9283]
Training iteration:  17%|█▋        | 167/1001 [03:38<12:30,  1.11it/s, avg loss=307.9283]Checkpoint at iteration 167 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 307.92834625244143

Training iteration:  17%|█▋        | 167/1001 [03:39<12:30,  1.11it/s, avg loss=128.8236]
Training iteration:  17%|█▋        | 168/1001 [03:39<12:29,  1.11it/s, avg loss=128.8236]Checkpoint at iteration 168 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 128.8236297607422

Training iteration:  17%|█▋        | 168/1001 [03:40<12:29,  1.11it/s, avg loss=300.2476]
Training iteration:  17%|█▋        | 169/1001 [03:40<12:28,  1.11it/s, avg loss=300.2476]Checkpoint at iteration 169 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 300.24763946533204

Training iteration:  17%|█▋        | 169/1001 [03:41<12:28,  1.11it/s, avg loss=129.4421]
Training iteration:  17%|█▋        | 170/1001 [03:41<12:27,  1.11it/s, avg loss=129.4421]Checkpoint at iteration 170 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 129.44209747314454

Training iteration:  17%|█▋        | 170/1001 [03:42<12:27,  1.11it/s, avg loss=307.2894]
Training iteration:  17%|█▋        | 171/1001 [03:42<12:26,  1.11it/s, avg loss=307.2894]Checkpoint at iteration 171 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 307.28943634033203

Training iteration:  17%|█▋        | 171/1001 [03:43<12:26,  1.11it/s, avg loss=135.3200]
Training iteration:  17%|█▋        | 172/1001 [03:43<12:25,  1.11it/s, avg loss=135.3200]Checkpoint at iteration 172 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 135.31997375488282

Training iteration:  17%|█▋        | 172/1001 [03:44<12:25,  1.11it/s, avg loss=122.3165]
Training iteration:  17%|█▋        | 173/1001 [03:44<12:25,  1.11it/s, avg loss=122.3165]Checkpoint at iteration 173 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 122.3165412902832

Training iteration:  17%|█▋        | 173/1001 [03:44<12:25,  1.11it/s, avg loss=133.9872]
Training iteration:  17%|█▋        | 174/1001 [03:44<12:24,  1.11it/s, avg loss=133.9872]Checkpoint at iteration 174 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 133.98719024658203

Training iteration:  17%|█▋        | 174/1001 [03:45<12:24,  1.11it/s, avg loss=307.6191]
Training iteration:  17%|█▋        | 175/1001 [03:45<12:22,  1.11it/s, avg loss=307.6191]Checkpoint at iteration 175 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 307.6191070556641

Training iteration:  17%|█▋        | 175/1001 [03:46<12:22,  1.11it/s, avg loss=303.3419]
Training iteration:  18%|█▊        | 176/1001 [03:46<12:21,  1.11it/s, avg loss=303.3419]Checkpoint at iteration 176 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 303.34192352294923

Training iteration:  18%|█▊        | 176/1001 [03:47<12:21,  1.11it/s, avg loss=302.2322]
Training iteration:  18%|█▊        | 177/1001 [03:47<12:20,  1.11it/s, avg loss=302.2322]Checkpoint at iteration 177 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 302.23216857910154

Training iteration:  18%|█▊        | 177/1001 [03:48<12:20,  1.11it/s, avg loss=302.6764]
Training iteration:  18%|█▊        | 178/1001 [03:48<12:19,  1.11it/s, avg loss=302.6764]Checkpoint at iteration 178 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 302.67644958496095

Training iteration:  18%|█▊        | 178/1001 [03:49<12:19,  1.11it/s, avg loss=126.7453]
Training iteration:  18%|█▊        | 179/1001 [03:49<12:18,  1.11it/s, avg loss=126.7453]Checkpoint at iteration 179 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 126.74530715942383

Training iteration:  18%|█▊        | 179/1001 [03:50<12:18,  1.11it/s, avg loss=300.4788]
Training iteration:  18%|█▊        | 180/1001 [03:50<12:18,  1.11it/s, avg loss=300.4788]Checkpoint at iteration 180 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 300.4788284301758

Training iteration:  18%|█▊        | 180/1001 [03:51<12:18,  1.11it/s, avg loss=120.8100]
Training iteration:  18%|█▊        | 181/1001 [03:51<12:17,  1.11it/s, avg loss=120.8100]Checkpoint at iteration 181 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 120.80998458862305

Training iteration:  18%|█▊        | 181/1001 [03:52<12:17,  1.11it/s, avg loss=170.5672]
Training iteration:  18%|█▊        | 182/1001 [03:52<12:16,  1.11it/s, avg loss=170.5672]Checkpoint at iteration 182 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 170.56720275878905

Training iteration:  18%|█▊        | 182/1001 [03:53<12:16,  1.11it/s, avg loss=292.4219]
Training iteration:  18%|█▊        | 183/1001 [03:53<12:16,  1.11it/s, avg loss=292.4219]Checkpoint at iteration 183 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 292.42188262939453

Training iteration:  18%|█▊        | 183/1001 [03:53<12:16,  1.11it/s, avg loss=307.8726]
Training iteration:  18%|█▊        | 184/1001 [03:53<12:15,  1.11it/s, avg loss=307.8726]Checkpoint at iteration 184 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 307.8726470947266

Training iteration:  18%|█▊        | 184/1001 [03:54<12:15,  1.11it/s, avg loss=301.6797]
Training iteration:  18%|█▊        | 185/1001 [03:54<12:14,  1.11it/s, avg loss=301.6797]Checkpoint at iteration 185 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 301.67967224121094

Training iteration:  18%|█▊        | 185/1001 [03:55<12:14,  1.11it/s, avg loss=126.1924]
Training iteration:  19%|█▊        | 186/1001 [03:55<12:12,  1.11it/s, avg loss=126.1924]Checkpoint at iteration 186 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 126.19241027832031

Training iteration:  19%|█▊        | 186/1001 [03:56<12:12,  1.11it/s, avg loss=129.4689]
Training iteration:  19%|█▊        | 187/1001 [03:56<12:12,  1.11it/s, avg loss=129.4689]Checkpoint at iteration 187 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 129.46891860961915

Training iteration:  19%|█▊        | 187/1001 [03:57<12:12,  1.11it/s, avg loss=300.1477]
Training iteration:  19%|█▉        | 188/1001 [03:57<12:11,  1.11it/s, avg loss=300.1477]Checkpoint at iteration 188 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 300.1476745605469

Training iteration:  19%|█▉        | 188/1001 [03:58<12:11,  1.11it/s, avg loss=126.4545]
Training iteration:  19%|█▉        | 189/1001 [03:58<12:10,  1.11it/s, avg loss=126.4545]Checkpoint at iteration 189 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 126.45446319580078

Training iteration:  19%|█▉        | 189/1001 [03:59<12:10,  1.11it/s, avg loss=127.0478]
Training iteration:  19%|█▉        | 190/1001 [03:59<12:09,  1.11it/s, avg loss=127.0478]Checkpoint at iteration 190 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 127.0477912902832

Training iteration:  19%|█▉        | 190/1001 [04:00<12:09,  1.11it/s, avg loss=301.7755]
Training iteration:  19%|█▉        | 191/1001 [04:00<12:09,  1.11it/s, avg loss=301.7755]Checkpoint at iteration 191 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 301.77549438476564

Training iteration:  19%|█▉        | 191/1001 [04:01<12:09,  1.11it/s, avg loss=127.8699]
Training iteration:  19%|█▉        | 192/1001 [04:01<12:08,  1.11it/s, avg loss=127.8699]Checkpoint at iteration 192 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 127.86986465454102

Training iteration:  19%|█▉        | 192/1001 [04:02<12:08,  1.11it/s, avg loss=307.5937]
Training iteration:  19%|█▉        | 193/1001 [04:02<12:07,  1.11it/s, avg loss=307.5937]Checkpoint at iteration 193 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 307.59370574951174

Training iteration:  19%|█▉        | 193/1001 [04:02<12:07,  1.11it/s, avg loss=125.6379]
Training iteration:  19%|█▉        | 194/1001 [04:02<12:06,  1.11it/s, avg loss=125.6379]Checkpoint at iteration 194 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 125.63792724609375

Training iteration:  19%|█▉        | 194/1001 [04:03<12:06,  1.11it/s, avg loss=243.0839]
Training iteration:  19%|█▉        | 195/1001 [04:03<12:04,  1.11it/s, avg loss=243.0839]Checkpoint at iteration 195 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 243.08391494750975

Training iteration:  19%|█▉        | 195/1001 [04:04<12:04,  1.11it/s, avg loss=166.6673]
Training iteration:  20%|█▉        | 196/1001 [04:04<12:03,  1.11it/s, avg loss=166.6673]Checkpoint at iteration 196 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 166.6672836303711

Training iteration:  20%|█▉        | 196/1001 [04:05<12:03,  1.11it/s, avg loss=135.5168]
Training iteration:  20%|█▉        | 197/1001 [04:05<12:02,  1.11it/s, avg loss=135.5168]Checkpoint at iteration 197 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 135.51679229736328

Training iteration:  20%|█▉        | 197/1001 [04:06<12:02,  1.11it/s, avg loss=304.4165]
Training iteration:  20%|█▉        | 198/1001 [04:06<12:01,  1.11it/s, avg loss=304.4165]Checkpoint at iteration 198 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 304.41651153564453

Training iteration:  20%|█▉        | 198/1001 [04:07<12:01,  1.11it/s, avg loss=301.5710]
Training iteration:  20%|█▉        | 199/1001 [04:07<12:00,  1.11it/s, avg loss=301.5710]Checkpoint at iteration 199 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 301.5709976196289

Training iteration:  20%|█▉        | 199/1001 [04:08<12:00,  1.11it/s, avg loss=127.4994]
Training iteration:  20%|█▉        | 200/1001 [04:08<12:00,  1.11it/s, avg loss=127.4994]Optimization iteration 200 evaluation begins...
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
A new evaluation visualization has been saved: ./saved_data/20240110-050655/it200.png
Training network 0 for evaluation...
Training network 1 for evaluation...
Training network 2 for evaluation...
Training network 3 for evaluation...
Testing network 0 on real datasets for evaluation...
Testing network 1 on real datasets for evaluation...
Testing network 2 on real datasets for evaluation...
Testing network 3 on real datasets for evaluation...
Optimization iteration 200, eval auroc score (train): 30067.5276, eval auroc score (test): 31387.1778
Checkpoint at iteration 200 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 127.49936218261719

Training iteration:  20%|█▉        | 200/1001 [06:00<12:00,  1.11it/s, avg loss=124.5327]
Training iteration:  20%|██        | 201/1001 [06:00<7:38:03, 34.35s/it, avg loss=124.5327]Checkpoint at iteration 201 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 124.53265151977538

Training iteration:  20%|██        | 201/1001 [06:01<7:38:03, 34.35s/it, avg loss=302.2854]
Training iteration:  20%|██        | 202/1001 [06:01<5:24:36, 24.38s/it, avg loss=302.2854]Checkpoint at iteration 202 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 302.2853668212891

Training iteration:  20%|██        | 202/1001 [06:02<5:24:36, 24.38s/it, avg loss=297.2107]
Training iteration:  20%|██        | 203/1001 [06:02<3:51:19, 17.39s/it, avg loss=297.2107]Checkpoint at iteration 203 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 297.2106643676758

Training iteration:  20%|██        | 203/1001 [06:04<3:51:19, 17.39s/it, avg loss=125.5893]
Training iteration:  20%|██        | 204/1001 [06:04<2:46:06, 12.50s/it, avg loss=125.5893]Checkpoint at iteration 204 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 125.58929595947265

Training iteration:  20%|██        | 204/1001 [06:05<2:46:06, 12.50s/it, avg loss=300.4998]
Training iteration:  20%|██        | 205/1001 [06:05<2:00:29,  9.08s/it, avg loss=300.4998]Checkpoint at iteration 205 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 300.49981384277345

Training iteration:  20%|██        | 205/1001 [06:06<2:00:29,  9.08s/it, avg loss=297.5876]
Training iteration:  21%|██        | 206/1001 [06:06<1:28:35,  6.69s/it, avg loss=297.5876]Checkpoint at iteration 206 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 297.5875610351562

Training iteration:  21%|██        | 206/1001 [06:07<1:28:35,  6.69s/it, avg loss=301.2330]
Training iteration:  21%|██        | 207/1001 [06:07<1:06:17,  5.01s/it, avg loss=301.2330]Checkpoint at iteration 207 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 301.23301696777344

Training iteration:  21%|██        | 207/1001 [06:08<1:06:17,  5.01s/it, avg loss=129.2803]
Training iteration:  21%|██        | 208/1001 [06:08<50:41,  3.84s/it, avg loss=129.2803]  Checkpoint at iteration 208 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 129.28032913208008

Training iteration:  21%|██        | 208/1001 [06:09<50:41,  3.84s/it, avg loss=127.3296]
Training iteration:  21%|██        | 209/1001 [06:09<39:46,  3.01s/it, avg loss=127.3296]Checkpoint at iteration 209 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 127.32958374023437

Training iteration:  21%|██        | 209/1001 [06:10<39:46,  3.01s/it, avg loss=296.0394]
Training iteration:  21%|██        | 210/1001 [06:10<32:08,  2.44s/it, avg loss=296.0394]Checkpoint at iteration 210 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 296.0393661499023

Training iteration:  21%|██        | 210/1001 [06:11<32:08,  2.44s/it, avg loss=129.3561]
Training iteration:  21%|██        | 211/1001 [06:11<26:47,  2.03s/it, avg loss=129.3561]Checkpoint at iteration 211 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 129.35606307983397

Training iteration:  21%|██        | 211/1001 [06:12<26:47,  2.03s/it, avg loss=131.4567]
Training iteration:  21%|██        | 212/1001 [06:12<23:02,  1.75s/it, avg loss=131.4567]Checkpoint at iteration 212 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 131.45669021606446

Training iteration:  21%|██        | 212/1001 [06:13<23:02,  1.75s/it, avg loss=296.8826]
Training iteration:  21%|██▏       | 213/1001 [06:13<20:25,  1.56s/it, avg loss=296.8826]Checkpoint at iteration 213 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 296.88255920410154

Training iteration:  21%|██▏       | 213/1001 [06:15<20:25,  1.56s/it, avg loss=303.2847]
Training iteration:  21%|██▏       | 214/1001 [06:15<18:35,  1.42s/it, avg loss=303.2847]Checkpoint at iteration 214 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 303.28472595214845

Training iteration:  21%|██▏       | 214/1001 [06:16<18:35,  1.42s/it, avg loss=304.0404]
Training iteration:  21%|██▏       | 215/1001 [06:16<17:18,  1.32s/it, avg loss=304.0404]Checkpoint at iteration 215 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 304.04044342041016

Training iteration:  21%|██▏       | 215/1001 [06:17<17:18,  1.32s/it, avg loss=302.5451]
Training iteration:  22%|██▏       | 216/1001 [06:17<16:23,  1.25s/it, avg loss=302.5451]Checkpoint at iteration 216 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 302.5451400756836

Training iteration:  22%|██▏       | 216/1001 [06:18<16:23,  1.25s/it, avg loss=284.5114]
Training iteration:  22%|██▏       | 217/1001 [06:18<15:44,  1.20s/it, avg loss=284.5114]Checkpoint at iteration 217 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 284.5114227294922

Training iteration:  22%|██▏       | 217/1001 [06:19<15:44,  1.20s/it, avg loss=130.5745]
Training iteration:  22%|██▏       | 218/1001 [06:19<15:15,  1.17s/it, avg loss=130.5745]Checkpoint at iteration 218 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 130.5745002746582

Training iteration:  22%|██▏       | 218/1001 [06:20<15:15,  1.17s/it, avg loss=130.5542]
Training iteration:  22%|██▏       | 219/1001 [06:20<14:55,  1.15s/it, avg loss=130.5542]Checkpoint at iteration 219 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 130.5541732788086

Training iteration:  22%|██▏       | 219/1001 [06:21<14:55,  1.15s/it, avg loss=129.9825]
Training iteration:  22%|██▏       | 220/1001 [06:21<14:40,  1.13s/it, avg loss=129.9825]Checkpoint at iteration 220 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 129.9825439453125

Training iteration:  22%|██▏       | 220/1001 [06:22<14:40,  1.13s/it, avg loss=121.6631]
Training iteration:  22%|██▏       | 221/1001 [06:22<14:30,  1.12s/it, avg loss=121.6631]Checkpoint at iteration 221 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 121.66311416625976

Training iteration:  22%|██▏       | 221/1001 [06:23<14:30,  1.12s/it, avg loss=297.4521]
Training iteration:  22%|██▏       | 222/1001 [06:23<14:22,  1.11s/it, avg loss=297.4521]Checkpoint at iteration 222 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 297.4520751953125

Training iteration:  22%|██▏       | 222/1001 [06:24<14:22,  1.11s/it, avg loss=295.7627]
Training iteration:  22%|██▏       | 223/1001 [06:24<14:17,  1.10s/it, avg loss=295.7627]Checkpoint at iteration 223 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 295.76265411376954

Training iteration:  22%|██▏       | 223/1001 [06:25<14:17,  1.10s/it, avg loss=131.2592]
Training iteration:  22%|██▏       | 224/1001 [06:25<14:12,  1.10s/it, avg loss=131.2592]Checkpoint at iteration 224 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 131.25921478271485

Training iteration:  22%|██▏       | 224/1001 [06:26<14:12,  1.10s/it, avg loss=297.6645]
Training iteration:  22%|██▏       | 225/1001 [06:26<14:09,  1.09s/it, avg loss=297.6645]Checkpoint at iteration 225 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 297.6645141601563

Training iteration:  22%|██▏       | 225/1001 [06:28<14:09,  1.09s/it, avg loss=297.1573]
Training iteration:  23%|██▎       | 226/1001 [06:28<14:06,  1.09s/it, avg loss=297.1573]Checkpoint at iteration 226 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 297.1572952270508

Training iteration:  23%|██▎       | 226/1001 [06:29<14:06,  1.09s/it, avg loss=296.0256]
Training iteration:  23%|██▎       | 227/1001 [06:29<14:04,  1.09s/it, avg loss=296.0256]Checkpoint at iteration 227 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 296.02562103271487

Training iteration:  23%|██▎       | 227/1001 [06:30<14:04,  1.09s/it, avg loss=293.8776]
Training iteration:  23%|██▎       | 228/1001 [06:30<14:02,  1.09s/it, avg loss=293.8776]Checkpoint at iteration 228 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 293.87764739990234

Training iteration:  23%|██▎       | 228/1001 [06:31<14:02,  1.09s/it, avg loss=133.1748]
Training iteration:  23%|██▎       | 229/1001 [06:31<14:00,  1.09s/it, avg loss=133.1748]Checkpoint at iteration 229 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 133.1748474121094

Training iteration:  23%|██▎       | 229/1001 [06:32<14:00,  1.09s/it, avg loss=297.2489]
Training iteration:  23%|██▎       | 230/1001 [06:32<13:59,  1.09s/it, avg loss=297.2489]Checkpoint at iteration 230 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 297.2489410400391

Training iteration:  23%|██▎       | 230/1001 [06:33<13:59,  1.09s/it, avg loss=130.0356]
Training iteration:  23%|██▎       | 231/1001 [06:33<13:58,  1.09s/it, avg loss=130.0356]Checkpoint at iteration 231 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 130.03560333251954

Training iteration:  23%|██▎       | 231/1001 [06:34<13:58,  1.09s/it, avg loss=121.9535]
Training iteration:  23%|██▎       | 232/1001 [06:34<13:56,  1.09s/it, avg loss=121.9535]Checkpoint at iteration 232 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 121.95350799560546

Training iteration:  23%|██▎       | 232/1001 [06:35<13:56,  1.09s/it, avg loss=137.6236]
Training iteration:  23%|██▎       | 233/1001 [06:35<13:55,  1.09s/it, avg loss=137.6236]Checkpoint at iteration 233 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 137.6236114501953

Training iteration:  23%|██▎       | 233/1001 [06:36<13:55,  1.09s/it, avg loss=124.4212]
Training iteration:  23%|██▎       | 234/1001 [06:36<13:54,  1.09s/it, avg loss=124.4212]Checkpoint at iteration 234 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 124.4212417602539

Training iteration:  23%|██▎       | 234/1001 [06:37<13:54,  1.09s/it, avg loss=135.8176]
Training iteration:  23%|██▎       | 235/1001 [06:37<13:54,  1.09s/it, avg loss=135.8176]Checkpoint at iteration 235 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 135.8175537109375

Training iteration:  23%|██▎       | 235/1001 [06:38<13:54,  1.09s/it, avg loss=134.4335]
Training iteration:  24%|██▎       | 236/1001 [06:38<13:52,  1.09s/it, avg loss=134.4335]Checkpoint at iteration 236 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 134.43345489501954

Training iteration:  24%|██▎       | 236/1001 [06:40<13:52,  1.09s/it, avg loss=125.4278]
Training iteration:  24%|██▎       | 237/1001 [06:40<13:50,  1.09s/it, avg loss=125.4278]Checkpoint at iteration 237 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 125.42784729003907

Training iteration:  24%|██▎       | 237/1001 [06:41<13:50,  1.09s/it, avg loss=127.9451]
Training iteration:  24%|██▍       | 238/1001 [06:41<13:49,  1.09s/it, avg loss=127.9451]Checkpoint at iteration 238 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 127.9451416015625

Training iteration:  24%|██▍       | 238/1001 [06:42<13:49,  1.09s/it, avg loss=166.5241]
Training iteration:  24%|██▍       | 239/1001 [06:42<13:48,  1.09s/it, avg loss=166.5241]Checkpoint at iteration 239 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 166.5241386413574

Training iteration:  24%|██▍       | 239/1001 [06:43<13:48,  1.09s/it, avg loss=167.0674]
Training iteration:  24%|██▍       | 240/1001 [06:43<13:47,  1.09s/it, avg loss=167.0674]Checkpoint at iteration 240 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 167.06738662719727

Training iteration:  24%|██▍       | 240/1001 [06:44<13:47,  1.09s/it, avg loss=136.9928]
Training iteration:  24%|██▍       | 241/1001 [06:44<13:46,  1.09s/it, avg loss=136.9928]Checkpoint at iteration 241 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 136.992822265625

Training iteration:  24%|██▍       | 241/1001 [06:45<13:46,  1.09s/it, avg loss=297.4209]
Training iteration:  24%|██▍       | 242/1001 [06:45<13:44,  1.09s/it, avg loss=297.4209]Checkpoint at iteration 242 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 297.42088623046874

Training iteration:  24%|██▍       | 242/1001 [06:46<13:44,  1.09s/it, avg loss=298.8699]
Training iteration:  24%|██▍       | 243/1001 [06:46<13:43,  1.09s/it, avg loss=298.8699]Checkpoint at iteration 243 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 298.8699020385742

Training iteration:  24%|██▍       | 243/1001 [06:47<13:43,  1.09s/it, avg loss=126.4682]
Training iteration:  24%|██▍       | 244/1001 [06:47<13:42,  1.09s/it, avg loss=126.4682]Checkpoint at iteration 244 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 126.46820907592773

Training iteration:  24%|██▍       | 244/1001 [06:48<13:42,  1.09s/it, avg loss=301.5925]
Training iteration:  24%|██▍       | 245/1001 [06:48<13:41,  1.09s/it, avg loss=301.5925]Checkpoint at iteration 245 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 301.5924774169922

Training iteration:  24%|██▍       | 245/1001 [06:49<13:41,  1.09s/it, avg loss=136.4627]
Training iteration:  25%|██▍       | 246/1001 [06:49<13:40,  1.09s/it, avg loss=136.4627]Checkpoint at iteration 246 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 136.46274108886718

Training iteration:  25%|██▍       | 246/1001 [06:50<13:40,  1.09s/it, avg loss=298.1618]
Training iteration:  25%|██▍       | 247/1001 [06:50<13:39,  1.09s/it, avg loss=298.1618]Checkpoint at iteration 247 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 298.16183319091795

Training iteration:  25%|██▍       | 247/1001 [06:52<13:39,  1.09s/it, avg loss=306.2581]
Training iteration:  25%|██▍       | 248/1001 [06:52<13:38,  1.09s/it, avg loss=306.2581]Checkpoint at iteration 248 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 306.2581130981445

Training iteration:  25%|██▍       | 248/1001 [06:53<13:38,  1.09s/it, avg loss=140.8776]
Training iteration:  25%|██▍       | 249/1001 [06:53<13:37,  1.09s/it, avg loss=140.8776]Checkpoint at iteration 249 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 140.87755279541017

Training iteration:  25%|██▍       | 249/1001 [06:54<13:37,  1.09s/it, avg loss=293.7452]
Training iteration:  25%|██▍       | 250/1001 [06:54<13:35,  1.09s/it, avg loss=293.7452]Checkpoint at iteration 250 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 293.74522552490237

Training iteration:  25%|██▍       | 250/1001 [06:55<13:35,  1.09s/it, avg loss=292.5272]
Training iteration:  25%|██▌       | 251/1001 [06:55<13:35,  1.09s/it, avg loss=292.5272]Checkpoint at iteration 251 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 292.52721099853517

Training iteration:  25%|██▌       | 251/1001 [06:56<13:35,  1.09s/it, avg loss=118.3863]
Training iteration:  25%|██▌       | 252/1001 [06:56<13:33,  1.09s/it, avg loss=118.3863]Checkpoint at iteration 252 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 118.38627853393555

Training iteration:  25%|██▌       | 252/1001 [06:57<13:33,  1.09s/it, avg loss=298.9636]
Training iteration:  25%|██▌       | 253/1001 [06:57<13:32,  1.09s/it, avg loss=298.9636]Checkpoint at iteration 253 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 298.9636459350586

Training iteration:  25%|██▌       | 253/1001 [06:58<13:32,  1.09s/it, avg loss=298.9300]
Training iteration:  25%|██▌       | 254/1001 [06:58<13:32,  1.09s/it, avg loss=298.9300]Checkpoint at iteration 254 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 298.93004684448243

Training iteration:  25%|██▌       | 254/1001 [06:59<13:32,  1.09s/it, avg loss=126.4400]
Training iteration:  25%|██▌       | 255/1001 [06:59<13:32,  1.09s/it, avg loss=126.4400]Checkpoint at iteration 255 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 126.44004364013672

Training iteration:  25%|██▌       | 255/1001 [07:00<13:32,  1.09s/it, avg loss=126.0529]
Training iteration:  26%|██▌       | 256/1001 [07:00<13:33,  1.09s/it, avg loss=126.0529]Checkpoint at iteration 256 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 126.0528549194336

Training iteration:  26%|██▌       | 256/1001 [07:01<13:33,  1.09s/it, avg loss=300.2137]
Training iteration:  26%|██▌       | 257/1001 [07:01<13:34,  1.09s/it, avg loss=300.2137]Checkpoint at iteration 257 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 300.2137481689453

Training iteration:  26%|██▌       | 257/1001 [07:02<13:34,  1.09s/it, avg loss=122.8996]
Training iteration:  26%|██▌       | 258/1001 [07:02<13:33,  1.09s/it, avg loss=122.8996]Checkpoint at iteration 258 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 122.89960479736328

Training iteration:  26%|██▌       | 258/1001 [07:04<13:33,  1.09s/it, avg loss=296.8392]
Training iteration:  26%|██▌       | 259/1001 [07:04<13:32,  1.09s/it, avg loss=296.8392]Checkpoint at iteration 259 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 296.8391860961914

Training iteration:  26%|██▌       | 259/1001 [07:05<13:32,  1.09s/it, avg loss=297.0437]
Training iteration:  26%|██▌       | 260/1001 [07:05<13:31,  1.10s/it, avg loss=297.0437]Checkpoint at iteration 260 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 297.0437438964844

Training iteration:  26%|██▌       | 260/1001 [07:06<13:31,  1.10s/it, avg loss=297.2016]
Training iteration:  26%|██▌       | 261/1001 [07:06<13:31,  1.10s/it, avg loss=297.2016]Checkpoint at iteration 261 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 297.20163879394534

Training iteration:  26%|██▌       | 261/1001 [07:07<13:31,  1.10s/it, avg loss=289.9751]
Training iteration:  26%|██▌       | 262/1001 [07:07<13:30,  1.10s/it, avg loss=289.9751]Checkpoint at iteration 262 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 289.9751235961914

Training iteration:  26%|██▌       | 262/1001 [07:08<13:30,  1.10s/it, avg loss=130.2558]
Training iteration:  26%|██▋       | 263/1001 [07:08<13:29,  1.10s/it, avg loss=130.2558]Checkpoint at iteration 263 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 130.25579452514648

Training iteration:  26%|██▋       | 263/1001 [07:09<13:29,  1.10s/it, avg loss=128.9850]
Training iteration:  26%|██▋       | 264/1001 [07:09<13:27,  1.10s/it, avg loss=128.9850]Checkpoint at iteration 264 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 128.98501052856446

Training iteration:  26%|██▋       | 264/1001 [07:10<13:27,  1.10s/it, avg loss=138.5607]
Training iteration:  26%|██▋       | 265/1001 [07:10<13:26,  1.10s/it, avg loss=138.5607]Checkpoint at iteration 265 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 138.56073760986328

Training iteration:  26%|██▋       | 265/1001 [07:11<13:26,  1.10s/it, avg loss=290.1868]
Training iteration:  27%|██▋       | 266/1001 [07:11<13:25,  1.10s/it, avg loss=290.1868]Checkpoint at iteration 266 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 290.1867950439453

Training iteration:  27%|██▋       | 266/1001 [07:12<13:25,  1.10s/it, avg loss=298.8255]
Training iteration:  27%|██▋       | 267/1001 [07:12<13:23,  1.10s/it, avg loss=298.8255]Checkpoint at iteration 267 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 298.82545776367186

Training iteration:  27%|██▋       | 267/1001 [07:13<13:23,  1.10s/it, avg loss=296.1903]
Training iteration:  27%|██▋       | 268/1001 [07:13<13:23,  1.10s/it, avg loss=296.1903]Checkpoint at iteration 268 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 296.19029998779297

Training iteration:  27%|██▋       | 268/1001 [07:14<13:23,  1.10s/it, avg loss=138.2677]
Training iteration:  27%|██▋       | 269/1001 [07:14<13:21,  1.10s/it, avg loss=138.2677]Checkpoint at iteration 269 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 138.26766204833984

Training iteration:  27%|██▋       | 269/1001 [07:16<13:21,  1.10s/it, avg loss=133.8480]
Training iteration:  27%|██▋       | 270/1001 [07:16<13:20,  1.10s/it, avg loss=133.8480]Checkpoint at iteration 270 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 133.84796752929688

Training iteration:  27%|██▋       | 270/1001 [07:17<13:20,  1.10s/it, avg loss=134.0057]
Training iteration:  27%|██▋       | 271/1001 [07:17<13:19,  1.10s/it, avg loss=134.0057]Checkpoint at iteration 271 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 134.00574951171876

Training iteration:  27%|██▋       | 271/1001 [07:18<13:19,  1.10s/it, avg loss=291.3575]
Training iteration:  27%|██▋       | 272/1001 [07:18<13:18,  1.10s/it, avg loss=291.3575]Checkpoint at iteration 272 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 291.35753326416017

Training iteration:  27%|██▋       | 272/1001 [07:19<13:18,  1.10s/it, avg loss=293.7075]
Training iteration:  27%|██▋       | 273/1001 [07:19<13:17,  1.09s/it, avg loss=293.7075]Checkpoint at iteration 273 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 293.707502746582

Training iteration:  27%|██▋       | 273/1001 [07:20<13:17,  1.09s/it, avg loss=298.0190]
Training iteration:  27%|██▋       | 274/1001 [07:20<13:16,  1.10s/it, avg loss=298.0190]Checkpoint at iteration 274 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 298.0190124511719

Training iteration:  27%|██▋       | 274/1001 [07:21<13:16,  1.10s/it, avg loss=133.0146]
Training iteration:  27%|██▋       | 275/1001 [07:21<13:14,  1.09s/it, avg loss=133.0146]Checkpoint at iteration 275 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 133.01458435058595

Training iteration:  27%|██▋       | 275/1001 [07:22<13:14,  1.09s/it, avg loss=295.2885]
Training iteration:  28%|██▊       | 276/1001 [07:22<13:13,  1.09s/it, avg loss=295.2885]Checkpoint at iteration 276 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 295.28846740722656

Training iteration:  28%|██▊       | 276/1001 [07:23<13:13,  1.09s/it, avg loss=286.8081]
Training iteration:  28%|██▊       | 277/1001 [07:23<13:12,  1.09s/it, avg loss=286.8081]Checkpoint at iteration 277 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 286.8080718994141

Training iteration:  28%|██▊       | 277/1001 [07:24<13:12,  1.09s/it, avg loss=295.4315]
Training iteration:  28%|██▊       | 278/1001 [07:24<13:11,  1.09s/it, avg loss=295.4315]Checkpoint at iteration 278 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 295.4315376281738

Training iteration:  28%|██▊       | 278/1001 [07:25<13:11,  1.09s/it, avg loss=130.5726]
Training iteration:  28%|██▊       | 279/1001 [07:25<13:09,  1.09s/it, avg loss=130.5726]Checkpoint at iteration 279 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 130.57256774902345

Training iteration:  28%|██▊       | 279/1001 [07:27<13:09,  1.09s/it, avg loss=299.6792]
Training iteration:  28%|██▊       | 280/1001 [07:27<13:08,  1.09s/it, avg loss=299.6792]Checkpoint at iteration 280 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 299.6791542053223

Training iteration:  28%|██▊       | 280/1001 [07:28<13:08,  1.09s/it, avg loss=297.5019]
Training iteration:  28%|██▊       | 281/1001 [07:28<13:08,  1.09s/it, avg loss=297.5019]Checkpoint at iteration 281 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 297.5018501281738

Training iteration:  28%|██▊       | 281/1001 [07:29<13:08,  1.09s/it, avg loss=284.8677]
Training iteration:  28%|██▊       | 282/1001 [07:29<13:07,  1.09s/it, avg loss=284.8677]Checkpoint at iteration 282 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 284.86771392822266

Training iteration:  28%|██▊       | 282/1001 [07:30<13:07,  1.09s/it, avg loss=291.3585]
Training iteration:  28%|██▊       | 283/1001 [07:30<13:06,  1.09s/it, avg loss=291.3585]Checkpoint at iteration 283 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 291.35852966308596

Training iteration:  28%|██▊       | 283/1001 [07:31<13:06,  1.09s/it, avg loss=139.4234]
Training iteration:  28%|██▊       | 284/1001 [07:31<13:04,  1.09s/it, avg loss=139.4234]Checkpoint at iteration 284 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 139.4233627319336

Training iteration:  28%|██▊       | 284/1001 [07:32<13:04,  1.09s/it, avg loss=294.5911]
Training iteration:  28%|██▊       | 285/1001 [07:32<13:03,  1.09s/it, avg loss=294.5911]Checkpoint at iteration 285 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 294.5910583496094

Training iteration:  28%|██▊       | 285/1001 [07:33<13:03,  1.09s/it, avg loss=132.7723]
Training iteration:  29%|██▊       | 286/1001 [07:33<13:02,  1.09s/it, avg loss=132.7723]Checkpoint at iteration 286 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 132.7723129272461

Training iteration:  29%|██▊       | 286/1001 [07:34<13:02,  1.09s/it, avg loss=292.7342]
Training iteration:  29%|██▊       | 287/1001 [07:34<13:01,  1.09s/it, avg loss=292.7342]Checkpoint at iteration 287 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 292.73423461914064

Training iteration:  29%|██▊       | 287/1001 [07:35<13:01,  1.09s/it, avg loss=132.5257]
Training iteration:  29%|██▉       | 288/1001 [07:35<13:00,  1.09s/it, avg loss=132.5257]Checkpoint at iteration 288 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 132.52573852539064

Training iteration:  29%|██▉       | 288/1001 [07:36<13:00,  1.09s/it, avg loss=289.6481]
Training iteration:  29%|██▉       | 289/1001 [07:36<12:59,  1.09s/it, avg loss=289.6481]Checkpoint at iteration 289 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 289.64813537597655

Training iteration:  29%|██▉       | 289/1001 [07:37<12:59,  1.09s/it, avg loss=142.6954]
Training iteration:  29%|██▉       | 290/1001 [07:37<12:58,  1.09s/it, avg loss=142.6954]Checkpoint at iteration 290 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 142.69538421630858

Training iteration:  29%|██▉       | 290/1001 [07:39<12:58,  1.09s/it, avg loss=135.0010]
Training iteration:  29%|██▉       | 291/1001 [07:39<12:57,  1.09s/it, avg loss=135.0010]Checkpoint at iteration 291 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 135.00099182128906

Training iteration:  29%|██▉       | 291/1001 [07:40<12:57,  1.09s/it, avg loss=288.8539]
Training iteration:  29%|██▉       | 292/1001 [07:40<12:56,  1.09s/it, avg loss=288.8539]Checkpoint at iteration 292 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 288.8538879394531

Training iteration:  29%|██▉       | 292/1001 [07:41<12:56,  1.09s/it, avg loss=128.0033]
Training iteration:  29%|██▉       | 293/1001 [07:41<12:54,  1.09s/it, avg loss=128.0033]Checkpoint at iteration 293 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 128.0032531738281

Training iteration:  29%|██▉       | 293/1001 [07:42<12:54,  1.09s/it, avg loss=132.2252]
Training iteration:  29%|██▉       | 294/1001 [07:42<12:53,  1.09s/it, avg loss=132.2252]Checkpoint at iteration 294 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 132.22520370483397

Training iteration:  29%|██▉       | 294/1001 [07:43<12:53,  1.09s/it, avg loss=134.4213]
Training iteration:  29%|██▉       | 295/1001 [07:43<12:52,  1.09s/it, avg loss=134.4213]Checkpoint at iteration 295 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 134.4213119506836

Training iteration:  29%|██▉       | 295/1001 [07:44<12:52,  1.09s/it, avg loss=295.1890]
Training iteration:  30%|██▉       | 296/1001 [07:44<12:51,  1.09s/it, avg loss=295.1890]Checkpoint at iteration 296 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 295.18902893066405

Training iteration:  30%|██▉       | 296/1001 [07:45<12:51,  1.09s/it, avg loss=297.9377]
Training iteration:  30%|██▉       | 297/1001 [07:45<12:50,  1.09s/it, avg loss=297.9377]Checkpoint at iteration 297 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 297.9376754760742

Training iteration:  30%|██▉       | 297/1001 [07:46<12:50,  1.09s/it, avg loss=125.3325]
Training iteration:  30%|██▉       | 298/1001 [07:46<12:49,  1.09s/it, avg loss=125.3325]Checkpoint at iteration 298 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 125.33253021240235

Training iteration:  30%|██▉       | 298/1001 [07:47<12:49,  1.09s/it, avg loss=291.2376]
Training iteration:  30%|██▉       | 299/1001 [07:47<12:48,  1.09s/it, avg loss=291.2376]Checkpoint at iteration 299 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 291.2376052856445

Training iteration:  30%|██▉       | 299/1001 [07:48<12:48,  1.09s/it, avg loss=284.0800]
Training iteration:  30%|██▉       | 300/1001 [07:48<12:47,  1.09s/it, avg loss=284.0800]Optimization iteration 300 evaluation begins...
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
A new evaluation visualization has been saved: ./saved_data/20240110-050655/it300.png
Training network 0 for evaluation...
Training network 1 for evaluation...
Training network 2 for evaluation...
Training network 3 for evaluation...
Testing network 0 on real datasets for evaluation...
Testing network 1 on real datasets for evaluation...
Testing network 2 on real datasets for evaluation...
Testing network 3 on real datasets for evaluation...
Optimization iteration 300, eval auroc score (train): 30984.7380, eval auroc score (test): 32344.6498
Checkpoint at iteration 300 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 284.0799987792969

Training iteration:  30%|██▉       | 300/1001 [10:52<12:47,  1.09s/it, avg loss=138.3203]
Training iteration:  30%|███       | 301/1001 [10:52<10:52:33, 55.93s/it, avg loss=138.3203]Checkpoint at iteration 301 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 138.32031707763673

Training iteration:  30%|███       | 301/1001 [10:54<10:52:33, 55.93s/it, avg loss=286.6693]
Training iteration:  30%|███       | 302/1001 [10:54<7:40:40, 39.54s/it, avg loss=286.6693] Checkpoint at iteration 302 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 286.6693389892578

Training iteration:  30%|███       | 302/1001 [10:55<7:40:40, 39.54s/it, avg loss=290.1832]
Training iteration:  30%|███       | 303/1001 [10:55<5:26:31, 28.07s/it, avg loss=290.1832]Checkpoint at iteration 303 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 290.1832305908203

Training iteration:  30%|███       | 303/1001 [10:56<5:26:31, 28.07s/it, avg loss=135.7796]
Training iteration:  30%|███       | 304/1001 [10:56<3:52:45, 20.04s/it, avg loss=135.7796]Checkpoint at iteration 304 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 135.77955780029296

Training iteration:  30%|███       | 304/1001 [10:57<3:52:45, 20.04s/it, avg loss=297.0328]
Training iteration:  30%|███       | 305/1001 [10:57<2:47:09, 14.41s/it, avg loss=297.0328]Checkpoint at iteration 305 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 297.03284149169923

Training iteration:  30%|███       | 305/1001 [10:59<2:47:09, 14.41s/it, avg loss=296.8215]
Training iteration:  31%|███       | 306/1001 [10:59<2:01:18, 10.47s/it, avg loss=296.8215]Checkpoint at iteration 306 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 296.8214645385742

Training iteration:  31%|███       | 306/1001 [11:00<2:01:18, 10.47s/it, avg loss=132.6214]
Training iteration:  31%|███       | 307/1001 [11:00<1:29:14,  7.72s/it, avg loss=132.6214]Checkpoint at iteration 307 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 132.62139282226562

Training iteration:  31%|███       | 307/1001 [11:01<1:29:14,  7.72s/it, avg loss=284.9596]
Training iteration:  31%|███       | 308/1001 [11:01<1:06:49,  5.79s/it, avg loss=284.9596]Checkpoint at iteration 308 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 284.9595642089844

Training iteration:  31%|███       | 308/1001 [11:03<1:06:49,  5.79s/it, avg loss=281.2338]
Training iteration:  31%|███       | 309/1001 [11:03<51:08,  4.43s/it, avg loss=281.2338]  Checkpoint at iteration 309 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 281.23377532958983

Training iteration:  31%|███       | 309/1001 [11:04<51:08,  4.43s/it, avg loss=286.8673]
Training iteration:  31%|███       | 310/1001 [11:04<40:10,  3.49s/it, avg loss=286.8673]Checkpoint at iteration 310 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 286.86730194091797

Training iteration:  31%|███       | 310/1001 [11:05<40:10,  3.49s/it, avg loss=139.4419]
Training iteration:  31%|███       | 311/1001 [11:05<32:30,  2.83s/it, avg loss=139.4419]Checkpoint at iteration 311 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 139.44190216064453

Training iteration:  31%|███       | 311/1001 [11:06<32:30,  2.83s/it, avg loss=295.7251]
Training iteration:  31%|███       | 312/1001 [11:06<27:08,  2.36s/it, avg loss=295.7251]Checkpoint at iteration 312 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 295.7250732421875

Training iteration:  31%|███       | 312/1001 [11:08<27:08,  2.36s/it, avg loss=287.9721]
Training iteration:  31%|███▏      | 313/1001 [11:08<23:22,  2.04s/it, avg loss=287.9721]Checkpoint at iteration 313 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 287.9720962524414

Training iteration:  31%|███▏      | 313/1001 [11:09<23:22,  2.04s/it, avg loss=141.5983]
Training iteration:  31%|███▏      | 314/1001 [11:09<20:44,  1.81s/it, avg loss=141.5983]Checkpoint at iteration 314 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 141.59827880859376

Training iteration:  31%|███▏      | 314/1001 [11:10<20:44,  1.81s/it, avg loss=280.9953]
Training iteration:  31%|███▏      | 315/1001 [11:10<18:53,  1.65s/it, avg loss=280.9953]Checkpoint at iteration 315 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 280.9953109741211

Training iteration:  31%|███▏      | 315/1001 [11:12<18:53,  1.65s/it, avg loss=284.9941]
Training iteration:  32%|███▏      | 316/1001 [11:12<17:36,  1.54s/it, avg loss=284.9941]Checkpoint at iteration 316 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 284.99405975341796

Training iteration:  32%|███▏      | 316/1001 [11:13<17:36,  1.54s/it, avg loss=285.6938]
Training iteration:  32%|███▏      | 317/1001 [11:13<16:41,  1.46s/it, avg loss=285.6938]Checkpoint at iteration 317 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 285.6938018798828

Training iteration:  32%|███▏      | 317/1001 [11:14<16:41,  1.46s/it, avg loss=280.1964]
Training iteration:  32%|███▏      | 318/1001 [11:14<16:02,  1.41s/it, avg loss=280.1964]Checkpoint at iteration 318 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 280.1963684082031

Training iteration:  32%|███▏      | 318/1001 [11:15<16:02,  1.41s/it, avg loss=275.5124]
Training iteration:  32%|███▏      | 319/1001 [11:15<15:35,  1.37s/it, avg loss=275.5124]Checkpoint at iteration 319 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 275.51239013671875

Training iteration:  32%|███▏      | 319/1001 [11:17<15:35,  1.37s/it, avg loss=280.6102]
Training iteration:  32%|███▏      | 320/1001 [11:17<15:16,  1.35s/it, avg loss=280.6102]Checkpoint at iteration 320 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 280.6101898193359

Training iteration:  32%|███▏      | 320/1001 [11:18<15:16,  1.35s/it, avg loss=151.1372]
Training iteration:  32%|███▏      | 321/1001 [11:18<15:02,  1.33s/it, avg loss=151.1372]Checkpoint at iteration 321 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 151.13720245361327

Training iteration:  32%|███▏      | 321/1001 [11:19<15:02,  1.33s/it, avg loss=281.4297]
Training iteration:  32%|███▏      | 322/1001 [11:19<14:51,  1.31s/it, avg loss=281.4297]Checkpoint at iteration 322 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 281.42974243164065

Training iteration:  32%|███▏      | 322/1001 [11:21<14:51,  1.31s/it, avg loss=269.4420]
Training iteration:  32%|███▏      | 323/1001 [11:21<14:44,  1.30s/it, avg loss=269.4420]Checkpoint at iteration 323 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 269.44203796386716

Training iteration:  32%|███▏      | 323/1001 [11:22<14:44,  1.30s/it, avg loss=279.2006]
Training iteration:  32%|███▏      | 324/1001 [11:22<14:38,  1.30s/it, avg loss=279.2006]Checkpoint at iteration 324 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 279.20060577392576

Training iteration:  32%|███▏      | 324/1001 [11:23<14:38,  1.30s/it, avg loss=156.2965]
Training iteration:  32%|███▏      | 325/1001 [11:23<14:34,  1.29s/it, avg loss=156.2965]Checkpoint at iteration 325 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 156.2964599609375

Training iteration:  32%|███▏      | 325/1001 [11:24<14:34,  1.29s/it, avg loss=280.2798]
Training iteration:  33%|███▎      | 326/1001 [11:24<14:30,  1.29s/it, avg loss=280.2798]Checkpoint at iteration 326 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 280.2797653198242

Training iteration:  33%|███▎      | 326/1001 [11:26<14:30,  1.29s/it, avg loss=277.5946]
Training iteration:  33%|███▎      | 327/1001 [11:26<14:27,  1.29s/it, avg loss=277.5946]Checkpoint at iteration 327 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 277.5946304321289

Training iteration:  33%|███▎      | 327/1001 [11:27<14:27,  1.29s/it, avg loss=281.2511]
Training iteration:  33%|███▎      | 328/1001 [11:27<14:25,  1.29s/it, avg loss=281.2511]Checkpoint at iteration 328 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 281.2511154174805

Training iteration:  33%|███▎      | 328/1001 [11:28<14:25,  1.29s/it, avg loss=275.9755]
Training iteration:  33%|███▎      | 329/1001 [11:28<14:23,  1.28s/it, avg loss=275.9755]Checkpoint at iteration 329 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 275.9754608154297

Training iteration:  33%|███▎      | 329/1001 [11:30<14:23,  1.28s/it, avg loss=150.1098]
Training iteration:  33%|███▎      | 330/1001 [11:30<14:21,  1.28s/it, avg loss=150.1098]Checkpoint at iteration 330 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 150.10981140136718

Training iteration:  33%|███▎      | 330/1001 [11:31<14:21,  1.28s/it, avg loss=281.7378]
Training iteration:  33%|███▎      | 331/1001 [11:31<14:19,  1.28s/it, avg loss=281.7378]Checkpoint at iteration 331 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 281.73778228759767

Training iteration:  33%|███▎      | 331/1001 [11:32<14:19,  1.28s/it, avg loss=275.8115]
Training iteration:  33%|███▎      | 332/1001 [11:32<14:18,  1.28s/it, avg loss=275.8115]Checkpoint at iteration 332 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 275.81146240234375

Training iteration:  33%|███▎      | 332/1001 [11:33<14:18,  1.28s/it, avg loss=274.1132]
Training iteration:  33%|███▎      | 333/1001 [11:33<14:16,  1.28s/it, avg loss=274.1132]Checkpoint at iteration 333 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 274.11324310302734

Training iteration:  33%|███▎      | 333/1001 [11:35<14:16,  1.28s/it, avg loss=279.9098]
Training iteration:  33%|███▎      | 334/1001 [11:35<14:16,  1.28s/it, avg loss=279.9098]Checkpoint at iteration 334 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 279.9098297119141

Training iteration:  33%|███▎      | 334/1001 [11:36<14:16,  1.28s/it, avg loss=272.9479]
Training iteration:  33%|███▎      | 335/1001 [11:36<14:14,  1.28s/it, avg loss=272.9479]Checkpoint at iteration 335 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 272.94786834716797

Training iteration:  33%|███▎      | 335/1001 [11:37<14:14,  1.28s/it, avg loss=272.1033]
Training iteration:  34%|███▎      | 336/1001 [11:37<14:13,  1.28s/it, avg loss=272.1033]Checkpoint at iteration 336 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 272.1033462524414

Training iteration:  34%|███▎      | 336/1001 [11:39<14:13,  1.28s/it, avg loss=166.0984]
Training iteration:  34%|███▎      | 337/1001 [11:39<14:11,  1.28s/it, avg loss=166.0984]Checkpoint at iteration 337 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 166.09837799072267

Training iteration:  34%|███▎      | 337/1001 [11:40<14:11,  1.28s/it, avg loss=154.6433]
Training iteration:  34%|███▍      | 338/1001 [11:40<14:10,  1.28s/it, avg loss=154.6433]Checkpoint at iteration 338 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 154.64331970214843

Training iteration:  34%|███▍      | 338/1001 [11:41<14:10,  1.28s/it, avg loss=149.9021]
Training iteration:  34%|███▍      | 339/1001 [11:41<14:09,  1.28s/it, avg loss=149.9021]Checkpoint at iteration 339 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 149.90208587646484

Training iteration:  34%|███▍      | 339/1001 [11:42<14:09,  1.28s/it, avg loss=276.5579]
Training iteration:  34%|███▍      | 340/1001 [11:42<14:08,  1.28s/it, avg loss=276.5579]Checkpoint at iteration 340 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 276.5579116821289

Training iteration:  34%|███▍      | 340/1001 [11:44<14:08,  1.28s/it, avg loss=278.0273]
Training iteration:  34%|███▍      | 341/1001 [11:44<14:06,  1.28s/it, avg loss=278.0273]Checkpoint at iteration 341 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 278.0273498535156

Training iteration:  34%|███▍      | 341/1001 [11:45<14:06,  1.28s/it, avg loss=150.1201]
Training iteration:  34%|███▍      | 342/1001 [11:45<14:06,  1.28s/it, avg loss=150.1201]Checkpoint at iteration 342 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 150.12010803222657

Training iteration:  34%|███▍      | 342/1001 [11:46<14:06,  1.28s/it, avg loss=152.6232]
Training iteration:  34%|███▍      | 343/1001 [11:46<14:04,  1.28s/it, avg loss=152.6232]Checkpoint at iteration 343 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 152.62320098876953

Training iteration:  34%|███▍      | 343/1001 [11:47<14:04,  1.28s/it, avg loss=146.9900]
Training iteration:  34%|███▍      | 344/1001 [11:47<14:03,  1.28s/it, avg loss=146.9900]Checkpoint at iteration 344 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 146.9900360107422

Training iteration:  34%|███▍      | 344/1001 [11:49<14:03,  1.28s/it, avg loss=278.1638]
Training iteration:  34%|███▍      | 345/1001 [11:49<14:02,  1.28s/it, avg loss=278.1638]Checkpoint at iteration 345 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 278.163801574707

Training iteration:  34%|███▍      | 345/1001 [11:50<14:02,  1.28s/it, avg loss=278.8634]
Training iteration:  35%|███▍      | 346/1001 [11:50<14:00,  1.28s/it, avg loss=278.8634]Checkpoint at iteration 346 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 278.86335906982424

Training iteration:  35%|███▍      | 346/1001 [11:51<14:00,  1.28s/it, avg loss=153.5355]
Training iteration:  35%|███▍      | 347/1001 [11:51<13:59,  1.28s/it, avg loss=153.5355]Checkpoint at iteration 347 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 153.53553161621093

Training iteration:  35%|███▍      | 347/1001 [11:53<13:59,  1.28s/it, avg loss=280.1257]
Training iteration:  35%|███▍      | 348/1001 [11:53<13:58,  1.28s/it, avg loss=280.1257]Checkpoint at iteration 348 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 280.1256729125977

Training iteration:  35%|███▍      | 348/1001 [11:54<13:58,  1.28s/it, avg loss=277.1835]
Training iteration:  35%|███▍      | 349/1001 [11:54<13:56,  1.28s/it, avg loss=277.1835]Checkpoint at iteration 349 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 277.18347625732423

Training iteration:  35%|███▍      | 349/1001 [11:55<13:56,  1.28s/it, avg loss=281.9562]
Training iteration:  35%|███▍      | 350/1001 [11:55<13:55,  1.28s/it, avg loss=281.9562]Checkpoint at iteration 350 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 281.9562042236328

Training iteration:  35%|███▍      | 350/1001 [11:56<13:55,  1.28s/it, avg loss=277.8158]
Training iteration:  35%|███▌      | 351/1001 [11:56<13:54,  1.28s/it, avg loss=277.8158]Checkpoint at iteration 351 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 277.81583404541016

Training iteration:  35%|███▌      | 351/1001 [11:58<13:54,  1.28s/it, avg loss=161.8182]
Training iteration:  35%|███▌      | 352/1001 [11:58<13:53,  1.28s/it, avg loss=161.8182]Checkpoint at iteration 352 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 161.81822052001954

Training iteration:  35%|███▌      | 352/1001 [11:59<13:53,  1.28s/it, avg loss=153.7804]
Training iteration:  35%|███▌      | 353/1001 [11:59<13:51,  1.28s/it, avg loss=153.7804]Checkpoint at iteration 353 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 153.78040161132813

Training iteration:  35%|███▌      | 353/1001 [12:00<13:51,  1.28s/it, avg loss=159.7498]
Training iteration:  35%|███▌      | 354/1001 [12:00<13:50,  1.28s/it, avg loss=159.7498]Checkpoint at iteration 354 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 159.74976043701173

Training iteration:  35%|███▌      | 354/1001 [12:02<13:50,  1.28s/it, avg loss=274.5342]
Training iteration:  35%|███▌      | 355/1001 [12:02<13:48,  1.28s/it, avg loss=274.5342]Checkpoint at iteration 355 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 274.5342086791992

Training iteration:  35%|███▌      | 355/1001 [12:03<13:48,  1.28s/it, avg loss=154.3307]
Training iteration:  36%|███▌      | 356/1001 [12:03<13:47,  1.28s/it, avg loss=154.3307]Checkpoint at iteration 356 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 154.3306686401367

Training iteration:  36%|███▌      | 356/1001 [12:04<13:47,  1.28s/it, avg loss=271.7394]
Training iteration:  36%|███▌      | 357/1001 [12:04<13:47,  1.28s/it, avg loss=271.7394]Checkpoint at iteration 357 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 271.7393997192383

Training iteration:  36%|███▌      | 357/1001 [12:05<13:47,  1.28s/it, avg loss=274.5241]
Training iteration:  36%|███▌      | 358/1001 [12:05<13:45,  1.28s/it, avg loss=274.5241]Checkpoint at iteration 358 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 274.524104309082

Training iteration:  36%|███▌      | 358/1001 [12:07<13:45,  1.28s/it, avg loss=279.3491]
Training iteration:  36%|███▌      | 359/1001 [12:07<13:43,  1.28s/it, avg loss=279.3491]Checkpoint at iteration 359 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 279.3490844726563

Training iteration:  36%|███▌      | 359/1001 [12:08<13:43,  1.28s/it, avg loss=273.4668]
Training iteration:  36%|███▌      | 360/1001 [12:08<13:42,  1.28s/it, avg loss=273.4668]Checkpoint at iteration 360 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 273.4667694091797

Training iteration:  36%|███▌      | 360/1001 [12:09<13:42,  1.28s/it, avg loss=275.4264]
Training iteration:  36%|███▌      | 361/1001 [12:09<13:41,  1.28s/it, avg loss=275.4264]Checkpoint at iteration 361 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 275.42640991210936

Training iteration:  36%|███▌      | 361/1001 [12:11<13:41,  1.28s/it, avg loss=157.1218]
Training iteration:  36%|███▌      | 362/1001 [12:11<13:39,  1.28s/it, avg loss=157.1218]Checkpoint at iteration 362 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 157.12177429199218

Training iteration:  36%|███▌      | 362/1001 [12:12<13:39,  1.28s/it, avg loss=150.9546]
Training iteration:  36%|███▋      | 363/1001 [12:12<13:39,  1.28s/it, avg loss=150.9546]Checkpoint at iteration 363 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 150.95456085205078

Training iteration:  36%|███▋      | 363/1001 [12:13<13:39,  1.28s/it, avg loss=156.4571]
Training iteration:  36%|███▋      | 364/1001 [12:13<13:37,  1.28s/it, avg loss=156.4571]Checkpoint at iteration 364 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 156.4570541381836

Training iteration:  36%|███▋      | 364/1001 [12:14<13:37,  1.28s/it, avg loss=273.3453]
Training iteration:  36%|███▋      | 365/1001 [12:14<13:35,  1.28s/it, avg loss=273.3453]Checkpoint at iteration 365 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 273.3453338623047

Training iteration:  36%|███▋      | 365/1001 [12:16<13:35,  1.28s/it, avg loss=279.5559]
Training iteration:  37%|███▋      | 366/1001 [12:16<13:34,  1.28s/it, avg loss=279.5559]Checkpoint at iteration 366 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 279.55586700439454

Training iteration:  37%|███▋      | 366/1001 [12:17<13:34,  1.28s/it, avg loss=273.8793]
Training iteration:  37%|███▋      | 367/1001 [12:17<13:33,  1.28s/it, avg loss=273.8793]Checkpoint at iteration 367 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 273.87928314208983

Training iteration:  37%|███▋      | 367/1001 [12:18<13:33,  1.28s/it, avg loss=276.5121]
Training iteration:  37%|███▋      | 368/1001 [12:18<13:32,  1.28s/it, avg loss=276.5121]Checkpoint at iteration 368 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 276.5120620727539

Training iteration:  37%|███▋      | 368/1001 [12:20<13:32,  1.28s/it, avg loss=275.2753]
Training iteration:  37%|███▋      | 369/1001 [12:20<13:30,  1.28s/it, avg loss=275.2753]Checkpoint at iteration 369 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 275.27528076171876

Training iteration:  37%|███▋      | 369/1001 [12:21<13:30,  1.28s/it, avg loss=166.9198]
Training iteration:  37%|███▋      | 370/1001 [12:21<13:29,  1.28s/it, avg loss=166.9198]Checkpoint at iteration 370 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 166.91983337402343

Training iteration:  37%|███▋      | 370/1001 [12:22<13:29,  1.28s/it, avg loss=271.8650]
Training iteration:  37%|███▋      | 371/1001 [12:22<13:29,  1.29s/it, avg loss=271.8650]Checkpoint at iteration 371 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 271.8649703979492

Training iteration:  37%|███▋      | 371/1001 [12:23<13:29,  1.29s/it, avg loss=150.3474]
Training iteration:  37%|███▋      | 372/1001 [12:23<13:29,  1.29s/it, avg loss=150.3474]Checkpoint at iteration 372 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 150.34740447998047

Training iteration:  37%|███▋      | 372/1001 [12:25<13:29,  1.29s/it, avg loss=280.6781]
Training iteration:  37%|███▋      | 373/1001 [12:25<13:29,  1.29s/it, avg loss=280.6781]Checkpoint at iteration 373 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 280.67806549072264

Training iteration:  37%|███▋      | 373/1001 [12:26<13:29,  1.29s/it, avg loss=153.8881]
Training iteration:  37%|███▋      | 374/1001 [12:26<13:29,  1.29s/it, avg loss=153.8881]Checkpoint at iteration 374 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 153.8881378173828

Training iteration:  37%|███▋      | 374/1001 [12:27<13:29,  1.29s/it, avg loss=147.6679]
Training iteration:  37%|███▋      | 375/1001 [12:27<13:27,  1.29s/it, avg loss=147.6679]Checkpoint at iteration 375 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 147.6678680419922

Training iteration:  37%|███▋      | 375/1001 [12:29<13:27,  1.29s/it, avg loss=281.3958]
Training iteration:  38%|███▊      | 376/1001 [12:29<13:27,  1.29s/it, avg loss=281.3958]Checkpoint at iteration 376 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 281.3958312988281

Training iteration:  38%|███▊      | 376/1001 [12:30<13:27,  1.29s/it, avg loss=152.3349]
Training iteration:  38%|███▊      | 377/1001 [12:30<13:25,  1.29s/it, avg loss=152.3349]Checkpoint at iteration 377 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 152.33492584228514

Training iteration:  38%|███▊      | 377/1001 [12:31<13:25,  1.29s/it, avg loss=281.8175]
Training iteration:  38%|███▊      | 378/1001 [12:31<13:24,  1.29s/it, avg loss=281.8175]Checkpoint at iteration 378 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 281.8175018310547

Training iteration:  38%|███▊      | 378/1001 [12:32<13:24,  1.29s/it, avg loss=154.9064]
Training iteration:  38%|███▊      | 379/1001 [12:32<13:23,  1.29s/it, avg loss=154.9064]Checkpoint at iteration 379 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 154.90639038085936

Training iteration:  38%|███▊      | 379/1001 [12:34<13:23,  1.29s/it, avg loss=275.8629]
Training iteration:  38%|███▊      | 380/1001 [12:34<13:22,  1.29s/it, avg loss=275.8629]Checkpoint at iteration 380 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 275.8629455566406

Training iteration:  38%|███▊      | 380/1001 [12:35<13:22,  1.29s/it, avg loss=280.9579]
Training iteration:  38%|███▊      | 381/1001 [12:35<13:20,  1.29s/it, avg loss=280.9579]Checkpoint at iteration 381 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 280.9578689575195

Training iteration:  38%|███▊      | 381/1001 [12:36<13:20,  1.29s/it, avg loss=158.5227]
Training iteration:  38%|███▊      | 382/1001 [12:36<13:19,  1.29s/it, avg loss=158.5227]Checkpoint at iteration 382 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 158.52268676757814

Training iteration:  38%|███▊      | 382/1001 [12:38<13:19,  1.29s/it, avg loss=280.6855]
Training iteration:  38%|███▊      | 383/1001 [12:38<13:17,  1.29s/it, avg loss=280.6855]Checkpoint at iteration 383 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 280.685481262207

Training iteration:  38%|███▊      | 383/1001 [12:39<13:17,  1.29s/it, avg loss=277.0471]
Training iteration:  38%|███▊      | 384/1001 [12:39<13:16,  1.29s/it, avg loss=277.0471]Checkpoint at iteration 384 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 277.0470657348633

Training iteration:  38%|███▊      | 384/1001 [12:40<13:16,  1.29s/it, avg loss=156.3482]
Training iteration:  38%|███▊      | 385/1001 [12:40<13:15,  1.29s/it, avg loss=156.3482]Checkpoint at iteration 385 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 156.3482208251953

Training iteration:  38%|███▊      | 385/1001 [12:42<13:15,  1.29s/it, avg loss=279.1023]
Training iteration:  39%|███▊      | 386/1001 [12:42<13:14,  1.29s/it, avg loss=279.1023]Checkpoint at iteration 386 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 279.10226287841795

Training iteration:  39%|███▊      | 386/1001 [12:43<13:14,  1.29s/it, avg loss=275.4130]
Training iteration:  39%|███▊      | 387/1001 [12:43<13:12,  1.29s/it, avg loss=275.4130]Checkpoint at iteration 387 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 275.4130004882812

Training iteration:  39%|███▊      | 387/1001 [12:44<13:12,  1.29s/it, avg loss=272.7163]
Training iteration:  39%|███▉      | 388/1001 [12:44<13:11,  1.29s/it, avg loss=272.7163]Checkpoint at iteration 388 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 272.71627349853514

Training iteration:  39%|███▉      | 388/1001 [12:45<13:11,  1.29s/it, avg loss=272.3071]
Training iteration:  39%|███▉      | 389/1001 [12:45<13:10,  1.29s/it, avg loss=272.3071]Checkpoint at iteration 389 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 272.30712738037107

Training iteration:  39%|███▉      | 389/1001 [12:47<13:10,  1.29s/it, avg loss=279.0882]
Training iteration:  39%|███▉      | 390/1001 [12:47<13:09,  1.29s/it, avg loss=279.0882]Checkpoint at iteration 390 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 279.0882141113281

Training iteration:  39%|███▉      | 390/1001 [12:48<13:09,  1.29s/it, avg loss=155.3004]
Training iteration:  39%|███▉      | 391/1001 [12:48<13:08,  1.29s/it, avg loss=155.3004]Checkpoint at iteration 391 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 155.30043029785156

Training iteration:  39%|███▉      | 391/1001 [12:49<13:08,  1.29s/it, avg loss=274.4778]
Training iteration:  39%|███▉      | 392/1001 [12:49<13:06,  1.29s/it, avg loss=274.4778]Checkpoint at iteration 392 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 274.4778091430664

Training iteration:  39%|███▉      | 392/1001 [12:51<13:06,  1.29s/it, avg loss=156.4844]
Training iteration:  39%|███▉      | 393/1001 [12:51<13:04,  1.29s/it, avg loss=156.4844]Checkpoint at iteration 393 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 156.4844192504883

Training iteration:  39%|███▉      | 393/1001 [12:52<13:04,  1.29s/it, avg loss=275.0705]
Training iteration:  39%|███▉      | 394/1001 [12:52<13:03,  1.29s/it, avg loss=275.0705]Checkpoint at iteration 394 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 275.07045593261716

Training iteration:  39%|███▉      | 394/1001 [12:53<13:03,  1.29s/it, avg loss=277.7218]
Training iteration:  39%|███▉      | 395/1001 [12:53<13:02,  1.29s/it, avg loss=277.7218]Checkpoint at iteration 395 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 277.7217559814453

Training iteration:  39%|███▉      | 395/1001 [12:54<13:02,  1.29s/it, avg loss=270.5144]
Training iteration:  40%|███▉      | 396/1001 [12:54<13:00,  1.29s/it, avg loss=270.5144]Checkpoint at iteration 396 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 270.51442565917966

Training iteration:  40%|███▉      | 396/1001 [12:56<13:00,  1.29s/it, avg loss=276.6975]
Training iteration:  40%|███▉      | 397/1001 [12:56<12:58,  1.29s/it, avg loss=276.6975]Checkpoint at iteration 397 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 276.6974899291992

Training iteration:  40%|███▉      | 397/1001 [12:57<12:58,  1.29s/it, avg loss=152.4990]
Training iteration:  40%|███▉      | 398/1001 [12:57<12:57,  1.29s/it, avg loss=152.4990]Checkpoint at iteration 398 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 152.49899291992188

Training iteration:  40%|███▉      | 398/1001 [12:58<12:57,  1.29s/it, avg loss=158.6851]
Training iteration:  40%|███▉      | 399/1001 [12:58<12:55,  1.29s/it, avg loss=158.6851]Checkpoint at iteration 399 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 158.68512725830078

Training iteration:  40%|███▉      | 399/1001 [13:00<12:55,  1.29s/it, avg loss=158.3512]
Training iteration:  40%|███▉      | 400/1001 [13:00<12:54,  1.29s/it, avg loss=158.3512]Optimization iteration 400 evaluation begins...
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
A new evaluation visualization has been saved: ./saved_data/20240110-050655/it400.png
Training network 0 for evaluation...
Training network 1 for evaluation...
Training network 2 for evaluation...
Training network 3 for evaluation...
Testing network 0 on real datasets for evaluation...
Testing network 1 on real datasets for evaluation...
Testing network 2 on real datasets for evaluation...
Testing network 3 on real datasets for evaluation...
Optimization iteration 400, eval auroc score (train): 36188.4463, eval auroc score (test): 37546.0435
Checkpoint at iteration 400 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 158.3512161254883

Training iteration:  40%|███▉      | 400/1001 [17:12<12:54,  1.29s/it, avg loss=274.8227]
Training iteration:  40%|████      | 401/1001 [17:12<12:46:45, 76.68s/it, avg loss=274.8227]Checkpoint at iteration 401 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 274.8226593017578

Training iteration:  40%|████      | 401/1001 [17:14<12:46:45, 76.68s/it, avg loss=153.1118]
Training iteration:  40%|████      | 402/1001 [17:14<9:00:18, 54.12s/it, avg loss=153.1118] Checkpoint at iteration 402 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 153.11175537109375

Training iteration:  40%|████      | 402/1001 [17:15<9:00:18, 54.12s/it, avg loss=276.1584]
Training iteration:  40%|████      | 403/1001 [17:15<6:22:02, 38.33s/it, avg loss=276.1584]Checkpoint at iteration 403 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 276.15842895507814

Training iteration:  40%|████      | 403/1001 [17:17<6:22:02, 38.33s/it, avg loss=275.1446]
Training iteration:  40%|████      | 404/1001 [17:17<4:31:26, 27.28s/it, avg loss=275.1446]Checkpoint at iteration 404 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 275.14464874267577

Training iteration:  40%|████      | 404/1001 [17:18<4:31:26, 27.28s/it, avg loss=156.0209]
Training iteration:  40%|████      | 405/1001 [17:18<3:14:08, 19.54s/it, avg loss=156.0209]Checkpoint at iteration 405 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 156.020947265625

Training iteration:  40%|████      | 405/1001 [17:20<3:14:08, 19.54s/it, avg loss=155.2773]
Training iteration:  41%|████      | 406/1001 [17:20<2:20:06, 14.13s/it, avg loss=155.2773]Checkpoint at iteration 406 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 155.27728424072265

Training iteration:  41%|████      | 406/1001 [17:21<2:20:06, 14.13s/it, avg loss=288.6223]
Training iteration:  41%|████      | 407/1001 [17:21<1:42:20, 10.34s/it, avg loss=288.6223]Checkpoint at iteration 407 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 288.6223419189453

Training iteration:  41%|████      | 407/1001 [17:23<1:42:20, 10.34s/it, avg loss=277.6011]
Training iteration:  41%|████      | 408/1001 [17:23<1:15:56,  7.68s/it, avg loss=277.6011]Checkpoint at iteration 408 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 277.60111846923826

Training iteration:  41%|████      | 408/1001 [17:24<1:15:56,  7.68s/it, avg loss=278.5504]
Training iteration:  41%|████      | 409/1001 [17:24<57:29,  5.83s/it, avg loss=278.5504]  Checkpoint at iteration 409 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 278.5503952026367

Training iteration:  41%|████      | 409/1001 [17:26<57:29,  5.83s/it, avg loss=277.2976]
Training iteration:  41%|████      | 410/1001 [17:26<44:35,  4.53s/it, avg loss=277.2976]Checkpoint at iteration 410 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 277.29762878417966

Training iteration:  41%|████      | 410/1001 [17:27<44:35,  4.53s/it, avg loss=165.1185]
Training iteration:  41%|████      | 411/1001 [17:27<35:34,  3.62s/it, avg loss=165.1185]Checkpoint at iteration 411 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 165.1185287475586

Training iteration:  41%|████      | 411/1001 [17:29<35:34,  3.62s/it, avg loss=213.9359]
Training iteration:  41%|████      | 412/1001 [17:29<29:15,  2.98s/it, avg loss=213.9359]Checkpoint at iteration 412 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 213.9359161376953

Training iteration:  41%|████      | 412/1001 [17:30<29:15,  2.98s/it, avg loss=277.7618]
Training iteration:  41%|████▏     | 413/1001 [17:30<24:50,  2.53s/it, avg loss=277.7618]Checkpoint at iteration 413 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 277.76177368164065

Training iteration:  41%|████▏     | 413/1001 [17:32<24:50,  2.53s/it, avg loss=167.2326]
Training iteration:  41%|████▏     | 414/1001 [17:32<21:44,  2.22s/it, avg loss=167.2326]Checkpoint at iteration 414 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 167.23255462646483

Training iteration:  41%|████▏     | 414/1001 [17:33<21:44,  2.22s/it, avg loss=210.4177]
Training iteration:  41%|████▏     | 415/1001 [17:33<19:34,  2.00s/it, avg loss=210.4177]Checkpoint at iteration 415 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 210.4177215576172

Training iteration:  41%|████▏     | 415/1001 [17:35<19:34,  2.00s/it, avg loss=161.9318]
Training iteration:  42%|████▏     | 416/1001 [17:35<18:02,  1.85s/it, avg loss=161.9318]Checkpoint at iteration 416 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 161.931787109375

Training iteration:  42%|████▏     | 416/1001 [17:36<18:02,  1.85s/it, avg loss=280.2687]
Training iteration:  42%|████▏     | 417/1001 [17:36<16:57,  1.74s/it, avg loss=280.2687]Checkpoint at iteration 417 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 280.2687103271484

Training iteration:  42%|████▏     | 417/1001 [17:38<16:57,  1.74s/it, avg loss=151.2386]
Training iteration:  42%|████▏     | 418/1001 [17:38<16:12,  1.67s/it, avg loss=151.2386]Checkpoint at iteration 418 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 151.23861694335938

Training iteration:  42%|████▏     | 418/1001 [17:39<16:12,  1.67s/it, avg loss=271.3622]
Training iteration:  42%|████▏     | 419/1001 [17:39<15:40,  1.62s/it, avg loss=271.3622]Checkpoint at iteration 419 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 271.362158203125

Training iteration:  42%|████▏     | 419/1001 [17:41<15:40,  1.62s/it, avg loss=273.1482]
Training iteration:  42%|████▏     | 420/1001 [17:41<15:18,  1.58s/it, avg loss=273.1482]Checkpoint at iteration 420 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 273.1482238769531

Training iteration:  42%|████▏     | 420/1001 [17:42<15:18,  1.58s/it, avg loss=156.6854]
Training iteration:  42%|████▏     | 421/1001 [17:42<15:01,  1.55s/it, avg loss=156.6854]Checkpoint at iteration 421 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 156.68542022705077

Training iteration:  42%|████▏     | 421/1001 [17:44<15:01,  1.55s/it, avg loss=278.6695]
Training iteration:  42%|████▏     | 422/1001 [17:44<14:49,  1.54s/it, avg loss=278.6695]Checkpoint at iteration 422 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 278.6695266723633

Training iteration:  42%|████▏     | 422/1001 [17:45<14:49,  1.54s/it, avg loss=283.0620]
Training iteration:  42%|████▏     | 423/1001 [17:45<14:40,  1.52s/it, avg loss=283.0620]Checkpoint at iteration 423 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 283.0620361328125

Training iteration:  42%|████▏     | 423/1001 [17:47<14:40,  1.52s/it, avg loss=279.3532]
Training iteration:  42%|████▏     | 424/1001 [17:47<14:33,  1.51s/it, avg loss=279.3532]Checkpoint at iteration 424 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 279.35316772460936

Training iteration:  42%|████▏     | 424/1001 [17:48<14:33,  1.51s/it, avg loss=162.9305]
Training iteration:  42%|████▏     | 425/1001 [17:48<14:28,  1.51s/it, avg loss=162.9305]Checkpoint at iteration 425 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 162.93053436279297

Training iteration:  42%|████▏     | 425/1001 [17:50<14:28,  1.51s/it, avg loss=273.0024]
Training iteration:  43%|████▎     | 426/1001 [17:50<14:25,  1.50s/it, avg loss=273.0024]Checkpoint at iteration 426 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 273.0023590087891

Training iteration:  43%|████▎     | 426/1001 [17:51<14:25,  1.50s/it, avg loss=165.4014]
Training iteration:  43%|████▎     | 427/1001 [17:51<14:21,  1.50s/it, avg loss=165.4014]Checkpoint at iteration 427 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 165.40137329101563

Training iteration:  43%|████▎     | 427/1001 [17:52<14:21,  1.50s/it, avg loss=274.4406]
Training iteration:  43%|████▎     | 428/1001 [17:52<14:19,  1.50s/it, avg loss=274.4406]Checkpoint at iteration 428 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 274.4405578613281

Training iteration:  43%|████▎     | 428/1001 [17:54<14:19,  1.50s/it, avg loss=270.6353]
Training iteration:  43%|████▎     | 429/1001 [17:54<14:16,  1.50s/it, avg loss=270.6353]Checkpoint at iteration 429 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 270.63531188964845

Training iteration:  43%|████▎     | 429/1001 [17:55<14:16,  1.50s/it, avg loss=157.0402]
Training iteration:  43%|████▎     | 430/1001 [17:55<14:14,  1.50s/it, avg loss=157.0402]Checkpoint at iteration 430 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 157.04015502929687

Training iteration:  43%|████▎     | 430/1001 [17:57<14:14,  1.50s/it, avg loss=284.0478]
Training iteration:  43%|████▎     | 431/1001 [17:57<14:12,  1.50s/it, avg loss=284.0478]Checkpoint at iteration 431 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 284.04775085449216

Training iteration:  43%|████▎     | 431/1001 [17:58<14:12,  1.50s/it, avg loss=165.6986]
Training iteration:  43%|████▎     | 432/1001 [17:58<14:10,  1.49s/it, avg loss=165.6986]Checkpoint at iteration 432 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 165.69862670898436

Training iteration:  43%|████▎     | 432/1001 [18:00<14:10,  1.49s/it, avg loss=269.1969]
Training iteration:  43%|████▎     | 433/1001 [18:00<14:08,  1.49s/it, avg loss=269.1969]Checkpoint at iteration 433 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 269.19691009521483

Training iteration:  43%|████▎     | 433/1001 [18:01<14:08,  1.49s/it, avg loss=160.6272]
Training iteration:  43%|████▎     | 434/1001 [18:01<14:06,  1.49s/it, avg loss=160.6272]Checkpoint at iteration 434 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 160.6271957397461

Training iteration:  43%|████▎     | 434/1001 [18:03<14:06,  1.49s/it, avg loss=156.5074]
Training iteration:  43%|████▎     | 435/1001 [18:03<14:05,  1.49s/it, avg loss=156.5074]Checkpoint at iteration 435 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 156.5074264526367

Training iteration:  43%|████▎     | 435/1001 [18:04<14:05,  1.49s/it, avg loss=157.4842]
Training iteration:  44%|████▎     | 436/1001 [18:04<14:03,  1.49s/it, avg loss=157.4842]Checkpoint at iteration 436 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 157.48421936035157

Training iteration:  44%|████▎     | 436/1001 [18:06<14:03,  1.49s/it, avg loss=270.6381]
Training iteration:  44%|████▎     | 437/1001 [18:06<14:02,  1.49s/it, avg loss=270.6381]Checkpoint at iteration 437 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 270.63807220458983

Training iteration:  44%|████▎     | 437/1001 [18:07<14:02,  1.49s/it, avg loss=173.2979]
Training iteration:  44%|████▍     | 438/1001 [18:07<14:00,  1.49s/it, avg loss=173.2979]Checkpoint at iteration 438 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 173.29790191650392

Training iteration:  44%|████▍     | 438/1001 [18:09<14:00,  1.49s/it, avg loss=156.9950]
Training iteration:  44%|████▍     | 439/1001 [18:09<13:59,  1.49s/it, avg loss=156.9950]Checkpoint at iteration 439 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 156.9949523925781

Training iteration:  44%|████▍     | 439/1001 [18:10<13:59,  1.49s/it, avg loss=149.9618]
Training iteration:  44%|████▍     | 440/1001 [18:10<13:58,  1.49s/it, avg loss=149.9618]Checkpoint at iteration 440 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 149.96175994873047

Training iteration:  44%|████▍     | 440/1001 [18:12<13:58,  1.49s/it, avg loss=280.2156]
Training iteration:  44%|████▍     | 441/1001 [18:12<13:56,  1.49s/it, avg loss=280.2156]Checkpoint at iteration 441 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 280.21561126708986

Training iteration:  44%|████▍     | 441/1001 [18:13<13:56,  1.49s/it, avg loss=150.0385]
Training iteration:  44%|████▍     | 442/1001 [18:13<13:54,  1.49s/it, avg loss=150.0385]Checkpoint at iteration 442 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 150.0384780883789

Training iteration:  44%|████▍     | 442/1001 [18:15<13:54,  1.49s/it, avg loss=275.7558]
Training iteration:  44%|████▍     | 443/1001 [18:15<13:52,  1.49s/it, avg loss=275.7558]Checkpoint at iteration 443 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 275.7557769775391

Training iteration:  44%|████▍     | 443/1001 [18:16<13:52,  1.49s/it, avg loss=287.4894]
Training iteration:  44%|████▍     | 444/1001 [18:16<13:51,  1.49s/it, avg loss=287.4894]Checkpoint at iteration 444 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 287.4893524169922

Training iteration:  44%|████▍     | 444/1001 [18:18<13:51,  1.49s/it, avg loss=159.9175]
Training iteration:  44%|████▍     | 445/1001 [18:18<13:50,  1.49s/it, avg loss=159.9175]Checkpoint at iteration 445 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 159.9175048828125

Training iteration:  44%|████▍     | 445/1001 [18:19<13:50,  1.49s/it, avg loss=275.2387]
Training iteration:  45%|████▍     | 446/1001 [18:19<13:48,  1.49s/it, avg loss=275.2387]Checkpoint at iteration 446 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 275.23870849609375

Training iteration:  45%|████▍     | 446/1001 [18:21<13:48,  1.49s/it, avg loss=280.9825]
Training iteration:  45%|████▍     | 447/1001 [18:21<13:47,  1.49s/it, avg loss=280.9825]Checkpoint at iteration 447 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 280.9824920654297

Training iteration:  45%|████▍     | 447/1001 [18:22<13:47,  1.49s/it, avg loss=274.2072]
Training iteration:  45%|████▍     | 448/1001 [18:22<13:45,  1.49s/it, avg loss=274.2072]Checkpoint at iteration 448 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 274.207209777832

Training iteration:  45%|████▍     | 448/1001 [18:24<13:45,  1.49s/it, avg loss=155.7282]
Training iteration:  45%|████▍     | 449/1001 [18:24<13:44,  1.49s/it, avg loss=155.7282]Checkpoint at iteration 449 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 155.72816009521483

Training iteration:  45%|████▍     | 449/1001 [18:25<13:44,  1.49s/it, avg loss=159.1222]
Training iteration:  45%|████▍     | 450/1001 [18:25<13:42,  1.49s/it, avg loss=159.1222]Checkpoint at iteration 450 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 159.12224578857422

Training iteration:  45%|████▍     | 450/1001 [18:27<13:42,  1.49s/it, avg loss=283.1663]
Training iteration:  45%|████▌     | 451/1001 [18:27<13:40,  1.49s/it, avg loss=283.1663]Checkpoint at iteration 451 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 283.1662826538086

Training iteration:  45%|████▌     | 451/1001 [18:28<13:40,  1.49s/it, avg loss=272.5255]
Training iteration:  45%|████▌     | 452/1001 [18:28<13:39,  1.49s/it, avg loss=272.5255]Checkpoint at iteration 452 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 272.5254821777344

Training iteration:  45%|████▌     | 452/1001 [18:30<13:39,  1.49s/it, avg loss=276.4911]
Training iteration:  45%|████▌     | 453/1001 [18:30<13:37,  1.49s/it, avg loss=276.4911]Checkpoint at iteration 453 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 276.491064453125

Training iteration:  45%|████▌     | 453/1001 [18:31<13:37,  1.49s/it, avg loss=275.9371]
Training iteration:  45%|████▌     | 454/1001 [18:31<13:35,  1.49s/it, avg loss=275.9371]Checkpoint at iteration 454 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 275.9371139526367

Training iteration:  45%|████▌     | 454/1001 [18:33<13:35,  1.49s/it, avg loss=157.7154]
Training iteration:  45%|████▌     | 455/1001 [18:33<13:34,  1.49s/it, avg loss=157.7154]Checkpoint at iteration 455 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 157.71544647216797

Training iteration:  45%|████▌     | 455/1001 [18:34<13:34,  1.49s/it, avg loss=163.1732]
Training iteration:  46%|████▌     | 456/1001 [18:34<13:32,  1.49s/it, avg loss=163.1732]Checkpoint at iteration 456 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 163.173193359375

Training iteration:  46%|████▌     | 456/1001 [18:36<13:32,  1.49s/it, avg loss=156.7530]
Training iteration:  46%|████▌     | 457/1001 [18:36<13:31,  1.49s/it, avg loss=156.7530]Checkpoint at iteration 457 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 156.75296020507812

Training iteration:  46%|████▌     | 457/1001 [18:37<13:31,  1.49s/it, avg loss=148.9091]
Training iteration:  46%|████▌     | 458/1001 [18:37<13:30,  1.49s/it, avg loss=148.9091]Checkpoint at iteration 458 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 148.9091049194336

Training iteration:  46%|████▌     | 458/1001 [18:39<13:30,  1.49s/it, avg loss=152.0409]
Training iteration:  46%|████▌     | 459/1001 [18:39<13:27,  1.49s/it, avg loss=152.0409]Checkpoint at iteration 459 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 152.04086151123047

Training iteration:  46%|████▌     | 459/1001 [18:40<13:27,  1.49s/it, avg loss=280.7754]
Training iteration:  46%|████▌     | 460/1001 [18:40<13:23,  1.49s/it, avg loss=280.7754]Checkpoint at iteration 460 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 280.77539978027346

Training iteration:  46%|████▌     | 460/1001 [18:42<13:23,  1.49s/it, avg loss=279.6318]
Training iteration:  46%|████▌     | 461/1001 [18:42<13:21,  1.48s/it, avg loss=279.6318]Checkpoint at iteration 461 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 279.63182525634767

Training iteration:  46%|████▌     | 461/1001 [18:43<13:21,  1.48s/it, avg loss=276.2110]
Training iteration:  46%|████▌     | 462/1001 [18:43<13:18,  1.48s/it, avg loss=276.2110]Checkpoint at iteration 462 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 276.21095123291013

Training iteration:  46%|████▌     | 462/1001 [18:45<13:18,  1.48s/it, avg loss=157.5109]
Training iteration:  46%|████▋     | 463/1001 [18:45<13:16,  1.48s/it, avg loss=157.5109]Checkpoint at iteration 463 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 157.51089172363282

Training iteration:  46%|████▋     | 463/1001 [18:46<13:16,  1.48s/it, avg loss=154.3042]
Training iteration:  46%|████▋     | 464/1001 [18:46<13:14,  1.48s/it, avg loss=154.3042]Checkpoint at iteration 464 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 154.30419921875

Training iteration:  46%|████▋     | 464/1001 [18:48<13:14,  1.48s/it, avg loss=152.3638]
Training iteration:  46%|████▋     | 465/1001 [18:48<13:12,  1.48s/it, avg loss=152.3638]Checkpoint at iteration 465 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 152.3637680053711

Training iteration:  46%|████▋     | 465/1001 [18:49<13:12,  1.48s/it, avg loss=283.3314]
Training iteration:  47%|████▋     | 466/1001 [18:49<13:10,  1.48s/it, avg loss=283.3314]Checkpoint at iteration 466 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 283.3314453125

Training iteration:  47%|████▋     | 466/1001 [18:51<13:10,  1.48s/it, avg loss=278.2199]
Training iteration:  47%|████▋     | 467/1001 [18:51<13:08,  1.48s/it, avg loss=278.2199]Checkpoint at iteration 467 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 278.21988372802736

Training iteration:  47%|████▋     | 467/1001 [18:52<13:08,  1.48s/it, avg loss=280.6782]
Training iteration:  47%|████▋     | 468/1001 [18:52<13:07,  1.48s/it, avg loss=280.6782]Checkpoint at iteration 468 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 280.67823028564453

Training iteration:  47%|████▋     | 468/1001 [18:54<13:07,  1.48s/it, avg loss=161.1985]
Training iteration:  47%|████▋     | 469/1001 [18:54<13:05,  1.48s/it, avg loss=161.1985]Checkpoint at iteration 469 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 161.1984893798828

Training iteration:  47%|████▋     | 469/1001 [18:55<13:05,  1.48s/it, avg loss=275.6752]
Training iteration:  47%|████▋     | 470/1001 [18:55<13:04,  1.48s/it, avg loss=275.6752]Checkpoint at iteration 470 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 275.6751541137695

Training iteration:  47%|████▋     | 470/1001 [18:56<13:04,  1.48s/it, avg loss=285.5639]
Training iteration:  47%|████▋     | 471/1001 [18:56<13:02,  1.48s/it, avg loss=285.5639]Checkpoint at iteration 471 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 285.5639389038086

Training iteration:  47%|████▋     | 471/1001 [18:58<13:02,  1.48s/it, avg loss=155.1870]
Training iteration:  47%|████▋     | 472/1001 [18:58<13:01,  1.48s/it, avg loss=155.1870]Checkpoint at iteration 472 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 155.1870101928711

Training iteration:  47%|████▋     | 472/1001 [18:59<13:01,  1.48s/it, avg loss=154.1827]
Training iteration:  47%|████▋     | 473/1001 [18:59<12:59,  1.48s/it, avg loss=154.1827]Checkpoint at iteration 473 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 154.1827163696289

Training iteration:  47%|████▋     | 473/1001 [19:01<12:59,  1.48s/it, avg loss=153.8701]
Training iteration:  47%|████▋     | 474/1001 [19:01<12:58,  1.48s/it, avg loss=153.8701]Checkpoint at iteration 474 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 153.8701141357422

Training iteration:  47%|████▋     | 474/1001 [19:02<12:58,  1.48s/it, avg loss=279.6964]
Training iteration:  47%|████▋     | 475/1001 [19:02<12:57,  1.48s/it, avg loss=279.6964]Checkpoint at iteration 475 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 279.6964401245117

Training iteration:  47%|████▋     | 475/1001 [19:04<12:57,  1.48s/it, avg loss=284.6612]
Training iteration:  48%|████▊     | 476/1001 [19:04<12:55,  1.48s/it, avg loss=284.6612]Checkpoint at iteration 476 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 284.6612243652344

Training iteration:  48%|████▊     | 476/1001 [19:05<12:55,  1.48s/it, avg loss=155.5353]
Training iteration:  48%|████▊     | 477/1001 [19:05<12:53,  1.48s/it, avg loss=155.5353]Checkpoint at iteration 477 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 155.53527374267577

Training iteration:  48%|████▊     | 477/1001 [19:07<12:53,  1.48s/it, avg loss=149.3095]
Training iteration:  48%|████▊     | 478/1001 [19:07<12:53,  1.48s/it, avg loss=149.3095]Checkpoint at iteration 478 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 149.30947570800782

Training iteration:  48%|████▊     | 478/1001 [19:08<12:53,  1.48s/it, avg loss=275.4892]
Training iteration:  48%|████▊     | 479/1001 [19:08<12:51,  1.48s/it, avg loss=275.4892]Checkpoint at iteration 479 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 275.48922576904295

Training iteration:  48%|████▊     | 479/1001 [19:10<12:51,  1.48s/it, avg loss=279.6737]
Training iteration:  48%|████▊     | 480/1001 [19:10<12:49,  1.48s/it, avg loss=279.6737]Checkpoint at iteration 480 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 279.67369842529297

Training iteration:  48%|████▊     | 480/1001 [19:11<12:49,  1.48s/it, avg loss=282.6585]
Training iteration:  48%|████▊     | 481/1001 [19:11<12:48,  1.48s/it, avg loss=282.6585]Checkpoint at iteration 481 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 282.6585235595703

Training iteration:  48%|████▊     | 481/1001 [19:13<12:48,  1.48s/it, avg loss=283.8235]
Training iteration:  48%|████▊     | 482/1001 [19:13<12:46,  1.48s/it, avg loss=283.8235]Checkpoint at iteration 482 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 283.82347259521487

Training iteration:  48%|████▊     | 482/1001 [19:14<12:46,  1.48s/it, avg loss=271.0211]
Training iteration:  48%|████▊     | 483/1001 [19:14<12:44,  1.48s/it, avg loss=271.0211]Checkpoint at iteration 483 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 271.02109375

Training iteration:  48%|████▊     | 483/1001 [19:16<12:44,  1.48s/it, avg loss=166.4788]
Training iteration:  48%|████▊     | 484/1001 [19:16<12:43,  1.48s/it, avg loss=166.4788]Checkpoint at iteration 484 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 166.47879486083986

Training iteration:  48%|████▊     | 484/1001 [19:17<12:43,  1.48s/it, avg loss=272.6858]
Training iteration:  48%|████▊     | 485/1001 [19:17<12:42,  1.48s/it, avg loss=272.6858]Checkpoint at iteration 485 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 272.68577880859374

Training iteration:  48%|████▊     | 485/1001 [19:19<12:42,  1.48s/it, avg loss=159.6594]
Training iteration:  49%|████▊     | 486/1001 [19:19<12:40,  1.48s/it, avg loss=159.6594]Checkpoint at iteration 486 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 159.65938568115234

Training iteration:  49%|████▊     | 486/1001 [19:20<12:40,  1.48s/it, avg loss=155.6080]
Training iteration:  49%|████▊     | 487/1001 [19:20<12:39,  1.48s/it, avg loss=155.6080]Checkpoint at iteration 487 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 155.60798187255858

Training iteration:  49%|████▊     | 487/1001 [19:22<12:39,  1.48s/it, avg loss=277.5501]
Training iteration:  49%|████▉     | 488/1001 [19:22<12:37,  1.48s/it, avg loss=277.5501]Checkpoint at iteration 488 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 277.5501251220703

Training iteration:  49%|████▉     | 488/1001 [19:23<12:37,  1.48s/it, avg loss=159.1037]
Training iteration:  49%|████▉     | 489/1001 [19:23<12:35,  1.48s/it, avg loss=159.1037]Checkpoint at iteration 489 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 159.10367584228516

Training iteration:  49%|████▉     | 489/1001 [19:25<12:35,  1.48s/it, avg loss=275.7184]
Training iteration:  49%|████▉     | 490/1001 [19:25<12:34,  1.48s/it, avg loss=275.7184]Checkpoint at iteration 490 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 275.71840209960936

Training iteration:  49%|████▉     | 490/1001 [19:26<12:34,  1.48s/it, avg loss=156.3525]
Training iteration:  49%|████▉     | 491/1001 [19:26<12:32,  1.48s/it, avg loss=156.3525]Checkpoint at iteration 491 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 156.35250701904297

Training iteration:  49%|████▉     | 491/1001 [19:27<12:32,  1.48s/it, avg loss=280.2157]
Training iteration:  49%|████▉     | 492/1001 [19:27<12:30,  1.48s/it, avg loss=280.2157]Checkpoint at iteration 492 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 280.21567993164064

Training iteration:  49%|████▉     | 492/1001 [19:29<12:30,  1.48s/it, avg loss=279.2423]
Training iteration:  49%|████▉     | 493/1001 [19:29<12:29,  1.48s/it, avg loss=279.2423]Checkpoint at iteration 493 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 279.2422897338867

Training iteration:  49%|████▉     | 493/1001 [19:30<12:29,  1.48s/it, avg loss=275.6028]
Training iteration:  49%|████▉     | 494/1001 [19:30<12:28,  1.48s/it, avg loss=275.6028]Checkpoint at iteration 494 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 275.602848815918

Training iteration:  49%|████▉     | 494/1001 [19:32<12:28,  1.48s/it, avg loss=158.2429]
Training iteration:  49%|████▉     | 495/1001 [19:32<12:27,  1.48s/it, avg loss=158.2429]Checkpoint at iteration 495 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 158.24290161132814

Training iteration:  49%|████▉     | 495/1001 [19:33<12:27,  1.48s/it, avg loss=273.5853]
Training iteration:  50%|████▉     | 496/1001 [19:33<12:25,  1.48s/it, avg loss=273.5853]Checkpoint at iteration 496 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 273.5852813720703

Training iteration:  50%|████▉     | 496/1001 [19:35<12:25,  1.48s/it, avg loss=273.0189]
Training iteration:  50%|████▉     | 497/1001 [19:35<12:24,  1.48s/it, avg loss=273.0189]Checkpoint at iteration 497 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 273.0189041137695

Training iteration:  50%|████▉     | 497/1001 [19:36<12:24,  1.48s/it, avg loss=275.2487]
Training iteration:  50%|████▉     | 498/1001 [19:36<12:22,  1.48s/it, avg loss=275.2487]Checkpoint at iteration 498 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 275.24874725341795

Training iteration:  50%|████▉     | 498/1001 [19:38<12:22,  1.48s/it, avg loss=157.8915]
Training iteration:  50%|████▉     | 499/1001 [19:38<12:21,  1.48s/it, avg loss=157.8915]Checkpoint at iteration 499 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 157.89149169921876

Training iteration:  50%|████▉     | 499/1001 [19:39<12:21,  1.48s/it, avg loss=159.2321]
Training iteration:  50%|████▉     | 500/1001 [19:39<12:19,  1.48s/it, avg loss=159.2321]Optimization iteration 500 evaluation begins...
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
A new evaluation visualization has been saved: ./saved_data/20240110-050655/it500.png
Training network 0 for evaluation...
Training network 1 for evaluation...
Training network 2 for evaluation...
Training network 3 for evaluation...
Testing network 0 on real datasets for evaluation...
Testing network 1 on real datasets for evaluation...
Testing network 2 on real datasets for evaluation...
Testing network 3 on real datasets for evaluation...
Optimization iteration 500, eval auroc score (train): 35951.3406, eval auroc score (test): 37340.2446
Checkpoint at iteration 500 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 159.23209228515626

Training iteration:  50%|████▉     | 500/1001 [25:07<12:19,  1.48s/it, avg loss=158.8362]
Training iteration:  50%|█████     | 501/1001 [25:07<13:48:50, 99.46s/it, avg loss=158.8362]Checkpoint at iteration 501 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 158.8362060546875

Training iteration:  50%|█████     | 501/1001 [25:09<13:48:50, 99.46s/it, avg loss=278.6476]
Training iteration:  50%|█████     | 502/1001 [25:09<9:43:16, 70.13s/it, avg loss=278.6476] Checkpoint at iteration 502 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 278.6476119995117

Training iteration:  50%|█████     | 502/1001 [25:11<9:43:16, 70.13s/it, avg loss=276.8846]
Training iteration:  50%|█████     | 503/1001 [25:11<6:51:42, 49.60s/it, avg loss=276.8846]Checkpoint at iteration 503 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 276.8845687866211

Training iteration:  50%|█████     | 503/1001 [25:12<6:51:42, 49.60s/it, avg loss=162.0237]
Training iteration:  50%|█████     | 504/1001 [25:12<4:51:50, 35.23s/it, avg loss=162.0237]Checkpoint at iteration 504 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 162.0236801147461

Training iteration:  50%|█████     | 504/1001 [25:14<4:51:50, 35.23s/it, avg loss=282.8707]
Training iteration:  50%|█████     | 505/1001 [25:14<3:28:06, 25.17s/it, avg loss=282.8707]Checkpoint at iteration 505 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 282.8706802368164

Training iteration:  50%|█████     | 505/1001 [25:16<3:28:06, 25.17s/it, avg loss=277.1933]
Training iteration:  51%|█████     | 506/1001 [25:16<2:29:35, 18.13s/it, avg loss=277.1933]Checkpoint at iteration 506 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 277.1932647705078

Training iteration:  51%|█████     | 506/1001 [25:18<2:29:35, 18.13s/it, avg loss=271.1231]
Training iteration:  51%|█████     | 507/1001 [25:18<1:48:42, 13.20s/it, avg loss=271.1231]Checkpoint at iteration 507 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 271.12313079833984

Training iteration:  51%|█████     | 507/1001 [25:19<1:48:42, 13.20s/it, avg loss=274.0798]
Training iteration:  51%|█████     | 508/1001 [25:19<1:20:08,  9.75s/it, avg loss=274.0798]Checkpoint at iteration 508 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 274.07979888916014

Training iteration:  51%|█████     | 508/1001 [25:21<1:20:08,  9.75s/it, avg loss=274.5920]
Training iteration:  51%|█████     | 509/1001 [25:21<1:00:10,  7.34s/it, avg loss=274.5920]Checkpoint at iteration 509 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 274.59203643798827

Training iteration:  51%|█████     | 509/1001 [25:23<1:00:10,  7.34s/it, avg loss=276.0735]
Training iteration:  51%|█████     | 510/1001 [25:23<46:10,  5.64s/it, avg loss=276.0735]  Checkpoint at iteration 510 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 276.07354431152345

Training iteration:  51%|█████     | 510/1001 [25:24<46:10,  5.64s/it, avg loss=157.6501]
Training iteration:  51%|█████     | 511/1001 [25:24<36:22,  4.45s/it, avg loss=157.6501]Checkpoint at iteration 511 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 157.65008392333985

Training iteration:  51%|█████     | 511/1001 [25:26<36:22,  4.45s/it, avg loss=161.1422]
Training iteration:  51%|█████     | 512/1001 [25:26<29:31,  3.62s/it, avg loss=161.1422]Checkpoint at iteration 512 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 161.1421676635742

Training iteration:  51%|█████     | 512/1001 [25:28<29:31,  3.62s/it, avg loss=158.3482]
Training iteration:  51%|█████     | 513/1001 [25:28<24:43,  3.04s/it, avg loss=158.3482]Checkpoint at iteration 513 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 158.34815216064453

Training iteration:  51%|█████     | 513/1001 [25:29<24:43,  3.04s/it, avg loss=154.2529]
Training iteration:  51%|█████▏    | 514/1001 [25:29<21:21,  2.63s/it, avg loss=154.2529]Checkpoint at iteration 514 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 154.25293426513673

Training iteration:  51%|█████▏    | 514/1001 [25:31<21:21,  2.63s/it, avg loss=276.9186]
Training iteration:  51%|█████▏    | 515/1001 [25:31<19:00,  2.35s/it, avg loss=276.9186]Checkpoint at iteration 515 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 276.91856689453124

Training iteration:  51%|█████▏    | 515/1001 [25:33<19:00,  2.35s/it, avg loss=274.6997]
Training iteration:  52%|█████▏    | 516/1001 [25:33<17:21,  2.15s/it, avg loss=274.6997]Checkpoint at iteration 516 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 274.69972229003906

Training iteration:  52%|█████▏    | 516/1001 [25:34<17:21,  2.15s/it, avg loss=160.4524]
Training iteration:  52%|█████▏    | 517/1001 [25:34<16:11,  2.01s/it, avg loss=160.4524]Checkpoint at iteration 517 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 160.45238037109374

Training iteration:  52%|█████▏    | 517/1001 [25:36<16:11,  2.01s/it, avg loss=278.5647]
Training iteration:  52%|█████▏    | 518/1001 [25:36<15:22,  1.91s/it, avg loss=278.5647]Checkpoint at iteration 518 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 278.564680480957

Training iteration:  52%|█████▏    | 518/1001 [25:38<15:22,  1.91s/it, avg loss=283.8543]
Training iteration:  52%|█████▏    | 519/1001 [25:38<14:47,  1.84s/it, avg loss=283.8543]Checkpoint at iteration 519 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 283.85430603027345

Training iteration:  52%|█████▏    | 519/1001 [25:40<14:47,  1.84s/it, avg loss=277.6935]
Training iteration:  52%|█████▏    | 520/1001 [25:40<14:22,  1.79s/it, avg loss=277.6935]Checkpoint at iteration 520 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 277.6935180664062

Training iteration:  52%|█████▏    | 520/1001 [25:41<14:22,  1.79s/it, avg loss=156.3946]
Training iteration:  52%|█████▏    | 521/1001 [25:41<14:04,  1.76s/it, avg loss=156.3946]Checkpoint at iteration 521 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 156.39456634521486

Training iteration:  52%|█████▏    | 521/1001 [25:43<14:04,  1.76s/it, avg loss=275.6075]
Training iteration:  52%|█████▏    | 522/1001 [25:43<13:51,  1.74s/it, avg loss=275.6075]Checkpoint at iteration 522 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 275.60748901367185

Training iteration:  52%|█████▏    | 522/1001 [25:45<13:51,  1.74s/it, avg loss=277.1756]
Training iteration:  52%|█████▏    | 523/1001 [25:45<13:41,  1.72s/it, avg loss=277.1756]Checkpoint at iteration 523 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 277.17559814453125

Training iteration:  52%|█████▏    | 523/1001 [25:46<13:41,  1.72s/it, avg loss=162.0562]
Training iteration:  52%|█████▏    | 524/1001 [25:46<13:34,  1.71s/it, avg loss=162.0562]Checkpoint at iteration 524 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 162.05618743896486

Training iteration:  52%|█████▏    | 524/1001 [25:48<13:34,  1.71s/it, avg loss=279.8113]
Training iteration:  52%|█████▏    | 525/1001 [25:48<13:28,  1.70s/it, avg loss=279.8113]Checkpoint at iteration 525 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 279.81127014160154

Training iteration:  52%|█████▏    | 525/1001 [25:50<13:28,  1.70s/it, avg loss=163.3215]
Training iteration:  53%|█████▎    | 526/1001 [25:50<13:24,  1.69s/it, avg loss=163.3215]Checkpoint at iteration 526 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 163.3214904785156

Training iteration:  53%|█████▎    | 526/1001 [25:51<13:24,  1.69s/it, avg loss=160.9898]
Training iteration:  53%|█████▎    | 527/1001 [25:51<13:20,  1.69s/it, avg loss=160.9898]Checkpoint at iteration 527 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 160.98975372314453

Training iteration:  53%|█████▎    | 527/1001 [25:53<13:20,  1.69s/it, avg loss=155.3278]
Training iteration:  53%|█████▎    | 528/1001 [25:53<13:17,  1.69s/it, avg loss=155.3278]Checkpoint at iteration 528 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 155.32782287597655

Training iteration:  53%|█████▎    | 528/1001 [25:55<13:17,  1.69s/it, avg loss=279.7219]
Training iteration:  53%|█████▎    | 529/1001 [25:55<13:15,  1.68s/it, avg loss=279.7219]Checkpoint at iteration 529 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 279.72193908691406

Training iteration:  53%|█████▎    | 529/1001 [25:56<13:15,  1.68s/it, avg loss=158.9532]
Training iteration:  53%|█████▎    | 530/1001 [25:56<13:13,  1.68s/it, avg loss=158.9532]Checkpoint at iteration 530 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 158.9532272338867

Training iteration:  53%|█████▎    | 530/1001 [25:58<13:13,  1.68s/it, avg loss=155.3234]
Training iteration:  53%|█████▎    | 531/1001 [25:58<13:10,  1.68s/it, avg loss=155.3234]Checkpoint at iteration 531 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 155.32344818115234

Training iteration:  53%|█████▎    | 531/1001 [26:00<13:10,  1.68s/it, avg loss=150.6336]
Training iteration:  53%|█████▎    | 532/1001 [26:00<13:08,  1.68s/it, avg loss=150.6336]Checkpoint at iteration 532 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 150.63360900878905

Training iteration:  53%|█████▎    | 532/1001 [26:01<13:08,  1.68s/it, avg loss=152.4694]
Training iteration:  53%|█████▎    | 533/1001 [26:01<13:06,  1.68s/it, avg loss=152.4694]Checkpoint at iteration 533 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 152.46939544677736

Training iteration:  53%|█████▎    | 533/1001 [26:03<13:06,  1.68s/it, avg loss=277.7883]
Training iteration:  53%|█████▎    | 534/1001 [26:03<13:05,  1.68s/it, avg loss=277.7883]Checkpoint at iteration 534 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 277.7883010864258

Training iteration:  53%|█████▎    | 534/1001 [26:05<13:05,  1.68s/it, avg loss=284.5427]
Training iteration:  53%|█████▎    | 535/1001 [26:05<13:03,  1.68s/it, avg loss=284.5427]Checkpoint at iteration 535 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 284.54269256591795

Training iteration:  53%|█████▎    | 535/1001 [26:06<13:03,  1.68s/it, avg loss=276.1510]
Training iteration:  54%|█████▎    | 536/1001 [26:06<13:01,  1.68s/it, avg loss=276.1510]Checkpoint at iteration 536 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 276.15099639892577

Training iteration:  54%|█████▎    | 536/1001 [26:08<13:01,  1.68s/it, avg loss=153.0544]
Training iteration:  54%|█████▎    | 537/1001 [26:08<12:59,  1.68s/it, avg loss=153.0544]Checkpoint at iteration 537 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 153.0544448852539

Training iteration:  54%|█████▎    | 537/1001 [26:10<12:59,  1.68s/it, avg loss=285.0851]
Training iteration:  54%|█████▎    | 538/1001 [26:10<12:58,  1.68s/it, avg loss=285.0851]Checkpoint at iteration 538 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 285.0851226806641

Training iteration:  54%|█████▎    | 538/1001 [26:11<12:58,  1.68s/it, avg loss=153.4893]
Training iteration:  54%|█████▍    | 539/1001 [26:11<12:56,  1.68s/it, avg loss=153.4893]Checkpoint at iteration 539 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 153.4892837524414

Training iteration:  54%|█████▍    | 539/1001 [26:13<12:56,  1.68s/it, avg loss=280.4765]
Training iteration:  54%|█████▍    | 540/1001 [26:13<12:54,  1.68s/it, avg loss=280.4765]Checkpoint at iteration 540 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 280.4764892578125

Training iteration:  54%|█████▍    | 540/1001 [26:15<12:54,  1.68s/it, avg loss=282.8645]
Training iteration:  54%|█████▍    | 541/1001 [26:15<12:52,  1.68s/it, avg loss=282.8645]Checkpoint at iteration 541 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 282.86451721191406

Training iteration:  54%|█████▍    | 541/1001 [26:16<12:52,  1.68s/it, avg loss=159.0638]
Training iteration:  54%|█████▍    | 542/1001 [26:16<12:51,  1.68s/it, avg loss=159.0638]Checkpoint at iteration 542 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 159.06375427246093

Training iteration:  54%|█████▍    | 542/1001 [26:18<12:51,  1.68s/it, avg loss=283.8129]
Training iteration:  54%|█████▍    | 543/1001 [26:18<12:49,  1.68s/it, avg loss=283.8129]Checkpoint at iteration 543 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 283.8129257202148

Training iteration:  54%|█████▍    | 543/1001 [26:20<12:49,  1.68s/it, avg loss=285.4683]
Training iteration:  54%|█████▍    | 544/1001 [26:20<12:48,  1.68s/it, avg loss=285.4683]Checkpoint at iteration 544 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 285.46825256347654

Training iteration:  54%|█████▍    | 544/1001 [26:22<12:48,  1.68s/it, avg loss=157.6993]
Training iteration:  54%|█████▍    | 545/1001 [26:22<12:46,  1.68s/it, avg loss=157.6993]Checkpoint at iteration 545 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 157.69929962158204

Training iteration:  54%|█████▍    | 545/1001 [26:23<12:46,  1.68s/it, avg loss=153.1045]
Training iteration:  55%|█████▍    | 546/1001 [26:23<12:45,  1.68s/it, avg loss=153.1045]Checkpoint at iteration 546 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 153.1045379638672

Training iteration:  55%|█████▍    | 546/1001 [26:25<12:45,  1.68s/it, avg loss=278.5227]
Training iteration:  55%|█████▍    | 547/1001 [26:25<12:43,  1.68s/it, avg loss=278.5227]Checkpoint at iteration 547 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 278.52270965576173

Training iteration:  55%|█████▍    | 547/1001 [26:27<12:43,  1.68s/it, avg loss=277.6798]
Training iteration:  55%|█████▍    | 548/1001 [26:27<12:41,  1.68s/it, avg loss=277.6798]Checkpoint at iteration 548 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 277.6797607421875

Training iteration:  55%|█████▍    | 548/1001 [26:28<12:41,  1.68s/it, avg loss=153.5948]
Training iteration:  55%|█████▍    | 549/1001 [26:28<12:40,  1.68s/it, avg loss=153.5948]Checkpoint at iteration 549 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 153.59479827880858

Training iteration:  55%|█████▍    | 549/1001 [26:30<12:40,  1.68s/it, avg loss=276.2916]
Training iteration:  55%|█████▍    | 550/1001 [26:30<12:38,  1.68s/it, avg loss=276.2916]Checkpoint at iteration 550 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 276.29162750244143

Training iteration:  55%|█████▍    | 550/1001 [26:32<12:38,  1.68s/it, avg loss=278.9358]
Training iteration:  55%|█████▌    | 551/1001 [26:32<12:36,  1.68s/it, avg loss=278.9358]Checkpoint at iteration 551 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 278.93582305908205

Training iteration:  55%|█████▌    | 551/1001 [26:33<12:36,  1.68s/it, avg loss=275.9682]
Training iteration:  55%|█████▌    | 552/1001 [26:33<12:35,  1.68s/it, avg loss=275.9682]Checkpoint at iteration 552 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 275.9681991577148

Training iteration:  55%|█████▌    | 552/1001 [26:35<12:35,  1.68s/it, avg loss=271.9230]
Training iteration:  55%|█████▌    | 553/1001 [26:35<12:33,  1.68s/it, avg loss=271.9230]Checkpoint at iteration 553 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 271.9230422973633

Training iteration:  55%|█████▌    | 553/1001 [26:37<12:33,  1.68s/it, avg loss=277.2008]
Training iteration:  55%|█████▌    | 554/1001 [26:37<12:31,  1.68s/it, avg loss=277.2008]Checkpoint at iteration 554 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 277.2008392333984

Training iteration:  55%|█████▌    | 554/1001 [26:38<12:31,  1.68s/it, avg loss=272.1725]
Training iteration:  55%|█████▌    | 555/1001 [26:38<12:29,  1.68s/it, avg loss=272.1725]Checkpoint at iteration 555 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 272.1724578857422

Training iteration:  55%|█████▌    | 555/1001 [26:40<12:29,  1.68s/it, avg loss=162.9764]
Training iteration:  56%|█████▌    | 556/1001 [26:40<12:28,  1.68s/it, avg loss=162.9764]Checkpoint at iteration 556 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 162.97637176513672

Training iteration:  56%|█████▌    | 556/1001 [26:42<12:28,  1.68s/it, avg loss=157.4132]
Training iteration:  56%|█████▌    | 557/1001 [26:42<12:27,  1.68s/it, avg loss=157.4132]Checkpoint at iteration 557 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 157.41317443847657

Training iteration:  56%|█████▌    | 557/1001 [26:43<12:27,  1.68s/it, avg loss=278.0891]
Training iteration:  56%|█████▌    | 558/1001 [26:43<12:25,  1.68s/it, avg loss=278.0891]Checkpoint at iteration 558 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 278.08907623291014

Training iteration:  56%|█████▌    | 558/1001 [26:45<12:25,  1.68s/it, avg loss=161.0647]
Training iteration:  56%|█████▌    | 559/1001 [26:45<12:23,  1.68s/it, avg loss=161.0647]Checkpoint at iteration 559 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 161.0647399902344

Training iteration:  56%|█████▌    | 559/1001 [26:47<12:23,  1.68s/it, avg loss=282.6831]
Training iteration:  56%|█████▌    | 560/1001 [26:47<12:21,  1.68s/it, avg loss=282.6831]Checkpoint at iteration 560 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 282.683122253418

Training iteration:  56%|█████▌    | 560/1001 [26:48<12:21,  1.68s/it, avg loss=152.7881]
Training iteration:  56%|█████▌    | 561/1001 [26:48<12:20,  1.68s/it, avg loss=152.7881]Checkpoint at iteration 561 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 152.78813934326172

Training iteration:  56%|█████▌    | 561/1001 [26:50<12:20,  1.68s/it, avg loss=158.5959]
Training iteration:  56%|█████▌    | 562/1001 [26:50<12:18,  1.68s/it, avg loss=158.5959]Checkpoint at iteration 562 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 158.59589080810548

Training iteration:  56%|█████▌    | 562/1001 [26:52<12:18,  1.68s/it, avg loss=157.9367]
Training iteration:  56%|█████▌    | 563/1001 [26:52<12:16,  1.68s/it, avg loss=157.9367]Checkpoint at iteration 563 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 157.93667755126953

Training iteration:  56%|█████▌    | 563/1001 [26:53<12:16,  1.68s/it, avg loss=277.1638]
Training iteration:  56%|█████▋    | 564/1001 [26:53<12:14,  1.68s/it, avg loss=277.1638]Checkpoint at iteration 564 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 277.16380310058594

Training iteration:  56%|█████▋    | 564/1001 [26:55<12:14,  1.68s/it, avg loss=156.0742]
Training iteration:  56%|█████▋    | 565/1001 [26:55<12:12,  1.68s/it, avg loss=156.0742]Checkpoint at iteration 565 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 156.07423553466796

Training iteration:  56%|█████▋    | 565/1001 [26:57<12:12,  1.68s/it, avg loss=154.4803]
Training iteration:  57%|█████▋    | 566/1001 [26:57<12:10,  1.68s/it, avg loss=154.4803]Checkpoint at iteration 566 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 154.4802993774414

Training iteration:  57%|█████▋    | 566/1001 [26:59<12:10,  1.68s/it, avg loss=279.8476]
Training iteration:  57%|█████▋    | 567/1001 [26:59<12:09,  1.68s/it, avg loss=279.8476]Checkpoint at iteration 567 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 279.84759521484375

Training iteration:  57%|█████▋    | 567/1001 [27:00<12:09,  1.68s/it, avg loss=279.0327]
Training iteration:  57%|█████▋    | 568/1001 [27:00<12:07,  1.68s/it, avg loss=279.0327]Checkpoint at iteration 568 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 279.03265380859375

Training iteration:  57%|█████▋    | 568/1001 [27:02<12:07,  1.68s/it, avg loss=145.5696]
Training iteration:  57%|█████▋    | 569/1001 [27:02<12:05,  1.68s/it, avg loss=145.5696]Checkpoint at iteration 569 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 145.56962127685546

Training iteration:  57%|█████▋    | 569/1001 [27:04<12:05,  1.68s/it, avg loss=279.9863]
Training iteration:  57%|█████▋    | 570/1001 [27:04<12:04,  1.68s/it, avg loss=279.9863]Checkpoint at iteration 570 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 279.98628692626954

Training iteration:  57%|█████▋    | 570/1001 [27:05<12:04,  1.68s/it, avg loss=164.1323]
Training iteration:  57%|█████▋    | 571/1001 [27:05<12:02,  1.68s/it, avg loss=164.1323]Checkpoint at iteration 571 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 164.13230590820314

Training iteration:  57%|█████▋    | 571/1001 [27:07<12:02,  1.68s/it, avg loss=286.0650]
Training iteration:  57%|█████▋    | 572/1001 [27:07<12:01,  1.68s/it, avg loss=286.0650]Checkpoint at iteration 572 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 286.0650207519531

Training iteration:  57%|█████▋    | 572/1001 [27:09<12:01,  1.68s/it, avg loss=277.3733]
Training iteration:  57%|█████▋    | 573/1001 [27:09<11:59,  1.68s/it, avg loss=277.3733]Checkpoint at iteration 573 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 277.37333984375

Training iteration:  57%|█████▋    | 573/1001 [27:10<11:59,  1.68s/it, avg loss=151.2211]
Training iteration:  57%|█████▋    | 574/1001 [27:10<11:57,  1.68s/it, avg loss=151.2211]Checkpoint at iteration 574 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 151.22112426757812

Training iteration:  57%|█████▋    | 574/1001 [27:12<11:57,  1.68s/it, avg loss=150.2101]
Training iteration:  57%|█████▋    | 575/1001 [27:12<11:56,  1.68s/it, avg loss=150.2101]Checkpoint at iteration 575 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 150.21006622314454

Training iteration:  57%|█████▋    | 575/1001 [27:14<11:56,  1.68s/it, avg loss=283.5392]
Training iteration:  58%|█████▊    | 576/1001 [27:14<11:54,  1.68s/it, avg loss=283.5392]Checkpoint at iteration 576 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 283.5392364501953

Training iteration:  58%|█████▊    | 576/1001 [27:15<11:54,  1.68s/it, avg loss=149.9301]
Training iteration:  58%|█████▊    | 577/1001 [27:15<11:52,  1.68s/it, avg loss=149.9301]Checkpoint at iteration 577 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 149.930078125

Training iteration:  58%|█████▊    | 577/1001 [27:17<11:52,  1.68s/it, avg loss=289.6719]
Training iteration:  58%|█████▊    | 578/1001 [27:17<11:51,  1.68s/it, avg loss=289.6719]Checkpoint at iteration 578 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 289.6718505859375

Training iteration:  58%|█████▊    | 578/1001 [27:19<11:51,  1.68s/it, avg loss=155.6377]
Training iteration:  58%|█████▊    | 579/1001 [27:19<11:49,  1.68s/it, avg loss=155.6377]Checkpoint at iteration 579 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 155.6376693725586

Training iteration:  58%|█████▊    | 579/1001 [27:20<11:49,  1.68s/it, avg loss=284.8454]
Training iteration:  58%|█████▊    | 580/1001 [27:20<11:47,  1.68s/it, avg loss=284.8454]Checkpoint at iteration 580 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 284.845393371582

Training iteration:  58%|█████▊    | 580/1001 [27:22<11:47,  1.68s/it, avg loss=276.4953]
Training iteration:  58%|█████▊    | 581/1001 [27:22<11:46,  1.68s/it, avg loss=276.4953]Checkpoint at iteration 581 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 276.4952758789062

Training iteration:  58%|█████▊    | 581/1001 [27:24<11:46,  1.68s/it, avg loss=158.3230]
Training iteration:  58%|█████▊    | 582/1001 [27:24<11:44,  1.68s/it, avg loss=158.3230]Checkpoint at iteration 582 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 158.3230209350586

Training iteration:  58%|█████▊    | 582/1001 [27:25<11:44,  1.68s/it, avg loss=151.5896]
Training iteration:  58%|█████▊    | 583/1001 [27:25<11:43,  1.68s/it, avg loss=151.5896]Checkpoint at iteration 583 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 151.589599609375

Training iteration:  58%|█████▊    | 583/1001 [27:27<11:43,  1.68s/it, avg loss=147.6045]
Training iteration:  58%|█████▊    | 584/1001 [27:27<11:41,  1.68s/it, avg loss=147.6045]Checkpoint at iteration 584 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 147.60452270507812

Training iteration:  58%|█████▊    | 584/1001 [27:29<11:41,  1.68s/it, avg loss=147.5695]
Training iteration:  58%|█████▊    | 585/1001 [27:29<11:39,  1.68s/it, avg loss=147.5695]Checkpoint at iteration 585 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 147.5694793701172

Training iteration:  58%|█████▊    | 585/1001 [27:30<11:39,  1.68s/it, avg loss=286.1133]
Training iteration:  59%|█████▊    | 586/1001 [27:30<11:38,  1.68s/it, avg loss=286.1133]Checkpoint at iteration 586 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 286.11329498291013

Training iteration:  59%|█████▊    | 586/1001 [27:32<11:38,  1.68s/it, avg loss=144.2466]
Training iteration:  59%|█████▊    | 587/1001 [27:32<11:36,  1.68s/it, avg loss=144.2466]Checkpoint at iteration 587 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 144.2466049194336

Training iteration:  59%|█████▊    | 587/1001 [27:34<11:36,  1.68s/it, avg loss=283.6445]
Training iteration:  59%|█████▊    | 588/1001 [27:34<11:34,  1.68s/it, avg loss=283.6445]Checkpoint at iteration 588 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 283.64454193115233

Training iteration:  59%|█████▊    | 588/1001 [27:36<11:34,  1.68s/it, avg loss=154.9247]
Training iteration:  59%|█████▉    | 589/1001 [27:36<11:32,  1.68s/it, avg loss=154.9247]Checkpoint at iteration 589 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 154.9246826171875

Training iteration:  59%|█████▉    | 589/1001 [27:37<11:32,  1.68s/it, avg loss=135.6090]
Training iteration:  59%|█████▉    | 590/1001 [27:37<11:31,  1.68s/it, avg loss=135.6090]Checkpoint at iteration 590 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 135.6090103149414

Training iteration:  59%|█████▉    | 590/1001 [27:39<11:31,  1.68s/it, avg loss=285.2719]
Training iteration:  59%|█████▉    | 591/1001 [27:39<11:29,  1.68s/it, avg loss=285.2719]Checkpoint at iteration 591 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 285.27186126708983

Training iteration:  59%|█████▉    | 591/1001 [27:41<11:29,  1.68s/it, avg loss=289.3090]
Training iteration:  59%|█████▉    | 592/1001 [27:41<11:27,  1.68s/it, avg loss=289.3090]Checkpoint at iteration 592 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 289.30901794433595

Training iteration:  59%|█████▉    | 592/1001 [27:42<11:27,  1.68s/it, avg loss=286.8561]
Training iteration:  59%|█████▉    | 593/1001 [27:42<11:26,  1.68s/it, avg loss=286.8561]Checkpoint at iteration 593 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 286.85611724853516

Training iteration:  59%|█████▉    | 593/1001 [27:44<11:26,  1.68s/it, avg loss=283.3905]
Training iteration:  59%|█████▉    | 594/1001 [27:44<11:24,  1.68s/it, avg loss=283.3905]Checkpoint at iteration 594 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 283.3904861450195

Training iteration:  59%|█████▉    | 594/1001 [27:46<11:24,  1.68s/it, avg loss=277.3979]
Training iteration:  59%|█████▉    | 595/1001 [27:46<11:22,  1.68s/it, avg loss=277.3979]Checkpoint at iteration 595 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 277.39790496826174

Training iteration:  59%|█████▉    | 595/1001 [27:47<11:22,  1.68s/it, avg loss=281.3233]
Training iteration:  60%|█████▉    | 596/1001 [27:47<11:20,  1.68s/it, avg loss=281.3233]Checkpoint at iteration 596 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 281.32326049804686

Training iteration:  60%|█████▉    | 596/1001 [27:49<11:20,  1.68s/it, avg loss=275.8417]
Training iteration:  60%|█████▉    | 597/1001 [27:49<11:19,  1.68s/it, avg loss=275.8417]Checkpoint at iteration 597 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 275.84171905517576

Training iteration:  60%|█████▉    | 597/1001 [27:51<11:19,  1.68s/it, avg loss=273.2810]
Training iteration:  60%|█████▉    | 598/1001 [27:51<11:17,  1.68s/it, avg loss=273.2810]Checkpoint at iteration 598 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 273.2810302734375

Training iteration:  60%|█████▉    | 598/1001 [27:52<11:17,  1.68s/it, avg loss=157.4411]
Training iteration:  60%|█████▉    | 599/1001 [27:52<11:15,  1.68s/it, avg loss=157.4411]Checkpoint at iteration 599 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 157.44113159179688

Training iteration:  60%|█████▉    | 599/1001 [27:54<11:15,  1.68s/it, avg loss=277.5670]
Training iteration:  60%|█████▉    | 600/1001 [27:54<11:14,  1.68s/it, avg loss=277.5670]Optimization iteration 600 evaluation begins...
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
A new evaluation visualization has been saved: ./saved_data/20240110-050655/it600.png
Training network 0 for evaluation...
Training network 1 for evaluation...
Training network 2 for evaluation...
Training network 3 for evaluation...
Testing network 0 on real datasets for evaluation...
Testing network 1 on real datasets for evaluation...
Testing network 2 on real datasets for evaluation...
Testing network 3 on real datasets for evaluation...
Optimization iteration 600, eval auroc score (train): 36548.9291, eval auroc score (test): 37898.8340
Checkpoint at iteration 600 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 277.5669647216797

Training iteration:  60%|█████▉    | 600/1001 [34:37<11:14,  1.68s/it, avg loss=152.4420]
Training iteration:  60%|██████    | 601/1001 [34:37<13:33:17, 121.99s/it, avg loss=152.4420]Checkpoint at iteration 601 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 152.44196624755858

Training iteration:  60%|██████    | 601/1001 [34:39<13:33:17, 121.99s/it, avg loss=280.2693]
Training iteration:  60%|██████    | 602/1001 [34:39<9:31:39, 85.96s/it, avg loss=280.2693]  Checkpoint at iteration 602 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 280.2692672729492

Training iteration:  60%|██████    | 602/1001 [34:41<9:31:39, 85.96s/it, avg loss=154.9170]
Training iteration:  60%|██████    | 603/1001 [34:41<6:42:56, 60.74s/it, avg loss=154.9170]Checkpoint at iteration 603 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 154.91700897216796

Training iteration:  60%|██████    | 603/1001 [34:42<6:42:56, 60.74s/it, avg loss=277.7405]
Training iteration:  60%|██████    | 604/1001 [34:42<4:45:06, 43.09s/it, avg loss=277.7405]Checkpoint at iteration 604 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 277.74046478271487

Training iteration:  60%|██████    | 604/1001 [34:44<4:45:06, 43.09s/it, avg loss=161.0733]
Training iteration:  60%|██████    | 605/1001 [34:44<3:22:50, 30.73s/it, avg loss=161.0733]Checkpoint at iteration 605 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 161.0732894897461

Training iteration:  60%|██████    | 605/1001 [34:46<3:22:50, 30.73s/it, avg loss=280.1597]
Training iteration:  61%|██████    | 606/1001 [34:46<2:25:24, 22.09s/it, avg loss=280.1597]Checkpoint at iteration 606 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 280.159733581543

Training iteration:  61%|██████    | 606/1001 [34:48<2:25:24, 22.09s/it, avg loss=158.3863]
Training iteration:  61%|██████    | 607/1001 [34:48<1:45:18, 16.04s/it, avg loss=158.3863]Checkpoint at iteration 607 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 158.38631286621094

Training iteration:  61%|██████    | 607/1001 [34:50<1:45:18, 16.04s/it, avg loss=278.1806]
Training iteration:  61%|██████    | 608/1001 [34:50<1:17:18, 11.80s/it, avg loss=278.1806]Checkpoint at iteration 608 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 278.1805938720703

Training iteration:  61%|██████    | 608/1001 [34:52<1:17:18, 11.80s/it, avg loss=150.7042]
Training iteration:  61%|██████    | 609/1001 [34:52<57:44,  8.84s/it, avg loss=150.7042]  Checkpoint at iteration 609 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 150.7041809082031

Training iteration:  61%|██████    | 609/1001 [34:54<57:44,  8.84s/it, avg loss=150.2046]
Training iteration:  61%|██████    | 610/1001 [34:54<44:03,  6.76s/it, avg loss=150.2046]Checkpoint at iteration 610 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 150.20460662841796

Training iteration:  61%|██████    | 610/1001 [34:56<44:03,  6.76s/it, avg loss=277.2429]
Training iteration:  61%|██████    | 611/1001 [34:56<34:30,  5.31s/it, avg loss=277.2429]Checkpoint at iteration 611 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 277.24285888671875

Training iteration:  61%|██████    | 611/1001 [34:58<34:30,  5.31s/it, avg loss=152.4931]
Training iteration:  61%|██████    | 612/1001 [34:58<27:49,  4.29s/it, avg loss=152.4931]Checkpoint at iteration 612 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 152.49310302734375

Training iteration:  61%|██████    | 612/1001 [35:00<27:49,  4.29s/it, avg loss=279.9717]
Training iteration:  61%|██████    | 613/1001 [35:00<23:09,  3.58s/it, avg loss=279.9717]Checkpoint at iteration 613 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 279.971728515625

Training iteration:  61%|██████    | 613/1001 [35:02<23:09,  3.58s/it, avg loss=282.0329]
Training iteration:  61%|██████▏   | 614/1001 [35:02<19:52,  3.08s/it, avg loss=282.0329]Checkpoint at iteration 614 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 282.0328872680664

Training iteration:  61%|██████▏   | 614/1001 [35:04<19:52,  3.08s/it, avg loss=151.6022]
Training iteration:  61%|██████▏   | 615/1001 [35:04<17:35,  2.73s/it, avg loss=151.6022]Checkpoint at iteration 615 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 151.60215454101564

Training iteration:  61%|██████▏   | 615/1001 [35:05<17:35,  2.73s/it, avg loss=150.9726]
Training iteration:  62%|██████▏   | 616/1001 [35:05<15:58,  2.49s/it, avg loss=150.9726]Checkpoint at iteration 616 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 150.97263793945314

Training iteration:  62%|██████▏   | 616/1001 [35:07<15:58,  2.49s/it, avg loss=282.3628]
Training iteration:  62%|██████▏   | 617/1001 [35:07<14:51,  2.32s/it, avg loss=282.3628]Checkpoint at iteration 617 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 282.3628234863281

Training iteration:  62%|██████▏   | 617/1001 [35:09<14:51,  2.32s/it, avg loss=147.2938]
Training iteration:  62%|██████▏   | 618/1001 [35:09<14:03,  2.20s/it, avg loss=147.2938]Checkpoint at iteration 618 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 147.29381408691407

Training iteration:  62%|██████▏   | 618/1001 [35:11<14:03,  2.20s/it, avg loss=158.9682]
Training iteration:  62%|██████▏   | 619/1001 [35:11<13:28,  2.12s/it, avg loss=158.9682]Checkpoint at iteration 619 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 158.96819458007812

Training iteration:  62%|██████▏   | 619/1001 [35:13<13:28,  2.12s/it, avg loss=285.3069]
Training iteration:  62%|██████▏   | 620/1001 [35:13<13:04,  2.06s/it, avg loss=285.3069]Checkpoint at iteration 620 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 285.30694885253905

Training iteration:  62%|██████▏   | 620/1001 [35:15<13:04,  2.06s/it, avg loss=279.2311]
Training iteration:  62%|██████▏   | 621/1001 [35:15<12:46,  2.02s/it, avg loss=279.2311]Checkpoint at iteration 621 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 279.2311447143555

Training iteration:  62%|██████▏   | 621/1001 [35:17<12:46,  2.02s/it, avg loss=271.6681]
Training iteration:  62%|██████▏   | 622/1001 [35:17<12:33,  1.99s/it, avg loss=271.6681]Checkpoint at iteration 622 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 271.6681167602539

Training iteration:  62%|██████▏   | 622/1001 [35:19<12:33,  1.99s/it, avg loss=279.2991]
Training iteration:  62%|██████▏   | 623/1001 [35:19<12:24,  1.97s/it, avg loss=279.2991]Checkpoint at iteration 623 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 279.29905700683594

Training iteration:  62%|██████▏   | 623/1001 [35:21<12:24,  1.97s/it, avg loss=279.2809]
Training iteration:  62%|██████▏   | 624/1001 [35:21<12:16,  1.95s/it, avg loss=279.2809]Checkpoint at iteration 624 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 279.2809432983398

Training iteration:  62%|██████▏   | 624/1001 [35:23<12:16,  1.95s/it, avg loss=286.0777]
Training iteration:  62%|██████▏   | 625/1001 [35:23<12:11,  1.94s/it, avg loss=286.0777]Checkpoint at iteration 625 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 286.0777359008789

Training iteration:  62%|██████▏   | 625/1001 [35:25<12:11,  1.94s/it, avg loss=161.5566]
Training iteration:  63%|██████▎   | 626/1001 [35:25<12:06,  1.94s/it, avg loss=161.5566]Checkpoint at iteration 626 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 161.55661010742188

Training iteration:  63%|██████▎   | 626/1001 [35:27<12:06,  1.94s/it, avg loss=284.9445]
Training iteration:  63%|██████▎   | 627/1001 [35:27<12:02,  1.93s/it, avg loss=284.9445]Checkpoint at iteration 627 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 284.94446563720703

Training iteration:  63%|██████▎   | 627/1001 [35:29<12:02,  1.93s/it, avg loss=153.2566]
Training iteration:  63%|██████▎   | 628/1001 [35:29<11:59,  1.93s/it, avg loss=153.2566]Checkpoint at iteration 628 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 153.2565658569336

Training iteration:  63%|██████▎   | 628/1001 [35:30<11:59,  1.93s/it, avg loss=151.2666]
Training iteration:  63%|██████▎   | 629/1001 [35:30<11:56,  1.93s/it, avg loss=151.2666]Checkpoint at iteration 629 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 151.2666229248047

Training iteration:  63%|██████▎   | 629/1001 [35:32<11:56,  1.93s/it, avg loss=284.4270]
Training iteration:  63%|██████▎   | 630/1001 [35:32<11:54,  1.92s/it, avg loss=284.4270]Checkpoint at iteration 630 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 284.42701416015626

Training iteration:  63%|██████▎   | 630/1001 [35:34<11:54,  1.92s/it, avg loss=283.9824]
Training iteration:  63%|██████▎   | 631/1001 [35:34<11:51,  1.92s/it, avg loss=283.9824]Checkpoint at iteration 631 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 283.98240661621094

Training iteration:  63%|██████▎   | 631/1001 [35:36<11:51,  1.92s/it, avg loss=158.0186]
Training iteration:  63%|██████▎   | 632/1001 [35:36<11:49,  1.92s/it, avg loss=158.0186]Checkpoint at iteration 632 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 158.0186340332031

Training iteration:  63%|██████▎   | 632/1001 [35:38<11:49,  1.92s/it, avg loss=274.5449]
Training iteration:  63%|██████▎   | 633/1001 [35:38<11:47,  1.92s/it, avg loss=274.5449]Checkpoint at iteration 633 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 274.54487762451174

Training iteration:  63%|██████▎   | 633/1001 [35:40<11:47,  1.92s/it, avg loss=273.3215]
Training iteration:  63%|██████▎   | 634/1001 [35:40<11:45,  1.92s/it, avg loss=273.3215]Checkpoint at iteration 634 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 273.3214736938477

Training iteration:  63%|██████▎   | 634/1001 [35:42<11:45,  1.92s/it, avg loss=157.8177]
Training iteration:  63%|██████▎   | 635/1001 [35:42<11:43,  1.92s/it, avg loss=157.8177]Checkpoint at iteration 635 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 157.81771545410157

Training iteration:  63%|██████▎   | 635/1001 [35:44<11:43,  1.92s/it, avg loss=155.6707]
Training iteration:  64%|██████▎   | 636/1001 [35:44<11:41,  1.92s/it, avg loss=155.6707]Checkpoint at iteration 636 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 155.6706573486328

Training iteration:  64%|██████▎   | 636/1001 [35:46<11:41,  1.92s/it, avg loss=276.1774]
Training iteration:  64%|██████▎   | 637/1001 [35:46<11:38,  1.92s/it, avg loss=276.1774]Checkpoint at iteration 637 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 276.1774444580078

Training iteration:  64%|██████▎   | 637/1001 [35:48<11:38,  1.92s/it, avg loss=277.8964]
Training iteration:  64%|██████▎   | 638/1001 [35:48<11:34,  1.91s/it, avg loss=277.8964]Checkpoint at iteration 638 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 277.89644927978514

Training iteration:  64%|██████▎   | 638/1001 [35:50<11:34,  1.91s/it, avg loss=155.4876]
Training iteration:  64%|██████▍   | 639/1001 [35:50<11:31,  1.91s/it, avg loss=155.4876]Checkpoint at iteration 639 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 155.4876251220703

Training iteration:  64%|██████▍   | 639/1001 [35:51<11:31,  1.91s/it, avg loss=280.5963]
Training iteration:  64%|██████▍   | 640/1001 [35:51<11:28,  1.91s/it, avg loss=280.5963]Checkpoint at iteration 640 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 280.5963439941406

Training iteration:  64%|██████▍   | 640/1001 [35:53<11:28,  1.91s/it, avg loss=282.2136]
Training iteration:  64%|██████▍   | 641/1001 [35:53<11:25,  1.91s/it, avg loss=282.2136]Checkpoint at iteration 641 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 282.2135513305664

Training iteration:  64%|██████▍   | 641/1001 [35:55<11:25,  1.91s/it, avg loss=278.1533]
Training iteration:  64%|██████▍   | 642/1001 [35:55<11:23,  1.90s/it, avg loss=278.1533]Checkpoint at iteration 642 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 278.1532730102539

Training iteration:  64%|██████▍   | 642/1001 [35:57<11:23,  1.90s/it, avg loss=158.8523]
Training iteration:  64%|██████▍   | 643/1001 [35:57<11:21,  1.90s/it, avg loss=158.8523]Checkpoint at iteration 643 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 158.85230255126953

Training iteration:  64%|██████▍   | 643/1001 [35:59<11:21,  1.90s/it, avg loss=281.6363]
Training iteration:  64%|██████▍   | 644/1001 [35:59<11:19,  1.90s/it, avg loss=281.6363]Checkpoint at iteration 644 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 281.636328125

Training iteration:  64%|██████▍   | 644/1001 [36:01<11:19,  1.90s/it, avg loss=276.2924]
Training iteration:  64%|██████▍   | 645/1001 [36:01<11:17,  1.90s/it, avg loss=276.2924]Checkpoint at iteration 645 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 276.2924041748047

Training iteration:  64%|██████▍   | 645/1001 [36:03<11:17,  1.90s/it, avg loss=154.6510]
Training iteration:  65%|██████▍   | 646/1001 [36:03<11:15,  1.90s/it, avg loss=154.6510]Checkpoint at iteration 646 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 154.6509796142578

Training iteration:  65%|██████▍   | 646/1001 [36:05<11:15,  1.90s/it, avg loss=157.9078]
Training iteration:  65%|██████▍   | 647/1001 [36:05<11:13,  1.90s/it, avg loss=157.9078]Checkpoint at iteration 647 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 157.90776977539062

Training iteration:  65%|██████▍   | 647/1001 [36:07<11:13,  1.90s/it, avg loss=147.5337]
Training iteration:  65%|██████▍   | 648/1001 [36:07<11:11,  1.90s/it, avg loss=147.5337]Checkpoint at iteration 648 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 147.53368377685547

Training iteration:  65%|██████▍   | 648/1001 [36:09<11:11,  1.90s/it, avg loss=150.6164]
Training iteration:  65%|██████▍   | 649/1001 [36:09<11:09,  1.90s/it, avg loss=150.6164]Checkpoint at iteration 649 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 150.6164337158203

Training iteration:  65%|██████▍   | 649/1001 [36:10<11:09,  1.90s/it, avg loss=275.6062]
Training iteration:  65%|██████▍   | 650/1001 [36:10<11:07,  1.90s/it, avg loss=275.6062]Checkpoint at iteration 650 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 275.60619354248047

Training iteration:  65%|██████▍   | 650/1001 [36:12<11:07,  1.90s/it, avg loss=284.7336]
Training iteration:  65%|██████▌   | 651/1001 [36:12<11:05,  1.90s/it, avg loss=284.7336]Checkpoint at iteration 651 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 284.73359375

Training iteration:  65%|██████▌   | 651/1001 [36:14<11:05,  1.90s/it, avg loss=150.8699]
Training iteration:  65%|██████▌   | 652/1001 [36:14<11:03,  1.90s/it, avg loss=150.8699]Checkpoint at iteration 652 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 150.8698760986328

Training iteration:  65%|██████▌   | 652/1001 [36:16<11:03,  1.90s/it, avg loss=281.4954]
Training iteration:  65%|██████▌   | 653/1001 [36:16<11:01,  1.90s/it, avg loss=281.4954]Checkpoint at iteration 653 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 281.49537658691406

Training iteration:  65%|██████▌   | 653/1001 [36:18<11:01,  1.90s/it, avg loss=280.1472]
Training iteration:  65%|██████▌   | 654/1001 [36:18<11:00,  1.90s/it, avg loss=280.1472]Checkpoint at iteration 654 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 280.1471908569336

Training iteration:  65%|██████▌   | 654/1001 [36:20<11:00,  1.90s/it, avg loss=148.1280]
Training iteration:  65%|██████▌   | 655/1001 [36:20<11:00,  1.91s/it, avg loss=148.1280]Checkpoint at iteration 655 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 148.12797088623046

Training iteration:  65%|██████▌   | 655/1001 [36:22<11:00,  1.91s/it, avg loss=279.6385]
Training iteration:  66%|██████▌   | 656/1001 [36:22<10:59,  1.91s/it, avg loss=279.6385]Checkpoint at iteration 656 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 279.63846893310546

Training iteration:  66%|██████▌   | 656/1001 [36:24<10:59,  1.91s/it, avg loss=157.7960]
Training iteration:  66%|██████▌   | 657/1001 [36:24<10:58,  1.91s/it, avg loss=157.7960]Checkpoint at iteration 657 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 157.7959762573242

Training iteration:  66%|██████▌   | 657/1001 [36:26<10:58,  1.91s/it, avg loss=279.3483]
Training iteration:  66%|██████▌   | 658/1001 [36:26<10:57,  1.92s/it, avg loss=279.3483]Checkpoint at iteration 658 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 279.34829864501955

Training iteration:  66%|██████▌   | 658/1001 [36:28<10:57,  1.92s/it, avg loss=284.9693]
Training iteration:  66%|██████▌   | 659/1001 [36:28<10:55,  1.92s/it, avg loss=284.9693]Checkpoint at iteration 659 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 284.9692581176758

Training iteration:  66%|██████▌   | 659/1001 [36:30<10:55,  1.92s/it, avg loss=277.2108]
Training iteration:  66%|██████▌   | 660/1001 [36:30<10:54,  1.92s/it, avg loss=277.2108]Checkpoint at iteration 660 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 277.2107727050781

Training iteration:  66%|██████▌   | 660/1001 [36:32<10:54,  1.92s/it, avg loss=151.8289]
Training iteration:  66%|██████▌   | 661/1001 [36:32<10:52,  1.92s/it, avg loss=151.8289]Checkpoint at iteration 661 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 151.82888946533203

Training iteration:  66%|██████▌   | 661/1001 [36:33<10:52,  1.92s/it, avg loss=152.8394]
Training iteration:  66%|██████▌   | 662/1001 [36:33<10:51,  1.92s/it, avg loss=152.8394]Checkpoint at iteration 662 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 152.83936462402343

Training iteration:  66%|██████▌   | 662/1001 [36:35<10:51,  1.92s/it, avg loss=147.9723]
Training iteration:  66%|██████▌   | 663/1001 [36:35<10:49,  1.92s/it, avg loss=147.9723]Checkpoint at iteration 663 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 147.97232513427736

Training iteration:  66%|██████▌   | 663/1001 [36:37<10:49,  1.92s/it, avg loss=281.7233]
Training iteration:  66%|██████▋   | 664/1001 [36:37<10:47,  1.92s/it, avg loss=281.7233]Checkpoint at iteration 664 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 281.72325286865237

Training iteration:  66%|██████▋   | 664/1001 [36:39<10:47,  1.92s/it, avg loss=151.3499]
Training iteration:  66%|██████▋   | 665/1001 [36:39<10:45,  1.92s/it, avg loss=151.3499]Checkpoint at iteration 665 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 151.34994659423828

Training iteration:  66%|██████▋   | 665/1001 [36:41<10:45,  1.92s/it, avg loss=277.7043]
Training iteration:  67%|██████▋   | 666/1001 [36:41<10:43,  1.92s/it, avg loss=277.7043]Checkpoint at iteration 666 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 277.7043090820313

Training iteration:  67%|██████▋   | 666/1001 [36:43<10:43,  1.92s/it, avg loss=281.5421]
Training iteration:  67%|██████▋   | 667/1001 [36:43<10:41,  1.92s/it, avg loss=281.5421]Checkpoint at iteration 667 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 281.5420669555664

Training iteration:  67%|██████▋   | 667/1001 [36:45<10:41,  1.92s/it, avg loss=147.8515]
Training iteration:  67%|██████▋   | 668/1001 [36:45<10:40,  1.92s/it, avg loss=147.8515]Checkpoint at iteration 668 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 147.8515411376953

Training iteration:  67%|██████▋   | 668/1001 [36:47<10:40,  1.92s/it, avg loss=276.5085]
Training iteration:  67%|██████▋   | 669/1001 [36:47<10:38,  1.92s/it, avg loss=276.5085]Checkpoint at iteration 669 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 276.50853271484374

Training iteration:  67%|██████▋   | 669/1001 [36:49<10:38,  1.92s/it, avg loss=151.6820]
Training iteration:  67%|██████▋   | 670/1001 [36:49<10:36,  1.92s/it, avg loss=151.6820]Checkpoint at iteration 670 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 151.6819854736328

Training iteration:  67%|██████▋   | 670/1001 [36:51<10:36,  1.92s/it, avg loss=151.7560]
Training iteration:  67%|██████▋   | 671/1001 [36:51<10:34,  1.92s/it, avg loss=151.7560]Checkpoint at iteration 671 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 151.75603485107422

Training iteration:  67%|██████▋   | 671/1001 [36:53<10:34,  1.92s/it, avg loss=152.7570]
Training iteration:  67%|██████▋   | 672/1001 [36:53<10:33,  1.92s/it, avg loss=152.7570]Checkpoint at iteration 672 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 152.7570373535156

Training iteration:  67%|██████▋   | 672/1001 [36:55<10:33,  1.92s/it, avg loss=286.1674]
Training iteration:  67%|██████▋   | 673/1001 [36:55<10:30,  1.92s/it, avg loss=286.1674]Checkpoint at iteration 673 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 286.16739959716796

Training iteration:  67%|██████▋   | 673/1001 [36:57<10:30,  1.92s/it, avg loss=282.9708]
Training iteration:  67%|██████▋   | 674/1001 [36:57<10:26,  1.92s/it, avg loss=282.9708]Checkpoint at iteration 674 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 282.9708419799805

Training iteration:  67%|██████▋   | 674/1001 [36:58<10:26,  1.92s/it, avg loss=276.0959]
Training iteration:  67%|██████▋   | 675/1001 [36:58<10:23,  1.91s/it, avg loss=276.0959]Checkpoint at iteration 675 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 276.0959228515625

Training iteration:  67%|██████▋   | 675/1001 [37:00<10:23,  1.91s/it, avg loss=285.6999]
Training iteration:  68%|██████▊   | 676/1001 [37:00<10:20,  1.91s/it, avg loss=285.6999]Checkpoint at iteration 676 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 285.699853515625

Training iteration:  68%|██████▊   | 676/1001 [37:02<10:20,  1.91s/it, avg loss=272.1999]
Training iteration:  68%|██████▊   | 677/1001 [37:02<10:17,  1.91s/it, avg loss=272.1999]Checkpoint at iteration 677 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 272.1998779296875

Training iteration:  68%|██████▊   | 677/1001 [37:04<10:17,  1.91s/it, avg loss=154.0385]
Training iteration:  68%|██████▊   | 678/1001 [37:04<10:15,  1.91s/it, avg loss=154.0385]Checkpoint at iteration 678 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 154.03853912353514

Training iteration:  68%|██████▊   | 678/1001 [37:06<10:15,  1.91s/it, avg loss=280.1946]
Training iteration:  68%|██████▊   | 679/1001 [37:06<10:13,  1.90s/it, avg loss=280.1946]Checkpoint at iteration 679 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 280.1945831298828

Training iteration:  68%|██████▊   | 679/1001 [37:08<10:13,  1.90s/it, avg loss=146.6187]
Training iteration:  68%|██████▊   | 680/1001 [37:08<10:11,  1.90s/it, avg loss=146.6187]Checkpoint at iteration 680 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 146.6187316894531

Training iteration:  68%|██████▊   | 680/1001 [37:10<10:11,  1.90s/it, avg loss=286.7254]
Training iteration:  68%|██████▊   | 681/1001 [37:10<10:09,  1.90s/it, avg loss=286.7254]Checkpoint at iteration 681 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 286.7253921508789

Training iteration:  68%|██████▊   | 681/1001 [37:12<10:09,  1.90s/it, avg loss=280.4964]
Training iteration:  68%|██████▊   | 682/1001 [37:12<10:07,  1.90s/it, avg loss=280.4964]Checkpoint at iteration 682 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 280.49644775390624

Training iteration:  68%|██████▊   | 682/1001 [37:14<10:07,  1.90s/it, avg loss=280.3995]
Training iteration:  68%|██████▊   | 683/1001 [37:14<10:05,  1.90s/it, avg loss=280.3995]Checkpoint at iteration 683 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 280.3994766235352

Training iteration:  68%|██████▊   | 683/1001 [37:16<10:05,  1.90s/it, avg loss=151.6051]
Training iteration:  68%|██████▊   | 684/1001 [37:16<10:03,  1.90s/it, avg loss=151.6051]Checkpoint at iteration 684 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 151.6051483154297

Training iteration:  68%|██████▊   | 684/1001 [37:17<10:03,  1.90s/it, avg loss=274.4942]
Training iteration:  68%|██████▊   | 685/1001 [37:17<10:01,  1.90s/it, avg loss=274.4942]Checkpoint at iteration 685 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 274.49416198730466

Training iteration:  68%|██████▊   | 685/1001 [37:19<10:01,  1.90s/it, avg loss=284.2338]
Training iteration:  69%|██████▊   | 686/1001 [37:19<09:59,  1.90s/it, avg loss=284.2338]Checkpoint at iteration 686 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 284.23375244140624

Training iteration:  69%|██████▊   | 686/1001 [37:21<09:59,  1.90s/it, avg loss=274.0394]
Training iteration:  69%|██████▊   | 687/1001 [37:21<09:57,  1.90s/it, avg loss=274.0394]Checkpoint at iteration 687 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 274.03940734863284

Training iteration:  69%|██████▊   | 687/1001 [37:23<09:57,  1.90s/it, avg loss=281.2186]
Training iteration:  69%|██████▊   | 688/1001 [37:23<09:55,  1.90s/it, avg loss=281.2186]Checkpoint at iteration 688 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 281.21864929199216

Training iteration:  69%|██████▊   | 688/1001 [37:25<09:55,  1.90s/it, avg loss=162.8964]
Training iteration:  69%|██████▉   | 689/1001 [37:25<09:53,  1.90s/it, avg loss=162.8964]Checkpoint at iteration 689 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 162.8964416503906

Training iteration:  69%|██████▉   | 689/1001 [37:27<09:53,  1.90s/it, avg loss=271.4881]
Training iteration:  69%|██████▉   | 690/1001 [37:27<09:51,  1.90s/it, avg loss=271.4881]Checkpoint at iteration 690 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 271.4880798339844

Training iteration:  69%|██████▉   | 690/1001 [37:29<09:51,  1.90s/it, avg loss=160.7594]
Training iteration:  69%|██████▉   | 691/1001 [37:29<09:49,  1.90s/it, avg loss=160.7594]Checkpoint at iteration 691 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 160.75937194824218

Training iteration:  69%|██████▉   | 691/1001 [37:31<09:49,  1.90s/it, avg loss=162.2703]
Training iteration:  69%|██████▉   | 692/1001 [37:31<09:47,  1.90s/it, avg loss=162.2703]Checkpoint at iteration 692 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 162.27029876708986

Training iteration:  69%|██████▉   | 692/1001 [37:33<09:47,  1.90s/it, avg loss=157.2959]
Training iteration:  69%|██████▉   | 693/1001 [37:33<09:47,  1.91s/it, avg loss=157.2959]Checkpoint at iteration 693 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 157.29592895507812

Training iteration:  69%|██████▉   | 693/1001 [37:35<09:47,  1.91s/it, avg loss=153.2240]
Training iteration:  69%|██████▉   | 694/1001 [37:35<09:47,  1.91s/it, avg loss=153.2240]Checkpoint at iteration 694 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 153.2239532470703

Training iteration:  69%|██████▉   | 694/1001 [37:37<09:47,  1.91s/it, avg loss=286.0667]
Training iteration:  69%|██████▉   | 695/1001 [37:37<09:46,  1.92s/it, avg loss=286.0667]Checkpoint at iteration 695 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 286.0667037963867

Training iteration:  69%|██████▉   | 695/1001 [37:38<09:46,  1.92s/it, avg loss=156.1528]
Training iteration:  70%|██████▉   | 696/1001 [37:38<09:44,  1.92s/it, avg loss=156.1528]Checkpoint at iteration 696 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 156.15276031494142

Training iteration:  70%|██████▉   | 696/1001 [37:40<09:44,  1.92s/it, avg loss=277.5695]
Training iteration:  70%|██████▉   | 697/1001 [37:40<09:42,  1.92s/it, avg loss=277.5695]Checkpoint at iteration 697 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 277.5695495605469

Training iteration:  70%|██████▉   | 697/1001 [37:42<09:42,  1.92s/it, avg loss=276.2441]
Training iteration:  70%|██████▉   | 698/1001 [37:42<09:41,  1.92s/it, avg loss=276.2441]Checkpoint at iteration 698 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 276.2440902709961

Training iteration:  70%|██████▉   | 698/1001 [37:44<09:41,  1.92s/it, avg loss=253.3813]
Training iteration:  70%|██████▉   | 699/1001 [37:44<09:39,  1.92s/it, avg loss=253.3813]Checkpoint at iteration 699 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 253.38128509521485

Training iteration:  70%|██████▉   | 699/1001 [37:46<09:39,  1.92s/it, avg loss=271.1430]
Training iteration:  70%|██████▉   | 700/1001 [37:46<09:38,  1.92s/it, avg loss=271.1430]Optimization iteration 700 evaluation begins...
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
A new evaluation visualization has been saved: ./saved_data/20240110-050655/it700.png
Training network 0 for evaluation...
Training network 1 for evaluation...
Training network 2 for evaluation...
Training network 3 for evaluation...
Testing network 0 on real datasets for evaluation...
Testing network 1 on real datasets for evaluation...
Testing network 2 on real datasets for evaluation...
Testing network 3 on real datasets for evaluation...
Optimization iteration 700, eval auroc score (train): 37394.2702, eval auroc score (test): 38736.7949
Checkpoint at iteration 700 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 271.1430206298828

Training iteration:  70%|██████▉   | 700/1001 [45:49<09:38,  1.92s/it, avg loss=163.7469]
Training iteration:  70%|███████   | 701/1001 [45:49<12:10:20, 146.07s/it, avg loss=163.7469]Checkpoint at iteration 701 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 163.74689483642578

Training iteration:  70%|███████   | 701/1001 [45:51<12:10:20, 146.07s/it, avg loss=157.1450]
Training iteration:  70%|███████   | 702/1001 [45:51<8:32:44, 102.89s/it, avg loss=157.1450] Checkpoint at iteration 702 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 157.1449768066406

Training iteration:  70%|███████   | 702/1001 [45:53<8:32:44, 102.89s/it, avg loss=153.9380]
Training iteration:  70%|███████   | 703/1001 [45:53<6:00:54, 72.67s/it, avg loss=153.9380] Checkpoint at iteration 703 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 153.93799743652343

Training iteration:  70%|███████   | 703/1001 [45:55<6:00:54, 72.67s/it, avg loss=148.3142]
Training iteration:  70%|███████   | 704/1001 [45:55<4:14:58, 51.51s/it, avg loss=148.3142]Checkpoint at iteration 704 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 148.3142349243164

Training iteration:  70%|███████   | 704/1001 [45:57<4:14:58, 51.51s/it, avg loss=149.4822]
Training iteration:  70%|███████   | 705/1001 [45:57<3:01:03, 36.70s/it, avg loss=149.4822]Checkpoint at iteration 705 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 149.48220672607422

Training iteration:  70%|███████   | 705/1001 [45:59<3:01:03, 36.70s/it, avg loss=288.2775]
Training iteration:  71%|███████   | 706/1001 [45:59<2:09:28, 26.33s/it, avg loss=288.2775]Checkpoint at iteration 706 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 288.27746124267577

Training iteration:  71%|███████   | 706/1001 [46:01<2:09:28, 26.33s/it, avg loss=287.5653]
Training iteration:  71%|███████   | 707/1001 [46:01<1:33:28, 19.08s/it, avg loss=287.5653]Checkpoint at iteration 707 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 287.56529388427737

Training iteration:  71%|███████   | 707/1001 [46:04<1:33:28, 19.08s/it, avg loss=278.7373]
Training iteration:  71%|███████   | 708/1001 [46:04<1:08:20, 14.00s/it, avg loss=278.7373]Checkpoint at iteration 708 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 278.73729095458987

Training iteration:  71%|███████   | 708/1001 [46:06<1:08:20, 14.00s/it, avg loss=159.7204]
Training iteration:  71%|███████   | 709/1001 [46:06<50:48, 10.44s/it, avg loss=159.7204]  Checkpoint at iteration 709 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 159.72040252685548

Training iteration:  71%|███████   | 709/1001 [46:08<50:48, 10.44s/it, avg loss=154.1570]
Training iteration:  71%|███████   | 710/1001 [46:08<38:33,  7.95s/it, avg loss=154.1570]Checkpoint at iteration 710 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 154.15703582763672

Training iteration:  71%|███████   | 710/1001 [46:10<38:33,  7.95s/it, avg loss=292.7453]
Training iteration:  71%|███████   | 711/1001 [46:10<29:59,  6.21s/it, avg loss=292.7453]Checkpoint at iteration 711 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 292.74530029296875

Training iteration:  71%|███████   | 711/1001 [46:12<29:59,  6.21s/it, avg loss=283.9246]
Training iteration:  71%|███████   | 712/1001 [46:12<24:01,  4.99s/it, avg loss=283.9246]Checkpoint at iteration 712 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 283.92459259033205

Training iteration:  71%|███████   | 712/1001 [46:14<24:01,  4.99s/it, avg loss=150.5253]
Training iteration:  71%|███████   | 713/1001 [46:14<19:50,  4.13s/it, avg loss=150.5253]Checkpoint at iteration 713 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 150.52526397705077

Training iteration:  71%|███████   | 713/1001 [46:16<19:50,  4.13s/it, avg loss=283.2032]
Training iteration:  71%|███████▏  | 714/1001 [46:16<16:54,  3.54s/it, avg loss=283.2032]Checkpoint at iteration 714 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 283.20323791503904

Training iteration:  71%|███████▏  | 714/1001 [46:19<16:54,  3.54s/it, avg loss=277.8917]
Training iteration:  71%|███████▏  | 715/1001 [46:19<14:51,  3.12s/it, avg loss=277.8917]Checkpoint at iteration 715 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 277.89169158935545

Training iteration:  71%|███████▏  | 715/1001 [46:21<14:51,  3.12s/it, avg loss=150.2166]
Training iteration:  72%|███████▏  | 716/1001 [46:21<13:24,  2.82s/it, avg loss=150.2166]Checkpoint at iteration 716 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 150.21660766601562

Training iteration:  72%|███████▏  | 716/1001 [46:23<13:24,  2.82s/it, avg loss=154.4158]
Training iteration:  72%|███████▏  | 717/1001 [46:23<12:23,  2.62s/it, avg loss=154.4158]Checkpoint at iteration 717 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 154.41576232910157

Training iteration:  72%|███████▏  | 717/1001 [46:25<12:23,  2.62s/it, avg loss=147.7012]
Training iteration:  72%|███████▏  | 718/1001 [46:25<11:40,  2.48s/it, avg loss=147.7012]Checkpoint at iteration 718 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 147.70116271972657

Training iteration:  72%|███████▏  | 718/1001 [46:27<11:40,  2.48s/it, avg loss=288.1145]
Training iteration:  72%|███████▏  | 719/1001 [46:27<11:09,  2.38s/it, avg loss=288.1145]Checkpoint at iteration 719 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 288.11446685791014

Training iteration:  72%|███████▏  | 719/1001 [46:29<11:09,  2.38s/it, avg loss=284.9777]
Training iteration:  72%|███████▏  | 720/1001 [46:29<10:47,  2.31s/it, avg loss=284.9777]Checkpoint at iteration 720 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 284.9777236938477

Training iteration:  72%|███████▏  | 720/1001 [46:31<10:47,  2.31s/it, avg loss=161.6922]
Training iteration:  72%|███████▏  | 721/1001 [46:31<10:31,  2.26s/it, avg loss=161.6922]Checkpoint at iteration 721 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 161.69222259521484

Training iteration:  72%|███████▏  | 721/1001 [46:34<10:31,  2.26s/it, avg loss=149.8174]
Training iteration:  72%|███████▏  | 722/1001 [46:34<10:19,  2.22s/it, avg loss=149.8174]Checkpoint at iteration 722 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 149.8173583984375

Training iteration:  72%|███████▏  | 722/1001 [46:36<10:19,  2.22s/it, avg loss=279.1936]
Training iteration:  72%|███████▏  | 723/1001 [46:36<10:10,  2.20s/it, avg loss=279.1936]Checkpoint at iteration 723 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 279.19355926513674

Training iteration:  72%|███████▏  | 723/1001 [46:38<10:10,  2.20s/it, avg loss=144.0817]
Training iteration:  72%|███████▏  | 724/1001 [46:38<10:03,  2.18s/it, avg loss=144.0817]Checkpoint at iteration 724 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 144.0816619873047

Training iteration:  72%|███████▏  | 724/1001 [46:40<10:03,  2.18s/it, avg loss=154.2409]
Training iteration:  72%|███████▏  | 725/1001 [46:40<09:58,  2.17s/it, avg loss=154.2409]Checkpoint at iteration 725 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 154.24090576171875

Training iteration:  72%|███████▏  | 725/1001 [46:42<09:58,  2.17s/it, avg loss=140.0214]
Training iteration:  73%|███████▎  | 726/1001 [46:42<09:53,  2.16s/it, avg loss=140.0214]Checkpoint at iteration 726 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 140.02142944335938

Training iteration:  73%|███████▎  | 726/1001 [46:44<09:53,  2.16s/it, avg loss=241.8027]
Training iteration:  73%|███████▎  | 727/1001 [46:44<09:50,  2.15s/it, avg loss=241.8027]Checkpoint at iteration 727 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 241.80267486572265

Training iteration:  73%|███████▎  | 727/1001 [46:46<09:50,  2.15s/it, avg loss=285.5076]
Training iteration:  73%|███████▎  | 728/1001 [46:46<09:47,  2.15s/it, avg loss=285.5076]Checkpoint at iteration 728 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 285.50757293701173

Training iteration:  73%|███████▎  | 728/1001 [46:49<09:47,  2.15s/it, avg loss=292.9187]
Training iteration:  73%|███████▎  | 729/1001 [46:49<09:44,  2.15s/it, avg loss=292.9187]Checkpoint at iteration 729 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 292.9187408447266

Training iteration:  73%|███████▎  | 729/1001 [46:51<09:44,  2.15s/it, avg loss=286.6110]
Training iteration:  73%|███████▎  | 730/1001 [46:51<09:41,  2.15s/it, avg loss=286.6110]Checkpoint at iteration 730 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 286.61098327636716

Training iteration:  73%|███████▎  | 730/1001 [46:53<09:41,  2.15s/it, avg loss=278.1143]
Training iteration:  73%|███████▎  | 731/1001 [46:53<09:39,  2.15s/it, avg loss=278.1143]Checkpoint at iteration 731 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 278.11430206298826

Training iteration:  73%|███████▎  | 731/1001 [46:55<09:39,  2.15s/it, avg loss=284.3175]
Training iteration:  73%|███████▎  | 732/1001 [46:55<09:36,  2.14s/it, avg loss=284.3175]Checkpoint at iteration 732 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 284.31754913330076

Training iteration:  73%|███████▎  | 732/1001 [46:57<09:36,  2.14s/it, avg loss=284.5726]
Training iteration:  73%|███████▎  | 733/1001 [46:57<09:34,  2.14s/it, avg loss=284.5726]Checkpoint at iteration 733 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 284.57255859375

Training iteration:  73%|███████▎  | 733/1001 [46:59<09:34,  2.14s/it, avg loss=149.1941]
Training iteration:  73%|███████▎  | 734/1001 [46:59<09:32,  2.14s/it, avg loss=149.1941]Checkpoint at iteration 734 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 149.19406280517578

Training iteration:  73%|███████▎  | 734/1001 [47:01<09:32,  2.14s/it, avg loss=147.3921]
Training iteration:  73%|███████▎  | 735/1001 [47:01<09:29,  2.14s/it, avg loss=147.3921]Checkpoint at iteration 735 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 147.39210205078126

Training iteration:  73%|███████▎  | 735/1001 [47:04<09:29,  2.14s/it, avg loss=277.7428]
Training iteration:  74%|███████▎  | 736/1001 [47:04<09:27,  2.14s/it, avg loss=277.7428]Checkpoint at iteration 736 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 277.7428314208984

Training iteration:  74%|███████▎  | 736/1001 [47:06<09:27,  2.14s/it, avg loss=152.9590]
Training iteration:  74%|███████▎  | 737/1001 [47:06<09:25,  2.14s/it, avg loss=152.9590]Checkpoint at iteration 737 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 152.95895538330078

Training iteration:  74%|███████▎  | 737/1001 [47:08<09:25,  2.14s/it, avg loss=153.8577]
Training iteration:  74%|███████▎  | 738/1001 [47:08<09:23,  2.14s/it, avg loss=153.8577]Checkpoint at iteration 738 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 153.85765075683594

Training iteration:  74%|███████▎  | 738/1001 [47:10<09:23,  2.14s/it, avg loss=141.4775]
Training iteration:  74%|███████▍  | 739/1001 [47:10<09:21,  2.14s/it, avg loss=141.4775]Checkpoint at iteration 739 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 141.47750244140624

Training iteration:  74%|███████▍  | 739/1001 [47:12<09:21,  2.14s/it, avg loss=146.1274]
Training iteration:  74%|███████▍  | 740/1001 [47:12<09:18,  2.14s/it, avg loss=146.1274]Checkpoint at iteration 740 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 146.12744598388673

Training iteration:  74%|███████▍  | 740/1001 [47:14<09:18,  2.14s/it, avg loss=143.2638]
Training iteration:  74%|███████▍  | 741/1001 [47:14<09:16,  2.14s/it, avg loss=143.2638]Checkpoint at iteration 741 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 143.26382141113282

Training iteration:  74%|███████▍  | 741/1001 [47:16<09:16,  2.14s/it, avg loss=287.6292]
Training iteration:  74%|███████▍  | 742/1001 [47:16<09:13,  2.14s/it, avg loss=287.6292]Checkpoint at iteration 742 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 287.62923736572264

Training iteration:  74%|███████▍  | 742/1001 [47:18<09:13,  2.14s/it, avg loss=285.8654]
Training iteration:  74%|███████▍  | 743/1001 [47:18<09:11,  2.14s/it, avg loss=285.8654]Checkpoint at iteration 743 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 285.8653793334961

Training iteration:  74%|███████▍  | 743/1001 [47:21<09:11,  2.14s/it, avg loss=289.7497]
Training iteration:  74%|███████▍  | 744/1001 [47:21<09:09,  2.14s/it, avg loss=289.7497]Checkpoint at iteration 744 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 289.74966583251955

Training iteration:  74%|███████▍  | 744/1001 [47:23<09:09,  2.14s/it, avg loss=147.2922]
Training iteration:  74%|███████▍  | 745/1001 [47:23<09:07,  2.14s/it, avg loss=147.2922]Checkpoint at iteration 745 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 147.2921920776367

Training iteration:  74%|███████▍  | 745/1001 [47:25<09:07,  2.14s/it, avg loss=141.9501]
Training iteration:  75%|███████▍  | 746/1001 [47:25<09:04,  2.14s/it, avg loss=141.9501]Checkpoint at iteration 746 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 141.95008697509766

Training iteration:  75%|███████▍  | 746/1001 [47:27<09:04,  2.14s/it, avg loss=288.8980]
Training iteration:  75%|███████▍  | 747/1001 [47:27<09:02,  2.14s/it, avg loss=288.8980]Checkpoint at iteration 747 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 288.8980117797852

Training iteration:  75%|███████▍  | 747/1001 [47:29<09:02,  2.14s/it, avg loss=287.2196]
Training iteration:  75%|███████▍  | 748/1001 [47:29<09:00,  2.14s/it, avg loss=287.2196]Checkpoint at iteration 748 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 287.21962585449216

Training iteration:  75%|███████▍  | 748/1001 [47:31<09:00,  2.14s/it, avg loss=151.8895]
Training iteration:  75%|███████▍  | 749/1001 [47:31<08:58,  2.14s/it, avg loss=151.8895]Checkpoint at iteration 749 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 151.88946838378905

Training iteration:  75%|███████▍  | 749/1001 [47:33<08:58,  2.14s/it, avg loss=144.3908]
Training iteration:  75%|███████▍  | 750/1001 [47:33<08:56,  2.14s/it, avg loss=144.3908]Checkpoint at iteration 750 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 144.39083557128907

Training iteration:  75%|███████▍  | 750/1001 [47:36<08:56,  2.14s/it, avg loss=287.8132]
Training iteration:  75%|███████▌  | 751/1001 [47:36<08:54,  2.14s/it, avg loss=287.8132]Checkpoint at iteration 751 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 287.8131576538086

Training iteration:  75%|███████▌  | 751/1001 [47:38<08:54,  2.14s/it, avg loss=288.0860]
Training iteration:  75%|███████▌  | 752/1001 [47:38<08:52,  2.14s/it, avg loss=288.0860]Checkpoint at iteration 752 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 288.08600463867185

Training iteration:  75%|███████▌  | 752/1001 [47:40<08:52,  2.14s/it, avg loss=284.1615]
Training iteration:  75%|███████▌  | 753/1001 [47:40<08:50,  2.14s/it, avg loss=284.1615]Checkpoint at iteration 753 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 284.16148986816404

Training iteration:  75%|███████▌  | 753/1001 [47:42<08:50,  2.14s/it, avg loss=152.1686]
Training iteration:  75%|███████▌  | 754/1001 [47:42<08:48,  2.14s/it, avg loss=152.1686]Checkpoint at iteration 754 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 152.16861572265626

Training iteration:  75%|███████▌  | 754/1001 [47:44<08:48,  2.14s/it, avg loss=143.1412]
Training iteration:  75%|███████▌  | 755/1001 [47:44<08:46,  2.14s/it, avg loss=143.1412]Checkpoint at iteration 755 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 143.14122619628907

Training iteration:  75%|███████▌  | 755/1001 [47:46<08:46,  2.14s/it, avg loss=286.7403]
Training iteration:  76%|███████▌  | 756/1001 [47:46<08:43,  2.14s/it, avg loss=286.7403]Checkpoint at iteration 756 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 286.7402648925781

Training iteration:  76%|███████▌  | 756/1001 [47:48<08:43,  2.14s/it, avg loss=283.8003]
Training iteration:  76%|███████▌  | 757/1001 [47:48<08:41,  2.14s/it, avg loss=283.8003]Checkpoint at iteration 757 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 283.80028228759767

Training iteration:  76%|███████▌  | 757/1001 [47:51<08:41,  2.14s/it, avg loss=141.2204]
Training iteration:  76%|███████▌  | 758/1001 [47:51<08:39,  2.14s/it, avg loss=141.2204]Checkpoint at iteration 758 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 141.2203598022461

Training iteration:  76%|███████▌  | 758/1001 [47:53<08:39,  2.14s/it, avg loss=290.9761]
Training iteration:  76%|███████▌  | 759/1001 [47:53<08:37,  2.14s/it, avg loss=290.9761]Checkpoint at iteration 759 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 290.9761032104492

Training iteration:  76%|███████▌  | 759/1001 [47:55<08:37,  2.14s/it, avg loss=145.3112]
Training iteration:  76%|███████▌  | 760/1001 [47:55<08:34,  2.14s/it, avg loss=145.3112]Checkpoint at iteration 760 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 145.31118621826172

Training iteration:  76%|███████▌  | 760/1001 [47:57<08:34,  2.14s/it, avg loss=286.6621]
Training iteration:  76%|███████▌  | 761/1001 [47:57<08:32,  2.14s/it, avg loss=286.6621]Checkpoint at iteration 761 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 286.6620559692383

Training iteration:  76%|███████▌  | 761/1001 [47:59<08:32,  2.14s/it, avg loss=283.2180]
Training iteration:  76%|███████▌  | 762/1001 [47:59<08:30,  2.14s/it, avg loss=283.2180]Checkpoint at iteration 762 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 283.21796264648435

Training iteration:  76%|███████▌  | 762/1001 [48:01<08:30,  2.14s/it, avg loss=156.0211]
Training iteration:  76%|███████▌  | 763/1001 [48:01<08:28,  2.14s/it, avg loss=156.0211]Checkpoint at iteration 763 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 156.0211410522461

Training iteration:  76%|███████▌  | 763/1001 [48:03<08:28,  2.14s/it, avg loss=277.5120]
Training iteration:  76%|███████▋  | 764/1001 [48:03<08:26,  2.14s/it, avg loss=277.5120]Checkpoint at iteration 764 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 277.51195068359374

Training iteration:  76%|███████▋  | 764/1001 [48:06<08:26,  2.14s/it, avg loss=285.6112]
Training iteration:  76%|███████▋  | 765/1001 [48:06<08:24,  2.14s/it, avg loss=285.6112]Checkpoint at iteration 765 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 285.6112365722656

Training iteration:  76%|███████▋  | 765/1001 [48:08<08:24,  2.14s/it, avg loss=151.8616]
Training iteration:  77%|███████▋  | 766/1001 [48:08<08:22,  2.14s/it, avg loss=151.8616]Checkpoint at iteration 766 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 151.86158294677733

Training iteration:  77%|███████▋  | 766/1001 [48:10<08:22,  2.14s/it, avg loss=279.4226]
Training iteration:  77%|███████▋  | 767/1001 [48:10<08:20,  2.14s/it, avg loss=279.4226]Checkpoint at iteration 767 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 279.42257232666014

Training iteration:  77%|███████▋  | 767/1001 [48:12<08:20,  2.14s/it, avg loss=147.5071]
Training iteration:  77%|███████▋  | 768/1001 [48:12<08:18,  2.14s/it, avg loss=147.5071]Checkpoint at iteration 768 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 147.50713653564452

Training iteration:  77%|███████▋  | 768/1001 [48:14<08:18,  2.14s/it, avg loss=149.8538]
Training iteration:  77%|███████▋  | 769/1001 [48:14<08:15,  2.14s/it, avg loss=149.8538]Checkpoint at iteration 769 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 149.85380096435546

Training iteration:  77%|███████▋  | 769/1001 [48:16<08:15,  2.14s/it, avg loss=140.4126]
Training iteration:  77%|███████▋  | 770/1001 [48:16<08:13,  2.14s/it, avg loss=140.4126]Checkpoint at iteration 770 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 140.41258239746094

Training iteration:  77%|███████▋  | 770/1001 [48:18<08:13,  2.14s/it, avg loss=140.0861]
Training iteration:  77%|███████▋  | 771/1001 [48:18<08:11,  2.14s/it, avg loss=140.0861]Checkpoint at iteration 771 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 140.08614196777344

Training iteration:  77%|███████▋  | 771/1001 [48:20<08:11,  2.14s/it, avg loss=140.6480]
Training iteration:  77%|███████▋  | 772/1001 [48:20<08:09,  2.14s/it, avg loss=140.6480]Checkpoint at iteration 772 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 140.64798889160156

Training iteration:  77%|███████▋  | 772/1001 [48:23<08:09,  2.14s/it, avg loss=136.2829]
Training iteration:  77%|███████▋  | 773/1001 [48:23<08:07,  2.14s/it, avg loss=136.2829]Checkpoint at iteration 773 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 136.28285522460936

Training iteration:  77%|███████▋  | 773/1001 [48:25<08:07,  2.14s/it, avg loss=291.5839]
Training iteration:  77%|███████▋  | 774/1001 [48:25<08:05,  2.14s/it, avg loss=291.5839]Checkpoint at iteration 774 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 291.5838684082031

Training iteration:  77%|███████▋  | 774/1001 [48:27<08:05,  2.14s/it, avg loss=131.8364]
Training iteration:  77%|███████▋  | 775/1001 [48:27<08:03,  2.14s/it, avg loss=131.8364]Checkpoint at iteration 775 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 131.83637390136718

Training iteration:  77%|███████▋  | 775/1001 [48:29<08:03,  2.14s/it, avg loss=136.7120]
Training iteration:  78%|███████▊  | 776/1001 [48:29<08:01,  2.14s/it, avg loss=136.7120]Checkpoint at iteration 776 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 136.71202697753907

Training iteration:  78%|███████▊  | 776/1001 [48:31<08:01,  2.14s/it, avg loss=291.6714]
Training iteration:  78%|███████▊  | 777/1001 [48:31<07:58,  2.14s/it, avg loss=291.6714]Checkpoint at iteration 777 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 291.6714126586914

Training iteration:  78%|███████▊  | 777/1001 [48:33<07:58,  2.14s/it, avg loss=299.4656]
Training iteration:  78%|███████▊  | 778/1001 [48:33<07:56,  2.14s/it, avg loss=299.4656]Checkpoint at iteration 778 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 299.46558074951173

Training iteration:  78%|███████▊  | 778/1001 [48:35<07:56,  2.14s/it, avg loss=287.7454]
Training iteration:  78%|███████▊  | 779/1001 [48:35<07:54,  2.14s/it, avg loss=287.7454]Checkpoint at iteration 779 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 287.74537353515626

Training iteration:  78%|███████▊  | 779/1001 [48:38<07:54,  2.14s/it, avg loss=142.3976]
Training iteration:  78%|███████▊  | 780/1001 [48:38<07:52,  2.14s/it, avg loss=142.3976]Checkpoint at iteration 780 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 142.3976043701172

Training iteration:  78%|███████▊  | 780/1001 [48:40<07:52,  2.14s/it, avg loss=296.4870]
Training iteration:  78%|███████▊  | 781/1001 [48:40<07:50,  2.14s/it, avg loss=296.4870]Checkpoint at iteration 781 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 296.4869674682617

Training iteration:  78%|███████▊  | 781/1001 [48:42<07:50,  2.14s/it, avg loss=291.5611]
Training iteration:  78%|███████▊  | 782/1001 [48:42<07:47,  2.14s/it, avg loss=291.5611]Checkpoint at iteration 782 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 291.5610595703125

Training iteration:  78%|███████▊  | 782/1001 [48:44<07:47,  2.14s/it, avg loss=256.9897]
Training iteration:  78%|███████▊  | 783/1001 [48:44<07:44,  2.13s/it, avg loss=256.9897]Checkpoint at iteration 783 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 256.9896835327148

Training iteration:  78%|███████▊  | 783/1001 [48:46<07:44,  2.13s/it, avg loss=290.7720]
Training iteration:  78%|███████▊  | 784/1001 [48:46<07:41,  2.12s/it, avg loss=290.7720]Checkpoint at iteration 784 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 290.77197113037107

Training iteration:  78%|███████▊  | 784/1001 [48:48<07:41,  2.12s/it, avg loss=281.8402]
Training iteration:  78%|███████▊  | 785/1001 [48:48<07:38,  2.12s/it, avg loss=281.8402]Checkpoint at iteration 785 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 281.84024810791016

Training iteration:  78%|███████▊  | 785/1001 [48:50<07:38,  2.12s/it, avg loss=279.1103]
Training iteration:  79%|███████▊  | 786/1001 [48:50<07:35,  2.12s/it, avg loss=279.1103]Checkpoint at iteration 786 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 279.1103042602539

Training iteration:  79%|███████▊  | 786/1001 [48:52<07:35,  2.12s/it, avg loss=276.8185]
Training iteration:  79%|███████▊  | 787/1001 [48:52<07:32,  2.12s/it, avg loss=276.8185]Checkpoint at iteration 787 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 276.81848907470703

Training iteration:  79%|███████▊  | 787/1001 [48:55<07:32,  2.12s/it, avg loss=277.2508]
Training iteration:  79%|███████▊  | 788/1001 [48:55<07:30,  2.11s/it, avg loss=277.2508]Checkpoint at iteration 788 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 277.25079650878905

Training iteration:  79%|███████▊  | 788/1001 [48:57<07:30,  2.11s/it, avg loss=154.8230]
Training iteration:  79%|███████▉  | 789/1001 [48:57<07:27,  2.11s/it, avg loss=154.8230]Checkpoint at iteration 789 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 154.8230010986328

Training iteration:  79%|███████▉  | 789/1001 [48:59<07:27,  2.11s/it, avg loss=153.8743]
Training iteration:  79%|███████▉  | 790/1001 [48:59<07:25,  2.11s/it, avg loss=153.8743]Checkpoint at iteration 790 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 153.87431640625

Training iteration:  79%|███████▉  | 790/1001 [49:01<07:25,  2.11s/it, avg loss=291.0878]
Training iteration:  79%|███████▉  | 791/1001 [49:01<07:23,  2.11s/it, avg loss=291.0878]Checkpoint at iteration 791 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 291.08780670166016

Training iteration:  79%|███████▉  | 791/1001 [49:03<07:23,  2.11s/it, avg loss=267.5570]
Training iteration:  79%|███████▉  | 792/1001 [49:03<07:21,  2.11s/it, avg loss=267.5570]Checkpoint at iteration 792 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 267.55698547363284

Training iteration:  79%|███████▉  | 792/1001 [49:05<07:21,  2.11s/it, avg loss=157.1276]
Training iteration:  79%|███████▉  | 793/1001 [49:05<07:19,  2.11s/it, avg loss=157.1276]Checkpoint at iteration 793 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 157.12760467529296

Training iteration:  79%|███████▉  | 793/1001 [49:07<07:19,  2.11s/it, avg loss=278.8571]
Training iteration:  79%|███████▉  | 794/1001 [49:07<07:17,  2.11s/it, avg loss=278.8571]Checkpoint at iteration 794 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 278.85709991455076

Training iteration:  79%|███████▉  | 794/1001 [49:09<07:17,  2.11s/it, avg loss=280.6765]
Training iteration:  79%|███████▉  | 795/1001 [49:09<07:14,  2.11s/it, avg loss=280.6765]Checkpoint at iteration 795 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 280.67647857666014

Training iteration:  79%|███████▉  | 795/1001 [49:11<07:14,  2.11s/it, avg loss=291.3257]
Training iteration:  80%|███████▉  | 796/1001 [49:11<07:12,  2.11s/it, avg loss=291.3257]Checkpoint at iteration 796 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 291.32573852539065

Training iteration:  80%|███████▉  | 796/1001 [49:14<07:12,  2.11s/it, avg loss=282.3946]
Training iteration:  80%|███████▉  | 797/1001 [49:14<07:10,  2.11s/it, avg loss=282.3946]Checkpoint at iteration 797 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 282.39464111328124

Training iteration:  80%|███████▉  | 797/1001 [49:16<07:10,  2.11s/it, avg loss=146.9077]
Training iteration:  80%|███████▉  | 798/1001 [49:16<07:08,  2.11s/it, avg loss=146.9077]Checkpoint at iteration 798 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 146.9077392578125

Training iteration:  80%|███████▉  | 798/1001 [49:18<07:08,  2.11s/it, avg loss=150.2369]
Training iteration:  80%|███████▉  | 799/1001 [49:18<07:06,  2.11s/it, avg loss=150.2369]Checkpoint at iteration 799 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 150.236865234375

Training iteration:  80%|███████▉  | 799/1001 [49:20<07:06,  2.11s/it, avg loss=149.4982]
Training iteration:  80%|███████▉  | 800/1001 [49:20<07:04,  2.11s/it, avg loss=149.4982]Optimization iteration 800 evaluation begins...
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
A new evaluation visualization has been saved: ./saved_data/20240110-050655/it800.png
Training network 0 for evaluation...
Training network 1 for evaluation...
Training network 2 for evaluation...
Training network 3 for evaluation...
Testing network 0 on real datasets for evaluation...
Testing network 1 on real datasets for evaluation...
Testing network 2 on real datasets for evaluation...
Testing network 3 on real datasets for evaluation...
Optimization iteration 800, eval auroc score (train): 35136.6286, eval auroc score (test): 36495.5120
Checkpoint at iteration 800 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 149.4981719970703

Training iteration:  80%|███████▉  | 800/1001 [58:37<07:04,  2.11s/it, avg loss=281.5623]
Training iteration:  80%|████████  | 801/1001 [58:37<9:22:03, 168.62s/it, avg loss=281.5623]Checkpoint at iteration 801 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 281.5623260498047

Training iteration:  80%|████████  | 801/1001 [58:39<9:22:03, 168.62s/it, avg loss=147.8664]
Training iteration:  80%|████████  | 802/1001 [58:39<6:33:47, 118.73s/it, avg loss=147.8664]Checkpoint at iteration 802 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 147.8664337158203

Training iteration:  80%|████████  | 802/1001 [58:42<6:33:47, 118.73s/it, avg loss=284.7991]
Training iteration:  80%|████████  | 803/1001 [58:42<4:36:34, 83.81s/it, avg loss=284.7991] Checkpoint at iteration 803 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 284.79910736083986

Training iteration:  80%|████████  | 803/1001 [58:44<4:36:34, 83.81s/it, avg loss=152.2011]
Training iteration:  80%|████████  | 804/1001 [58:44<3:14:55, 59.37s/it, avg loss=152.2011]Checkpoint at iteration 804 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 152.2010925292969

Training iteration:  80%|████████  | 804/1001 [58:46<3:14:55, 59.37s/it, avg loss=145.4308]
Training iteration:  80%|████████  | 805/1001 [58:46<2:18:01, 42.25s/it, avg loss=145.4308]Checkpoint at iteration 805 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 145.4307830810547

Training iteration:  80%|████████  | 805/1001 [58:49<2:18:01, 42.25s/it, avg loss=280.5463]
Training iteration:  81%|████████  | 806/1001 [58:49<1:38:23, 30.28s/it, avg loss=280.5463]Checkpoint at iteration 806 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 280.5462951660156

Training iteration:  81%|████████  | 806/1001 [58:51<1:38:23, 30.28s/it, avg loss=147.5509]
Training iteration:  81%|████████  | 807/1001 [58:51<1:10:47, 21.89s/it, avg loss=147.5509]Checkpoint at iteration 807 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 147.55091400146483

Training iteration:  81%|████████  | 807/1001 [58:53<1:10:47, 21.89s/it, avg loss=284.5607]
Training iteration:  81%|████████  | 808/1001 [58:53<51:32, 16.02s/it, avg loss=284.5607]  Checkpoint at iteration 808 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 284.5607086181641

Training iteration:  81%|████████  | 808/1001 [58:56<51:32, 16.02s/it, avg loss=280.8474]
Training iteration:  81%|████████  | 809/1001 [58:56<38:07, 11.91s/it, avg loss=280.8474]Checkpoint at iteration 809 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 280.84739685058594

Training iteration:  81%|████████  | 809/1001 [58:58<38:07, 11.91s/it, avg loss=143.0997]
Training iteration:  81%|████████  | 810/1001 [58:58<28:46,  9.04s/it, avg loss=143.0997]Checkpoint at iteration 810 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 143.09971313476564

Training iteration:  81%|████████  | 810/1001 [59:00<28:46,  9.04s/it, avg loss=285.4099]
Training iteration:  81%|████████  | 811/1001 [59:00<22:14,  7.02s/it, avg loss=285.4099]Checkpoint at iteration 811 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 285.40990295410154

Training iteration:  81%|████████  | 811/1001 [59:03<22:14,  7.02s/it, avg loss=281.5913]
Training iteration:  81%|████████  | 812/1001 [59:03<17:41,  5.62s/it, avg loss=281.5913]Checkpoint at iteration 812 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 281.591291809082

Training iteration:  81%|████████  | 812/1001 [59:05<17:41,  5.62s/it, avg loss=149.7579]
Training iteration:  81%|████████  | 813/1001 [59:05<14:30,  4.63s/it, avg loss=149.7579]Checkpoint at iteration 813 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 149.7578903198242

Training iteration:  81%|████████  | 813/1001 [59:07<14:30,  4.63s/it, avg loss=146.8401]
Training iteration:  81%|████████▏ | 814/1001 [59:07<12:16,  3.94s/it, avg loss=146.8401]Checkpoint at iteration 814 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 146.84012756347656

Training iteration:  81%|████████▏ | 814/1001 [59:10<12:16,  3.94s/it, avg loss=150.2436]
Training iteration:  81%|████████▏ | 815/1001 [59:10<10:43,  3.46s/it, avg loss=150.2436]Checkpoint at iteration 815 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 150.2435516357422

Training iteration:  81%|████████▏ | 815/1001 [59:12<10:43,  3.46s/it, avg loss=141.3475]
Training iteration:  82%|████████▏ | 816/1001 [59:12<09:37,  3.12s/it, avg loss=141.3475]Checkpoint at iteration 816 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 141.3474548339844

Training iteration:  82%|████████▏ | 816/1001 [59:14<09:37,  3.12s/it, avg loss=287.4147]
Training iteration:  82%|████████▏ | 817/1001 [59:14<08:50,  2.88s/it, avg loss=287.4147]Checkpoint at iteration 817 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 287.41468658447263

Training iteration:  82%|████████▏ | 817/1001 [59:17<08:50,  2.88s/it, avg loss=290.5900]
Training iteration:  82%|████████▏ | 818/1001 [59:17<08:17,  2.72s/it, avg loss=290.5900]Checkpoint at iteration 818 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 290.5900375366211

Training iteration:  82%|████████▏ | 818/1001 [59:19<08:17,  2.72s/it, avg loss=150.4652]
Training iteration:  82%|████████▏ | 819/1001 [59:19<07:53,  2.60s/it, avg loss=150.4652]Checkpoint at iteration 819 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 150.46520538330077

Training iteration:  82%|████████▏ | 819/1001 [59:21<07:53,  2.60s/it, avg loss=282.2490]
Training iteration:  82%|████████▏ | 820/1001 [59:21<07:36,  2.52s/it, avg loss=282.2490]Checkpoint at iteration 820 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 282.2489837646484

Training iteration:  82%|████████▏ | 820/1001 [59:24<07:36,  2.52s/it, avg loss=144.7887]
Training iteration:  82%|████████▏ | 821/1001 [59:24<07:23,  2.46s/it, avg loss=144.7887]Checkpoint at iteration 821 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 144.7887435913086

Training iteration:  82%|████████▏ | 821/1001 [59:26<07:23,  2.46s/it, avg loss=290.0316]
Training iteration:  82%|████████▏ | 822/1001 [59:26<07:14,  2.43s/it, avg loss=290.0316]Checkpoint at iteration 822 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 290.03163757324216

Training iteration:  82%|████████▏ | 822/1001 [59:28<07:14,  2.43s/it, avg loss=282.8174]
Training iteration:  82%|████████▏ | 823/1001 [59:28<07:07,  2.40s/it, avg loss=282.8174]Checkpoint at iteration 823 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 282.81738128662107

Training iteration:  82%|████████▏ | 823/1001 [59:31<07:07,  2.40s/it, avg loss=288.3594]
Training iteration:  82%|████████▏ | 824/1001 [59:31<07:02,  2.39s/it, avg loss=288.3594]Checkpoint at iteration 824 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 288.3594436645508

Training iteration:  82%|████████▏ | 824/1001 [59:33<07:02,  2.39s/it, avg loss=280.2424]
Training iteration:  82%|████████▏ | 825/1001 [59:33<06:58,  2.38s/it, avg loss=280.2424]Checkpoint at iteration 825 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 280.24236450195315

Training iteration:  82%|████████▏ | 825/1001 [59:35<06:58,  2.38s/it, avg loss=282.7561]
Training iteration:  83%|████████▎ | 826/1001 [59:35<06:54,  2.37s/it, avg loss=282.7561]Checkpoint at iteration 826 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 282.7561462402344

Training iteration:  83%|████████▎ | 826/1001 [59:38<06:54,  2.37s/it, avg loss=147.6636]
Training iteration:  83%|████████▎ | 827/1001 [59:38<06:51,  2.36s/it, avg loss=147.6636]Checkpoint at iteration 827 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 147.6635971069336

Training iteration:  83%|████████▎ | 827/1001 [59:40<06:51,  2.36s/it, avg loss=282.6268]
Training iteration:  83%|████████▎ | 828/1001 [59:40<06:48,  2.36s/it, avg loss=282.6268]Checkpoint at iteration 828 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 282.62678985595704

Training iteration:  83%|████████▎ | 828/1001 [59:42<06:48,  2.36s/it, avg loss=286.1872]
Training iteration:  83%|████████▎ | 829/1001 [59:42<06:44,  2.35s/it, avg loss=286.1872]Checkpoint at iteration 829 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 286.1872222900391

Training iteration:  83%|████████▎ | 829/1001 [59:45<06:44,  2.35s/it, avg loss=150.1017]
Training iteration:  83%|████████▎ | 830/1001 [59:45<06:41,  2.35s/it, avg loss=150.1017]Checkpoint at iteration 830 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 150.10167083740234

Training iteration:  83%|████████▎ | 830/1001 [59:47<06:41,  2.35s/it, avg loss=148.6042]
Training iteration:  83%|████████▎ | 831/1001 [59:47<06:38,  2.34s/it, avg loss=148.6042]Checkpoint at iteration 831 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 148.60420989990234

Training iteration:  83%|████████▎ | 831/1001 [59:49<06:38,  2.34s/it, avg loss=279.3487]
Training iteration:  83%|████████▎ | 832/1001 [59:49<06:35,  2.34s/it, avg loss=279.3487]Checkpoint at iteration 832 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 279.3486862182617

Training iteration:  83%|████████▎ | 832/1001 [59:52<06:35,  2.34s/it, avg loss=149.7787]
Training iteration:  83%|████████▎ | 833/1001 [59:52<06:32,  2.34s/it, avg loss=149.7787]Checkpoint at iteration 833 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 149.77874298095702

Training iteration:  83%|████████▎ | 833/1001 [59:54<06:32,  2.34s/it, avg loss=151.0110]
Training iteration:  83%|████████▎ | 834/1001 [59:54<06:29,  2.33s/it, avg loss=151.0110]Checkpoint at iteration 834 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 151.01104125976562

Training iteration:  83%|████████▎ | 834/1001 [59:56<06:29,  2.33s/it, avg loss=278.8971]
Training iteration:  83%|████████▎ | 835/1001 [59:56<06:27,  2.33s/it, avg loss=278.8971]Checkpoint at iteration 835 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 278.8971115112305

Training iteration:  83%|████████▎ | 835/1001 [59:59<06:27,  2.33s/it, avg loss=153.5214]
Training iteration:  84%|████████▎ | 836/1001 [59:59<06:24,  2.33s/it, avg loss=153.5214]Checkpoint at iteration 836 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 153.52137145996093

Training iteration:  84%|████████▎ | 836/1001 [1:00:01<06:24,  2.33s/it, avg loss=142.8331]
Training iteration:  84%|████████▎ | 837/1001 [1:00:01<06:22,  2.33s/it, avg loss=142.8331]Checkpoint at iteration 837 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 142.83309326171874

Training iteration:  84%|████████▎ | 837/1001 [1:00:03<06:22,  2.33s/it, avg loss=286.1593]
Training iteration:  84%|████████▎ | 838/1001 [1:00:03<06:19,  2.33s/it, avg loss=286.1593]Checkpoint at iteration 838 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 286.1593383789062

Training iteration:  84%|████████▎ | 838/1001 [1:00:06<06:19,  2.33s/it, avg loss=152.4986]
Training iteration:  84%|████████▍ | 839/1001 [1:00:06<06:17,  2.33s/it, avg loss=152.4986]Checkpoint at iteration 839 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 152.49861755371094

Training iteration:  84%|████████▍ | 839/1001 [1:00:08<06:17,  2.33s/it, avg loss=281.3102]
Training iteration:  84%|████████▍ | 840/1001 [1:00:08<06:14,  2.33s/it, avg loss=281.3102]Checkpoint at iteration 840 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 281.3101776123047

Training iteration:  84%|████████▍ | 840/1001 [1:00:10<06:14,  2.33s/it, avg loss=286.9696]
Training iteration:  84%|████████▍ | 841/1001 [1:00:10<06:12,  2.33s/it, avg loss=286.9696]Checkpoint at iteration 841 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 286.96960906982423

Training iteration:  84%|████████▍ | 841/1001 [1:00:13<06:12,  2.33s/it, avg loss=156.5629]
Training iteration:  84%|████████▍ | 842/1001 [1:00:13<06:10,  2.33s/it, avg loss=156.5629]Checkpoint at iteration 842 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 156.5628646850586

Training iteration:  84%|████████▍ | 842/1001 [1:00:15<06:10,  2.33s/it, avg loss=285.6875]
Training iteration:  84%|████████▍ | 843/1001 [1:00:15<06:07,  2.33s/it, avg loss=285.6875]Checkpoint at iteration 843 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 285.68746185302734

Training iteration:  84%|████████▍ | 843/1001 [1:00:17<06:07,  2.33s/it, avg loss=150.4353]
Training iteration:  84%|████████▍ | 844/1001 [1:00:17<06:05,  2.33s/it, avg loss=150.4353]Checkpoint at iteration 844 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 150.43531799316406

Training iteration:  84%|████████▍ | 844/1001 [1:00:20<06:05,  2.33s/it, avg loss=287.5213]
Training iteration:  84%|████████▍ | 845/1001 [1:00:20<06:03,  2.33s/it, avg loss=287.5213]Checkpoint at iteration 845 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 287.52129821777345

Training iteration:  84%|████████▍ | 845/1001 [1:00:22<06:03,  2.33s/it, avg loss=146.5976]
Training iteration:  85%|████████▍ | 846/1001 [1:00:22<06:00,  2.33s/it, avg loss=146.5976]Checkpoint at iteration 846 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 146.5975601196289

Training iteration:  85%|████████▍ | 846/1001 [1:00:24<06:00,  2.33s/it, avg loss=287.7364]
Training iteration:  85%|████████▍ | 847/1001 [1:00:24<05:58,  2.33s/it, avg loss=287.7364]Checkpoint at iteration 847 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 287.73643188476564

Training iteration:  85%|████████▍ | 847/1001 [1:00:27<05:58,  2.33s/it, avg loss=270.2225]
Training iteration:  85%|████████▍ | 848/1001 [1:00:27<05:56,  2.33s/it, avg loss=270.2225]Checkpoint at iteration 848 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 270.2225372314453

Training iteration:  85%|████████▍ | 848/1001 [1:00:29<05:56,  2.33s/it, avg loss=148.8733]
Training iteration:  85%|████████▍ | 849/1001 [1:00:29<05:53,  2.33s/it, avg loss=148.8733]Checkpoint at iteration 849 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 148.8732681274414

Training iteration:  85%|████████▍ | 849/1001 [1:00:31<05:53,  2.33s/it, avg loss=284.8832]
Training iteration:  85%|████████▍ | 850/1001 [1:00:31<05:51,  2.33s/it, avg loss=284.8832]Checkpoint at iteration 850 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 284.8831954956055

Training iteration:  85%|████████▍ | 850/1001 [1:00:34<05:51,  2.33s/it, avg loss=156.5055]
Training iteration:  85%|████████▌ | 851/1001 [1:00:34<05:49,  2.33s/it, avg loss=156.5055]Checkpoint at iteration 851 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 156.50553283691406

Training iteration:  85%|████████▌ | 851/1001 [1:00:36<05:49,  2.33s/it, avg loss=276.7580]
Training iteration:  85%|████████▌ | 852/1001 [1:00:36<05:47,  2.33s/it, avg loss=276.7580]Checkpoint at iteration 852 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 276.75797271728516

Training iteration:  85%|████████▌ | 852/1001 [1:00:38<05:47,  2.33s/it, avg loss=162.2167]
Training iteration:  85%|████████▌ | 853/1001 [1:00:38<05:44,  2.33s/it, avg loss=162.2167]Checkpoint at iteration 853 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 162.2166534423828

Training iteration:  85%|████████▌ | 853/1001 [1:00:41<05:44,  2.33s/it, avg loss=147.3145]
Training iteration:  85%|████████▌ | 854/1001 [1:00:41<05:42,  2.33s/it, avg loss=147.3145]Checkpoint at iteration 854 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 147.31448211669922

Training iteration:  85%|████████▌ | 854/1001 [1:00:43<05:42,  2.33s/it, avg loss=149.4596]
Training iteration:  85%|████████▌ | 855/1001 [1:00:43<05:40,  2.33s/it, avg loss=149.4596]Checkpoint at iteration 855 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 149.45958862304687

Training iteration:  85%|████████▌ | 855/1001 [1:00:45<05:40,  2.33s/it, avg loss=140.1927]
Training iteration:  86%|████████▌ | 856/1001 [1:00:45<05:37,  2.33s/it, avg loss=140.1927]Checkpoint at iteration 856 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 140.19273071289064

Training iteration:  86%|████████▌ | 856/1001 [1:00:48<05:37,  2.33s/it, avg loss=294.4980]
Training iteration:  86%|████████▌ | 857/1001 [1:00:48<05:35,  2.33s/it, avg loss=294.4980]Checkpoint at iteration 857 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 294.4979949951172

Training iteration:  86%|████████▌ | 857/1001 [1:00:50<05:35,  2.33s/it, avg loss=146.5191]
Training iteration:  86%|████████▌ | 858/1001 [1:00:50<05:33,  2.33s/it, avg loss=146.5191]Checkpoint at iteration 858 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 146.5191421508789

Training iteration:  86%|████████▌ | 858/1001 [1:00:52<05:33,  2.33s/it, avg loss=290.8979]
Training iteration:  86%|████████▌ | 859/1001 [1:00:52<05:30,  2.33s/it, avg loss=290.8979]Checkpoint at iteration 859 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 290.89791107177734

Training iteration:  86%|████████▌ | 859/1001 [1:00:55<05:30,  2.33s/it, avg loss=291.5710]
Training iteration:  86%|████████▌ | 860/1001 [1:00:55<05:28,  2.33s/it, avg loss=291.5710]Checkpoint at iteration 860 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 291.5710189819336

Training iteration:  86%|████████▌ | 860/1001 [1:00:57<05:28,  2.33s/it, avg loss=147.3538]
Training iteration:  86%|████████▌ | 861/1001 [1:00:57<05:26,  2.33s/it, avg loss=147.3538]Checkpoint at iteration 861 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 147.35377349853516

Training iteration:  86%|████████▌ | 861/1001 [1:00:59<05:26,  2.33s/it, avg loss=145.6291]
Training iteration:  86%|████████▌ | 862/1001 [1:00:59<05:23,  2.33s/it, avg loss=145.6291]Checkpoint at iteration 862 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 145.6290710449219

Training iteration:  86%|████████▌ | 862/1001 [1:01:02<05:23,  2.33s/it, avg loss=151.4934]
Training iteration:  86%|████████▌ | 863/1001 [1:01:02<05:21,  2.33s/it, avg loss=151.4934]Checkpoint at iteration 863 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 151.49342041015626

Training iteration:  86%|████████▌ | 863/1001 [1:01:04<05:21,  2.33s/it, avg loss=289.0112]
Training iteration:  86%|████████▋ | 864/1001 [1:01:04<05:19,  2.33s/it, avg loss=289.0112]Checkpoint at iteration 864 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 289.01117248535155

Training iteration:  86%|████████▋ | 864/1001 [1:01:06<05:19,  2.33s/it, avg loss=210.1050]
Training iteration:  86%|████████▋ | 865/1001 [1:01:06<05:16,  2.33s/it, avg loss=210.1050]Checkpoint at iteration 865 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 210.10503540039062

Training iteration:  86%|████████▋ | 865/1001 [1:01:09<05:16,  2.33s/it, avg loss=286.4583]
Training iteration:  87%|████████▋ | 866/1001 [1:01:09<05:14,  2.33s/it, avg loss=286.4583]Checkpoint at iteration 866 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 286.4583343505859

Training iteration:  87%|████████▋ | 866/1001 [1:01:11<05:14,  2.33s/it, avg loss=292.2217]
Training iteration:  87%|████████▋ | 867/1001 [1:01:11<05:12,  2.33s/it, avg loss=292.2217]Checkpoint at iteration 867 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 292.22171783447266

Training iteration:  87%|████████▋ | 867/1001 [1:01:13<05:12,  2.33s/it, avg loss=278.2811]
Training iteration:  87%|████████▋ | 868/1001 [1:01:13<05:09,  2.33s/it, avg loss=278.2811]Checkpoint at iteration 868 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 278.2810882568359

Training iteration:  87%|████████▋ | 868/1001 [1:01:16<05:09,  2.33s/it, avg loss=146.1313]
Training iteration:  87%|████████▋ | 869/1001 [1:01:16<05:07,  2.33s/it, avg loss=146.1313]Checkpoint at iteration 869 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 146.13125305175782

Training iteration:  87%|████████▋ | 869/1001 [1:01:18<05:07,  2.33s/it, avg loss=140.9208]
Training iteration:  87%|████████▋ | 870/1001 [1:01:18<05:05,  2.33s/it, avg loss=140.9208]Checkpoint at iteration 870 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 140.92084197998048

Training iteration:  87%|████████▋ | 870/1001 [1:01:20<05:05,  2.33s/it, avg loss=288.8315]
Training iteration:  87%|████████▋ | 871/1001 [1:01:20<05:03,  2.33s/it, avg loss=288.8315]Checkpoint at iteration 871 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 288.83152465820314

Training iteration:  87%|████████▋ | 871/1001 [1:01:23<05:03,  2.33s/it, avg loss=283.4874]
Training iteration:  87%|████████▋ | 872/1001 [1:01:23<05:00,  2.33s/it, avg loss=283.4874]Checkpoint at iteration 872 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 283.4874328613281

Training iteration:  87%|████████▋ | 872/1001 [1:01:25<05:00,  2.33s/it, avg loss=283.9249]
Training iteration:  87%|████████▋ | 873/1001 [1:01:25<04:58,  2.33s/it, avg loss=283.9249]Checkpoint at iteration 873 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 283.9248672485352

Training iteration:  87%|████████▋ | 873/1001 [1:01:27<04:58,  2.33s/it, avg loss=286.5877]
Training iteration:  87%|████████▋ | 874/1001 [1:01:27<04:55,  2.33s/it, avg loss=286.5877]Checkpoint at iteration 874 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 286.5877212524414

Training iteration:  87%|████████▋ | 874/1001 [1:01:30<04:55,  2.33s/it, avg loss=144.4270]
Training iteration:  87%|████████▋ | 875/1001 [1:01:30<04:53,  2.33s/it, avg loss=144.4270]Checkpoint at iteration 875 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 144.4269592285156

Training iteration:  87%|████████▋ | 875/1001 [1:01:32<04:53,  2.33s/it, avg loss=286.4575]
Training iteration:  88%|████████▊ | 876/1001 [1:01:32<04:51,  2.33s/it, avg loss=286.4575]Checkpoint at iteration 876 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 286.45750885009767

Training iteration:  88%|████████▊ | 876/1001 [1:01:34<04:51,  2.33s/it, avg loss=282.4590]
Training iteration:  88%|████████▊ | 877/1001 [1:01:34<04:48,  2.33s/it, avg loss=282.4590]Checkpoint at iteration 877 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 282.4589508056641

Training iteration:  88%|████████▊ | 877/1001 [1:01:37<04:48,  2.33s/it, avg loss=278.4172]
Training iteration:  88%|████████▊ | 878/1001 [1:01:37<04:46,  2.33s/it, avg loss=278.4172]Checkpoint at iteration 878 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 278.4172119140625

Training iteration:  88%|████████▊ | 878/1001 [1:01:39<04:46,  2.33s/it, avg loss=284.7722]
Training iteration:  88%|████████▊ | 879/1001 [1:01:39<04:44,  2.33s/it, avg loss=284.7722]Checkpoint at iteration 879 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 284.7722137451172

Training iteration:  88%|████████▊ | 879/1001 [1:01:41<04:44,  2.33s/it, avg loss=273.3615]
Training iteration:  88%|████████▊ | 880/1001 [1:01:41<04:41,  2.33s/it, avg loss=273.3615]Checkpoint at iteration 880 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 273.36151428222655

Training iteration:  88%|████████▊ | 880/1001 [1:01:44<04:41,  2.33s/it, avg loss=278.5598]
Training iteration:  88%|████████▊ | 881/1001 [1:01:44<04:39,  2.33s/it, avg loss=278.5598]Checkpoint at iteration 881 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 278.5597885131836

Training iteration:  88%|████████▊ | 881/1001 [1:01:46<04:39,  2.33s/it, avg loss=275.6317]
Training iteration:  88%|████████▊ | 882/1001 [1:01:46<04:37,  2.33s/it, avg loss=275.6317]Checkpoint at iteration 882 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 275.63172912597656

Training iteration:  88%|████████▊ | 882/1001 [1:01:48<04:37,  2.33s/it, avg loss=163.8150]
Training iteration:  88%|████████▊ | 883/1001 [1:01:48<04:34,  2.33s/it, avg loss=163.8150]Checkpoint at iteration 883 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 163.81503601074218

Training iteration:  88%|████████▊ | 883/1001 [1:01:51<04:34,  2.33s/it, avg loss=275.2437]
Training iteration:  88%|████████▊ | 884/1001 [1:01:51<04:32,  2.33s/it, avg loss=275.2437]Checkpoint at iteration 884 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 275.24365692138673

Training iteration:  88%|████████▊ | 884/1001 [1:01:53<04:32,  2.33s/it, avg loss=155.5080]
Training iteration:  88%|████████▊ | 885/1001 [1:01:53<04:30,  2.33s/it, avg loss=155.5080]Checkpoint at iteration 885 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 155.50796966552736

Training iteration:  88%|████████▊ | 885/1001 [1:01:55<04:30,  2.33s/it, avg loss=152.6620]
Training iteration:  89%|████████▊ | 886/1001 [1:01:55<04:28,  2.33s/it, avg loss=152.6620]Checkpoint at iteration 886 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 152.66195068359374

Training iteration:  89%|████████▊ | 886/1001 [1:01:57<04:28,  2.33s/it, avg loss=277.3192]
Training iteration:  89%|████████▊ | 887/1001 [1:01:57<04:25,  2.33s/it, avg loss=277.3192]Checkpoint at iteration 887 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 277.3191650390625

Training iteration:  89%|████████▊ | 887/1001 [1:02:00<04:25,  2.33s/it, avg loss=164.4999]
Training iteration:  89%|████████▊ | 888/1001 [1:02:00<04:23,  2.33s/it, avg loss=164.4999]Checkpoint at iteration 888 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 164.4998580932617

Training iteration:  89%|████████▊ | 888/1001 [1:02:02<04:23,  2.33s/it, avg loss=277.3611]
Training iteration:  89%|████████▉ | 889/1001 [1:02:02<04:21,  2.33s/it, avg loss=277.3611]Checkpoint at iteration 889 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 277.3611404418945

Training iteration:  89%|████████▉ | 889/1001 [1:02:04<04:21,  2.33s/it, avg loss=152.4019]
Training iteration:  89%|████████▉ | 890/1001 [1:02:04<04:18,  2.33s/it, avg loss=152.4019]Checkpoint at iteration 890 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 152.4018524169922

Training iteration:  89%|████████▉ | 890/1001 [1:02:07<04:18,  2.33s/it, avg loss=150.9545]
Training iteration:  89%|████████▉ | 891/1001 [1:02:07<04:16,  2.33s/it, avg loss=150.9545]Checkpoint at iteration 891 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 150.95445251464844

Training iteration:  89%|████████▉ | 891/1001 [1:02:09<04:16,  2.33s/it, avg loss=152.9632]
Training iteration:  89%|████████▉ | 892/1001 [1:02:09<04:14,  2.33s/it, avg loss=152.9632]Checkpoint at iteration 892 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 152.96316528320312

Training iteration:  89%|████████▉ | 892/1001 [1:02:11<04:14,  2.33s/it, avg loss=151.3754]
Training iteration:  89%|████████▉ | 893/1001 [1:02:11<04:11,  2.33s/it, avg loss=151.3754]Checkpoint at iteration 893 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 151.37540588378906

Training iteration:  89%|████████▉ | 893/1001 [1:02:14<04:11,  2.33s/it, avg loss=146.0039]
Training iteration:  89%|████████▉ | 894/1001 [1:02:14<04:09,  2.33s/it, avg loss=146.0039]Checkpoint at iteration 894 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 146.00391235351563

Training iteration:  89%|████████▉ | 894/1001 [1:02:16<04:09,  2.33s/it, avg loss=282.5308]
Training iteration:  89%|████████▉ | 895/1001 [1:02:16<04:06,  2.33s/it, avg loss=282.5308]Checkpoint at iteration 895 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 282.5307891845703

Training iteration:  89%|████████▉ | 895/1001 [1:02:18<04:06,  2.33s/it, avg loss=265.2906]
Training iteration:  90%|████████▉ | 896/1001 [1:02:18<04:04,  2.33s/it, avg loss=265.2906]Checkpoint at iteration 896 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 265.2906463623047

Training iteration:  90%|████████▉ | 896/1001 [1:02:21<04:04,  2.33s/it, avg loss=281.6158]
Training iteration:  90%|████████▉ | 897/1001 [1:02:21<04:02,  2.33s/it, avg loss=281.6158]Checkpoint at iteration 897 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 281.6157501220703

Training iteration:  90%|████████▉ | 897/1001 [1:02:23<04:02,  2.33s/it, avg loss=283.1582]
Training iteration:  90%|████████▉ | 898/1001 [1:02:23<03:59,  2.33s/it, avg loss=283.1582]Checkpoint at iteration 898 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 283.1582489013672

Training iteration:  90%|████████▉ | 898/1001 [1:02:25<03:59,  2.33s/it, avg loss=150.6476]
Training iteration:  90%|████████▉ | 899/1001 [1:02:25<03:57,  2.33s/it, avg loss=150.6476]Checkpoint at iteration 899 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 150.64759521484376

Training iteration:  90%|████████▉ | 899/1001 [1:02:28<03:57,  2.33s/it, avg loss=154.5609]
Training iteration:  90%|████████▉ | 900/1001 [1:02:28<03:55,  2.33s/it, avg loss=154.5609]Optimization iteration 900 evaluation begins...
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
A new evaluation visualization has been saved: ./saved_data/20240110-050655/it900.png
Training network 0 for evaluation...
Training network 1 for evaluation...
Training network 2 for evaluation...
Training network 3 for evaluation...
Testing network 0 on real datasets for evaluation...
Testing network 1 on real datasets for evaluation...
Testing network 2 on real datasets for evaluation...
Testing network 3 on real datasets for evaluation...
Optimization iteration 900, eval auroc score (train): 34484.4882, eval auroc score (test): 35828.3926
Checkpoint at iteration 900 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 154.5609146118164

Training iteration:  90%|████████▉ | 900/1001 [1:13:04<03:55,  2.33s/it, avg loss=147.8512]
Training iteration:  90%|█████████ | 901/1001 [1:13:04<5:20:43, 192.43s/it, avg loss=147.8512]Checkpoint at iteration 901 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 147.85117950439454

Training iteration:  90%|█████████ | 901/1001 [1:13:06<5:20:43, 192.43s/it, avg loss=154.3263]
Training iteration:  90%|█████████ | 902/1001 [1:13:06<3:43:32, 135.48s/it, avg loss=154.3263]Checkpoint at iteration 902 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 154.3262954711914

Training iteration:  90%|█████████ | 902/1001 [1:13:09<3:43:32, 135.48s/it, avg loss=282.6643]
Training iteration:  90%|█████████ | 903/1001 [1:13:09<2:36:09, 95.61s/it, avg loss=282.6643] Checkpoint at iteration 903 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 282.6643295288086

Training iteration:  90%|█████████ | 903/1001 [1:13:12<2:36:09, 95.61s/it, avg loss=284.3266]
Training iteration:  90%|█████████ | 904/1001 [1:13:12<1:49:27, 67.70s/it, avg loss=284.3266]Checkpoint at iteration 904 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 284.3265808105469

Training iteration:  90%|█████████ | 904/1001 [1:13:14<1:49:27, 67.70s/it, avg loss=148.6216]
Training iteration:  90%|█████████ | 905/1001 [1:13:14<1:17:03, 48.17s/it, avg loss=148.6216]Checkpoint at iteration 905 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 148.6215606689453

Training iteration:  90%|█████████ | 905/1001 [1:13:17<1:17:03, 48.17s/it, avg loss=141.1842]
Training iteration:  91%|█████████ | 906/1001 [1:13:17<54:36, 34.49s/it, avg loss=141.1842]  Checkpoint at iteration 906 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 141.18422088623046

Training iteration:  91%|█████████ | 906/1001 [1:13:19<54:36, 34.49s/it, avg loss=278.0433]
Training iteration:  91%|█████████ | 907/1001 [1:13:19<39:02, 24.92s/it, avg loss=278.0433]Checkpoint at iteration 907 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 278.04325714111326

Training iteration:  91%|█████████ | 907/1001 [1:13:22<39:02, 24.92s/it, avg loss=279.9372]
Training iteration:  91%|█████████ | 908/1001 [1:13:22<28:14, 18.22s/it, avg loss=279.9372]Checkpoint at iteration 908 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 279.93718872070315

Training iteration:  91%|█████████ | 908/1001 [1:13:24<28:14, 18.22s/it, avg loss=284.4729]
Training iteration:  91%|█████████ | 909/1001 [1:13:24<20:44, 13.53s/it, avg loss=284.4729]Checkpoint at iteration 909 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 284.4729202270508

Training iteration:  91%|█████████ | 909/1001 [1:13:27<20:44, 13.53s/it, avg loss=278.1792]
Training iteration:  91%|█████████ | 910/1001 [1:13:27<15:32, 10.24s/it, avg loss=278.1792]Checkpoint at iteration 910 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 278.1791717529297

Training iteration:  91%|█████████ | 910/1001 [1:13:30<15:32, 10.24s/it, avg loss=282.5276]
Training iteration:  91%|█████████ | 911/1001 [1:13:30<11:55,  7.95s/it, avg loss=282.5276]Checkpoint at iteration 911 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 282.5276153564453

Training iteration:  91%|█████████ | 911/1001 [1:13:32<11:55,  7.95s/it, avg loss=279.6915]
Training iteration:  91%|█████████ | 912/1001 [1:13:32<09:23,  6.34s/it, avg loss=279.6915]Checkpoint at iteration 912 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 279.6914794921875

Training iteration:  91%|█████████ | 912/1001 [1:13:35<09:23,  6.34s/it, avg loss=155.6757]
Training iteration:  91%|█████████ | 913/1001 [1:13:35<07:38,  5.21s/it, avg loss=155.6757]Checkpoint at iteration 913 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 155.6757034301758

Training iteration:  91%|█████████ | 913/1001 [1:13:37<07:38,  5.21s/it, avg loss=151.5095]
Training iteration:  91%|█████████▏| 914/1001 [1:13:37<06:23,  4.41s/it, avg loss=151.5095]Checkpoint at iteration 914 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 151.5095428466797

Training iteration:  91%|█████████▏| 914/1001 [1:13:40<06:23,  4.41s/it, avg loss=152.1453]
Training iteration:  91%|█████████▏| 915/1001 [1:13:40<05:31,  3.85s/it, avg loss=152.1453]Checkpoint at iteration 915 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 152.14525146484374

Training iteration:  91%|█████████▏| 915/1001 [1:13:42<05:31,  3.85s/it, avg loss=153.3013]
Training iteration:  92%|█████████▏| 916/1001 [1:13:42<04:54,  3.46s/it, avg loss=153.3013]Checkpoint at iteration 916 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 153.30128784179686

Training iteration:  92%|█████████▏| 916/1001 [1:13:45<04:54,  3.46s/it, avg loss=151.5310]
Training iteration:  92%|█████████▏| 917/1001 [1:13:45<04:27,  3.19s/it, avg loss=151.5310]Checkpoint at iteration 917 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 151.53096771240234

Training iteration:  92%|█████████▏| 917/1001 [1:13:48<04:27,  3.19s/it, avg loss=152.1958]
Training iteration:  92%|█████████▏| 918/1001 [1:13:48<04:08,  3.00s/it, avg loss=152.1958]Checkpoint at iteration 918 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 152.19578704833984

Training iteration:  92%|█████████▏| 918/1001 [1:13:50<04:08,  3.00s/it, avg loss=139.3915]
Training iteration:  92%|█████████▏| 919/1001 [1:13:50<03:54,  2.86s/it, avg loss=139.3915]Checkpoint at iteration 919 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 139.39152069091796

Training iteration:  92%|█████████▏| 919/1001 [1:13:53<03:54,  2.86s/it, avg loss=284.1608]
Training iteration:  92%|█████████▏| 920/1001 [1:13:53<03:44,  2.77s/it, avg loss=284.1608]Checkpoint at iteration 920 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 284.160791015625

Training iteration:  92%|█████████▏| 920/1001 [1:13:55<03:44,  2.77s/it, avg loss=291.7127]
Training iteration:  92%|█████████▏| 921/1001 [1:13:55<03:36,  2.71s/it, avg loss=291.7127]Checkpoint at iteration 921 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 291.7126525878906

Training iteration:  92%|█████████▏| 921/1001 [1:13:58<03:36,  2.71s/it, avg loss=150.0863]
Training iteration:  92%|█████████▏| 922/1001 [1:13:58<03:30,  2.66s/it, avg loss=150.0863]Checkpoint at iteration 922 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 150.0862564086914

Training iteration:  92%|█████████▏| 922/1001 [1:14:00<03:30,  2.66s/it, avg loss=281.2934]
Training iteration:  92%|█████████▏| 923/1001 [1:14:00<03:24,  2.63s/it, avg loss=281.2934]Checkpoint at iteration 923 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 281.293359375

Training iteration:  92%|█████████▏| 923/1001 [1:14:03<03:24,  2.63s/it, avg loss=283.7287]
Training iteration:  92%|█████████▏| 924/1001 [1:14:03<03:20,  2.60s/it, avg loss=283.7287]Checkpoint at iteration 924 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 283.72867279052736

Training iteration:  92%|█████████▏| 924/1001 [1:14:05<03:20,  2.60s/it, avg loss=282.8146]
Training iteration:  92%|█████████▏| 925/1001 [1:14:05<03:16,  2.59s/it, avg loss=282.8146]Checkpoint at iteration 925 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 282.81456298828124

Training iteration:  92%|█████████▏| 925/1001 [1:14:08<03:16,  2.59s/it, avg loss=155.3423]
Training iteration:  93%|█████████▎| 926/1001 [1:14:08<03:13,  2.58s/it, avg loss=155.3423]Checkpoint at iteration 926 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 155.34226837158204

Training iteration:  93%|█████████▎| 926/1001 [1:14:11<03:13,  2.58s/it, avg loss=280.1940]
Training iteration:  93%|█████████▎| 927/1001 [1:14:11<03:10,  2.57s/it, avg loss=280.1940]Checkpoint at iteration 927 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 280.1939895629883

Training iteration:  93%|█████████▎| 927/1001 [1:14:13<03:10,  2.57s/it, avg loss=148.9024]
Training iteration:  93%|█████████▎| 928/1001 [1:14:13<03:07,  2.57s/it, avg loss=148.9024]Checkpoint at iteration 928 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 148.90240631103515

Training iteration:  93%|█████████▎| 928/1001 [1:14:16<03:07,  2.57s/it, avg loss=154.8782]
Training iteration:  93%|█████████▎| 929/1001 [1:14:16<03:04,  2.56s/it, avg loss=154.8782]Checkpoint at iteration 929 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 154.87822418212892

Training iteration:  93%|█████████▎| 929/1001 [1:14:18<03:04,  2.56s/it, avg loss=284.8772]
Training iteration:  93%|█████████▎| 930/1001 [1:14:18<03:01,  2.56s/it, avg loss=284.8772]Checkpoint at iteration 930 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 284.87721557617186

Training iteration:  93%|█████████▎| 930/1001 [1:14:21<03:01,  2.56s/it, avg loss=144.4314]
Training iteration:  93%|█████████▎| 931/1001 [1:14:21<02:59,  2.56s/it, avg loss=144.4314]Checkpoint at iteration 931 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 144.43143157958986

Training iteration:  93%|█████████▎| 931/1001 [1:14:23<02:59,  2.56s/it, avg loss=149.6335]
Training iteration:  93%|█████████▎| 932/1001 [1:14:23<02:56,  2.56s/it, avg loss=149.6335]Checkpoint at iteration 932 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 149.63352966308594

Training iteration:  93%|█████████▎| 932/1001 [1:14:26<02:56,  2.56s/it, avg loss=140.0191]
Training iteration:  93%|█████████▎| 933/1001 [1:14:26<02:53,  2.56s/it, avg loss=140.0191]Checkpoint at iteration 933 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 140.01913452148438

Training iteration:  93%|█████████▎| 933/1001 [1:14:28<02:53,  2.56s/it, avg loss=140.2075]
Training iteration:  93%|█████████▎| 934/1001 [1:14:28<02:51,  2.56s/it, avg loss=140.2075]Checkpoint at iteration 934 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 140.20749206542968

Training iteration:  93%|█████████▎| 934/1001 [1:14:31<02:51,  2.56s/it, avg loss=144.1175]
Training iteration:  93%|█████████▎| 935/1001 [1:14:31<02:48,  2.55s/it, avg loss=144.1175]Checkpoint at iteration 935 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 144.1174530029297

Training iteration:  93%|█████████▎| 935/1001 [1:14:33<02:48,  2.55s/it, avg loss=294.2247]
Training iteration:  94%|█████████▎| 936/1001 [1:14:33<02:45,  2.55s/it, avg loss=294.2247]Checkpoint at iteration 936 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 294.2246978759766

Training iteration:  94%|█████████▎| 936/1001 [1:14:36<02:45,  2.55s/it, avg loss=144.4188]
Training iteration:  94%|█████████▎| 937/1001 [1:14:36<02:43,  2.55s/it, avg loss=144.4188]Checkpoint at iteration 937 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 144.4187759399414

Training iteration:  94%|█████████▎| 937/1001 [1:14:39<02:43,  2.55s/it, avg loss=135.9043]
Training iteration:  94%|█████████▎| 938/1001 [1:14:39<02:40,  2.55s/it, avg loss=135.9043]Checkpoint at iteration 938 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 135.90428466796874

Training iteration:  94%|█████████▎| 938/1001 [1:14:41<02:40,  2.55s/it, avg loss=292.7095]
Training iteration:  94%|█████████▍| 939/1001 [1:14:41<02:38,  2.55s/it, avg loss=292.7095]Checkpoint at iteration 939 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 292.70953063964845

Training iteration:  94%|█████████▍| 939/1001 [1:14:44<02:38,  2.55s/it, avg loss=141.4629]
Training iteration:  94%|█████████▍| 940/1001 [1:14:44<02:35,  2.55s/it, avg loss=141.4629]Checkpoint at iteration 940 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 141.4628662109375

Training iteration:  94%|█████████▍| 940/1001 [1:14:46<02:35,  2.55s/it, avg loss=295.8072]
Training iteration:  94%|█████████▍| 941/1001 [1:14:46<02:33,  2.55s/it, avg loss=295.8072]Checkpoint at iteration 941 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 295.8071594238281

Training iteration:  94%|█████████▍| 941/1001 [1:14:49<02:33,  2.55s/it, avg loss=133.3186]
Training iteration:  94%|█████████▍| 942/1001 [1:14:49<02:30,  2.55s/it, avg loss=133.3186]Checkpoint at iteration 942 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 133.3186233520508

Training iteration:  94%|█████████▍| 942/1001 [1:14:51<02:30,  2.55s/it, avg loss=132.3535]
Training iteration:  94%|█████████▍| 943/1001 [1:14:51<02:28,  2.55s/it, avg loss=132.3535]Checkpoint at iteration 943 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 132.35347213745118

Training iteration:  94%|█████████▍| 943/1001 [1:14:54<02:28,  2.55s/it, avg loss=282.0442]
Training iteration:  94%|█████████▍| 944/1001 [1:14:54<02:25,  2.55s/it, avg loss=282.0442]Checkpoint at iteration 944 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 282.0442428588867

Training iteration:  94%|█████████▍| 944/1001 [1:14:56<02:25,  2.55s/it, avg loss=296.9697]
Training iteration:  94%|█████████▍| 945/1001 [1:14:56<02:22,  2.55s/it, avg loss=296.9697]Checkpoint at iteration 945 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 296.96971130371094

Training iteration:  94%|█████████▍| 945/1001 [1:14:59<02:22,  2.55s/it, avg loss=192.4199]
Training iteration:  95%|█████████▍| 946/1001 [1:14:59<02:20,  2.55s/it, avg loss=192.4199]Checkpoint at iteration 946 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 192.41988677978514

Training iteration:  95%|█████████▍| 946/1001 [1:15:02<02:20,  2.55s/it, avg loss=135.6828]
Training iteration:  95%|█████████▍| 947/1001 [1:15:02<02:17,  2.55s/it, avg loss=135.6828]Checkpoint at iteration 947 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 135.68279418945312

Training iteration:  95%|█████████▍| 947/1001 [1:15:04<02:17,  2.55s/it, avg loss=121.7733]
Training iteration:  95%|█████████▍| 948/1001 [1:15:04<02:15,  2.55s/it, avg loss=121.7733]Checkpoint at iteration 948 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 121.77333145141601

Training iteration:  95%|█████████▍| 948/1001 [1:15:07<02:15,  2.55s/it, avg loss=128.7893]
Training iteration:  95%|█████████▍| 949/1001 [1:15:07<02:12,  2.55s/it, avg loss=128.7893]Checkpoint at iteration 949 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 128.7893295288086

Training iteration:  95%|█████████▍| 949/1001 [1:15:09<02:12,  2.55s/it, avg loss=285.2721]
Training iteration:  95%|█████████▍| 950/1001 [1:15:09<02:10,  2.55s/it, avg loss=285.2721]Checkpoint at iteration 950 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 285.27205963134764

Training iteration:  95%|█████████▍| 950/1001 [1:15:12<02:10,  2.55s/it, avg loss=133.7762]
Training iteration:  95%|█████████▌| 951/1001 [1:15:12<02:07,  2.55s/it, avg loss=133.7762]Checkpoint at iteration 951 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 133.7762023925781

Training iteration:  95%|█████████▌| 951/1001 [1:15:14<02:07,  2.55s/it, avg loss=136.7592]
Training iteration:  95%|█████████▌| 952/1001 [1:15:14<02:05,  2.55s/it, avg loss=136.7592]Checkpoint at iteration 952 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 136.75922698974608

Training iteration:  95%|█████████▌| 952/1001 [1:15:17<02:05,  2.55s/it, avg loss=296.4119]
Training iteration:  95%|█████████▌| 953/1001 [1:15:17<02:02,  2.55s/it, avg loss=296.4119]Checkpoint at iteration 953 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 296.411882019043

Training iteration:  95%|█████████▌| 953/1001 [1:15:19<02:02,  2.55s/it, avg loss=303.6999]
Training iteration:  95%|█████████▌| 954/1001 [1:15:19<01:59,  2.55s/it, avg loss=303.6999]Checkpoint at iteration 954 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 303.69986419677736

Training iteration:  95%|█████████▌| 954/1001 [1:15:22<01:59,  2.55s/it, avg loss=302.3103]
Training iteration:  95%|█████████▌| 955/1001 [1:15:22<01:57,  2.55s/it, avg loss=302.3103]Checkpoint at iteration 955 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 302.3103317260742

Training iteration:  95%|█████████▌| 955/1001 [1:15:25<01:57,  2.55s/it, avg loss=132.0328]
Training iteration:  96%|█████████▌| 956/1001 [1:15:25<01:54,  2.55s/it, avg loss=132.0328]Checkpoint at iteration 956 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 132.0327896118164

Training iteration:  96%|█████████▌| 956/1001 [1:15:27<01:54,  2.55s/it, avg loss=294.9627]
Training iteration:  96%|█████████▌| 957/1001 [1:15:27<01:52,  2.55s/it, avg loss=294.9627]Checkpoint at iteration 957 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 294.9626937866211

Training iteration:  96%|█████████▌| 957/1001 [1:15:30<01:52,  2.55s/it, avg loss=299.1079]
Training iteration:  96%|█████████▌| 958/1001 [1:15:30<01:49,  2.55s/it, avg loss=299.1079]Checkpoint at iteration 958 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 299.1079406738281

Training iteration:  96%|█████████▌| 958/1001 [1:15:32<01:49,  2.55s/it, avg loss=131.1033]
Training iteration:  96%|█████████▌| 959/1001 [1:15:32<01:47,  2.55s/it, avg loss=131.1033]Checkpoint at iteration 959 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 131.1032859802246

Training iteration:  96%|█████████▌| 959/1001 [1:15:35<01:47,  2.55s/it, avg loss=131.7087]
Training iteration:  96%|█████████▌| 960/1001 [1:15:35<01:44,  2.55s/it, avg loss=131.7087]Checkpoint at iteration 960 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 131.70865478515626

Training iteration:  96%|█████████▌| 960/1001 [1:15:37<01:44,  2.55s/it, avg loss=307.1679]
Training iteration:  96%|█████████▌| 961/1001 [1:15:37<01:41,  2.55s/it, avg loss=307.1679]Checkpoint at iteration 961 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 307.16792755126954

Training iteration:  96%|█████████▌| 961/1001 [1:15:40<01:41,  2.55s/it, avg loss=123.6176]
Training iteration:  96%|█████████▌| 962/1001 [1:15:40<01:39,  2.55s/it, avg loss=123.6176]Checkpoint at iteration 962 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 123.61762466430665

Training iteration:  96%|█████████▌| 962/1001 [1:15:42<01:39,  2.55s/it, avg loss=297.7768]
Training iteration:  96%|█████████▌| 963/1001 [1:15:42<01:36,  2.55s/it, avg loss=297.7768]Checkpoint at iteration 963 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 297.7767501831055

Training iteration:  96%|█████████▌| 963/1001 [1:15:45<01:36,  2.55s/it, avg loss=133.0444]
Training iteration:  96%|█████████▋| 964/1001 [1:15:45<01:34,  2.55s/it, avg loss=133.0444]Checkpoint at iteration 964 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 133.04442138671874

Training iteration:  96%|█████████▋| 964/1001 [1:15:47<01:34,  2.55s/it, avg loss=131.2507]
Training iteration:  96%|█████████▋| 965/1001 [1:15:47<01:31,  2.55s/it, avg loss=131.2507]Checkpoint at iteration 965 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 131.25067291259765

Training iteration:  96%|█████████▋| 965/1001 [1:15:50<01:31,  2.55s/it, avg loss=300.8427]
Training iteration:  97%|█████████▋| 966/1001 [1:15:50<01:29,  2.55s/it, avg loss=300.8427]Checkpoint at iteration 966 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 300.84270935058595

Training iteration:  97%|█████████▋| 966/1001 [1:15:53<01:29,  2.55s/it, avg loss=127.5530]
Training iteration:  97%|█████████▋| 967/1001 [1:15:53<01:26,  2.55s/it, avg loss=127.5530]Checkpoint at iteration 967 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 127.55302963256835

Training iteration:  97%|█████████▋| 967/1001 [1:15:55<01:26,  2.55s/it, avg loss=128.4203]
Training iteration:  97%|█████████▋| 968/1001 [1:15:55<01:24,  2.55s/it, avg loss=128.4203]Checkpoint at iteration 968 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 128.42025909423828

Training iteration:  97%|█████████▋| 968/1001 [1:15:58<01:24,  2.55s/it, avg loss=129.2803]
Training iteration:  97%|█████████▋| 969/1001 [1:15:58<01:21,  2.55s/it, avg loss=129.2803]Checkpoint at iteration 969 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 129.28034133911132

Training iteration:  97%|█████████▋| 969/1001 [1:16:00<01:21,  2.55s/it, avg loss=302.4202]
Training iteration:  97%|█████████▋| 970/1001 [1:16:00<01:19,  2.55s/it, avg loss=302.4202]Checkpoint at iteration 970 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 302.4202285766602

Training iteration:  97%|█████████▋| 970/1001 [1:16:03<01:19,  2.55s/it, avg loss=302.4960]
Training iteration:  97%|█████████▋| 971/1001 [1:16:03<01:16,  2.55s/it, avg loss=302.4960]Checkpoint at iteration 971 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 302.49598999023436

Training iteration:  97%|█████████▋| 971/1001 [1:16:05<01:16,  2.55s/it, avg loss=304.2075]
Training iteration:  97%|█████████▋| 972/1001 [1:16:05<01:13,  2.55s/it, avg loss=304.2075]Checkpoint at iteration 972 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 304.2074821472168

Training iteration:  97%|█████████▋| 972/1001 [1:16:08<01:13,  2.55s/it, avg loss=128.0146]
Training iteration:  97%|█████████▋| 973/1001 [1:16:08<01:11,  2.55s/it, avg loss=128.0146]Checkpoint at iteration 973 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 128.01456527709962

Training iteration:  97%|█████████▋| 973/1001 [1:16:10<01:11,  2.55s/it, avg loss=129.0322]
Training iteration:  97%|█████████▋| 974/1001 [1:16:10<01:08,  2.55s/it, avg loss=129.0322]Checkpoint at iteration 974 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 129.03219757080078

Training iteration:  97%|█████████▋| 974/1001 [1:16:13<01:08,  2.55s/it, avg loss=126.5952]
Training iteration:  97%|█████████▋| 975/1001 [1:16:13<01:06,  2.55s/it, avg loss=126.5952]Checkpoint at iteration 975 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 126.59519805908204

Training iteration:  97%|█████████▋| 975/1001 [1:16:16<01:06,  2.55s/it, avg loss=129.9675]
Training iteration:  98%|█████████▊| 976/1001 [1:16:16<01:03,  2.55s/it, avg loss=129.9675]Checkpoint at iteration 976 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 129.96754531860353

Training iteration:  98%|█████████▊| 976/1001 [1:16:18<01:03,  2.55s/it, avg loss=299.9646]
Training iteration:  98%|█████████▊| 977/1001 [1:16:18<01:01,  2.55s/it, avg loss=299.9646]Checkpoint at iteration 977 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 299.96460113525393

Training iteration:  98%|█████████▊| 977/1001 [1:16:21<01:01,  2.55s/it, avg loss=133.7597]
Training iteration:  98%|█████████▊| 978/1001 [1:16:21<00:58,  2.55s/it, avg loss=133.7597]Checkpoint at iteration 978 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 133.75965270996093

Training iteration:  98%|█████████▊| 978/1001 [1:16:23<00:58,  2.55s/it, avg loss=305.2126]
Training iteration:  98%|█████████▊| 979/1001 [1:16:23<00:56,  2.55s/it, avg loss=305.2126]Checkpoint at iteration 979 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 305.2126205444336

Training iteration:  98%|█████████▊| 979/1001 [1:16:26<00:56,  2.55s/it, avg loss=298.0900]
Training iteration:  98%|█████████▊| 980/1001 [1:16:26<00:53,  2.55s/it, avg loss=298.0900]Checkpoint at iteration 980 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 298.08997802734376

Training iteration:  98%|█████████▊| 980/1001 [1:16:28<00:53,  2.55s/it, avg loss=124.1061]
Training iteration:  98%|█████████▊| 981/1001 [1:16:28<00:51,  2.55s/it, avg loss=124.1061]Checkpoint at iteration 981 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 124.10610809326172

Training iteration:  98%|█████████▊| 981/1001 [1:16:31<00:51,  2.55s/it, avg loss=132.3369]
Training iteration:  98%|█████████▊| 982/1001 [1:16:31<00:48,  2.55s/it, avg loss=132.3369]Checkpoint at iteration 982 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 132.33692169189453

Training iteration:  98%|█████████▊| 982/1001 [1:16:33<00:48,  2.55s/it, avg loss=131.2301]
Training iteration:  98%|█████████▊| 983/1001 [1:16:33<00:45,  2.55s/it, avg loss=131.2301]Checkpoint at iteration 983 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 131.2301452636719

Training iteration:  98%|█████████▊| 983/1001 [1:16:36<00:45,  2.55s/it, avg loss=299.9826]
Training iteration:  98%|█████████▊| 984/1001 [1:16:36<00:43,  2.55s/it, avg loss=299.9826]Checkpoint at iteration 984 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 299.9826385498047

Training iteration:  98%|█████████▊| 984/1001 [1:16:38<00:43,  2.55s/it, avg loss=297.6086]
Training iteration:  98%|█████████▊| 985/1001 [1:16:38<00:40,  2.55s/it, avg loss=297.6086]Checkpoint at iteration 985 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 297.6086120605469

Training iteration:  98%|█████████▊| 985/1001 [1:16:41<00:40,  2.55s/it, avg loss=134.3892]
Training iteration:  99%|█████████▊| 986/1001 [1:16:41<00:38,  2.55s/it, avg loss=134.3892]Checkpoint at iteration 986 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 134.38924560546874

Training iteration:  99%|█████████▊| 986/1001 [1:16:44<00:38,  2.55s/it, avg loss=303.0606]
Training iteration:  99%|█████████▊| 987/1001 [1:16:44<00:35,  2.55s/it, avg loss=303.0606]Checkpoint at iteration 987 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 303.06058197021486

Training iteration:  99%|█████████▊| 987/1001 [1:16:46<00:35,  2.55s/it, avg loss=132.7732]
Training iteration:  99%|█████████▊| 988/1001 [1:16:46<00:33,  2.55s/it, avg loss=132.7732]Checkpoint at iteration 988 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 132.77318725585937

Training iteration:  99%|█████████▊| 988/1001 [1:16:49<00:33,  2.55s/it, avg loss=297.5981]
Training iteration:  99%|█████████▉| 989/1001 [1:16:49<00:30,  2.55s/it, avg loss=297.5981]Checkpoint at iteration 989 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 297.59805221557616

Training iteration:  99%|█████████▉| 989/1001 [1:16:51<00:30,  2.55s/it, avg loss=125.3049]
Training iteration:  99%|█████████▉| 990/1001 [1:16:51<00:28,  2.55s/it, avg loss=125.3049]Checkpoint at iteration 990 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 125.30485153198242

Training iteration:  99%|█████████▉| 990/1001 [1:16:54<00:28,  2.55s/it, avg loss=133.9708]
Training iteration:  99%|█████████▉| 991/1001 [1:16:54<00:25,  2.55s/it, avg loss=133.9708]Checkpoint at iteration 991 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 133.97079010009764

Training iteration:  99%|█████████▉| 991/1001 [1:16:56<00:25,  2.55s/it, avg loss=301.1837]
Training iteration:  99%|█████████▉| 992/1001 [1:16:56<00:22,  2.55s/it, avg loss=301.1837]Checkpoint at iteration 992 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 301.18373107910156

Training iteration:  99%|█████████▉| 992/1001 [1:16:59<00:22,  2.55s/it, avg loss=299.9575]
Training iteration:  99%|█████████▉| 993/1001 [1:16:59<00:20,  2.55s/it, avg loss=299.9575]Checkpoint at iteration 993 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 299.95752182006834

Training iteration:  99%|█████████▉| 993/1001 [1:17:01<00:20,  2.55s/it, avg loss=299.6442]
Training iteration:  99%|█████████▉| 994/1001 [1:17:01<00:17,  2.55s/it, avg loss=299.6442]Checkpoint at iteration 994 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 299.64422912597655

Training iteration:  99%|█████████▉| 994/1001 [1:17:04<00:17,  2.55s/it, avg loss=300.4855]
Training iteration:  99%|█████████▉| 995/1001 [1:17:04<00:15,  2.55s/it, avg loss=300.4855]Checkpoint at iteration 995 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 300.4854675292969

Training iteration:  99%|█████████▉| 995/1001 [1:17:07<00:15,  2.55s/it, avg loss=305.3208]
Training iteration: 100%|█████████▉| 996/1001 [1:17:07<00:12,  2.55s/it, avg loss=305.3208]Checkpoint at iteration 996 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 305.32082214355466

Training iteration: 100%|█████████▉| 996/1001 [1:17:09<00:12,  2.55s/it, avg loss=301.1678]
Training iteration: 100%|█████████▉| 997/1001 [1:17:09<00:10,  2.55s/it, avg loss=301.1678]Checkpoint at iteration 997 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 301.1678131103516

Training iteration: 100%|█████████▉| 997/1001 [1:17:12<00:10,  2.55s/it, avg loss=298.4391]
Training iteration: 100%|█████████▉| 998/1001 [1:17:12<00:07,  2.55s/it, avg loss=298.4391]Checkpoint at iteration 998 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 298.4391159057617

Training iteration: 100%|█████████▉| 998/1001 [1:17:14<00:07,  2.55s/it, avg loss=132.7182]
Training iteration: 100%|█████████▉| 999/1001 [1:17:14<00:05,  2.55s/it, avg loss=132.7182]Checkpoint at iteration 999 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 132.71819915771485

Training iteration: 100%|█████████▉| 999/1001 [1:17:17<00:05,  2.55s/it, avg loss=142.9456]
Training iteration: 100%|█████████▉| 1000/1001 [1:17:17<00:02,  2.55s/it, avg loss=142.9456]Optimization iteration 1000 evaluation begins...
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
A new evaluation visualization has been saved: ./saved_data/20240110-050655/it1000.png
Training network 0 for evaluation...
Training network 1 for evaluation...
Training network 2 for evaluation...
Training network 3 for evaluation...
Testing network 0 on real datasets for evaluation...
Testing network 1 on real datasets for evaluation...
Testing network 2 on real datasets for evaluation...
Testing network 3 on real datasets for evaluation...
Optimization iteration 1000, eval auroc score (train): 31074.0019, eval auroc score (test): 32399.6891
Checkpoint at iteration 1000 saved at ./saved_data/20240110-050655/chckpnt_los_1samples.pth. Loss = 142.94560699462892

Training iteration: 100%|█████████▉| 1000/1001 [1:29:05<00:05,  5.35s/it, avg loss=142.9456]
All data will be output to ./saved_data/20240110-063719
Running on device: CUDA
Objective has been set to ihm
Initializing train set for ihm objective...
Loading dataset to RAM...
Loading from file ./data/mimic3/multitask_preliminary/train/all.pkl, skipping individuals...
Preprocessing dataset...
Computing dataset statistics...
First item in the dataset: 
(tensor([[ 1.0000,  0.0000,  0.1069,  ...,  0.0000,  0.0000,  0.0000],
        [ 1.0000,  0.0000,  0.0802,  ...,  0.0000,  0.0000,  0.0000],
        [ 1.0000,  0.0000,  0.0980,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 1.0000,  0.0000, -0.0583,  ...,  0.1849, -0.2451,  0.0219],
        [ 1.0000,  0.0000, -0.0672,  ...,  0.2056, -0.2451,  0.0219],
        [ 1.0000,  0.0000, -0.0806,  ...,  0.2159, -0.2451,  0.0219]]), tensor(1))
Feature tensor shape: torch.Size([48, 42])
Objective has been set to ihm
Initializing test set for ihm objective...
Loading dataset to RAM...
Loading from file ./data/mimic3/multitask_preliminary/test/all.pkl, skipping individuals...
Preprocessing dataset...
Computing dataset statistics...
First item in the dataset: 
(tensor([[ 1.0000,  0.0000, -0.0538,  ...,  0.0000,  0.0000,  0.0000],
        [ 1.0000,  0.0000, -0.0806,  ..., -0.0698,  0.0000,  0.0000],
        [ 1.0000,  0.0000, -0.0717,  ..., -0.0698,  0.0000, -0.3360],
        ...,
        [ 1.0000,  0.0000, -0.0627,  ..., -0.0698,  0.0000,  0.0823],
        [ 1.0000,  0.0000, -0.0627,  ..., -0.0698,  0.0000,  0.0823],
        [ 1.0000,  0.0000, -0.0627,  ..., -0.0698,  0.0000,  0.0823]]), tensor(1))
Feature tensor shape: torch.Size([48, 42])
Input tensor shape: torch.Size([48, 42])
Initializing synthetic dataset. Number of samples in total = 10
Objective has been set to los
Objective has been set to los
Synthetic feature shape: torch.Size([10, 48, 42])
Synthetic label shape: torch.Size([10])
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Ready for training

Training iteration:   0%|          | 0/1001 [00:00<?, ?it/s]Optimization iteration 0 evaluation begins...
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
A new evaluation visualization has been saved: ./saved_data/20240110-063719/it0.png
Training network 0 for evaluation...
Training network 1 for evaluation...
Training network 2 for evaluation...
Training network 3 for evaluation...
Testing network 0 on real datasets for evaluation...
Testing network 1 on real datasets for evaluation...
Testing network 2 on real datasets for evaluation...
Testing network 3 on real datasets for evaluation...
Optimization iteration 0, eval auroc score (train): 27447.6537, eval auroc score (test): 28447.7934
Checkpoint at iteration 0 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = None
/home1/dingyini/.conda/envs/playground/lib/python3.11/site-packages/torch/nn/utils/clip_grad.py:39: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /opt/conda/conda-bld/pytorch_1695392026823/work/build/aten/src/ATen/core/TensorBody.h:489.)
  grads = [p.grad for p in parameters if p.grad is not None]

Training iteration:   0%|          | 0/1001 [00:46<?, ?it/s, avg loss=267.5607]New best at iteratoin 0!

Training iteration:   0%|          | 1/1001 [00:46<12:54:10, 46.45s/it, avg loss=267.5607]Checkpoint at iteration 1 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 267.5607284545898

Training iteration:   0%|          | 1/1001 [00:47<12:54:10, 46.45s/it, avg loss=142.2338]New best at iteratoin 1!

Training iteration:   0%|          | 2/1001 [00:47<5:25:53, 19.57s/it, avg loss=142.2338] Checkpoint at iteration 2 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 142.2338088989258

Training iteration:   0%|          | 2/1001 [00:47<5:25:53, 19.57s/it, avg loss=207.9416]
Training iteration:   0%|          | 3/1001 [00:47<3:02:21, 10.96s/it, avg loss=207.9416]Checkpoint at iteration 3 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 207.94155731201172

Training iteration:   0%|          | 3/1001 [00:48<3:02:21, 10.96s/it, avg loss=245.5027]
Training iteration:   0%|          | 4/1001 [00:48<1:54:58,  6.92s/it, avg loss=245.5027]Checkpoint at iteration 4 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 245.50268325805663

Training iteration:   0%|          | 4/1001 [00:49<1:54:58,  6.92s/it, avg loss=220.8524]
Training iteration:   0%|          | 5/1001 [00:49<1:17:44,  4.68s/it, avg loss=220.8524]Checkpoint at iteration 5 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 220.85241165161133

Training iteration:   0%|          | 5/1001 [00:50<1:17:44,  4.68s/it, avg loss=159.9620]
Training iteration:   1%|          | 6/1001 [00:50<55:18,  3.34s/it, avg loss=159.9620]  Checkpoint at iteration 6 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 159.96202697753907

Training iteration:   1%|          | 6/1001 [00:50<55:18,  3.34s/it, avg loss=130.3397]New best at iteratoin 6!

Training iteration:   1%|          | 7/1001 [00:50<41:04,  2.48s/it, avg loss=130.3397]Checkpoint at iteration 7 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 130.33969955444337

Training iteration:   1%|          | 7/1001 [00:51<41:04,  2.48s/it, avg loss=208.5465]
Training iteration:   1%|          | 8/1001 [00:51<31:45,  1.92s/it, avg loss=208.5465]Checkpoint at iteration 8 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 208.54654541015626

Training iteration:   1%|          | 8/1001 [00:52<31:45,  1.92s/it, avg loss=223.9050]
Training iteration:   1%|          | 9/1001 [00:52<25:31,  1.54s/it, avg loss=223.9050]Checkpoint at iteration 9 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 223.90499877929688

Training iteration:   1%|          | 9/1001 [00:52<25:31,  1.54s/it, avg loss=126.4150]New best at iteratoin 9!

Training iteration:   1%|          | 10/1001 [00:52<21:17,  1.29s/it, avg loss=126.4150]Checkpoint at iteration 10 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 126.41500625610351

Training iteration:   1%|          | 10/1001 [00:53<21:17,  1.29s/it, avg loss=174.8535]
Training iteration:   1%|          | 11/1001 [00:53<18:24,  1.12s/it, avg loss=174.8535]Checkpoint at iteration 11 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 174.85354537963866

Training iteration:   1%|          | 11/1001 [00:54<18:24,  1.12s/it, avg loss=112.4867]New best at iteratoin 11!

Training iteration:   1%|          | 12/1001 [00:54<16:23,  1.01it/s, avg loss=112.4867]Checkpoint at iteration 12 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 112.48670883178711

Training iteration:   1%|          | 12/1001 [00:55<16:23,  1.01it/s, avg loss=173.5769]
Training iteration:   1%|▏         | 13/1001 [00:55<14:59,  1.10it/s, avg loss=173.5769]Checkpoint at iteration 13 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 173.5769073486328

Training iteration:   1%|▏         | 13/1001 [00:55<14:59,  1.10it/s, avg loss=184.7192]
Training iteration:   1%|▏         | 14/1001 [00:55<14:02,  1.17it/s, avg loss=184.7192]Checkpoint at iteration 14 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 184.71915435791016

Training iteration:   1%|▏         | 14/1001 [00:56<14:02,  1.17it/s, avg loss=225.2825]
Training iteration:   1%|▏         | 15/1001 [00:56<13:21,  1.23it/s, avg loss=225.2825]Checkpoint at iteration 15 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 225.28254776000978

Training iteration:   1%|▏         | 15/1001 [00:57<13:21,  1.23it/s, avg loss=116.0091]
Training iteration:   2%|▏         | 16/1001 [00:57<12:53,  1.27it/s, avg loss=116.0091]Checkpoint at iteration 16 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 116.00911865234374

Training iteration:   2%|▏         | 16/1001 [00:57<12:53,  1.27it/s, avg loss=101.6704]New best at iteratoin 16!

Training iteration:   2%|▏         | 17/1001 [00:57<12:33,  1.31it/s, avg loss=101.6704]Checkpoint at iteration 17 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 101.67038421630859

Training iteration:   2%|▏         | 17/1001 [00:58<12:33,  1.31it/s, avg loss=113.4919]
Training iteration:   2%|▏         | 18/1001 [00:58<12:19,  1.33it/s, avg loss=113.4919]Checkpoint at iteration 18 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 113.49189453125

Training iteration:   2%|▏         | 18/1001 [00:59<12:19,  1.33it/s, avg loss=235.6145]
Training iteration:   2%|▏         | 19/1001 [00:59<12:08,  1.35it/s, avg loss=235.6145]Checkpoint at iteration 19 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 235.61449432373047

Training iteration:   2%|▏         | 19/1001 [01:00<12:08,  1.35it/s, avg loss=137.4059]
Training iteration:   2%|▏         | 20/1001 [01:00<12:01,  1.36it/s, avg loss=137.4059]Checkpoint at iteration 20 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 137.40585403442384

Training iteration:   2%|▏         | 20/1001 [01:00<12:01,  1.36it/s, avg loss=190.0105]
Training iteration:   2%|▏         | 21/1001 [01:00<11:56,  1.37it/s, avg loss=190.0105]Checkpoint at iteration 21 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 190.0104652404785

Training iteration:   2%|▏         | 21/1001 [01:01<11:56,  1.37it/s, avg loss=115.6978]
Training iteration:   2%|▏         | 22/1001 [01:01<11:52,  1.37it/s, avg loss=115.6978]Checkpoint at iteration 22 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 115.69780960083008

Training iteration:   2%|▏         | 22/1001 [01:02<11:52,  1.37it/s, avg loss=156.6265]
Training iteration:   2%|▏         | 23/1001 [01:02<11:50,  1.38it/s, avg loss=156.6265]Checkpoint at iteration 23 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 156.62653732299805

Training iteration:   2%|▏         | 23/1001 [01:03<11:50,  1.38it/s, avg loss=260.9459]
Training iteration:   2%|▏         | 24/1001 [01:03<11:49,  1.38it/s, avg loss=260.9459]Checkpoint at iteration 24 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 260.9458770751953

Training iteration:   2%|▏         | 24/1001 [01:03<11:49,  1.38it/s, avg loss=241.2682]
Training iteration:   2%|▏         | 25/1001 [01:03<11:47,  1.38it/s, avg loss=241.2682]Checkpoint at iteration 25 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 241.26821212768556

Training iteration:   2%|▏         | 25/1001 [01:04<11:47,  1.38it/s, avg loss=157.4362]
Training iteration:   3%|▎         | 26/1001 [01:04<11:46,  1.38it/s, avg loss=157.4362]Checkpoint at iteration 26 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 157.4362060546875

Training iteration:   3%|▎         | 26/1001 [01:05<11:46,  1.38it/s, avg loss=107.9217]
Training iteration:   3%|▎         | 27/1001 [01:05<11:44,  1.38it/s, avg loss=107.9217]Checkpoint at iteration 27 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 107.92174682617187

Training iteration:   3%|▎         | 27/1001 [01:05<11:44,  1.38it/s, avg loss=135.7865]
Training iteration:   3%|▎         | 28/1001 [01:05<11:43,  1.38it/s, avg loss=135.7865]Checkpoint at iteration 28 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 135.7865364074707

Training iteration:   3%|▎         | 28/1001 [01:06<11:43,  1.38it/s, avg loss=168.2005]
Training iteration:   3%|▎         | 29/1001 [01:06<11:42,  1.38it/s, avg loss=168.2005]Checkpoint at iteration 29 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 168.20053634643554

Training iteration:   3%|▎         | 29/1001 [01:07<11:42,  1.38it/s, avg loss=178.3191]
Training iteration:   3%|▎         | 30/1001 [01:07<11:41,  1.38it/s, avg loss=178.3191]Checkpoint at iteration 30 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 178.31913070678712

Training iteration:   3%|▎         | 30/1001 [01:08<11:41,  1.38it/s, avg loss=186.2447]
Training iteration:   3%|▎         | 31/1001 [01:08<11:41,  1.38it/s, avg loss=186.2447]Checkpoint at iteration 31 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 186.24472579956054

Training iteration:   3%|▎         | 31/1001 [01:08<11:41,  1.38it/s, avg loss=125.2889]
Training iteration:   3%|▎         | 32/1001 [01:08<11:40,  1.38it/s, avg loss=125.2889]Checkpoint at iteration 32 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 125.28892669677734

Training iteration:   3%|▎         | 32/1001 [01:09<11:40,  1.38it/s, avg loss=203.7916]
Training iteration:   3%|▎         | 33/1001 [01:09<11:40,  1.38it/s, avg loss=203.7916]Checkpoint at iteration 33 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 203.7916015625

Training iteration:   3%|▎         | 33/1001 [01:10<11:40,  1.38it/s, avg loss=129.5693]
Training iteration:   3%|▎         | 34/1001 [01:10<11:39,  1.38it/s, avg loss=129.5693]Checkpoint at iteration 34 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 129.56933517456054

Training iteration:   3%|▎         | 34/1001 [01:10<11:39,  1.38it/s, avg loss=176.8483]
Training iteration:   3%|▎         | 35/1001 [01:10<11:38,  1.38it/s, avg loss=176.8483]Checkpoint at iteration 35 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 176.84825897216797

Training iteration:   3%|▎         | 35/1001 [01:11<11:38,  1.38it/s, avg loss=248.1551]
Training iteration:   4%|▎         | 36/1001 [01:11<11:38,  1.38it/s, avg loss=248.1551]Checkpoint at iteration 36 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 248.15509490966798

Training iteration:   4%|▎         | 36/1001 [01:12<11:38,  1.38it/s, avg loss=215.2014]
Training iteration:   4%|▎         | 37/1001 [01:12<11:37,  1.38it/s, avg loss=215.2014]Checkpoint at iteration 37 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 215.20138092041014

Training iteration:   4%|▎         | 37/1001 [01:13<11:37,  1.38it/s, avg loss=134.3268]
Training iteration:   4%|▍         | 38/1001 [01:13<11:37,  1.38it/s, avg loss=134.3268]Checkpoint at iteration 38 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 134.32678108215333

Training iteration:   4%|▍         | 38/1001 [01:13<11:37,  1.38it/s, avg loss=268.1378]
Training iteration:   4%|▍         | 39/1001 [01:13<11:36,  1.38it/s, avg loss=268.1378]Checkpoint at iteration 39 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 268.13782119750977

Training iteration:   4%|▍         | 39/1001 [01:14<11:36,  1.38it/s, avg loss=170.2311]
Training iteration:   4%|▍         | 40/1001 [01:14<11:35,  1.38it/s, avg loss=170.2311]Checkpoint at iteration 40 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 170.23107986450196

Training iteration:   4%|▍         | 40/1001 [01:15<11:35,  1.38it/s, avg loss=164.2946]
Training iteration:   4%|▍         | 41/1001 [01:15<11:34,  1.38it/s, avg loss=164.2946]Checkpoint at iteration 41 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 164.2945816040039

Training iteration:   4%|▍         | 41/1001 [01:16<11:34,  1.38it/s, avg loss=135.9223]
Training iteration:   4%|▍         | 42/1001 [01:16<11:33,  1.38it/s, avg loss=135.9223]Checkpoint at iteration 42 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 135.92228927612305

Training iteration:   4%|▍         | 42/1001 [01:16<11:33,  1.38it/s, avg loss=234.0348]
Training iteration:   4%|▍         | 43/1001 [01:16<11:33,  1.38it/s, avg loss=234.0348]Checkpoint at iteration 43 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 234.03479461669923

Training iteration:   4%|▍         | 43/1001 [01:17<11:33,  1.38it/s, avg loss=234.0160]
Training iteration:   4%|▍         | 44/1001 [01:17<11:32,  1.38it/s, avg loss=234.0160]Checkpoint at iteration 44 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 234.01599655151367

Training iteration:   4%|▍         | 44/1001 [01:18<11:32,  1.38it/s, avg loss=178.5723]
Training iteration:   4%|▍         | 45/1001 [01:18<11:31,  1.38it/s, avg loss=178.5723]Checkpoint at iteration 45 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 178.57232208251952

Training iteration:   4%|▍         | 45/1001 [01:18<11:31,  1.38it/s, avg loss=217.1291]
Training iteration:   5%|▍         | 46/1001 [01:18<11:30,  1.38it/s, avg loss=217.1291]Checkpoint at iteration 46 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 217.1290710449219

Training iteration:   5%|▍         | 46/1001 [01:19<11:30,  1.38it/s, avg loss=196.9824]
Training iteration:   5%|▍         | 47/1001 [01:19<11:29,  1.38it/s, avg loss=196.9824]Checkpoint at iteration 47 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 196.9824104309082

Training iteration:   5%|▍         | 47/1001 [01:20<11:29,  1.38it/s, avg loss=253.1092]
Training iteration:   5%|▍         | 48/1001 [01:20<11:28,  1.38it/s, avg loss=253.1092]Checkpoint at iteration 48 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 253.10918350219725

Training iteration:   5%|▍         | 48/1001 [01:21<11:28,  1.38it/s, avg loss=128.5356]
Training iteration:   5%|▍         | 49/1001 [01:21<11:27,  1.38it/s, avg loss=128.5356]Checkpoint at iteration 49 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 128.53559608459472

Training iteration:   5%|▍         | 49/1001 [01:21<11:27,  1.38it/s, avg loss=128.5770]
Training iteration:   5%|▍         | 50/1001 [01:21<11:26,  1.38it/s, avg loss=128.5770]Checkpoint at iteration 50 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 128.5770008087158

Training iteration:   5%|▍         | 50/1001 [01:22<11:26,  1.38it/s, avg loss=209.2563]
Training iteration:   5%|▌         | 51/1001 [01:22<11:26,  1.38it/s, avg loss=209.2563]Checkpoint at iteration 51 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 209.2563003540039

Training iteration:   5%|▌         | 51/1001 [01:23<11:26,  1.38it/s, avg loss=174.6727]
Training iteration:   5%|▌         | 52/1001 [01:23<11:24,  1.39it/s, avg loss=174.6727]Checkpoint at iteration 52 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 174.672705078125

Training iteration:   5%|▌         | 52/1001 [01:24<11:24,  1.39it/s, avg loss=138.3967]
Training iteration:   5%|▌         | 53/1001 [01:24<11:23,  1.39it/s, avg loss=138.3967]Checkpoint at iteration 53 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 138.39667816162108

Training iteration:   5%|▌         | 53/1001 [01:24<11:23,  1.39it/s, avg loss=208.3347]
Training iteration:   5%|▌         | 54/1001 [01:24<11:23,  1.39it/s, avg loss=208.3347]Checkpoint at iteration 54 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 208.33474044799806

Training iteration:   5%|▌         | 54/1001 [01:25<11:23,  1.39it/s, avg loss=281.3434]
Training iteration:   5%|▌         | 55/1001 [01:25<11:22,  1.39it/s, avg loss=281.3434]Checkpoint at iteration 55 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 281.3433807373047

Training iteration:   5%|▌         | 55/1001 [01:26<11:22,  1.39it/s, avg loss=131.6615]
Training iteration:   6%|▌         | 56/1001 [01:26<11:22,  1.38it/s, avg loss=131.6615]Checkpoint at iteration 56 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 131.66153717041016

Training iteration:   6%|▌         | 56/1001 [01:26<11:22,  1.38it/s, avg loss=220.5580]
Training iteration:   6%|▌         | 57/1001 [01:26<11:22,  1.38it/s, avg loss=220.5580]Checkpoint at iteration 57 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 220.55800552368163

Training iteration:   6%|▌         | 57/1001 [01:27<11:22,  1.38it/s, avg loss=184.6083]
Training iteration:   6%|▌         | 58/1001 [01:27<11:21,  1.38it/s, avg loss=184.6083]Checkpoint at iteration 58 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 184.60827751159667

Training iteration:   6%|▌         | 58/1001 [01:28<11:21,  1.38it/s, avg loss=189.2597]
Training iteration:   6%|▌         | 59/1001 [01:28<11:20,  1.38it/s, avg loss=189.2597]Checkpoint at iteration 59 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 189.25970993041992

Training iteration:   6%|▌         | 59/1001 [01:29<11:20,  1.38it/s, avg loss=177.5212]
Training iteration:   6%|▌         | 60/1001 [01:29<11:19,  1.38it/s, avg loss=177.5212]Checkpoint at iteration 60 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 177.52120552062988

Training iteration:   6%|▌         | 60/1001 [01:29<11:19,  1.38it/s, avg loss=192.2016]
Training iteration:   6%|▌         | 61/1001 [01:29<11:19,  1.38it/s, avg loss=192.2016]Checkpoint at iteration 61 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 192.20161056518555

Training iteration:   6%|▌         | 61/1001 [01:30<11:19,  1.38it/s, avg loss=204.7396]
Training iteration:   6%|▌         | 62/1001 [01:30<11:18,  1.38it/s, avg loss=204.7396]Checkpoint at iteration 62 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 204.73956222534179

Training iteration:   6%|▌         | 62/1001 [01:31<11:18,  1.38it/s, avg loss=227.1200]
Training iteration:   6%|▋         | 63/1001 [01:31<11:17,  1.38it/s, avg loss=227.1200]Checkpoint at iteration 63 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 227.11999130249023

Training iteration:   6%|▋         | 63/1001 [01:31<11:17,  1.38it/s, avg loss=165.8040]
Training iteration:   6%|▋         | 64/1001 [01:31<11:17,  1.38it/s, avg loss=165.8040]Checkpoint at iteration 64 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 165.80402603149415

Training iteration:   6%|▋         | 64/1001 [01:32<11:17,  1.38it/s, avg loss=206.9139]
Training iteration:   6%|▋         | 65/1001 [01:32<11:16,  1.38it/s, avg loss=206.9139]Checkpoint at iteration 65 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 206.91386032104492

Training iteration:   6%|▋         | 65/1001 [01:33<11:16,  1.38it/s, avg loss=214.8178]
Training iteration:   7%|▋         | 66/1001 [01:33<11:15,  1.38it/s, avg loss=214.8178]Checkpoint at iteration 66 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 214.81776809692383

Training iteration:   7%|▋         | 66/1001 [01:34<11:15,  1.38it/s, avg loss=183.0034]
Training iteration:   7%|▋         | 67/1001 [01:34<11:14,  1.38it/s, avg loss=183.0034]Checkpoint at iteration 67 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 183.00338134765624

Training iteration:   7%|▋         | 67/1001 [01:34<11:14,  1.38it/s, avg loss=242.2623]
Training iteration:   7%|▋         | 68/1001 [01:34<11:13,  1.38it/s, avg loss=242.2623]Checkpoint at iteration 68 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 242.26231269836427

Training iteration:   7%|▋         | 68/1001 [01:35<11:13,  1.38it/s, avg loss=186.5003]
Training iteration:   7%|▋         | 69/1001 [01:35<11:13,  1.38it/s, avg loss=186.5003]Checkpoint at iteration 69 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 186.50028190612792

Training iteration:   7%|▋         | 69/1001 [01:36<11:13,  1.38it/s, avg loss=218.6733]
Training iteration:   7%|▋         | 70/1001 [01:36<11:11,  1.39it/s, avg loss=218.6733]Checkpoint at iteration 70 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 218.6733367919922

Training iteration:   7%|▋         | 70/1001 [01:37<11:11,  1.39it/s, avg loss=160.1010]
Training iteration:   7%|▋         | 71/1001 [01:37<11:11,  1.38it/s, avg loss=160.1010]Checkpoint at iteration 71 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 160.10098037719726

Training iteration:   7%|▋         | 71/1001 [01:37<11:11,  1.38it/s, avg loss=153.4152]
Training iteration:   7%|▋         | 72/1001 [01:37<11:11,  1.38it/s, avg loss=153.4152]Checkpoint at iteration 72 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 153.4152084350586

Training iteration:   7%|▋         | 72/1001 [01:38<11:11,  1.38it/s, avg loss=206.4156]
Training iteration:   7%|▋         | 73/1001 [01:38<11:10,  1.38it/s, avg loss=206.4156]Checkpoint at iteration 73 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 206.4156478881836

Training iteration:   7%|▋         | 73/1001 [01:39<11:10,  1.38it/s, avg loss=151.1158]
Training iteration:   7%|▋         | 74/1001 [01:39<11:10,  1.38it/s, avg loss=151.1158]Checkpoint at iteration 74 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 151.1157600402832

Training iteration:   7%|▋         | 74/1001 [01:39<11:10,  1.38it/s, avg loss=232.4102]
Training iteration:   7%|▋         | 75/1001 [01:39<11:09,  1.38it/s, avg loss=232.4102]Checkpoint at iteration 75 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 232.41018524169922

Training iteration:   7%|▋         | 75/1001 [01:40<11:09,  1.38it/s, avg loss=170.7306]
Training iteration:   8%|▊         | 76/1001 [01:40<11:08,  1.38it/s, avg loss=170.7306]Checkpoint at iteration 76 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 170.73064193725585

Training iteration:   8%|▊         | 76/1001 [01:41<11:08,  1.38it/s, avg loss=167.8436]
Training iteration:   8%|▊         | 77/1001 [01:41<11:07,  1.38it/s, avg loss=167.8436]Checkpoint at iteration 77 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 167.84362754821777

Training iteration:   8%|▊         | 77/1001 [01:42<11:07,  1.38it/s, avg loss=114.2007]
Training iteration:   8%|▊         | 78/1001 [01:42<11:07,  1.38it/s, avg loss=114.2007]Checkpoint at iteration 78 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 114.20068283081055

Training iteration:   8%|▊         | 78/1001 [01:42<11:07,  1.38it/s, avg loss=120.7595]
Training iteration:   8%|▊         | 79/1001 [01:42<11:06,  1.38it/s, avg loss=120.7595]Checkpoint at iteration 79 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 120.75952224731445

Training iteration:   8%|▊         | 79/1001 [01:43<11:06,  1.38it/s, avg loss=103.1269]
Training iteration:   8%|▊         | 80/1001 [01:43<11:05,  1.38it/s, avg loss=103.1269]Checkpoint at iteration 80 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 103.1268741607666

Training iteration:   8%|▊         | 80/1001 [01:44<11:05,  1.38it/s, avg loss=246.5164]
Training iteration:   8%|▊         | 81/1001 [01:44<11:04,  1.38it/s, avg loss=246.5164]Checkpoint at iteration 81 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 246.51639709472656

Training iteration:   8%|▊         | 81/1001 [01:44<11:04,  1.38it/s, avg loss=219.8740]
Training iteration:   8%|▊         | 82/1001 [01:44<11:04,  1.38it/s, avg loss=219.8740]Checkpoint at iteration 82 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 219.87396163940429

Training iteration:   8%|▊         | 82/1001 [01:45<11:04,  1.38it/s, avg loss=214.5245]
Training iteration:   8%|▊         | 83/1001 [01:45<11:02,  1.39it/s, avg loss=214.5245]Checkpoint at iteration 83 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 214.52445526123046

Training iteration:   8%|▊         | 83/1001 [01:46<11:02,  1.39it/s, avg loss=167.6346]
Training iteration:   8%|▊         | 84/1001 [01:46<11:02,  1.38it/s, avg loss=167.6346]Checkpoint at iteration 84 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 167.6346061706543

Training iteration:   8%|▊         | 84/1001 [01:47<11:02,  1.38it/s, avg loss=184.7358]
Training iteration:   8%|▊         | 85/1001 [01:47<11:01,  1.38it/s, avg loss=184.7358]Checkpoint at iteration 85 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 184.73584442138673

Training iteration:   8%|▊         | 85/1001 [01:47<11:01,  1.38it/s, avg loss=155.0604]
Training iteration:   9%|▊         | 86/1001 [01:47<11:01,  1.38it/s, avg loss=155.0604]Checkpoint at iteration 86 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 155.0604476928711

Training iteration:   9%|▊         | 86/1001 [01:48<11:01,  1.38it/s, avg loss=249.9089]
Training iteration:   9%|▊         | 87/1001 [01:48<11:00,  1.38it/s, avg loss=249.9089]Checkpoint at iteration 87 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 249.90889053344728

Training iteration:   9%|▊         | 87/1001 [01:49<11:00,  1.38it/s, avg loss=226.7848]
Training iteration:   9%|▉         | 88/1001 [01:49<11:00,  1.38it/s, avg loss=226.7848]Checkpoint at iteration 88 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 226.78484878540038

Training iteration:   9%|▉         | 88/1001 [01:50<11:00,  1.38it/s, avg loss=209.4152]
Training iteration:   9%|▉         | 89/1001 [01:50<10:59,  1.38it/s, avg loss=209.4152]Checkpoint at iteration 89 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 209.41520309448242

Training iteration:   9%|▉         | 89/1001 [01:50<10:59,  1.38it/s, avg loss=153.7347]
Training iteration:   9%|▉         | 90/1001 [01:50<10:58,  1.38it/s, avg loss=153.7347]Checkpoint at iteration 90 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 153.7346504211426

Training iteration:   9%|▉         | 90/1001 [01:51<10:58,  1.38it/s, avg loss=207.3590]
Training iteration:   9%|▉         | 91/1001 [01:51<10:58,  1.38it/s, avg loss=207.3590]Checkpoint at iteration 91 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 207.35900192260743

Training iteration:   9%|▉         | 91/1001 [01:52<10:58,  1.38it/s, avg loss=201.7757]
Training iteration:   9%|▉         | 92/1001 [01:52<10:57,  1.38it/s, avg loss=201.7757]Checkpoint at iteration 92 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 201.77566452026366

Training iteration:   9%|▉         | 92/1001 [01:52<10:57,  1.38it/s, avg loss=158.1873]
Training iteration:   9%|▉         | 93/1001 [01:52<10:56,  1.38it/s, avg loss=158.1873]Checkpoint at iteration 93 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 158.1872673034668

Training iteration:   9%|▉         | 93/1001 [01:53<10:56,  1.38it/s, avg loss=151.2565]
Training iteration:   9%|▉         | 94/1001 [01:53<10:55,  1.38it/s, avg loss=151.2565]Checkpoint at iteration 94 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 151.25653228759765

Training iteration:   9%|▉         | 94/1001 [01:54<10:55,  1.38it/s, avg loss=175.1594]
Training iteration:   9%|▉         | 95/1001 [01:54<10:54,  1.38it/s, avg loss=175.1594]Checkpoint at iteration 95 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 175.1594467163086

Training iteration:   9%|▉         | 95/1001 [01:55<10:54,  1.38it/s, avg loss=199.5081]
Training iteration:  10%|▉         | 96/1001 [01:55<10:54,  1.38it/s, avg loss=199.5081]Checkpoint at iteration 96 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 199.50812759399415

Training iteration:  10%|▉         | 96/1001 [01:55<10:54,  1.38it/s, avg loss=180.1540]
Training iteration:  10%|▉         | 97/1001 [01:55<10:53,  1.38it/s, avg loss=180.1540]Checkpoint at iteration 97 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 180.15398178100585

Training iteration:  10%|▉         | 97/1001 [01:56<10:53,  1.38it/s, avg loss=164.0303]
Training iteration:  10%|▉         | 98/1001 [01:56<10:52,  1.38it/s, avg loss=164.0303]Checkpoint at iteration 98 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 164.03030090332032

Training iteration:  10%|▉         | 98/1001 [01:57<10:52,  1.38it/s, avg loss=224.5552]
Training iteration:  10%|▉         | 99/1001 [01:57<10:52,  1.38it/s, avg loss=224.5552]Checkpoint at iteration 99 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 224.5551586151123

Training iteration:  10%|▉         | 99/1001 [01:57<10:52,  1.38it/s, avg loss=220.3922]
Training iteration:  10%|▉         | 100/1001 [01:57<10:51,  1.38it/s, avg loss=220.3922]Optimization iteration 100 evaluation begins...
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
A new evaluation visualization has been saved: ./saved_data/20240110-063719/it100.png
Training network 0 for evaluation...
Training network 1 for evaluation...
Training network 2 for evaluation...
Training network 3 for evaluation...
Testing network 0 on real datasets for evaluation...
Testing network 1 on real datasets for evaluation...
Testing network 2 on real datasets for evaluation...
Testing network 3 on real datasets for evaluation...
Optimization iteration 100, eval auroc score (train): 20413.3034, eval auroc score (test): 21306.9952
Checkpoint at iteration 100 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 220.39219436645507

Training iteration:  10%|▉         | 100/1001 [02:41<10:51,  1.38it/s, avg loss=234.2415]
Training iteration:  10%|█         | 101/1001 [02:41<3:22:36, 13.51s/it, avg loss=234.2415]Checkpoint at iteration 101 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 234.24146041870117

Training iteration:  10%|█         | 101/1001 [02:42<3:22:36, 13.51s/it, avg loss=192.9394]
Training iteration:  10%|█         | 102/1001 [02:42<2:25:48,  9.73s/it, avg loss=192.9394]Checkpoint at iteration 102 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 192.93944625854493

Training iteration:  10%|█         | 102/1001 [02:43<2:25:48,  9.73s/it, avg loss=171.1273]
Training iteration:  10%|█         | 103/1001 [02:43<1:46:04,  7.09s/it, avg loss=171.1273]Checkpoint at iteration 103 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 171.12733535766603

Training iteration:  10%|█         | 103/1001 [02:44<1:46:04,  7.09s/it, avg loss=194.9519]
Training iteration:  10%|█         | 104/1001 [02:44<1:18:17,  5.24s/it, avg loss=194.9519]Checkpoint at iteration 104 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 194.95189361572267

Training iteration:  10%|█         | 104/1001 [02:44<1:18:17,  5.24s/it, avg loss=111.0877]
Training iteration:  10%|█         | 105/1001 [02:44<58:51,  3.94s/it, avg loss=111.0877]  Checkpoint at iteration 105 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 111.08766403198243

Training iteration:  10%|█         | 105/1001 [02:45<58:51,  3.94s/it, avg loss=117.7096]
Training iteration:  11%|█         | 106/1001 [02:45<45:16,  3.03s/it, avg loss=117.7096]Checkpoint at iteration 106 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 117.70958938598633

Training iteration:  11%|█         | 106/1001 [02:46<45:16,  3.03s/it, avg loss=154.7504]
Training iteration:  11%|█         | 107/1001 [02:46<35:46,  2.40s/it, avg loss=154.7504]Checkpoint at iteration 107 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 154.7503875732422

Training iteration:  11%|█         | 107/1001 [02:47<35:46,  2.40s/it, avg loss=143.2391]
Training iteration:  11%|█         | 108/1001 [02:47<29:06,  1.96s/it, avg loss=143.2391]Checkpoint at iteration 108 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 143.23913116455077

Training iteration:  11%|█         | 108/1001 [02:48<29:06,  1.96s/it, avg loss=245.2808]
Training iteration:  11%|█         | 109/1001 [02:48<24:27,  1.65s/it, avg loss=245.2808]Checkpoint at iteration 109 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 245.2808349609375

Training iteration:  11%|█         | 109/1001 [02:49<24:27,  1.65s/it, avg loss=100.6891]New best at iteratoin 109!

Training iteration:  11%|█         | 110/1001 [02:49<21:12,  1.43s/it, avg loss=100.6891]Checkpoint at iteration 110 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 100.68906173706054

Training iteration:  11%|█         | 110/1001 [02:50<21:12,  1.43s/it, avg loss=147.1574]
Training iteration:  11%|█         | 111/1001 [02:50<18:54,  1.27s/it, avg loss=147.1574]Checkpoint at iteration 111 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 147.1573928833008

Training iteration:  11%|█         | 111/1001 [02:51<18:54,  1.27s/it, avg loss=158.5026]
Training iteration:  11%|█         | 112/1001 [02:51<17:18,  1.17s/it, avg loss=158.5026]Checkpoint at iteration 112 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 158.50259590148926

Training iteration:  11%|█         | 112/1001 [02:52<17:18,  1.17s/it, avg loss=166.6776]
Training iteration:  11%|█▏        | 113/1001 [02:52<16:10,  1.09s/it, avg loss=166.6776]Checkpoint at iteration 113 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 166.67759017944337

Training iteration:  11%|█▏        | 113/1001 [02:53<16:10,  1.09s/it, avg loss=100.0885]New best at iteratoin 113!

Training iteration:  11%|█▏        | 114/1001 [02:53<15:23,  1.04s/it, avg loss=100.0885]Checkpoint at iteration 114 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 100.08852577209473

Training iteration:  11%|█▏        | 114/1001 [02:54<15:23,  1.04s/it, avg loss=179.9698]
Training iteration:  11%|█▏        | 115/1001 [02:54<14:50,  1.00s/it, avg loss=179.9698]Checkpoint at iteration 115 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 179.96976776123046

Training iteration:  11%|█▏        | 115/1001 [02:55<14:50,  1.00s/it, avg loss=206.4120]
Training iteration:  12%|█▏        | 116/1001 [02:55<14:26,  1.02it/s, avg loss=206.4120]Checkpoint at iteration 116 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 206.41202125549316

Training iteration:  12%|█▏        | 116/1001 [02:56<14:26,  1.02it/s, avg loss=175.0899]
Training iteration:  12%|█▏        | 117/1001 [02:56<14:10,  1.04it/s, avg loss=175.0899]Checkpoint at iteration 117 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 175.08994903564454

Training iteration:  12%|█▏        | 117/1001 [02:56<14:10,  1.04it/s, avg loss=231.9476]
Training iteration:  12%|█▏        | 118/1001 [02:56<13:58,  1.05it/s, avg loss=231.9476]Checkpoint at iteration 118 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 231.94756011962892

Training iteration:  12%|█▏        | 118/1001 [02:57<13:58,  1.05it/s, avg loss=141.8204]
Training iteration:  12%|█▏        | 119/1001 [02:57<13:49,  1.06it/s, avg loss=141.8204]Checkpoint at iteration 119 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 141.82038116455078

Training iteration:  12%|█▏        | 119/1001 [02:58<13:49,  1.06it/s, avg loss=178.4778]
Training iteration:  12%|█▏        | 120/1001 [02:58<13:43,  1.07it/s, avg loss=178.4778]Checkpoint at iteration 120 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 178.4777862548828

Training iteration:  12%|█▏        | 120/1001 [02:59<13:43,  1.07it/s, avg loss=124.4031]
Training iteration:  12%|█▏        | 121/1001 [02:59<13:39,  1.07it/s, avg loss=124.4031]Checkpoint at iteration 121 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 124.40311546325684

Training iteration:  12%|█▏        | 121/1001 [03:00<13:39,  1.07it/s, avg loss=201.4377]
Training iteration:  12%|█▏        | 122/1001 [03:00<13:35,  1.08it/s, avg loss=201.4377]Checkpoint at iteration 122 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 201.43771743774414

Training iteration:  12%|█▏        | 122/1001 [03:01<13:35,  1.08it/s, avg loss=203.3793]
Training iteration:  12%|█▏        | 123/1001 [03:01<13:32,  1.08it/s, avg loss=203.3793]Checkpoint at iteration 123 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 203.37925033569337

Training iteration:  12%|█▏        | 123/1001 [03:02<13:32,  1.08it/s, avg loss=193.1802]
Training iteration:  12%|█▏        | 124/1001 [03:02<13:30,  1.08it/s, avg loss=193.1802]Checkpoint at iteration 124 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 193.1801742553711

Training iteration:  12%|█▏        | 124/1001 [03:03<13:30,  1.08it/s, avg loss=141.9229]
Training iteration:  12%|█▏        | 125/1001 [03:03<13:28,  1.08it/s, avg loss=141.9229]Checkpoint at iteration 125 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 141.92286071777343

Training iteration:  12%|█▏        | 125/1001 [03:04<13:28,  1.08it/s, avg loss=164.2188]
Training iteration:  13%|█▎        | 126/1001 [03:04<13:27,  1.08it/s, avg loss=164.2188]Checkpoint at iteration 126 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 164.21877975463866

Training iteration:  13%|█▎        | 126/1001 [03:05<13:27,  1.08it/s, avg loss=164.4423]
Training iteration:  13%|█▎        | 127/1001 [03:05<13:25,  1.09it/s, avg loss=164.4423]Checkpoint at iteration 127 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 164.44228286743163

Training iteration:  13%|█▎        | 127/1001 [03:06<13:25,  1.09it/s, avg loss=180.6822]
Training iteration:  13%|█▎        | 128/1001 [03:06<13:23,  1.09it/s, avg loss=180.6822]Checkpoint at iteration 128 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 180.68219070434571

Training iteration:  13%|█▎        | 128/1001 [03:07<13:23,  1.09it/s, avg loss=207.2953]
Training iteration:  13%|█▎        | 129/1001 [03:07<13:23,  1.09it/s, avg loss=207.2953]Checkpoint at iteration 129 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 207.29529571533203

Training iteration:  13%|█▎        | 129/1001 [03:07<13:23,  1.09it/s, avg loss=125.3575]
Training iteration:  13%|█▎        | 130/1001 [03:07<13:21,  1.09it/s, avg loss=125.3575]Checkpoint at iteration 130 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 125.35749282836915

Training iteration:  13%|█▎        | 130/1001 [03:08<13:21,  1.09it/s, avg loss=124.8813]
Training iteration:  13%|█▎        | 131/1001 [03:08<13:20,  1.09it/s, avg loss=124.8813]Checkpoint at iteration 131 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 124.88130722045898

Training iteration:  13%|█▎        | 131/1001 [03:09<13:20,  1.09it/s, avg loss=209.7719]
Training iteration:  13%|█▎        | 132/1001 [03:09<13:19,  1.09it/s, avg loss=209.7719]Checkpoint at iteration 132 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 209.7718635559082

Training iteration:  13%|█▎        | 132/1001 [03:10<13:19,  1.09it/s, avg loss=164.4217]
Training iteration:  13%|█▎        | 133/1001 [03:10<13:18,  1.09it/s, avg loss=164.4217]Checkpoint at iteration 133 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 164.4217330932617

Training iteration:  13%|█▎        | 133/1001 [03:11<13:18,  1.09it/s, avg loss=126.9775]
Training iteration:  13%|█▎        | 134/1001 [03:11<13:18,  1.09it/s, avg loss=126.9775]Checkpoint at iteration 134 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 126.97749519348145

Training iteration:  13%|█▎        | 134/1001 [03:12<13:18,  1.09it/s, avg loss=134.2570]
Training iteration:  13%|█▎        | 135/1001 [03:12<13:17,  1.09it/s, avg loss=134.2570]Checkpoint at iteration 135 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 134.25703048706055

Training iteration:  13%|█▎        | 135/1001 [03:13<13:17,  1.09it/s, avg loss=208.4320]
Training iteration:  14%|█▎        | 136/1001 [03:13<13:16,  1.09it/s, avg loss=208.4320]Checkpoint at iteration 136 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 208.4320068359375

Training iteration:  14%|█▎        | 136/1001 [03:14<13:16,  1.09it/s, avg loss=93.8754] New best at iteratoin 136!

Training iteration:  14%|█▎        | 137/1001 [03:14<13:14,  1.09it/s, avg loss=93.8754]Checkpoint at iteration 137 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 93.87541236877442

Training iteration:  14%|█▎        | 137/1001 [03:15<13:14,  1.09it/s, avg loss=248.5824]
Training iteration:  14%|█▍        | 138/1001 [03:15<13:14,  1.09it/s, avg loss=248.5824]Checkpoint at iteration 138 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 248.5824172973633

Training iteration:  14%|█▍        | 138/1001 [03:16<13:14,  1.09it/s, avg loss=174.5909]
Training iteration:  14%|█▍        | 139/1001 [03:16<13:13,  1.09it/s, avg loss=174.5909]Checkpoint at iteration 139 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 174.59086990356445

Training iteration:  14%|█▍        | 139/1001 [03:17<13:13,  1.09it/s, avg loss=220.0196]
Training iteration:  14%|█▍        | 140/1001 [03:17<13:12,  1.09it/s, avg loss=220.0196]Checkpoint at iteration 140 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 220.0196388244629

Training iteration:  14%|█▍        | 140/1001 [03:18<13:12,  1.09it/s, avg loss=129.3555]
Training iteration:  14%|█▍        | 141/1001 [03:18<13:11,  1.09it/s, avg loss=129.3555]Checkpoint at iteration 141 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 129.35554275512695

Training iteration:  14%|█▍        | 141/1001 [03:19<13:11,  1.09it/s, avg loss=159.3063]
Training iteration:  14%|█▍        | 142/1001 [03:19<13:10,  1.09it/s, avg loss=159.3063]Checkpoint at iteration 142 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 159.3063159942627

Training iteration:  14%|█▍        | 142/1001 [03:19<13:10,  1.09it/s, avg loss=139.1961]
Training iteration:  14%|█▍        | 143/1001 [03:19<13:10,  1.09it/s, avg loss=139.1961]Checkpoint at iteration 143 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 139.19610900878905

Training iteration:  14%|█▍        | 143/1001 [03:20<13:10,  1.09it/s, avg loss=203.4893]
Training iteration:  14%|█▍        | 144/1001 [03:20<13:08,  1.09it/s, avg loss=203.4893]Checkpoint at iteration 144 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 203.48934478759764

Training iteration:  14%|█▍        | 144/1001 [03:21<13:08,  1.09it/s, avg loss=204.1107]
Training iteration:  14%|█▍        | 145/1001 [03:21<13:07,  1.09it/s, avg loss=204.1107]Checkpoint at iteration 145 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 204.11066970825195

Training iteration:  14%|█▍        | 145/1001 [03:22<13:07,  1.09it/s, avg loss=199.5842]
Training iteration:  15%|█▍        | 146/1001 [03:22<13:07,  1.09it/s, avg loss=199.5842]Checkpoint at iteration 146 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 199.5842430114746

Training iteration:  15%|█▍        | 146/1001 [03:23<13:07,  1.09it/s, avg loss=215.0003]
Training iteration:  15%|█▍        | 147/1001 [03:23<13:06,  1.09it/s, avg loss=215.0003]Checkpoint at iteration 147 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 215.00034866333007

Training iteration:  15%|█▍        | 147/1001 [03:24<13:06,  1.09it/s, avg loss=119.7562]
Training iteration:  15%|█▍        | 148/1001 [03:24<13:05,  1.09it/s, avg loss=119.7562]Checkpoint at iteration 148 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 119.75623168945313

Training iteration:  15%|█▍        | 148/1001 [03:25<13:05,  1.09it/s, avg loss=176.0436]
Training iteration:  15%|█▍        | 149/1001 [03:25<13:04,  1.09it/s, avg loss=176.0436]Checkpoint at iteration 149 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 176.0436134338379

Training iteration:  15%|█▍        | 149/1001 [03:26<13:04,  1.09it/s, avg loss=204.7402]
Training iteration:  15%|█▍        | 150/1001 [03:26<13:03,  1.09it/s, avg loss=204.7402]Checkpoint at iteration 150 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 204.74016036987305

Training iteration:  15%|█▍        | 150/1001 [03:27<13:03,  1.09it/s, avg loss=157.5698]
Training iteration:  15%|█▌        | 151/1001 [03:27<13:01,  1.09it/s, avg loss=157.5698]Checkpoint at iteration 151 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 157.56976737976075

Training iteration:  15%|█▌        | 151/1001 [03:28<13:01,  1.09it/s, avg loss=225.8666]
Training iteration:  15%|█▌        | 152/1001 [03:28<13:01,  1.09it/s, avg loss=225.8666]Checkpoint at iteration 152 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 225.86655197143554

Training iteration:  15%|█▌        | 152/1001 [03:29<13:01,  1.09it/s, avg loss=233.9840]
Training iteration:  15%|█▌        | 153/1001 [03:29<13:00,  1.09it/s, avg loss=233.9840]Checkpoint at iteration 153 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 233.9840431213379

Training iteration:  15%|█▌        | 153/1001 [03:30<13:00,  1.09it/s, avg loss=166.4296]
Training iteration:  15%|█▌        | 154/1001 [03:30<12:59,  1.09it/s, avg loss=166.4296]Checkpoint at iteration 154 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 166.42955017089844

Training iteration:  15%|█▌        | 154/1001 [03:30<12:59,  1.09it/s, avg loss=156.8975]
Training iteration:  15%|█▌        | 155/1001 [03:30<12:57,  1.09it/s, avg loss=156.8975]Checkpoint at iteration 155 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 156.89746322631837

Training iteration:  15%|█▌        | 155/1001 [03:31<12:57,  1.09it/s, avg loss=98.1465] 
Training iteration:  16%|█▌        | 156/1001 [03:31<12:57,  1.09it/s, avg loss=98.1465]Checkpoint at iteration 156 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 98.1465446472168

Training iteration:  16%|█▌        | 156/1001 [03:32<12:57,  1.09it/s, avg loss=176.8890]
Training iteration:  16%|█▌        | 157/1001 [03:32<12:56,  1.09it/s, avg loss=176.8890]Checkpoint at iteration 157 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 176.88900146484374

Training iteration:  16%|█▌        | 157/1001 [03:33<12:56,  1.09it/s, avg loss=162.8654]
Training iteration:  16%|█▌        | 158/1001 [03:33<12:55,  1.09it/s, avg loss=162.8654]Checkpoint at iteration 158 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 162.86535415649413

Training iteration:  16%|█▌        | 158/1001 [03:34<12:55,  1.09it/s, avg loss=231.1283]
Training iteration:  16%|█▌        | 159/1001 [03:34<12:54,  1.09it/s, avg loss=231.1283]Checkpoint at iteration 159 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 231.12831115722656

Training iteration:  16%|█▌        | 159/1001 [03:35<12:54,  1.09it/s, avg loss=186.9353]
Training iteration:  16%|█▌        | 160/1001 [03:35<12:53,  1.09it/s, avg loss=186.9353]Checkpoint at iteration 160 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 186.93530197143554

Training iteration:  16%|█▌        | 160/1001 [03:36<12:53,  1.09it/s, avg loss=118.6866]
Training iteration:  16%|█▌        | 161/1001 [03:36<12:52,  1.09it/s, avg loss=118.6866]Checkpoint at iteration 161 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 118.68663444519044

Training iteration:  16%|█▌        | 161/1001 [03:37<12:52,  1.09it/s, avg loss=204.5779]
Training iteration:  16%|█▌        | 162/1001 [03:37<12:52,  1.09it/s, avg loss=204.5779]Checkpoint at iteration 162 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 204.57794265747071

Training iteration:  16%|█▌        | 162/1001 [03:38<12:52,  1.09it/s, avg loss=167.5024]
Training iteration:  16%|█▋        | 163/1001 [03:38<12:51,  1.09it/s, avg loss=167.5024]Checkpoint at iteration 163 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 167.50237045288085

Training iteration:  16%|█▋        | 163/1001 [03:39<12:51,  1.09it/s, avg loss=140.9025]
Training iteration:  16%|█▋        | 164/1001 [03:39<12:50,  1.09it/s, avg loss=140.9025]Checkpoint at iteration 164 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 140.9024917602539

Training iteration:  16%|█▋        | 164/1001 [03:40<12:50,  1.09it/s, avg loss=159.9457]
Training iteration:  16%|█▋        | 165/1001 [03:40<12:49,  1.09it/s, avg loss=159.9457]Checkpoint at iteration 165 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 159.94567947387696

Training iteration:  16%|█▋        | 165/1001 [03:41<12:49,  1.09it/s, avg loss=140.9517]
Training iteration:  17%|█▋        | 166/1001 [03:41<12:48,  1.09it/s, avg loss=140.9517]Checkpoint at iteration 166 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 140.9517364501953

Training iteration:  17%|█▋        | 166/1001 [03:42<12:48,  1.09it/s, avg loss=211.8670]
Training iteration:  17%|█▋        | 167/1001 [03:42<12:47,  1.09it/s, avg loss=211.8670]Checkpoint at iteration 167 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 211.86697082519532

Training iteration:  17%|█▋        | 167/1001 [03:42<12:47,  1.09it/s, avg loss=166.0314]
Training iteration:  17%|█▋        | 168/1001 [03:42<12:46,  1.09it/s, avg loss=166.0314]Checkpoint at iteration 168 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 166.031396484375

Training iteration:  17%|█▋        | 168/1001 [03:43<12:46,  1.09it/s, avg loss=141.1387]
Training iteration:  17%|█▋        | 169/1001 [03:43<12:46,  1.09it/s, avg loss=141.1387]Checkpoint at iteration 169 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 141.13871841430665

Training iteration:  17%|█▋        | 169/1001 [03:44<12:46,  1.09it/s, avg loss=215.6103]
Training iteration:  17%|█▋        | 170/1001 [03:44<12:44,  1.09it/s, avg loss=215.6103]Checkpoint at iteration 170 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 215.61029357910155

Training iteration:  17%|█▋        | 170/1001 [03:45<12:44,  1.09it/s, avg loss=170.8138]
Training iteration:  17%|█▋        | 171/1001 [03:45<12:43,  1.09it/s, avg loss=170.8138]Checkpoint at iteration 171 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 170.81383743286133

Training iteration:  17%|█▋        | 171/1001 [03:46<12:43,  1.09it/s, avg loss=175.4411]
Training iteration:  17%|█▋        | 172/1001 [03:46<12:42,  1.09it/s, avg loss=175.4411]Checkpoint at iteration 172 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 175.4410873413086

Training iteration:  17%|█▋        | 172/1001 [03:47<12:42,  1.09it/s, avg loss=199.6719]
Training iteration:  17%|█▋        | 173/1001 [03:47<12:41,  1.09it/s, avg loss=199.6719]Checkpoint at iteration 173 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 199.67185440063477

Training iteration:  17%|█▋        | 173/1001 [03:48<12:41,  1.09it/s, avg loss=175.1981]
Training iteration:  17%|█▋        | 174/1001 [03:48<12:40,  1.09it/s, avg loss=175.1981]Checkpoint at iteration 174 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 175.1980987548828

Training iteration:  17%|█▋        | 174/1001 [03:49<12:40,  1.09it/s, avg loss=168.5038]
Training iteration:  17%|█▋        | 175/1001 [03:49<12:39,  1.09it/s, avg loss=168.5038]Checkpoint at iteration 175 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 168.50375747680664

Training iteration:  17%|█▋        | 175/1001 [03:50<12:39,  1.09it/s, avg loss=108.4854]
Training iteration:  18%|█▊        | 176/1001 [03:50<12:38,  1.09it/s, avg loss=108.4854]Checkpoint at iteration 176 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 108.48542861938476

Training iteration:  18%|█▊        | 176/1001 [03:51<12:38,  1.09it/s, avg loss=163.8984]
Training iteration:  18%|█▊        | 177/1001 [03:51<12:37,  1.09it/s, avg loss=163.8984]Checkpoint at iteration 177 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 163.89835433959962

Training iteration:  18%|█▊        | 177/1001 [03:52<12:37,  1.09it/s, avg loss=130.5509]
Training iteration:  18%|█▊        | 178/1001 [03:52<12:36,  1.09it/s, avg loss=130.5509]Checkpoint at iteration 178 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 130.55087890625

Training iteration:  18%|█▊        | 178/1001 [03:53<12:36,  1.09it/s, avg loss=104.2464]
Training iteration:  18%|█▊        | 179/1001 [03:53<12:35,  1.09it/s, avg loss=104.2464]Checkpoint at iteration 179 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 104.24638900756835

Training iteration:  18%|█▊        | 179/1001 [03:53<12:35,  1.09it/s, avg loss=189.6209]
Training iteration:  18%|█▊        | 180/1001 [03:53<12:35,  1.09it/s, avg loss=189.6209]Checkpoint at iteration 180 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 189.62094802856444

Training iteration:  18%|█▊        | 180/1001 [03:54<12:35,  1.09it/s, avg loss=191.1970]
Training iteration:  18%|█▊        | 181/1001 [03:54<12:34,  1.09it/s, avg loss=191.1970]Checkpoint at iteration 181 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 191.19703979492186

Training iteration:  18%|█▊        | 181/1001 [03:55<12:34,  1.09it/s, avg loss=176.6358]
Training iteration:  18%|█▊        | 182/1001 [03:55<12:33,  1.09it/s, avg loss=176.6358]Checkpoint at iteration 182 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 176.6357837677002

Training iteration:  18%|█▊        | 182/1001 [03:56<12:33,  1.09it/s, avg loss=155.3852]
Training iteration:  18%|█▊        | 183/1001 [03:56<12:32,  1.09it/s, avg loss=155.3852]Checkpoint at iteration 183 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 155.38521614074708

Training iteration:  18%|█▊        | 183/1001 [03:57<12:32,  1.09it/s, avg loss=141.2741]
Training iteration:  18%|█▊        | 184/1001 [03:57<12:31,  1.09it/s, avg loss=141.2741]Checkpoint at iteration 184 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 141.27410964965821

Training iteration:  18%|█▊        | 184/1001 [03:58<12:31,  1.09it/s, avg loss=213.2906]
Training iteration:  18%|█▊        | 185/1001 [03:58<12:30,  1.09it/s, avg loss=213.2906]Checkpoint at iteration 185 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 213.29057998657225

Training iteration:  18%|█▊        | 185/1001 [03:59<12:30,  1.09it/s, avg loss=161.1617]
Training iteration:  19%|█▊        | 186/1001 [03:59<12:29,  1.09it/s, avg loss=161.1617]Checkpoint at iteration 186 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 161.16172103881837

Training iteration:  19%|█▊        | 186/1001 [04:00<12:29,  1.09it/s, avg loss=191.5981]
Training iteration:  19%|█▊        | 187/1001 [04:00<12:28,  1.09it/s, avg loss=191.5981]Checkpoint at iteration 187 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 191.59805145263672

Training iteration:  19%|█▊        | 187/1001 [04:01<12:28,  1.09it/s, avg loss=165.2003]
Training iteration:  19%|█▉        | 188/1001 [04:01<12:27,  1.09it/s, avg loss=165.2003]Checkpoint at iteration 188 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 165.20029525756837

Training iteration:  19%|█▉        | 188/1001 [04:02<12:27,  1.09it/s, avg loss=136.4346]
Training iteration:  19%|█▉        | 189/1001 [04:02<12:26,  1.09it/s, avg loss=136.4346]Checkpoint at iteration 189 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 136.43456802368163

Training iteration:  19%|█▉        | 189/1001 [04:03<12:26,  1.09it/s, avg loss=208.2200]
Training iteration:  19%|█▉        | 190/1001 [04:03<12:25,  1.09it/s, avg loss=208.2200]Checkpoint at iteration 190 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 208.22002334594725

Training iteration:  19%|█▉        | 190/1001 [04:04<12:25,  1.09it/s, avg loss=249.1673]
Training iteration:  19%|█▉        | 191/1001 [04:04<12:25,  1.09it/s, avg loss=249.1673]Checkpoint at iteration 191 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 249.16734313964844

Training iteration:  19%|█▉        | 191/1001 [04:05<12:25,  1.09it/s, avg loss=167.3615]
Training iteration:  19%|█▉        | 192/1001 [04:05<12:23,  1.09it/s, avg loss=167.3615]Checkpoint at iteration 192 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 167.36149063110352

Training iteration:  19%|█▉        | 192/1001 [04:05<12:23,  1.09it/s, avg loss=167.4614]
Training iteration:  19%|█▉        | 193/1001 [04:05<12:23,  1.09it/s, avg loss=167.4614]Checkpoint at iteration 193 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 167.4614227294922

Training iteration:  19%|█▉        | 193/1001 [04:06<12:23,  1.09it/s, avg loss=165.1598]
Training iteration:  19%|█▉        | 194/1001 [04:06<12:23,  1.09it/s, avg loss=165.1598]Checkpoint at iteration 194 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 165.1598258972168

Training iteration:  19%|█▉        | 194/1001 [04:07<12:23,  1.09it/s, avg loss=196.9524]
Training iteration:  19%|█▉        | 195/1001 [04:07<12:23,  1.08it/s, avg loss=196.9524]Checkpoint at iteration 195 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 196.95242614746093

Training iteration:  19%|█▉        | 195/1001 [04:08<12:23,  1.08it/s, avg loss=193.2138]
Training iteration:  20%|█▉        | 196/1001 [04:08<12:22,  1.08it/s, avg loss=193.2138]Checkpoint at iteration 196 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 193.21383666992188

Training iteration:  20%|█▉        | 196/1001 [04:09<12:22,  1.08it/s, avg loss=186.4898]
Training iteration:  20%|█▉        | 197/1001 [04:09<12:21,  1.08it/s, avg loss=186.4898]Checkpoint at iteration 197 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 186.48984909057617

Training iteration:  20%|█▉        | 197/1001 [04:10<12:21,  1.08it/s, avg loss=195.0494]
Training iteration:  20%|█▉        | 198/1001 [04:10<12:19,  1.09it/s, avg loss=195.0494]Checkpoint at iteration 198 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 195.04939804077148

Training iteration:  20%|█▉        | 198/1001 [04:11<12:19,  1.09it/s, avg loss=164.2164]
Training iteration:  20%|█▉        | 199/1001 [04:11<12:18,  1.09it/s, avg loss=164.2164]Checkpoint at iteration 199 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 164.21642379760743

Training iteration:  20%|█▉        | 199/1001 [04:12<12:18,  1.09it/s, avg loss=164.4215]
Training iteration:  20%|█▉        | 200/1001 [04:12<12:16,  1.09it/s, avg loss=164.4215]Optimization iteration 200 evaluation begins...
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
A new evaluation visualization has been saved: ./saved_data/20240110-063719/it200.png
Training network 0 for evaluation...
Training network 1 for evaluation...
Training network 2 for evaluation...
Training network 3 for evaluation...
Testing network 0 on real datasets for evaluation...
Testing network 1 on real datasets for evaluation...
Testing network 2 on real datasets for evaluation...
Testing network 3 on real datasets for evaluation...
Optimization iteration 200, eval auroc score (train): 20060.3286, eval auroc score (test): 20787.3670
Checkpoint at iteration 200 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 164.4214729309082

Training iteration:  20%|█▉        | 200/1001 [06:07<12:16,  1.09it/s, avg loss=130.2013]
Training iteration:  20%|██        | 201/1001 [06:07<7:48:50, 35.16s/it, avg loss=130.2013]Checkpoint at iteration 201 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 130.20125427246094

Training iteration:  20%|██        | 201/1001 [06:08<7:48:50, 35.16s/it, avg loss=129.8586]
Training iteration:  20%|██        | 202/1001 [06:08<5:32:16, 24.95s/it, avg loss=129.8586]Checkpoint at iteration 202 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 129.85856552124022

Training iteration:  20%|██        | 202/1001 [06:09<5:32:16, 24.95s/it, avg loss=121.6343]
Training iteration:  20%|██        | 203/1001 [06:09<3:56:47, 17.80s/it, avg loss=121.6343]Checkpoint at iteration 203 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 121.63428802490235

Training iteration:  20%|██        | 203/1001 [06:10<3:56:47, 17.80s/it, avg loss=217.4195]
Training iteration:  20%|██        | 204/1001 [06:10<2:50:01, 12.80s/it, avg loss=217.4195]Checkpoint at iteration 204 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 217.41953201293944

Training iteration:  20%|██        | 204/1001 [06:11<2:50:01, 12.80s/it, avg loss=193.1614]
Training iteration:  20%|██        | 205/1001 [06:11<2:03:20,  9.30s/it, avg loss=193.1614]Checkpoint at iteration 205 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 193.16140747070312

Training iteration:  20%|██        | 205/1001 [06:13<2:03:20,  9.30s/it, avg loss=186.2401]
Training iteration:  21%|██        | 206/1001 [06:13<1:30:41,  6.85s/it, avg loss=186.2401]Checkpoint at iteration 206 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 186.2401092529297

Training iteration:  21%|██        | 206/1001 [06:14<1:30:41,  6.85s/it, avg loss=136.0035]
Training iteration:  21%|██        | 207/1001 [06:14<1:07:51,  5.13s/it, avg loss=136.0035]Checkpoint at iteration 207 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 136.00347213745118

Training iteration:  21%|██        | 207/1001 [06:15<1:07:51,  5.13s/it, avg loss=131.3551]
Training iteration:  21%|██        | 208/1001 [06:15<51:53,  3.93s/it, avg loss=131.3551]  Checkpoint at iteration 208 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 131.3550796508789

Training iteration:  21%|██        | 208/1001 [06:16<51:53,  3.93s/it, avg loss=139.8124]
Training iteration:  21%|██        | 209/1001 [06:16<40:43,  3.09s/it, avg loss=139.8124]Checkpoint at iteration 209 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 139.8124206542969

Training iteration:  21%|██        | 209/1001 [06:17<40:43,  3.09s/it, avg loss=199.7996]
Training iteration:  21%|██        | 210/1001 [06:17<32:54,  2.50s/it, avg loss=199.7996]Checkpoint at iteration 210 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 199.79964294433594

Training iteration:  21%|██        | 210/1001 [06:18<32:54,  2.50s/it, avg loss=120.5681]
Training iteration:  21%|██        | 211/1001 [06:18<27:26,  2.08s/it, avg loss=120.5681]Checkpoint at iteration 211 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 120.56808395385742

Training iteration:  21%|██        | 211/1001 [06:19<27:26,  2.08s/it, avg loss=197.0899]
Training iteration:  21%|██        | 212/1001 [06:19<23:37,  1.80s/it, avg loss=197.0899]Checkpoint at iteration 212 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 197.08988723754882

Training iteration:  21%|██        | 212/1001 [06:20<23:37,  1.80s/it, avg loss=108.3533]
Training iteration:  21%|██▏       | 213/1001 [06:20<20:56,  1.59s/it, avg loss=108.3533]Checkpoint at iteration 213 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 108.35331306457519

Training iteration:  21%|██▏       | 213/1001 [06:22<20:56,  1.59s/it, avg loss=186.1746]
Training iteration:  21%|██▏       | 214/1001 [06:22<19:02,  1.45s/it, avg loss=186.1746]Checkpoint at iteration 214 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 186.17461547851562

Training iteration:  21%|██▏       | 214/1001 [06:23<19:02,  1.45s/it, avg loss=177.0743]
Training iteration:  21%|██▏       | 215/1001 [06:23<17:43,  1.35s/it, avg loss=177.0743]Checkpoint at iteration 215 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 177.07427520751952

Training iteration:  21%|██▏       | 215/1001 [06:24<17:43,  1.35s/it, avg loss=161.3263]
Training iteration:  22%|██▏       | 216/1001 [06:24<16:47,  1.28s/it, avg loss=161.3263]Checkpoint at iteration 216 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 161.32633285522462

Training iteration:  22%|██▏       | 216/1001 [06:25<16:47,  1.28s/it, avg loss=146.6644]
Training iteration:  22%|██▏       | 217/1001 [06:25<16:08,  1.24s/it, avg loss=146.6644]Checkpoint at iteration 217 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 146.6644016265869

Training iteration:  22%|██▏       | 217/1001 [06:26<16:08,  1.24s/it, avg loss=217.0310]
Training iteration:  22%|██▏       | 218/1001 [06:26<15:40,  1.20s/it, avg loss=217.0310]Checkpoint at iteration 218 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 217.03102340698243

Training iteration:  22%|██▏       | 218/1001 [06:27<15:40,  1.20s/it, avg loss=161.7720]
Training iteration:  22%|██▏       | 219/1001 [06:27<15:20,  1.18s/it, avg loss=161.7720]Checkpoint at iteration 219 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 161.7719570159912

Training iteration:  22%|██▏       | 219/1001 [06:28<15:20,  1.18s/it, avg loss=163.2516]
Training iteration:  22%|██▏       | 220/1001 [06:28<15:06,  1.16s/it, avg loss=163.2516]Checkpoint at iteration 220 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 163.25157012939454

Training iteration:  22%|██▏       | 220/1001 [06:29<15:06,  1.16s/it, avg loss=157.1199]
Training iteration:  22%|██▏       | 221/1001 [06:29<14:56,  1.15s/it, avg loss=157.1199]Checkpoint at iteration 221 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 157.11988067626953

Training iteration:  22%|██▏       | 221/1001 [06:31<14:56,  1.15s/it, avg loss=229.9764]
Training iteration:  22%|██▏       | 222/1001 [06:31<14:49,  1.14s/it, avg loss=229.9764]Checkpoint at iteration 222 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 229.97641983032227

Training iteration:  22%|██▏       | 222/1001 [06:32<14:49,  1.14s/it, avg loss=135.5760]
Training iteration:  22%|██▏       | 223/1001 [06:32<14:44,  1.14s/it, avg loss=135.5760]Checkpoint at iteration 223 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 135.57596435546876

Training iteration:  22%|██▏       | 223/1001 [06:33<14:44,  1.14s/it, avg loss=130.8343]
Training iteration:  22%|██▏       | 224/1001 [06:33<14:39,  1.13s/it, avg loss=130.8343]Checkpoint at iteration 224 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 130.83429336547852

Training iteration:  22%|██▏       | 224/1001 [06:34<14:39,  1.13s/it, avg loss=147.9652]
Training iteration:  22%|██▏       | 225/1001 [06:34<14:36,  1.13s/it, avg loss=147.9652]Checkpoint at iteration 225 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 147.96521606445313

Training iteration:  22%|██▏       | 225/1001 [06:35<14:36,  1.13s/it, avg loss=157.2753]
Training iteration:  23%|██▎       | 226/1001 [06:35<14:33,  1.13s/it, avg loss=157.2753]Checkpoint at iteration 226 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 157.27526397705077

Training iteration:  23%|██▎       | 226/1001 [06:36<14:33,  1.13s/it, avg loss=183.9351]
Training iteration:  23%|██▎       | 227/1001 [06:36<14:31,  1.13s/it, avg loss=183.9351]Checkpoint at iteration 227 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 183.93508262634276

Training iteration:  23%|██▎       | 227/1001 [06:37<14:31,  1.13s/it, avg loss=203.1967]
Training iteration:  23%|██▎       | 228/1001 [06:37<14:29,  1.13s/it, avg loss=203.1967]Checkpoint at iteration 228 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 203.19667930603026

Training iteration:  23%|██▎       | 228/1001 [06:38<14:29,  1.13s/it, avg loss=271.0924]
Training iteration:  23%|██▎       | 229/1001 [06:38<14:27,  1.12s/it, avg loss=271.0924]Checkpoint at iteration 229 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 271.0923728942871

Training iteration:  23%|██▎       | 229/1001 [06:40<14:27,  1.12s/it, avg loss=254.9823]
Training iteration:  23%|██▎       | 230/1001 [06:40<14:26,  1.12s/it, avg loss=254.9823]Checkpoint at iteration 230 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 254.9823341369629

Training iteration:  23%|██▎       | 230/1001 [06:41<14:26,  1.12s/it, avg loss=211.9145]
Training iteration:  23%|██▎       | 231/1001 [06:41<14:25,  1.12s/it, avg loss=211.9145]Checkpoint at iteration 231 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 211.91449508666992

Training iteration:  23%|██▎       | 231/1001 [06:42<14:25,  1.12s/it, avg loss=184.7769]
Training iteration:  23%|██▎       | 232/1001 [06:42<14:24,  1.12s/it, avg loss=184.7769]Checkpoint at iteration 232 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 184.77687454223633

Training iteration:  23%|██▎       | 232/1001 [06:43<14:24,  1.12s/it, avg loss=209.5635]
Training iteration:  23%|██▎       | 233/1001 [06:43<14:22,  1.12s/it, avg loss=209.5635]Checkpoint at iteration 233 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 209.5634651184082

Training iteration:  23%|██▎       | 233/1001 [06:44<14:22,  1.12s/it, avg loss=129.6377]
Training iteration:  23%|██▎       | 234/1001 [06:44<14:21,  1.12s/it, avg loss=129.6377]Checkpoint at iteration 234 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 129.63769989013673

Training iteration:  23%|██▎       | 234/1001 [06:45<14:21,  1.12s/it, avg loss=129.3801]
Training iteration:  23%|██▎       | 235/1001 [06:45<14:19,  1.12s/it, avg loss=129.3801]Checkpoint at iteration 235 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 129.38010787963867

Training iteration:  23%|██▎       | 235/1001 [06:46<14:19,  1.12s/it, avg loss=156.6700]
Training iteration:  24%|██▎       | 236/1001 [06:46<14:18,  1.12s/it, avg loss=156.6700]Checkpoint at iteration 236 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 156.67000885009764

Training iteration:  24%|██▎       | 236/1001 [06:47<14:18,  1.12s/it, avg loss=119.9723]
Training iteration:  24%|██▎       | 237/1001 [06:47<14:17,  1.12s/it, avg loss=119.9723]Checkpoint at iteration 237 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 119.97231025695801

Training iteration:  24%|██▎       | 237/1001 [06:49<14:17,  1.12s/it, avg loss=128.2994]
Training iteration:  24%|██▍       | 238/1001 [06:49<14:16,  1.12s/it, avg loss=128.2994]Checkpoint at iteration 238 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 128.29944763183593

Training iteration:  24%|██▍       | 238/1001 [06:50<14:16,  1.12s/it, avg loss=169.6777]
Training iteration:  24%|██▍       | 239/1001 [06:50<14:16,  1.12s/it, avg loss=169.6777]Checkpoint at iteration 239 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 169.67772102355957

Training iteration:  24%|██▍       | 239/1001 [06:51<14:16,  1.12s/it, avg loss=221.2529]
Training iteration:  24%|██▍       | 240/1001 [06:51<14:14,  1.12s/it, avg loss=221.2529]Checkpoint at iteration 240 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 221.25290222167968

Training iteration:  24%|██▍       | 240/1001 [06:52<14:14,  1.12s/it, avg loss=108.8030]
Training iteration:  24%|██▍       | 241/1001 [06:52<14:13,  1.12s/it, avg loss=108.8030]Checkpoint at iteration 241 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 108.80304718017578

Training iteration:  24%|██▍       | 241/1001 [06:53<14:13,  1.12s/it, avg loss=202.4850]
Training iteration:  24%|██▍       | 242/1001 [06:53<14:12,  1.12s/it, avg loss=202.4850]Checkpoint at iteration 242 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 202.48495788574218

Training iteration:  24%|██▍       | 242/1001 [06:54<14:12,  1.12s/it, avg loss=132.3283]
Training iteration:  24%|██▍       | 243/1001 [06:54<14:11,  1.12s/it, avg loss=132.3283]Checkpoint at iteration 243 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 132.32827796936036

Training iteration:  24%|██▍       | 243/1001 [06:55<14:11,  1.12s/it, avg loss=230.7186]
Training iteration:  24%|██▍       | 244/1001 [06:55<14:10,  1.12s/it, avg loss=230.7186]Checkpoint at iteration 244 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 230.71863174438477

Training iteration:  24%|██▍       | 244/1001 [06:56<14:10,  1.12s/it, avg loss=212.5549]
Training iteration:  24%|██▍       | 245/1001 [06:56<14:09,  1.12s/it, avg loss=212.5549]Checkpoint at iteration 245 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 212.5549186706543

Training iteration:  24%|██▍       | 245/1001 [06:57<14:09,  1.12s/it, avg loss=165.5273]
Training iteration:  25%|██▍       | 246/1001 [06:57<14:08,  1.12s/it, avg loss=165.5273]Checkpoint at iteration 246 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 165.5273124694824

Training iteration:  25%|██▍       | 246/1001 [06:59<14:08,  1.12s/it, avg loss=171.2650]
Training iteration:  25%|██▍       | 247/1001 [06:59<14:07,  1.12s/it, avg loss=171.2650]Checkpoint at iteration 247 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 171.26495361328125

Training iteration:  25%|██▍       | 247/1001 [07:00<14:07,  1.12s/it, avg loss=190.2028]
Training iteration:  25%|██▍       | 248/1001 [07:00<14:06,  1.12s/it, avg loss=190.2028]Checkpoint at iteration 248 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 190.2027717590332

Training iteration:  25%|██▍       | 248/1001 [07:01<14:06,  1.12s/it, avg loss=180.3714]
Training iteration:  25%|██▍       | 249/1001 [07:01<14:04,  1.12s/it, avg loss=180.3714]Checkpoint at iteration 249 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 180.3714141845703

Training iteration:  25%|██▍       | 249/1001 [07:02<14:04,  1.12s/it, avg loss=144.1740]
Training iteration:  25%|██▍       | 250/1001 [07:02<14:03,  1.12s/it, avg loss=144.1740]Checkpoint at iteration 250 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 144.17403717041014

Training iteration:  25%|██▍       | 250/1001 [07:03<14:03,  1.12s/it, avg loss=173.8103]
Training iteration:  25%|██▌       | 251/1001 [07:03<14:02,  1.12s/it, avg loss=173.8103]Checkpoint at iteration 251 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 173.81025085449218

Training iteration:  25%|██▌       | 251/1001 [07:04<14:02,  1.12s/it, avg loss=181.6417]
Training iteration:  25%|██▌       | 252/1001 [07:04<14:01,  1.12s/it, avg loss=181.6417]Checkpoint at iteration 252 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 181.64170837402344

Training iteration:  25%|██▌       | 252/1001 [07:05<14:01,  1.12s/it, avg loss=99.3803] 
Training iteration:  25%|██▌       | 253/1001 [07:05<14:00,  1.12s/it, avg loss=99.3803]Checkpoint at iteration 253 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 99.38028259277344

Training iteration:  25%|██▌       | 253/1001 [07:06<14:00,  1.12s/it, avg loss=210.1472]
Training iteration:  25%|██▌       | 254/1001 [07:06<13:59,  1.12s/it, avg loss=210.1472]Checkpoint at iteration 254 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 210.1471694946289

Training iteration:  25%|██▌       | 254/1001 [07:08<13:59,  1.12s/it, avg loss=201.1025]
Training iteration:  25%|██▌       | 255/1001 [07:08<13:57,  1.12s/it, avg loss=201.1025]Checkpoint at iteration 255 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 201.10247268676758

Training iteration:  25%|██▌       | 255/1001 [07:09<13:57,  1.12s/it, avg loss=186.1172]
Training iteration:  26%|██▌       | 256/1001 [07:09<13:56,  1.12s/it, avg loss=186.1172]Checkpoint at iteration 256 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 186.1171604156494

Training iteration:  26%|██▌       | 256/1001 [07:10<13:56,  1.12s/it, avg loss=203.7310]
Training iteration:  26%|██▌       | 257/1001 [07:10<13:55,  1.12s/it, avg loss=203.7310]Checkpoint at iteration 257 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 203.73101577758788

Training iteration:  26%|██▌       | 257/1001 [07:11<13:55,  1.12s/it, avg loss=155.9880]
Training iteration:  26%|██▌       | 258/1001 [07:11<13:54,  1.12s/it, avg loss=155.9880]Checkpoint at iteration 258 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 155.98797798156738

Training iteration:  26%|██▌       | 258/1001 [07:12<13:54,  1.12s/it, avg loss=88.1436] New best at iteratoin 258!

Training iteration:  26%|██▌       | 259/1001 [07:12<13:52,  1.12s/it, avg loss=88.1436]Checkpoint at iteration 259 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 88.14355354309082

Training iteration:  26%|██▌       | 259/1001 [07:13<13:52,  1.12s/it, avg loss=133.5712]
Training iteration:  26%|██▌       | 260/1001 [07:13<13:51,  1.12s/it, avg loss=133.5712]Checkpoint at iteration 260 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 133.57119445800782

Training iteration:  26%|██▌       | 260/1001 [07:14<13:51,  1.12s/it, avg loss=118.1269]
Training iteration:  26%|██▌       | 261/1001 [07:14<13:50,  1.12s/it, avg loss=118.1269]Checkpoint at iteration 261 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 118.12689743041992

Training iteration:  26%|██▌       | 261/1001 [07:15<13:50,  1.12s/it, avg loss=238.4359]
Training iteration:  26%|██▌       | 262/1001 [07:15<13:49,  1.12s/it, avg loss=238.4359]Checkpoint at iteration 262 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 238.43592834472656

Training iteration:  26%|██▌       | 262/1001 [07:17<13:49,  1.12s/it, avg loss=248.5239]
Training iteration:  26%|██▋       | 263/1001 [07:17<13:48,  1.12s/it, avg loss=248.5239]Checkpoint at iteration 263 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 248.52392044067383

Training iteration:  26%|██▋       | 263/1001 [07:18<13:48,  1.12s/it, avg loss=109.2412]
Training iteration:  26%|██▋       | 264/1001 [07:18<13:47,  1.12s/it, avg loss=109.2412]Checkpoint at iteration 264 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 109.2412010192871

Training iteration:  26%|██▋       | 264/1001 [07:19<13:47,  1.12s/it, avg loss=159.7639]
Training iteration:  26%|██▋       | 265/1001 [07:19<13:46,  1.12s/it, avg loss=159.7639]Checkpoint at iteration 265 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 159.76392974853516

Training iteration:  26%|██▋       | 265/1001 [07:20<13:46,  1.12s/it, avg loss=168.2480]
Training iteration:  27%|██▋       | 266/1001 [07:20<13:45,  1.12s/it, avg loss=168.2480]Checkpoint at iteration 266 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 168.2480239868164

Training iteration:  27%|██▋       | 266/1001 [07:21<13:45,  1.12s/it, avg loss=178.4772]
Training iteration:  27%|██▋       | 267/1001 [07:21<13:44,  1.12s/it, avg loss=178.4772]Checkpoint at iteration 267 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 178.47719116210936

Training iteration:  27%|██▋       | 267/1001 [07:22<13:44,  1.12s/it, avg loss=245.8570]
Training iteration:  27%|██▋       | 268/1001 [07:22<13:42,  1.12s/it, avg loss=245.8570]Checkpoint at iteration 268 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 245.85702362060547

Training iteration:  27%|██▋       | 268/1001 [07:23<13:42,  1.12s/it, avg loss=243.9953]
Training iteration:  27%|██▋       | 269/1001 [07:23<13:41,  1.12s/it, avg loss=243.9953]Checkpoint at iteration 269 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 243.9953140258789

Training iteration:  27%|██▋       | 269/1001 [07:24<13:41,  1.12s/it, avg loss=203.8801]
Training iteration:  27%|██▋       | 270/1001 [07:24<13:40,  1.12s/it, avg loss=203.8801]Checkpoint at iteration 270 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 203.88006134033202

Training iteration:  27%|██▋       | 270/1001 [07:26<13:40,  1.12s/it, avg loss=144.7439]
Training iteration:  27%|██▋       | 271/1001 [07:26<13:39,  1.12s/it, avg loss=144.7439]Checkpoint at iteration 271 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 144.7438648223877

Training iteration:  27%|██▋       | 271/1001 [07:27<13:39,  1.12s/it, avg loss=217.6933]
Training iteration:  27%|██▋       | 272/1001 [07:27<13:38,  1.12s/it, avg loss=217.6933]Checkpoint at iteration 272 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 217.6933250427246

Training iteration:  27%|██▋       | 272/1001 [07:28<13:38,  1.12s/it, avg loss=144.9111]
Training iteration:  27%|██▋       | 273/1001 [07:28<13:37,  1.12s/it, avg loss=144.9111]Checkpoint at iteration 273 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 144.91106872558595

Training iteration:  27%|██▋       | 273/1001 [07:29<13:37,  1.12s/it, avg loss=135.7494]
Training iteration:  27%|██▋       | 274/1001 [07:29<13:35,  1.12s/it, avg loss=135.7494]Checkpoint at iteration 274 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 135.74935302734374

Training iteration:  27%|██▋       | 274/1001 [07:30<13:35,  1.12s/it, avg loss=101.5473]
Training iteration:  27%|██▋       | 275/1001 [07:30<13:35,  1.12s/it, avg loss=101.5473]Checkpoint at iteration 275 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 101.54728393554687

Training iteration:  27%|██▋       | 275/1001 [07:31<13:35,  1.12s/it, avg loss=150.8366]
Training iteration:  28%|██▊       | 276/1001 [07:31<13:33,  1.12s/it, avg loss=150.8366]Checkpoint at iteration 276 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 150.8366226196289

Training iteration:  28%|██▊       | 276/1001 [07:32<13:33,  1.12s/it, avg loss=127.3193]
Training iteration:  28%|██▊       | 277/1001 [07:32<13:32,  1.12s/it, avg loss=127.3193]Checkpoint at iteration 277 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 127.31934967041016

Training iteration:  28%|██▊       | 277/1001 [07:33<13:32,  1.12s/it, avg loss=205.7458]
Training iteration:  28%|██▊       | 278/1001 [07:33<13:32,  1.12s/it, avg loss=205.7458]Checkpoint at iteration 278 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 205.74579544067382

Training iteration:  28%|██▊       | 278/1001 [07:35<13:32,  1.12s/it, avg loss=113.4840]
Training iteration:  28%|██▊       | 279/1001 [07:35<13:30,  1.12s/it, avg loss=113.4840]Checkpoint at iteration 279 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 113.48397216796874

Training iteration:  28%|██▊       | 279/1001 [07:36<13:30,  1.12s/it, avg loss=174.9593]
Training iteration:  28%|██▊       | 280/1001 [07:36<13:29,  1.12s/it, avg loss=174.9593]Checkpoint at iteration 280 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 174.95927047729492

Training iteration:  28%|██▊       | 280/1001 [07:37<13:29,  1.12s/it, avg loss=116.6282]
Training iteration:  28%|██▊       | 281/1001 [07:37<13:28,  1.12s/it, avg loss=116.6282]Checkpoint at iteration 281 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 116.62824096679688

Training iteration:  28%|██▊       | 281/1001 [07:38<13:28,  1.12s/it, avg loss=149.4477]
Training iteration:  28%|██▊       | 282/1001 [07:38<13:27,  1.12s/it, avg loss=149.4477]Checkpoint at iteration 282 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 149.44774780273437

Training iteration:  28%|██▊       | 282/1001 [07:39<13:27,  1.12s/it, avg loss=167.4127]
Training iteration:  28%|██▊       | 283/1001 [07:39<13:27,  1.12s/it, avg loss=167.4127]Checkpoint at iteration 283 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 167.4127082824707

Training iteration:  28%|██▊       | 283/1001 [07:40<13:27,  1.12s/it, avg loss=116.8078]
Training iteration:  28%|██▊       | 284/1001 [07:40<13:27,  1.13s/it, avg loss=116.8078]Checkpoint at iteration 284 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 116.80779151916504

Training iteration:  28%|██▊       | 284/1001 [07:41<13:27,  1.13s/it, avg loss=100.1346]
Training iteration:  28%|██▊       | 285/1001 [07:41<13:26,  1.13s/it, avg loss=100.1346]Checkpoint at iteration 285 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 100.13455505371094

Training iteration:  28%|██▊       | 285/1001 [07:42<13:26,  1.13s/it, avg loss=167.7664]
Training iteration:  29%|██▊       | 286/1001 [07:42<13:24,  1.12s/it, avg loss=167.7664]Checkpoint at iteration 286 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 167.7663589477539

Training iteration:  29%|██▊       | 286/1001 [07:44<13:24,  1.12s/it, avg loss=249.1519]
Training iteration:  29%|██▊       | 287/1001 [07:44<13:22,  1.12s/it, avg loss=249.1519]Checkpoint at iteration 287 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 249.1518783569336

Training iteration:  29%|██▊       | 287/1001 [07:45<13:22,  1.12s/it, avg loss=143.9969]
Training iteration:  29%|██▉       | 288/1001 [07:45<13:21,  1.12s/it, avg loss=143.9969]Checkpoint at iteration 288 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 143.99694175720214

Training iteration:  29%|██▉       | 288/1001 [07:46<13:21,  1.12s/it, avg loss=137.4878]
Training iteration:  29%|██▉       | 289/1001 [07:46<13:20,  1.12s/it, avg loss=137.4878]Checkpoint at iteration 289 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 137.48782539367676

Training iteration:  29%|██▉       | 289/1001 [07:47<13:20,  1.12s/it, avg loss=262.3858]
Training iteration:  29%|██▉       | 290/1001 [07:47<13:19,  1.12s/it, avg loss=262.3858]Checkpoint at iteration 290 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 262.3857551574707

Training iteration:  29%|██▉       | 290/1001 [07:48<13:19,  1.12s/it, avg loss=224.2858]
Training iteration:  29%|██▉       | 291/1001 [07:48<13:18,  1.12s/it, avg loss=224.2858]Checkpoint at iteration 291 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 224.28584365844728

Training iteration:  29%|██▉       | 291/1001 [07:49<13:18,  1.12s/it, avg loss=107.4103]
Training iteration:  29%|██▉       | 292/1001 [07:49<13:17,  1.13s/it, avg loss=107.4103]Checkpoint at iteration 292 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 107.41032676696777

Training iteration:  29%|██▉       | 292/1001 [07:50<13:17,  1.13s/it, avg loss=137.2015]
Training iteration:  29%|██▉       | 293/1001 [07:50<13:16,  1.13s/it, avg loss=137.2015]Checkpoint at iteration 293 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 137.2015068054199

Training iteration:  29%|██▉       | 293/1001 [07:51<13:16,  1.13s/it, avg loss=191.3314]
Training iteration:  29%|██▉       | 294/1001 [07:51<13:15,  1.13s/it, avg loss=191.3314]Checkpoint at iteration 294 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 191.33137741088868

Training iteration:  29%|██▉       | 294/1001 [07:53<13:15,  1.13s/it, avg loss=132.5307]
Training iteration:  29%|██▉       | 295/1001 [07:53<13:14,  1.12s/it, avg loss=132.5307]Checkpoint at iteration 295 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 132.53067932128906

Training iteration:  29%|██▉       | 295/1001 [07:54<13:14,  1.12s/it, avg loss=232.8985]
Training iteration:  30%|██▉       | 296/1001 [07:54<13:12,  1.12s/it, avg loss=232.8985]Checkpoint at iteration 296 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 232.89845352172853

Training iteration:  30%|██▉       | 296/1001 [07:55<13:12,  1.12s/it, avg loss=171.1460]
Training iteration:  30%|██▉       | 297/1001 [07:55<13:11,  1.12s/it, avg loss=171.1460]Checkpoint at iteration 297 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 171.1459705352783

Training iteration:  30%|██▉       | 297/1001 [07:56<13:11,  1.12s/it, avg loss=187.2414]
Training iteration:  30%|██▉       | 298/1001 [07:56<13:10,  1.12s/it, avg loss=187.2414]Checkpoint at iteration 298 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 187.2414176940918

Training iteration:  30%|██▉       | 298/1001 [07:57<13:10,  1.12s/it, avg loss=132.5994]
Training iteration:  30%|██▉       | 299/1001 [07:57<13:09,  1.12s/it, avg loss=132.5994]Checkpoint at iteration 299 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 132.5994445800781

Training iteration:  30%|██▉       | 299/1001 [07:58<13:09,  1.12s/it, avg loss=210.4280]
Training iteration:  30%|██▉       | 300/1001 [07:58<13:08,  1.12s/it, avg loss=210.4280]Optimization iteration 300 evaluation begins...
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
A new evaluation visualization has been saved: ./saved_data/20240110-063719/it300.png
Training network 0 for evaluation...
Training network 1 for evaluation...
Training network 2 for evaluation...
Training network 3 for evaluation...
Testing network 0 on real datasets for evaluation...
Testing network 1 on real datasets for evaluation...
Testing network 2 on real datasets for evaluation...
Testing network 3 on real datasets for evaluation...
Optimization iteration 300, eval auroc score (train): 20283.3007, eval auroc score (test): 21021.4895
Checkpoint at iteration 300 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 210.42802886962892

Training iteration:  30%|██▉       | 300/1001 [11:07<13:08,  1.12s/it, avg loss=181.4713]
Training iteration:  30%|███       | 301/1001 [11:07<11:10:40, 57.49s/it, avg loss=181.4713]Checkpoint at iteration 301 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 181.47133102416993

Training iteration:  30%|███       | 301/1001 [11:09<11:10:40, 57.49s/it, avg loss=232.4061]
Training iteration:  30%|███       | 302/1001 [11:09<7:53:27, 40.64s/it, avg loss=232.4061] Checkpoint at iteration 302 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 232.40610046386718

Training iteration:  30%|███       | 302/1001 [11:10<7:53:27, 40.64s/it, avg loss=160.8412]
Training iteration:  30%|███       | 303/1001 [11:10<5:35:37, 28.85s/it, avg loss=160.8412]Checkpoint at iteration 303 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 160.84122848510742

Training iteration:  30%|███       | 303/1001 [11:11<5:35:37, 28.85s/it, avg loss=211.1016]
Training iteration:  30%|███       | 304/1001 [11:11<3:59:13, 20.59s/it, avg loss=211.1016]Checkpoint at iteration 304 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 211.10161361694335

Training iteration:  30%|███       | 304/1001 [11:13<3:59:13, 20.59s/it, avg loss=193.3342]
Training iteration:  30%|███       | 305/1001 [11:13<2:51:52, 14.82s/it, avg loss=193.3342]Checkpoint at iteration 305 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 193.33419609069824

Training iteration:  30%|███       | 305/1001 [11:14<2:51:52, 14.82s/it, avg loss=165.1757]
Training iteration:  31%|███       | 306/1001 [11:14<2:04:46, 10.77s/it, avg loss=165.1757]Checkpoint at iteration 306 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 165.17567405700683

Training iteration:  31%|███       | 306/1001 [11:15<2:04:46, 10.77s/it, avg loss=161.1671]
Training iteration:  31%|███       | 307/1001 [11:15<1:31:51,  7.94s/it, avg loss=161.1671]Checkpoint at iteration 307 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 161.1670829772949

Training iteration:  31%|███       | 307/1001 [11:17<1:31:51,  7.94s/it, avg loss=138.8860]
Training iteration:  31%|███       | 308/1001 [11:17<1:08:49,  5.96s/it, avg loss=138.8860]Checkpoint at iteration 308 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 138.88600158691406

Training iteration:  31%|███       | 308/1001 [11:18<1:08:49,  5.96s/it, avg loss=209.7770]
Training iteration:  31%|███       | 309/1001 [11:18<52:43,  4.57s/it, avg loss=209.7770]  Checkpoint at iteration 309 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 209.7770263671875

Training iteration:  31%|███       | 309/1001 [11:19<52:43,  4.57s/it, avg loss=178.8684]
Training iteration:  31%|███       | 310/1001 [11:19<41:29,  3.60s/it, avg loss=178.8684]Checkpoint at iteration 310 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 178.86840209960937

Training iteration:  31%|███       | 310/1001 [11:21<41:29,  3.60s/it, avg loss=173.0757]
Training iteration:  31%|███       | 311/1001 [11:21<33:36,  2.92s/it, avg loss=173.0757]Checkpoint at iteration 311 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 173.0757278442383

Training iteration:  31%|███       | 311/1001 [11:22<33:36,  2.92s/it, avg loss=167.2552]
Training iteration:  31%|███       | 312/1001 [11:22<28:06,  2.45s/it, avg loss=167.2552]Checkpoint at iteration 312 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 167.25518493652345

Training iteration:  31%|███       | 312/1001 [11:23<28:06,  2.45s/it, avg loss=126.3843]
Training iteration:  31%|███▏      | 313/1001 [11:23<24:14,  2.11s/it, avg loss=126.3843]Checkpoint at iteration 313 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 126.38433990478515

Training iteration:  31%|███▏      | 313/1001 [11:25<24:14,  2.11s/it, avg loss=152.0748]
Training iteration:  31%|███▏      | 314/1001 [11:25<21:32,  1.88s/it, avg loss=152.0748]Checkpoint at iteration 314 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 152.07483291625977

Training iteration:  31%|███▏      | 314/1001 [11:26<21:32,  1.88s/it, avg loss=212.9655]
Training iteration:  31%|███▏      | 315/1001 [11:26<19:38,  1.72s/it, avg loss=212.9655]Checkpoint at iteration 315 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 212.96551971435548

Training iteration:  31%|███▏      | 315/1001 [11:27<19:38,  1.72s/it, avg loss=146.7953]
Training iteration:  32%|███▏      | 316/1001 [11:27<18:17,  1.60s/it, avg loss=146.7953]Checkpoint at iteration 316 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 146.79528427124023

Training iteration:  32%|███▏      | 316/1001 [11:29<18:17,  1.60s/it, avg loss=168.1331]
Training iteration:  32%|███▏      | 317/1001 [11:29<17:21,  1.52s/it, avg loss=168.1331]Checkpoint at iteration 317 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 168.13312835693358

Training iteration:  32%|███▏      | 317/1001 [11:30<17:21,  1.52s/it, avg loss=138.5902]
Training iteration:  32%|███▏      | 318/1001 [11:30<16:41,  1.47s/it, avg loss=138.5902]Checkpoint at iteration 318 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 138.59021797180176

Training iteration:  32%|███▏      | 318/1001 [11:31<16:41,  1.47s/it, avg loss=177.2203]
Training iteration:  32%|███▏      | 319/1001 [11:31<16:14,  1.43s/it, avg loss=177.2203]Checkpoint at iteration 319 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 177.22027740478515

Training iteration:  32%|███▏      | 319/1001 [11:33<16:14,  1.43s/it, avg loss=104.1385]
Training iteration:  32%|███▏      | 320/1001 [11:33<15:53,  1.40s/it, avg loss=104.1385]Checkpoint at iteration 320 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 104.13850479125976

Training iteration:  32%|███▏      | 320/1001 [11:34<15:53,  1.40s/it, avg loss=105.3135]
Training iteration:  32%|███▏      | 321/1001 [11:34<15:39,  1.38s/it, avg loss=105.3135]Checkpoint at iteration 321 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 105.31352462768555

Training iteration:  32%|███▏      | 321/1001 [11:35<15:39,  1.38s/it, avg loss=116.6570]
Training iteration:  32%|███▏      | 322/1001 [11:35<15:28,  1.37s/it, avg loss=116.6570]Checkpoint at iteration 322 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 116.65695114135742

Training iteration:  32%|███▏      | 322/1001 [11:37<15:28,  1.37s/it, avg loss=168.7852]
Training iteration:  32%|███▏      | 323/1001 [11:37<15:21,  1.36s/it, avg loss=168.7852]Checkpoint at iteration 323 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 168.78521728515625

Training iteration:  32%|███▏      | 323/1001 [11:38<15:21,  1.36s/it, avg loss=169.6645]
Training iteration:  32%|███▏      | 324/1001 [11:38<15:15,  1.35s/it, avg loss=169.6645]Checkpoint at iteration 324 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 169.66452178955078

Training iteration:  32%|███▏      | 324/1001 [11:39<15:15,  1.35s/it, avg loss=212.4516]
Training iteration:  32%|███▏      | 325/1001 [11:39<15:10,  1.35s/it, avg loss=212.4516]Checkpoint at iteration 325 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 212.45164794921874

Training iteration:  32%|███▏      | 325/1001 [11:41<15:10,  1.35s/it, avg loss=191.6215]
Training iteration:  33%|███▎      | 326/1001 [11:41<15:06,  1.34s/it, avg loss=191.6215]Checkpoint at iteration 326 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 191.62148056030273

Training iteration:  33%|███▎      | 326/1001 [11:42<15:06,  1.34s/it, avg loss=211.5917]
Training iteration:  33%|███▎      | 327/1001 [11:42<15:03,  1.34s/it, avg loss=211.5917]Checkpoint at iteration 327 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 211.59168243408203

Training iteration:  33%|███▎      | 327/1001 [11:43<15:03,  1.34s/it, avg loss=153.7600]
Training iteration:  33%|███▎      | 328/1001 [11:43<14:59,  1.34s/it, avg loss=153.7600]Checkpoint at iteration 328 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 153.75997009277344

Training iteration:  33%|███▎      | 328/1001 [11:45<14:59,  1.34s/it, avg loss=161.7498]
Training iteration:  33%|███▎      | 329/1001 [11:45<14:57,  1.34s/it, avg loss=161.7498]Checkpoint at iteration 329 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 161.7497673034668

Training iteration:  33%|███▎      | 329/1001 [11:46<14:57,  1.34s/it, avg loss=182.4174]
Training iteration:  33%|███▎      | 330/1001 [11:46<14:55,  1.33s/it, avg loss=182.4174]Checkpoint at iteration 330 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 182.4173557281494

Training iteration:  33%|███▎      | 330/1001 [11:47<14:55,  1.33s/it, avg loss=169.6426]
Training iteration:  33%|███▎      | 331/1001 [11:47<14:53,  1.33s/it, avg loss=169.6426]Checkpoint at iteration 331 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 169.642578125

Training iteration:  33%|███▎      | 331/1001 [11:49<14:53,  1.33s/it, avg loss=223.7149]
Training iteration:  33%|███▎      | 332/1001 [11:49<14:52,  1.33s/it, avg loss=223.7149]Checkpoint at iteration 332 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 223.71493530273438

Training iteration:  33%|███▎      | 332/1001 [11:50<14:52,  1.33s/it, avg loss=215.3933]
Training iteration:  33%|███▎      | 333/1001 [11:50<14:51,  1.33s/it, avg loss=215.3933]Checkpoint at iteration 333 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 215.39331283569337

Training iteration:  33%|███▎      | 333/1001 [11:51<14:51,  1.33s/it, avg loss=127.0891]
Training iteration:  33%|███▎      | 334/1001 [11:51<14:49,  1.33s/it, avg loss=127.0891]Checkpoint at iteration 334 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 127.0890869140625

Training iteration:  33%|███▎      | 334/1001 [11:53<14:49,  1.33s/it, avg loss=113.1771]
Training iteration:  33%|███▎      | 335/1001 [11:53<14:48,  1.33s/it, avg loss=113.1771]Checkpoint at iteration 335 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 113.17708778381348

Training iteration:  33%|███▎      | 335/1001 [11:54<14:48,  1.33s/it, avg loss=212.4691]
Training iteration:  34%|███▎      | 336/1001 [11:54<14:47,  1.33s/it, avg loss=212.4691]Checkpoint at iteration 336 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 212.46906509399415

Training iteration:  34%|███▎      | 336/1001 [11:55<14:47,  1.33s/it, avg loss=192.5658]
Training iteration:  34%|███▎      | 337/1001 [11:55<14:45,  1.33s/it, avg loss=192.5658]Checkpoint at iteration 337 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 192.5658203125

Training iteration:  34%|███▎      | 337/1001 [11:57<14:45,  1.33s/it, avg loss=200.3368]
Training iteration:  34%|███▍      | 338/1001 [11:57<14:44,  1.33s/it, avg loss=200.3368]Checkpoint at iteration 338 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 200.33683242797852

Training iteration:  34%|███▍      | 338/1001 [11:58<14:44,  1.33s/it, avg loss=150.9335]
Training iteration:  34%|███▍      | 339/1001 [11:58<14:42,  1.33s/it, avg loss=150.9335]Checkpoint at iteration 339 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 150.93350830078126

Training iteration:  34%|███▍      | 339/1001 [11:59<14:42,  1.33s/it, avg loss=160.3827]
Training iteration:  34%|███▍      | 340/1001 [11:59<14:41,  1.33s/it, avg loss=160.3827]Checkpoint at iteration 340 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 160.3826759338379

Training iteration:  34%|███▍      | 340/1001 [12:01<14:41,  1.33s/it, avg loss=197.5908]
Training iteration:  34%|███▍      | 341/1001 [12:01<14:40,  1.33s/it, avg loss=197.5908]Checkpoint at iteration 341 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 197.5908458709717

Training iteration:  34%|███▍      | 341/1001 [12:02<14:40,  1.33s/it, avg loss=173.1034]
Training iteration:  34%|███▍      | 342/1001 [12:02<14:39,  1.33s/it, avg loss=173.1034]Checkpoint at iteration 342 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 173.10337829589844

Training iteration:  34%|███▍      | 342/1001 [12:03<14:39,  1.33s/it, avg loss=207.5537]
Training iteration:  34%|███▍      | 343/1001 [12:03<14:37,  1.33s/it, avg loss=207.5537]Checkpoint at iteration 343 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 207.5537467956543

Training iteration:  34%|███▍      | 343/1001 [12:05<14:37,  1.33s/it, avg loss=197.7715]
Training iteration:  34%|███▍      | 344/1001 [12:05<14:36,  1.33s/it, avg loss=197.7715]Checkpoint at iteration 344 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 197.77154541015625

Training iteration:  34%|███▍      | 344/1001 [12:06<14:36,  1.33s/it, avg loss=157.4738]
Training iteration:  34%|███▍      | 345/1001 [12:06<14:34,  1.33s/it, avg loss=157.4738]Checkpoint at iteration 345 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 157.47383079528808

Training iteration:  34%|███▍      | 345/1001 [12:07<14:34,  1.33s/it, avg loss=220.5044]
Training iteration:  35%|███▍      | 346/1001 [12:07<14:33,  1.33s/it, avg loss=220.5044]Checkpoint at iteration 346 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 220.5043716430664

Training iteration:  35%|███▍      | 346/1001 [12:09<14:33,  1.33s/it, avg loss=111.0162]
Training iteration:  35%|███▍      | 347/1001 [12:09<14:32,  1.33s/it, avg loss=111.0162]Checkpoint at iteration 347 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 111.01617050170898

Training iteration:  35%|███▍      | 347/1001 [12:10<14:32,  1.33s/it, avg loss=202.1202]
Training iteration:  35%|███▍      | 348/1001 [12:10<14:30,  1.33s/it, avg loss=202.1202]Checkpoint at iteration 348 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 202.12023544311523

Training iteration:  35%|███▍      | 348/1001 [12:11<14:30,  1.33s/it, avg loss=132.4230]
Training iteration:  35%|███▍      | 349/1001 [12:11<14:29,  1.33s/it, avg loss=132.4230]Checkpoint at iteration 349 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 132.4229949951172

Training iteration:  35%|███▍      | 349/1001 [12:13<14:29,  1.33s/it, avg loss=89.0503] 
Training iteration:  35%|███▍      | 350/1001 [12:13<14:28,  1.33s/it, avg loss=89.0503]Checkpoint at iteration 350 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 89.05030479431153

Training iteration:  35%|███▍      | 350/1001 [12:14<14:28,  1.33s/it, avg loss=101.1844]
Training iteration:  35%|███▌      | 351/1001 [12:14<14:27,  1.33s/it, avg loss=101.1844]Checkpoint at iteration 351 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 101.18435707092286

Training iteration:  35%|███▌      | 351/1001 [12:15<14:27,  1.33s/it, avg loss=91.1543] 
Training iteration:  35%|███▌      | 352/1001 [12:15<14:26,  1.33s/it, avg loss=91.1543]Checkpoint at iteration 352 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 91.15432586669922

Training iteration:  35%|███▌      | 352/1001 [12:17<14:26,  1.33s/it, avg loss=93.4044]
Training iteration:  35%|███▌      | 353/1001 [12:17<14:25,  1.33s/it, avg loss=93.4044]Checkpoint at iteration 353 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 93.40443229675293

Training iteration:  35%|███▌      | 353/1001 [12:18<14:25,  1.33s/it, avg loss=197.5977]
Training iteration:  35%|███▌      | 354/1001 [12:18<14:23,  1.33s/it, avg loss=197.5977]Checkpoint at iteration 354 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 197.59769592285156

Training iteration:  35%|███▌      | 354/1001 [12:19<14:23,  1.33s/it, avg loss=171.2720]
Training iteration:  35%|███▌      | 355/1001 [12:19<14:22,  1.33s/it, avg loss=171.2720]Checkpoint at iteration 355 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 171.27200622558593

Training iteration:  35%|███▌      | 355/1001 [12:21<14:22,  1.33s/it, avg loss=179.8218]
Training iteration:  36%|███▌      | 356/1001 [12:21<14:20,  1.33s/it, avg loss=179.8218]Checkpoint at iteration 356 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 179.8217514038086

Training iteration:  36%|███▌      | 356/1001 [12:22<14:20,  1.33s/it, avg loss=120.6093]
Training iteration:  36%|███▌      | 357/1001 [12:22<14:19,  1.33s/it, avg loss=120.6093]Checkpoint at iteration 357 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 120.60927352905273

Training iteration:  36%|███▌      | 357/1001 [12:23<14:19,  1.33s/it, avg loss=151.0892]
Training iteration:  36%|███▌      | 358/1001 [12:23<14:18,  1.34s/it, avg loss=151.0892]Checkpoint at iteration 358 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 151.08923683166503

Training iteration:  36%|███▌      | 358/1001 [12:25<14:18,  1.34s/it, avg loss=217.5493]
Training iteration:  36%|███▌      | 359/1001 [12:25<14:17,  1.34s/it, avg loss=217.5493]Checkpoint at iteration 359 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 217.54931716918946

Training iteration:  36%|███▌      | 359/1001 [12:26<14:17,  1.34s/it, avg loss=189.3698]
Training iteration:  36%|███▌      | 360/1001 [12:26<14:15,  1.33s/it, avg loss=189.3698]Checkpoint at iteration 360 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 189.3697536468506

Training iteration:  36%|███▌      | 360/1001 [12:27<14:15,  1.33s/it, avg loss=112.2847]
Training iteration:  36%|███▌      | 361/1001 [12:27<14:14,  1.33s/it, avg loss=112.2847]Checkpoint at iteration 361 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 112.28473777770996

Training iteration:  36%|███▌      | 361/1001 [12:29<14:14,  1.33s/it, avg loss=153.9318]
Training iteration:  36%|███▌      | 362/1001 [12:29<14:12,  1.33s/it, avg loss=153.9318]Checkpoint at iteration 362 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 153.93177871704103

Training iteration:  36%|███▌      | 362/1001 [12:30<14:12,  1.33s/it, avg loss=172.5467]
Training iteration:  36%|███▋      | 363/1001 [12:30<14:12,  1.34s/it, avg loss=172.5467]Checkpoint at iteration 363 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 172.54672775268554

Training iteration:  36%|███▋      | 363/1001 [12:31<14:12,  1.34s/it, avg loss=186.9437]
Training iteration:  36%|███▋      | 364/1001 [12:31<14:10,  1.34s/it, avg loss=186.9437]Checkpoint at iteration 364 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 186.94373512268066

Training iteration:  36%|███▋      | 364/1001 [12:33<14:10,  1.34s/it, avg loss=191.9774]
Training iteration:  36%|███▋      | 365/1001 [12:33<14:10,  1.34s/it, avg loss=191.9774]Checkpoint at iteration 365 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 191.9774299621582

Training iteration:  36%|███▋      | 365/1001 [12:34<14:10,  1.34s/it, avg loss=155.1890]
Training iteration:  37%|███▋      | 366/1001 [12:34<14:08,  1.34s/it, avg loss=155.1890]Checkpoint at iteration 366 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 155.18897018432617

Training iteration:  37%|███▋      | 366/1001 [12:35<14:08,  1.34s/it, avg loss=190.8303]
Training iteration:  37%|███▋      | 367/1001 [12:35<14:06,  1.34s/it, avg loss=190.8303]Checkpoint at iteration 367 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 190.83025741577148

Training iteration:  37%|███▋      | 367/1001 [12:37<14:06,  1.34s/it, avg loss=131.7865]
Training iteration:  37%|███▋      | 368/1001 [12:37<14:05,  1.33s/it, avg loss=131.7865]Checkpoint at iteration 368 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 131.7864860534668

Training iteration:  37%|███▋      | 368/1001 [12:38<14:05,  1.33s/it, avg loss=147.3458]
Training iteration:  37%|███▋      | 369/1001 [12:38<14:03,  1.33s/it, avg loss=147.3458]Checkpoint at iteration 369 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 147.34575004577636

Training iteration:  37%|███▋      | 369/1001 [12:39<14:03,  1.33s/it, avg loss=151.8300]
Training iteration:  37%|███▋      | 370/1001 [12:39<14:01,  1.33s/it, avg loss=151.8300]Checkpoint at iteration 370 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 151.82999114990236

Training iteration:  37%|███▋      | 370/1001 [12:41<14:01,  1.33s/it, avg loss=149.8810]
Training iteration:  37%|███▋      | 371/1001 [12:41<14:00,  1.33s/it, avg loss=149.8810]Checkpoint at iteration 371 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 149.880961227417

Training iteration:  37%|███▋      | 371/1001 [12:42<14:00,  1.33s/it, avg loss=128.3557]
Training iteration:  37%|███▋      | 372/1001 [12:42<13:59,  1.33s/it, avg loss=128.3557]Checkpoint at iteration 372 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 128.355712890625

Training iteration:  37%|███▋      | 372/1001 [12:43<13:59,  1.33s/it, avg loss=221.8831]
Training iteration:  37%|███▋      | 373/1001 [12:43<13:58,  1.33s/it, avg loss=221.8831]Checkpoint at iteration 373 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 221.88313484191895

Training iteration:  37%|███▋      | 373/1001 [12:45<13:58,  1.33s/it, avg loss=148.8954]
Training iteration:  37%|███▋      | 374/1001 [12:45<13:57,  1.34s/it, avg loss=148.8954]Checkpoint at iteration 374 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 148.8954284667969

Training iteration:  37%|███▋      | 374/1001 [12:46<13:57,  1.34s/it, avg loss=198.1008]
Training iteration:  37%|███▋      | 375/1001 [12:46<13:56,  1.34s/it, avg loss=198.1008]Checkpoint at iteration 375 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 198.10084381103516

Training iteration:  37%|███▋      | 375/1001 [12:47<13:56,  1.34s/it, avg loss=222.3268]
Training iteration:  38%|███▊      | 376/1001 [12:47<13:53,  1.33s/it, avg loss=222.3268]Checkpoint at iteration 376 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 222.3267623901367

Training iteration:  38%|███▊      | 376/1001 [12:49<13:53,  1.33s/it, avg loss=156.1436]
Training iteration:  38%|███▊      | 377/1001 [12:49<13:52,  1.33s/it, avg loss=156.1436]Checkpoint at iteration 377 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 156.14363327026368

Training iteration:  38%|███▊      | 377/1001 [12:50<13:52,  1.33s/it, avg loss=223.9414]
Training iteration:  38%|███▊      | 378/1001 [12:50<13:50,  1.33s/it, avg loss=223.9414]Checkpoint at iteration 378 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 223.94135208129882

Training iteration:  38%|███▊      | 378/1001 [12:51<13:50,  1.33s/it, avg loss=165.4690]
Training iteration:  38%|███▊      | 379/1001 [12:51<13:49,  1.33s/it, avg loss=165.4690]Checkpoint at iteration 379 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 165.46903457641602

Training iteration:  38%|███▊      | 379/1001 [12:53<13:49,  1.33s/it, avg loss=222.1279]
Training iteration:  38%|███▊      | 380/1001 [12:53<13:47,  1.33s/it, avg loss=222.1279]Checkpoint at iteration 380 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 222.12793350219727

Training iteration:  38%|███▊      | 380/1001 [12:54<13:47,  1.33s/it, avg loss=137.5615]
Training iteration:  38%|███▊      | 381/1001 [12:54<13:46,  1.33s/it, avg loss=137.5615]Checkpoint at iteration 381 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 137.56152954101563

Training iteration:  38%|███▊      | 381/1001 [12:55<13:46,  1.33s/it, avg loss=107.1511]
Training iteration:  38%|███▊      | 382/1001 [12:55<13:45,  1.33s/it, avg loss=107.1511]Checkpoint at iteration 382 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 107.15105323791504

Training iteration:  38%|███▊      | 382/1001 [12:57<13:45,  1.33s/it, avg loss=112.7400]
Training iteration:  38%|███▊      | 383/1001 [12:57<13:44,  1.33s/it, avg loss=112.7400]Checkpoint at iteration 383 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 112.73997077941894

Training iteration:  38%|███▊      | 383/1001 [12:58<13:44,  1.33s/it, avg loss=99.6194] 
Training iteration:  38%|███▊      | 384/1001 [12:58<13:43,  1.33s/it, avg loss=99.6194]Checkpoint at iteration 384 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 99.61941833496094

Training iteration:  38%|███▊      | 384/1001 [12:59<13:43,  1.33s/it, avg loss=203.3723]
Training iteration:  38%|███▊      | 385/1001 [12:59<13:42,  1.33s/it, avg loss=203.3723]Checkpoint at iteration 385 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 203.37227096557618

Training iteration:  38%|███▊      | 385/1001 [13:01<13:42,  1.33s/it, avg loss=174.9186]
Training iteration:  39%|███▊      | 386/1001 [13:01<13:40,  1.33s/it, avg loss=174.9186]Checkpoint at iteration 386 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 174.91863403320312

Training iteration:  39%|███▊      | 386/1001 [13:02<13:40,  1.33s/it, avg loss=202.8154]
Training iteration:  39%|███▊      | 387/1001 [13:02<13:39,  1.33s/it, avg loss=202.8154]Checkpoint at iteration 387 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 202.81544189453126

Training iteration:  39%|███▊      | 387/1001 [13:03<13:39,  1.33s/it, avg loss=159.4186]
Training iteration:  39%|███▉      | 388/1001 [13:03<13:37,  1.33s/it, avg loss=159.4186]Checkpoint at iteration 388 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 159.41856002807617

Training iteration:  39%|███▉      | 388/1001 [13:05<13:37,  1.33s/it, avg loss=201.8339]
Training iteration:  39%|███▉      | 389/1001 [13:05<13:36,  1.33s/it, avg loss=201.8339]Checkpoint at iteration 389 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 201.83390274047852

Training iteration:  39%|███▉      | 389/1001 [13:06<13:36,  1.33s/it, avg loss=142.3235]
Training iteration:  39%|███▉      | 390/1001 [13:06<13:35,  1.34s/it, avg loss=142.3235]Checkpoint at iteration 390 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 142.3234889984131

Training iteration:  39%|███▉      | 390/1001 [13:07<13:35,  1.34s/it, avg loss=274.8006]
Training iteration:  39%|███▉      | 391/1001 [13:07<13:34,  1.33s/it, avg loss=274.8006]Checkpoint at iteration 391 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 274.8005905151367

Training iteration:  39%|███▉      | 391/1001 [13:09<13:34,  1.33s/it, avg loss=130.8982]
Training iteration:  39%|███▉      | 392/1001 [13:09<13:33,  1.34s/it, avg loss=130.8982]Checkpoint at iteration 392 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 130.89818878173827

Training iteration:  39%|███▉      | 392/1001 [13:10<13:33,  1.34s/it, avg loss=111.9445]
Training iteration:  39%|███▉      | 393/1001 [13:10<13:31,  1.34s/it, avg loss=111.9445]Checkpoint at iteration 393 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 111.94448966979981

Training iteration:  39%|███▉      | 393/1001 [13:11<13:31,  1.34s/it, avg loss=196.7832]
Training iteration:  39%|███▉      | 394/1001 [13:11<13:30,  1.33s/it, avg loss=196.7832]Checkpoint at iteration 394 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 196.7832359313965

Training iteration:  39%|███▉      | 394/1001 [13:13<13:30,  1.33s/it, avg loss=88.5419] 
Training iteration:  39%|███▉      | 395/1001 [13:13<13:29,  1.34s/it, avg loss=88.5419]Checkpoint at iteration 395 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 88.54186515808105

Training iteration:  39%|███▉      | 395/1001 [13:14<13:29,  1.34s/it, avg loss=123.1483]
Training iteration:  40%|███▉      | 396/1001 [13:14<13:27,  1.34s/it, avg loss=123.1483]Checkpoint at iteration 396 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 123.14829292297364

Training iteration:  40%|███▉      | 396/1001 [13:15<13:27,  1.34s/it, avg loss=197.1174]
Training iteration:  40%|███▉      | 397/1001 [13:15<13:26,  1.34s/it, avg loss=197.1174]Checkpoint at iteration 397 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 197.11741943359374

Training iteration:  40%|███▉      | 397/1001 [13:17<13:26,  1.34s/it, avg loss=213.2521]
Training iteration:  40%|███▉      | 398/1001 [13:17<13:25,  1.34s/it, avg loss=213.2521]Checkpoint at iteration 398 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 213.25213012695312

Training iteration:  40%|███▉      | 398/1001 [13:18<13:25,  1.34s/it, avg loss=173.5351]
Training iteration:  40%|███▉      | 399/1001 [13:18<13:23,  1.33s/it, avg loss=173.5351]Checkpoint at iteration 399 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 173.53505859375

Training iteration:  40%|███▉      | 399/1001 [13:19<13:23,  1.33s/it, avg loss=177.6505]
Training iteration:  40%|███▉      | 400/1001 [13:19<13:22,  1.34s/it, avg loss=177.6505]Optimization iteration 400 evaluation begins...
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
A new evaluation visualization has been saved: ./saved_data/20240110-063719/it400.png
Training network 0 for evaluation...
Training network 1 for evaluation...
Training network 2 for evaluation...
Training network 3 for evaluation...
Testing network 0 on real datasets for evaluation...
Testing network 1 on real datasets for evaluation...
Testing network 2 on real datasets for evaluation...
Testing network 3 on real datasets for evaluation...
Optimization iteration 400, eval auroc score (train): 20077.7408, eval auroc score (test): 21068.3910
Checkpoint at iteration 400 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 177.65051803588867

Training iteration:  40%|███▉      | 400/1001 [17:44<13:22,  1.34s/it, avg loss=171.8568]
Training iteration:  40%|████      | 401/1001 [17:44<13:22:33, 80.26s/it, avg loss=171.8568]Checkpoint at iteration 401 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 171.85684204101562

Training iteration:  40%|████      | 401/1001 [17:45<13:22:33, 80.26s/it, avg loss=118.9909]
Training iteration:  40%|████      | 402/1001 [17:45<9:25:29, 56.64s/it, avg loss=118.9909] Checkpoint at iteration 402 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 118.99093208312988

Training iteration:  40%|████      | 402/1001 [17:47<9:25:29, 56.64s/it, avg loss=141.7553]
Training iteration:  40%|████      | 403/1001 [17:47<6:39:48, 40.11s/it, avg loss=141.7553]Checkpoint at iteration 403 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 141.75530166625975

Training iteration:  40%|████      | 403/1001 [17:48<6:39:48, 40.11s/it, avg loss=190.3983]
Training iteration:  40%|████      | 404/1001 [17:48<4:44:00, 28.54s/it, avg loss=190.3983]Checkpoint at iteration 404 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 190.3982711791992

Training iteration:  40%|████      | 404/1001 [17:50<4:44:00, 28.54s/it, avg loss=242.1700]
Training iteration:  40%|████      | 405/1001 [17:50<3:23:05, 20.45s/it, avg loss=242.1700]Checkpoint at iteration 405 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 242.17001342773438

Training iteration:  40%|████      | 405/1001 [17:51<3:23:05, 20.45s/it, avg loss=134.2132]
Training iteration:  41%|████      | 406/1001 [17:51<2:26:31, 14.78s/it, avg loss=134.2132]Checkpoint at iteration 406 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 134.21315994262696

Training iteration:  41%|████      | 406/1001 [17:53<2:26:31, 14.78s/it, avg loss=204.8532]
Training iteration:  41%|████      | 407/1001 [17:53<1:47:00, 10.81s/it, avg loss=204.8532]Checkpoint at iteration 407 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 204.85321807861328

Training iteration:  41%|████      | 407/1001 [17:55<1:47:00, 10.81s/it, avg loss=252.3619]
Training iteration:  41%|████      | 408/1001 [17:55<1:19:21,  8.03s/it, avg loss=252.3619]Checkpoint at iteration 408 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 252.3619415283203

Training iteration:  41%|████      | 408/1001 [17:56<1:19:21,  8.03s/it, avg loss=129.4622]
Training iteration:  41%|████      | 409/1001 [17:56<1:00:01,  6.08s/it, avg loss=129.4622]Checkpoint at iteration 409 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 129.46217041015626

Training iteration:  41%|████      | 409/1001 [17:58<1:00:01,  6.08s/it, avg loss=205.2086]
Training iteration:  41%|████      | 410/1001 [17:58<46:31,  4.72s/it, avg loss=205.2086]  Checkpoint at iteration 410 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 205.20858993530274

Training iteration:  41%|████      | 410/1001 [17:59<46:31,  4.72s/it, avg loss=185.9778]
Training iteration:  41%|████      | 411/1001 [17:59<37:04,  3.77s/it, avg loss=185.9778]Checkpoint at iteration 411 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 185.9777702331543

Training iteration:  41%|████      | 411/1001 [18:01<37:04,  3.77s/it, avg loss=163.5648]
Training iteration:  41%|████      | 412/1001 [18:01<30:26,  3.10s/it, avg loss=163.5648]Checkpoint at iteration 412 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 163.56481552124023

Training iteration:  41%|████      | 412/1001 [18:02<30:26,  3.10s/it, avg loss=208.7076]
Training iteration:  41%|████▏     | 413/1001 [18:02<25:49,  2.64s/it, avg loss=208.7076]Checkpoint at iteration 413 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 208.70757675170898

Training iteration:  41%|████▏     | 413/1001 [18:04<25:49,  2.64s/it, avg loss=157.6405]
Training iteration:  41%|████▏     | 414/1001 [18:04<22:35,  2.31s/it, avg loss=157.6405]Checkpoint at iteration 414 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 157.6405372619629

Training iteration:  41%|████▏     | 414/1001 [18:05<22:35,  2.31s/it, avg loss=102.6853]
Training iteration:  41%|████▏     | 415/1001 [18:05<20:19,  2.08s/it, avg loss=102.6853]Checkpoint at iteration 415 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 102.68525161743165

Training iteration:  41%|████▏     | 415/1001 [18:07<20:19,  2.08s/it, avg loss=117.9074]
Training iteration:  42%|████▏     | 416/1001 [18:07<18:43,  1.92s/it, avg loss=117.9074]Checkpoint at iteration 416 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 117.90743408203124

Training iteration:  42%|████▏     | 416/1001 [18:08<18:43,  1.92s/it, avg loss=213.6532]
Training iteration:  42%|████▏     | 417/1001 [18:08<17:36,  1.81s/it, avg loss=213.6532]Checkpoint at iteration 417 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 213.65317459106444

Training iteration:  42%|████▏     | 417/1001 [18:10<17:36,  1.81s/it, avg loss=185.0292]
Training iteration:  42%|████▏     | 418/1001 [18:10<16:49,  1.73s/it, avg loss=185.0292]Checkpoint at iteration 418 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 185.02919921875

Training iteration:  42%|████▏     | 418/1001 [18:12<16:49,  1.73s/it, avg loss=132.5874]
Training iteration:  42%|████▏     | 419/1001 [18:12<16:15,  1.68s/it, avg loss=132.5874]Checkpoint at iteration 419 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 132.58741607666016

Training iteration:  42%|████▏     | 419/1001 [18:13<16:15,  1.68s/it, avg loss=208.1050]
Training iteration:  42%|████▏     | 420/1001 [18:13<15:51,  1.64s/it, avg loss=208.1050]Checkpoint at iteration 420 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 208.10501670837402

Training iteration:  42%|████▏     | 420/1001 [18:15<15:51,  1.64s/it, avg loss=217.0900]
Training iteration:  42%|████▏     | 421/1001 [18:15<15:33,  1.61s/it, avg loss=217.0900]Checkpoint at iteration 421 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 217.0900100708008

Training iteration:  42%|████▏     | 421/1001 [18:16<15:33,  1.61s/it, avg loss=204.2249]
Training iteration:  42%|████▏     | 422/1001 [18:16<15:21,  1.59s/it, avg loss=204.2249]Checkpoint at iteration 422 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 204.2248748779297

Training iteration:  42%|████▏     | 422/1001 [18:18<15:21,  1.59s/it, avg loss=152.9887]
Training iteration:  42%|████▏     | 423/1001 [18:18<15:11,  1.58s/it, avg loss=152.9887]Checkpoint at iteration 423 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 152.98871345520018

Training iteration:  42%|████▏     | 423/1001 [18:19<15:11,  1.58s/it, avg loss=182.1237]
Training iteration:  42%|████▏     | 424/1001 [18:19<15:05,  1.57s/it, avg loss=182.1237]Checkpoint at iteration 424 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 182.12371520996095

Training iteration:  42%|████▏     | 424/1001 [18:21<15:05,  1.57s/it, avg loss=171.8144]
Training iteration:  42%|████▏     | 425/1001 [18:21<14:59,  1.56s/it, avg loss=171.8144]Checkpoint at iteration 425 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 171.81444091796874

Training iteration:  42%|████▏     | 425/1001 [18:22<14:59,  1.56s/it, avg loss=240.4641]
Training iteration:  43%|████▎     | 426/1001 [18:22<14:56,  1.56s/it, avg loss=240.4641]Checkpoint at iteration 426 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 240.46413040161133

Training iteration:  43%|████▎     | 426/1001 [18:24<14:56,  1.56s/it, avg loss=134.7698]
Training iteration:  43%|████▎     | 427/1001 [18:24<14:52,  1.56s/it, avg loss=134.7698]Checkpoint at iteration 427 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 134.76983642578125

Training iteration:  43%|████▎     | 427/1001 [18:25<14:52,  1.56s/it, avg loss=161.6868]
Training iteration:  43%|████▎     | 428/1001 [18:25<14:49,  1.55s/it, avg loss=161.6868]Checkpoint at iteration 428 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 161.68675231933594

Training iteration:  43%|████▎     | 428/1001 [18:27<14:49,  1.55s/it, avg loss=156.5155]
Training iteration:  43%|████▎     | 429/1001 [18:27<14:46,  1.55s/it, avg loss=156.5155]Checkpoint at iteration 429 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 156.51553192138672

Training iteration:  43%|████▎     | 429/1001 [18:29<14:46,  1.55s/it, avg loss=168.3087]
Training iteration:  43%|████▎     | 430/1001 [18:29<14:44,  1.55s/it, avg loss=168.3087]Checkpoint at iteration 430 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 168.30874252319336

Training iteration:  43%|████▎     | 430/1001 [18:30<14:44,  1.55s/it, avg loss=147.1605]
Training iteration:  43%|████▎     | 431/1001 [18:30<14:43,  1.55s/it, avg loss=147.1605]Checkpoint at iteration 431 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 147.16045875549315

Training iteration:  43%|████▎     | 431/1001 [18:32<14:43,  1.55s/it, avg loss=125.7814]
Training iteration:  43%|████▎     | 432/1001 [18:32<14:41,  1.55s/it, avg loss=125.7814]Checkpoint at iteration 432 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 125.78143997192383

Training iteration:  43%|████▎     | 432/1001 [18:33<14:41,  1.55s/it, avg loss=125.9749]
Training iteration:  43%|████▎     | 433/1001 [18:33<14:39,  1.55s/it, avg loss=125.9749]Checkpoint at iteration 433 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 125.97491722106933

Training iteration:  43%|████▎     | 433/1001 [18:35<14:39,  1.55s/it, avg loss=122.3763]
Training iteration:  43%|████▎     | 434/1001 [18:35<14:37,  1.55s/it, avg loss=122.3763]Checkpoint at iteration 434 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 122.37627334594727

Training iteration:  43%|████▎     | 434/1001 [18:36<14:37,  1.55s/it, avg loss=234.1638]
Training iteration:  43%|████▎     | 435/1001 [18:36<14:35,  1.55s/it, avg loss=234.1638]Checkpoint at iteration 435 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 234.1638084411621

Training iteration:  43%|████▎     | 435/1001 [18:38<14:35,  1.55s/it, avg loss=202.3874]
Training iteration:  44%|████▎     | 436/1001 [18:38<14:33,  1.55s/it, avg loss=202.3874]Checkpoint at iteration 436 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 202.38737945556642

Training iteration:  44%|████▎     | 436/1001 [18:39<14:33,  1.55s/it, avg loss=109.0339]
Training iteration:  44%|████▎     | 437/1001 [18:39<14:32,  1.55s/it, avg loss=109.0339]Checkpoint at iteration 437 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 109.03387451171875

Training iteration:  44%|████▎     | 437/1001 [18:41<14:32,  1.55s/it, avg loss=178.1733]
Training iteration:  44%|████▍     | 438/1001 [18:41<14:30,  1.55s/it, avg loss=178.1733]Checkpoint at iteration 438 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 178.17333755493163

Training iteration:  44%|████▍     | 438/1001 [18:43<14:30,  1.55s/it, avg loss=156.2474]
Training iteration:  44%|████▍     | 439/1001 [18:43<14:28,  1.55s/it, avg loss=156.2474]Checkpoint at iteration 439 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 156.2474395751953

Training iteration:  44%|████▍     | 439/1001 [18:44<14:28,  1.55s/it, avg loss=175.0326]
Training iteration:  44%|████▍     | 440/1001 [18:44<14:26,  1.54s/it, avg loss=175.0326]Checkpoint at iteration 440 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 175.03259658813477

Training iteration:  44%|████▍     | 440/1001 [18:46<14:26,  1.54s/it, avg loss=238.0244]
Training iteration:  44%|████▍     | 441/1001 [18:46<14:24,  1.54s/it, avg loss=238.0244]Checkpoint at iteration 441 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 238.0244239807129

Training iteration:  44%|████▍     | 441/1001 [18:47<14:24,  1.54s/it, avg loss=128.2704]
Training iteration:  44%|████▍     | 442/1001 [18:47<14:22,  1.54s/it, avg loss=128.2704]Checkpoint at iteration 442 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 128.27036361694337

Training iteration:  44%|████▍     | 442/1001 [18:49<14:22,  1.54s/it, avg loss=238.1617]
Training iteration:  44%|████▍     | 443/1001 [18:49<14:21,  1.54s/it, avg loss=238.1617]Checkpoint at iteration 443 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 238.1617431640625

Training iteration:  44%|████▍     | 443/1001 [18:50<14:21,  1.54s/it, avg loss=107.1958]
Training iteration:  44%|████▍     | 444/1001 [18:50<14:20,  1.54s/it, avg loss=107.1958]Checkpoint at iteration 444 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 107.19575805664063

Training iteration:  44%|████▍     | 444/1001 [18:52<14:20,  1.54s/it, avg loss=157.0628]
Training iteration:  44%|████▍     | 445/1001 [18:52<14:19,  1.55s/it, avg loss=157.0628]Checkpoint at iteration 445 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 157.0627899169922

Training iteration:  44%|████▍     | 445/1001 [18:53<14:19,  1.55s/it, avg loss=198.6285]
Training iteration:  45%|████▍     | 446/1001 [18:53<14:17,  1.54s/it, avg loss=198.6285]Checkpoint at iteration 446 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 198.6284507751465

Training iteration:  45%|████▍     | 446/1001 [18:55<14:17,  1.54s/it, avg loss=230.1861]
Training iteration:  45%|████▍     | 447/1001 [18:55<14:15,  1.54s/it, avg loss=230.1861]Checkpoint at iteration 447 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 230.18614196777344

Training iteration:  45%|████▍     | 447/1001 [18:56<14:15,  1.54s/it, avg loss=208.6803]
Training iteration:  45%|████▍     | 448/1001 [18:56<14:14,  1.55s/it, avg loss=208.6803]Checkpoint at iteration 448 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 208.6803009033203

Training iteration:  45%|████▍     | 448/1001 [18:58<14:14,  1.55s/it, avg loss=121.2849]
Training iteration:  45%|████▍     | 449/1001 [18:58<14:12,  1.55s/it, avg loss=121.2849]Checkpoint at iteration 449 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 121.28486442565918

Training iteration:  45%|████▍     | 449/1001 [18:59<14:12,  1.55s/it, avg loss=187.4967]
Training iteration:  45%|████▍     | 450/1001 [18:59<14:11,  1.55s/it, avg loss=187.4967]Checkpoint at iteration 450 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 187.49674377441406

Training iteration:  45%|████▍     | 450/1001 [19:01<14:11,  1.55s/it, avg loss=212.1714]
Training iteration:  45%|████▌     | 451/1001 [19:01<14:09,  1.55s/it, avg loss=212.1714]Checkpoint at iteration 451 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 212.17144241333008

Training iteration:  45%|████▌     | 451/1001 [19:03<14:09,  1.55s/it, avg loss=168.0888]
Training iteration:  45%|████▌     | 452/1001 [19:03<14:08,  1.54s/it, avg loss=168.0888]Checkpoint at iteration 452 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 168.08881225585938

Training iteration:  45%|████▌     | 452/1001 [19:04<14:08,  1.54s/it, avg loss=114.5894]
Training iteration:  45%|████▌     | 453/1001 [19:04<14:06,  1.54s/it, avg loss=114.5894]Checkpoint at iteration 453 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 114.5893684387207

Training iteration:  45%|████▌     | 453/1001 [19:06<14:06,  1.54s/it, avg loss=269.0902]
Training iteration:  45%|████▌     | 454/1001 [19:06<14:04,  1.54s/it, avg loss=269.0902]Checkpoint at iteration 454 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 269.0901786804199

Training iteration:  45%|████▌     | 454/1001 [19:07<14:04,  1.54s/it, avg loss=174.8492]
Training iteration:  45%|████▌     | 455/1001 [19:07<14:02,  1.54s/it, avg loss=174.8492]Checkpoint at iteration 455 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 174.84924774169923

Training iteration:  45%|████▌     | 455/1001 [19:09<14:02,  1.54s/it, avg loss=135.4733]
Training iteration:  46%|████▌     | 456/1001 [19:09<14:00,  1.54s/it, avg loss=135.4733]Checkpoint at iteration 456 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 135.47333221435548

Training iteration:  46%|████▌     | 456/1001 [19:10<14:00,  1.54s/it, avg loss=120.6131]
Training iteration:  46%|████▌     | 457/1001 [19:10<13:59,  1.54s/it, avg loss=120.6131]Checkpoint at iteration 457 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 120.61306762695312

Training iteration:  46%|████▌     | 457/1001 [19:12<13:59,  1.54s/it, avg loss=173.6935]
Training iteration:  46%|████▌     | 458/1001 [19:12<13:57,  1.54s/it, avg loss=173.6935]Checkpoint at iteration 458 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 173.69354324340821

Training iteration:  46%|████▌     | 458/1001 [19:13<13:57,  1.54s/it, avg loss=174.8227]
Training iteration:  46%|████▌     | 459/1001 [19:13<13:55,  1.54s/it, avg loss=174.8227]Checkpoint at iteration 459 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 174.822664642334

Training iteration:  46%|████▌     | 459/1001 [19:15<13:55,  1.54s/it, avg loss=135.9767]
Training iteration:  46%|████▌     | 460/1001 [19:15<13:53,  1.54s/it, avg loss=135.9767]Checkpoint at iteration 460 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 135.9766616821289

Training iteration:  46%|████▌     | 460/1001 [19:16<13:53,  1.54s/it, avg loss=158.7925]
Training iteration:  46%|████▌     | 461/1001 [19:16<13:51,  1.54s/it, avg loss=158.7925]Checkpoint at iteration 461 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 158.79245223999024

Training iteration:  46%|████▌     | 461/1001 [19:18<13:51,  1.54s/it, avg loss=217.6176]
Training iteration:  46%|████▌     | 462/1001 [19:18<13:49,  1.54s/it, avg loss=217.6176]Checkpoint at iteration 462 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 217.6175750732422

Training iteration:  46%|████▌     | 462/1001 [19:20<13:49,  1.54s/it, avg loss=230.0059]
Training iteration:  46%|████▋     | 463/1001 [19:20<13:48,  1.54s/it, avg loss=230.0059]Checkpoint at iteration 463 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 230.00585861206054

Training iteration:  46%|████▋     | 463/1001 [19:21<13:48,  1.54s/it, avg loss=199.2552]
Training iteration:  46%|████▋     | 464/1001 [19:21<13:46,  1.54s/it, avg loss=199.2552]Checkpoint at iteration 464 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 199.25519561767578

Training iteration:  46%|████▋     | 464/1001 [19:23<13:46,  1.54s/it, avg loss=196.4514]
Training iteration:  46%|████▋     | 465/1001 [19:23<13:44,  1.54s/it, avg loss=196.4514]Checkpoint at iteration 465 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 196.4513832092285

Training iteration:  46%|████▋     | 465/1001 [19:24<13:44,  1.54s/it, avg loss=202.6003]
Training iteration:  47%|████▋     | 466/1001 [19:24<13:43,  1.54s/it, avg loss=202.6003]Checkpoint at iteration 466 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 202.60026664733886

Training iteration:  47%|████▋     | 466/1001 [19:26<13:43,  1.54s/it, avg loss=163.3340]
Training iteration:  47%|████▋     | 467/1001 [19:26<13:41,  1.54s/it, avg loss=163.3340]Checkpoint at iteration 467 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 163.3340316772461

Training iteration:  47%|████▋     | 467/1001 [19:27<13:41,  1.54s/it, avg loss=223.3866]
Training iteration:  47%|████▋     | 468/1001 [19:27<13:40,  1.54s/it, avg loss=223.3866]Checkpoint at iteration 468 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 223.3866081237793

Training iteration:  47%|████▋     | 468/1001 [19:29<13:40,  1.54s/it, avg loss=170.6022]
Training iteration:  47%|████▋     | 469/1001 [19:29<13:38,  1.54s/it, avg loss=170.6022]Checkpoint at iteration 469 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 170.6021644592285

Training iteration:  47%|████▋     | 469/1001 [19:30<13:38,  1.54s/it, avg loss=158.2639]
Training iteration:  47%|████▋     | 470/1001 [19:30<13:37,  1.54s/it, avg loss=158.2639]Checkpoint at iteration 470 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 158.26393966674806

Training iteration:  47%|████▋     | 470/1001 [19:32<13:37,  1.54s/it, avg loss=161.3423]
Training iteration:  47%|████▋     | 471/1001 [19:32<13:36,  1.54s/it, avg loss=161.3423]Checkpoint at iteration 471 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 161.3423065185547

Training iteration:  47%|████▋     | 471/1001 [19:33<13:36,  1.54s/it, avg loss=162.1017]
Training iteration:  47%|████▋     | 472/1001 [19:33<13:34,  1.54s/it, avg loss=162.1017]Checkpoint at iteration 472 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 162.1016975402832

Training iteration:  47%|████▋     | 472/1001 [19:35<13:34,  1.54s/it, avg loss=150.0015]
Training iteration:  47%|████▋     | 473/1001 [19:35<13:32,  1.54s/it, avg loss=150.0015]Checkpoint at iteration 473 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 150.00147094726563

Training iteration:  47%|████▋     | 473/1001 [19:36<13:32,  1.54s/it, avg loss=222.3696]
Training iteration:  47%|████▋     | 474/1001 [19:36<13:31,  1.54s/it, avg loss=222.3696]Checkpoint at iteration 474 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 222.36959228515624

Training iteration:  47%|████▋     | 474/1001 [19:38<13:31,  1.54s/it, avg loss=164.3783]
Training iteration:  47%|████▋     | 475/1001 [19:38<13:29,  1.54s/it, avg loss=164.3783]Checkpoint at iteration 475 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 164.37830123901367

Training iteration:  47%|████▋     | 475/1001 [19:40<13:29,  1.54s/it, avg loss=186.4332]
Training iteration:  48%|████▊     | 476/1001 [19:40<13:29,  1.54s/it, avg loss=186.4332]Checkpoint at iteration 476 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 186.43322677612304

Training iteration:  48%|████▊     | 476/1001 [19:41<13:29,  1.54s/it, avg loss=192.7528]
Training iteration:  48%|████▊     | 477/1001 [19:41<13:28,  1.54s/it, avg loss=192.7528]Checkpoint at iteration 477 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 192.75281448364257

Training iteration:  48%|████▊     | 477/1001 [19:43<13:28,  1.54s/it, avg loss=253.7734]
Training iteration:  48%|████▊     | 478/1001 [19:43<13:27,  1.54s/it, avg loss=253.7734]Checkpoint at iteration 478 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 253.773388671875

Training iteration:  48%|████▊     | 478/1001 [19:44<13:27,  1.54s/it, avg loss=196.4856]
Training iteration:  48%|████▊     | 479/1001 [19:44<13:25,  1.54s/it, avg loss=196.4856]Checkpoint at iteration 479 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 196.48562774658203

Training iteration:  48%|████▊     | 479/1001 [19:46<13:25,  1.54s/it, avg loss=97.7494] 
Training iteration:  48%|████▊     | 480/1001 [19:46<13:23,  1.54s/it, avg loss=97.7494]Checkpoint at iteration 480 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 97.74937553405762

Training iteration:  48%|████▊     | 480/1001 [19:47<13:23,  1.54s/it, avg loss=123.3514]
Training iteration:  48%|████▊     | 481/1001 [19:47<13:20,  1.54s/it, avg loss=123.3514]Checkpoint at iteration 481 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 123.35139083862305

Training iteration:  48%|████▊     | 481/1001 [19:49<13:20,  1.54s/it, avg loss=169.6872]
Training iteration:  48%|████▊     | 482/1001 [19:49<13:19,  1.54s/it, avg loss=169.6872]Checkpoint at iteration 482 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 169.68722686767578

Training iteration:  48%|████▊     | 482/1001 [19:50<13:19,  1.54s/it, avg loss=187.3532]
Training iteration:  48%|████▊     | 483/1001 [19:50<13:18,  1.54s/it, avg loss=187.3532]Checkpoint at iteration 483 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 187.3532257080078

Training iteration:  48%|████▊     | 483/1001 [19:52<13:18,  1.54s/it, avg loss=196.3073]
Training iteration:  48%|████▊     | 484/1001 [19:52<13:16,  1.54s/it, avg loss=196.3073]Checkpoint at iteration 484 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 196.30730209350585

Training iteration:  48%|████▊     | 484/1001 [19:53<13:16,  1.54s/it, avg loss=174.7959]
Training iteration:  48%|████▊     | 485/1001 [19:53<13:15,  1.54s/it, avg loss=174.7959]Checkpoint at iteration 485 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 174.79589157104493

Training iteration:  48%|████▊     | 485/1001 [19:55<13:15,  1.54s/it, avg loss=139.3558]
Training iteration:  49%|████▊     | 486/1001 [19:55<13:13,  1.54s/it, avg loss=139.3558]Checkpoint at iteration 486 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 139.35583534240723

Training iteration:  49%|████▊     | 486/1001 [19:57<13:13,  1.54s/it, avg loss=176.7457]
Training iteration:  49%|████▊     | 487/1001 [19:57<13:12,  1.54s/it, avg loss=176.7457]Checkpoint at iteration 487 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 176.74568862915038

Training iteration:  49%|████▊     | 487/1001 [19:58<13:12,  1.54s/it, avg loss=177.0561]
Training iteration:  49%|████▉     | 488/1001 [19:58<13:10,  1.54s/it, avg loss=177.0561]Checkpoint at iteration 488 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 177.05608596801758

Training iteration:  49%|████▉     | 488/1001 [20:00<13:10,  1.54s/it, avg loss=224.4007]
Training iteration:  49%|████▉     | 489/1001 [20:00<13:09,  1.54s/it, avg loss=224.4007]Checkpoint at iteration 489 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 224.4007209777832

Training iteration:  49%|████▉     | 489/1001 [20:01<13:09,  1.54s/it, avg loss=165.4269]
Training iteration:  49%|████▉     | 490/1001 [20:01<13:07,  1.54s/it, avg loss=165.4269]Checkpoint at iteration 490 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 165.42690734863282

Training iteration:  49%|████▉     | 490/1001 [20:03<13:07,  1.54s/it, avg loss=103.5582]
Training iteration:  49%|████▉     | 491/1001 [20:03<13:06,  1.54s/it, avg loss=103.5582]Checkpoint at iteration 491 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 103.55820770263672

Training iteration:  49%|████▉     | 491/1001 [20:04<13:06,  1.54s/it, avg loss=254.1079]
Training iteration:  49%|████▉     | 492/1001 [20:04<13:05,  1.54s/it, avg loss=254.1079]Checkpoint at iteration 492 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 254.10786361694335

Training iteration:  49%|████▉     | 492/1001 [20:06<13:05,  1.54s/it, avg loss=130.8074]
Training iteration:  49%|████▉     | 493/1001 [20:06<13:04,  1.54s/it, avg loss=130.8074]Checkpoint at iteration 493 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 130.80741424560546

Training iteration:  49%|████▉     | 493/1001 [20:07<13:04,  1.54s/it, avg loss=196.3244]
Training iteration:  49%|████▉     | 494/1001 [20:07<13:02,  1.54s/it, avg loss=196.3244]Checkpoint at iteration 494 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 196.32441482543945

Training iteration:  49%|████▉     | 494/1001 [20:09<13:02,  1.54s/it, avg loss=181.1148]
Training iteration:  49%|████▉     | 495/1001 [20:09<13:01,  1.54s/it, avg loss=181.1148]Checkpoint at iteration 495 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 181.1148254394531

Training iteration:  49%|████▉     | 495/1001 [20:10<13:01,  1.54s/it, avg loss=166.9883]
Training iteration:  50%|████▉     | 496/1001 [20:10<12:59,  1.54s/it, avg loss=166.9883]Checkpoint at iteration 496 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 166.98832015991212

Training iteration:  50%|████▉     | 496/1001 [20:12<12:59,  1.54s/it, avg loss=98.4011] 
Training iteration:  50%|████▉     | 497/1001 [20:12<12:57,  1.54s/it, avg loss=98.4011]Checkpoint at iteration 497 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 98.4011329650879

Training iteration:  50%|████▉     | 497/1001 [20:13<12:57,  1.54s/it, avg loss=173.3945]
Training iteration:  50%|████▉     | 498/1001 [20:13<12:55,  1.54s/it, avg loss=173.3945]Checkpoint at iteration 498 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 173.3945213317871

Training iteration:  50%|████▉     | 498/1001 [20:15<12:55,  1.54s/it, avg loss=178.4441]
Training iteration:  50%|████▉     | 499/1001 [20:15<12:53,  1.54s/it, avg loss=178.4441]Checkpoint at iteration 499 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 178.44406433105468

Training iteration:  50%|████▉     | 499/1001 [20:17<12:53,  1.54s/it, avg loss=109.5636]
Training iteration:  50%|████▉     | 500/1001 [20:17<12:52,  1.54s/it, avg loss=109.5636]Optimization iteration 500 evaluation begins...
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
A new evaluation visualization has been saved: ./saved_data/20240110-063719/it500.png
Training network 0 for evaluation...
Training network 1 for evaluation...
Training network 2 for evaluation...
Training network 3 for evaluation...
Testing network 0 on real datasets for evaluation...
Testing network 1 on real datasets for evaluation...
Testing network 2 on real datasets for evaluation...
Testing network 3 on real datasets for evaluation...
Optimization iteration 500, eval auroc score (train): 20011.5492, eval auroc score (test): 20954.5291
Checkpoint at iteration 500 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 109.56356430053711

Training iteration:  50%|████▉     | 500/1001 [25:58<12:52,  1.54s/it, avg loss=161.9396]
Training iteration:  50%|█████     | 501/1001 [25:58<14:23:12, 103.58s/it, avg loss=161.9396]Checkpoint at iteration 501 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 161.9396064758301

Training iteration:  50%|█████     | 501/1001 [26:00<14:23:12, 103.58s/it, avg loss=184.8327]
Training iteration:  50%|█████     | 502/1001 [26:00<10:07:25, 73.04s/it, avg loss=184.8327] Checkpoint at iteration 502 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 184.83269386291505

Training iteration:  50%|█████     | 502/1001 [26:02<10:07:25, 73.04s/it, avg loss=166.4353]
Training iteration:  50%|█████     | 503/1001 [26:02<7:08:44, 51.66s/it, avg loss=166.4353] Checkpoint at iteration 503 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 166.4352668762207

Training iteration:  50%|█████     | 503/1001 [26:04<7:08:44, 51.66s/it, avg loss=126.4521]
Training iteration:  50%|█████     | 504/1001 [26:04<5:03:52, 36.69s/it, avg loss=126.4521]Checkpoint at iteration 504 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 126.4520824432373

Training iteration:  50%|█████     | 504/1001 [26:05<5:03:52, 36.69s/it, avg loss=131.4865]
Training iteration:  50%|█████     | 505/1001 [26:05<3:36:39, 26.21s/it, avg loss=131.4865]Checkpoint at iteration 505 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 131.48650970458985

Training iteration:  50%|█████     | 505/1001 [26:07<3:36:39, 26.21s/it, avg loss=160.2783]
Training iteration:  51%|█████     | 506/1001 [26:07<2:35:41, 18.87s/it, avg loss=160.2783]Checkpoint at iteration 506 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 160.27833633422853

Training iteration:  51%|█████     | 506/1001 [26:09<2:35:41, 18.87s/it, avg loss=225.4639]
Training iteration:  51%|█████     | 507/1001 [26:09<1:53:06, 13.74s/it, avg loss=225.4639]Checkpoint at iteration 507 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 225.46390533447266

Training iteration:  51%|█████     | 507/1001 [26:11<1:53:06, 13.74s/it, avg loss=225.0172]
Training iteration:  51%|█████     | 508/1001 [26:11<1:23:20, 10.14s/it, avg loss=225.0172]Checkpoint at iteration 508 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 225.0172264099121

Training iteration:  51%|█████     | 508/1001 [26:12<1:23:20, 10.14s/it, avg loss=166.6542]
Training iteration:  51%|█████     | 509/1001 [26:12<1:02:32,  7.63s/it, avg loss=166.6542]Checkpoint at iteration 509 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 166.65422897338868

Training iteration:  51%|█████     | 509/1001 [26:14<1:02:32,  7.63s/it, avg loss=157.1426]
Training iteration:  51%|█████     | 510/1001 [26:14<48:00,  5.87s/it, avg loss=157.1426]  Checkpoint at iteration 510 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 157.14257926940917

Training iteration:  51%|█████     | 510/1001 [26:16<48:00,  5.87s/it, avg loss=217.2995]
Training iteration:  51%|█████     | 511/1001 [26:16<37:50,  4.63s/it, avg loss=217.2995]Checkpoint at iteration 511 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 217.29950637817382

Training iteration:  51%|█████     | 511/1001 [26:18<37:50,  4.63s/it, avg loss=159.1049]
Training iteration:  51%|█████     | 512/1001 [26:18<30:43,  3.77s/it, avg loss=159.1049]Checkpoint at iteration 512 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 159.10494537353514

Training iteration:  51%|█████     | 512/1001 [26:19<30:43,  3.77s/it, avg loss=146.8332]
Training iteration:  51%|█████     | 513/1001 [26:19<25:44,  3.17s/it, avg loss=146.8332]Checkpoint at iteration 513 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 146.8331787109375

Training iteration:  51%|█████     | 513/1001 [26:21<25:44,  3.17s/it, avg loss=176.3075]
Training iteration:  51%|█████▏    | 514/1001 [26:21<22:15,  2.74s/it, avg loss=176.3075]Checkpoint at iteration 514 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 176.30750122070313

Training iteration:  51%|█████▏    | 514/1001 [26:23<22:15,  2.74s/it, avg loss=226.1609]
Training iteration:  51%|█████▏    | 515/1001 [26:23<19:48,  2.45s/it, avg loss=226.1609]Checkpoint at iteration 515 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 226.16087493896484

Training iteration:  51%|█████▏    | 515/1001 [26:25<19:48,  2.45s/it, avg loss=147.2819]
Training iteration:  52%|█████▏    | 516/1001 [26:25<18:05,  2.24s/it, avg loss=147.2819]Checkpoint at iteration 516 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 147.28192138671875

Training iteration:  52%|█████▏    | 516/1001 [26:26<18:05,  2.24s/it, avg loss=196.9250]
Training iteration:  52%|█████▏    | 517/1001 [26:26<16:53,  2.09s/it, avg loss=196.9250]Checkpoint at iteration 517 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 196.92497787475585

Training iteration:  52%|█████▏    | 517/1001 [26:28<16:53,  2.09s/it, avg loss=192.7256]
Training iteration:  52%|█████▏    | 518/1001 [26:28<16:01,  1.99s/it, avg loss=192.7256]Checkpoint at iteration 518 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 192.72555694580078

Training iteration:  52%|█████▏    | 518/1001 [26:30<16:01,  1.99s/it, avg loss=208.7040]
Training iteration:  52%|█████▏    | 519/1001 [26:30<15:26,  1.92s/it, avg loss=208.7040]Checkpoint at iteration 519 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 208.70403594970702

Training iteration:  52%|█████▏    | 519/1001 [26:32<15:26,  1.92s/it, avg loss=166.4619]
Training iteration:  52%|█████▏    | 520/1001 [26:32<15:00,  1.87s/it, avg loss=166.4619]Checkpoint at iteration 520 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 166.46187057495118

Training iteration:  52%|█████▏    | 520/1001 [26:33<15:00,  1.87s/it, avg loss=180.0901]
Training iteration:  52%|█████▏    | 521/1001 [26:33<14:42,  1.84s/it, avg loss=180.0901]Checkpoint at iteration 521 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 180.09010009765626

Training iteration:  52%|█████▏    | 521/1001 [26:35<14:42,  1.84s/it, avg loss=182.9918]
Training iteration:  52%|█████▏    | 522/1001 [26:35<14:29,  1.81s/it, avg loss=182.9918]Checkpoint at iteration 522 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 182.99179077148438

Training iteration:  52%|█████▏    | 522/1001 [26:37<14:29,  1.81s/it, avg loss=200.1328]
Training iteration:  52%|█████▏    | 523/1001 [26:37<14:18,  1.80s/it, avg loss=200.1328]Checkpoint at iteration 523 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 200.13276596069335

Training iteration:  52%|█████▏    | 523/1001 [26:39<14:18,  1.80s/it, avg loss=164.5279]
Training iteration:  52%|█████▏    | 524/1001 [26:39<14:10,  1.78s/it, avg loss=164.5279]Checkpoint at iteration 524 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 164.52791900634764

Training iteration:  52%|█████▏    | 524/1001 [26:40<14:10,  1.78s/it, avg loss=144.6185]
Training iteration:  52%|█████▏    | 525/1001 [26:40<14:05,  1.78s/it, avg loss=144.6185]Checkpoint at iteration 525 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 144.618497467041

Training iteration:  52%|█████▏    | 525/1001 [26:42<14:05,  1.78s/it, avg loss=226.9512]
Training iteration:  53%|█████▎    | 526/1001 [26:42<14:01,  1.77s/it, avg loss=226.9512]Checkpoint at iteration 526 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 226.95121154785156

Training iteration:  53%|█████▎    | 526/1001 [26:44<14:01,  1.77s/it, avg loss=135.2978]
Training iteration:  53%|█████▎    | 527/1001 [26:44<13:59,  1.77s/it, avg loss=135.2978]Checkpoint at iteration 527 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 135.29778709411622

Training iteration:  53%|█████▎    | 527/1001 [26:46<13:59,  1.77s/it, avg loss=116.9530]
Training iteration:  53%|█████▎    | 528/1001 [26:46<13:55,  1.77s/it, avg loss=116.9530]Checkpoint at iteration 528 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 116.95298233032227

Training iteration:  53%|█████▎    | 528/1001 [26:47<13:55,  1.77s/it, avg loss=186.5619]
Training iteration:  53%|█████▎    | 529/1001 [26:47<13:52,  1.76s/it, avg loss=186.5619]Checkpoint at iteration 529 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 186.56193161010742

Training iteration:  53%|█████▎    | 529/1001 [26:49<13:52,  1.76s/it, avg loss=94.5154] 
Training iteration:  53%|█████▎    | 530/1001 [26:49<13:50,  1.76s/it, avg loss=94.5154]Checkpoint at iteration 530 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 94.51539611816406

Training iteration:  53%|█████▎    | 530/1001 [26:51<13:50,  1.76s/it, avg loss=105.6266]
Training iteration:  53%|█████▎    | 531/1001 [26:51<13:47,  1.76s/it, avg loss=105.6266]Checkpoint at iteration 531 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 105.62656059265137

Training iteration:  53%|█████▎    | 531/1001 [26:53<13:47,  1.76s/it, avg loss=136.0437]
Training iteration:  53%|█████▎    | 532/1001 [26:53<13:44,  1.76s/it, avg loss=136.0437]Checkpoint at iteration 532 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 136.04369506835937

Training iteration:  53%|█████▎    | 532/1001 [26:54<13:44,  1.76s/it, avg loss=189.5761]
Training iteration:  53%|█████▎    | 533/1001 [26:54<13:41,  1.76s/it, avg loss=189.5761]Checkpoint at iteration 533 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 189.5761245727539

Training iteration:  53%|█████▎    | 533/1001 [26:56<13:41,  1.76s/it, avg loss=235.0581]
Training iteration:  53%|█████▎    | 534/1001 [26:56<13:39,  1.76s/it, avg loss=235.0581]Checkpoint at iteration 534 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 235.05811080932617

Training iteration:  53%|█████▎    | 534/1001 [26:58<13:39,  1.76s/it, avg loss=219.0245]
Training iteration:  53%|█████▎    | 535/1001 [26:58<13:38,  1.76s/it, avg loss=219.0245]Checkpoint at iteration 535 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 219.0245262145996

Training iteration:  53%|█████▎    | 535/1001 [27:00<13:38,  1.76s/it, avg loss=104.3015]
Training iteration:  54%|█████▎    | 536/1001 [27:00<13:36,  1.76s/it, avg loss=104.3015]Checkpoint at iteration 536 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 104.30147705078124

Training iteration:  54%|█████▎    | 536/1001 [27:01<13:36,  1.76s/it, avg loss=179.1174]
Training iteration:  54%|█████▎    | 537/1001 [27:01<13:33,  1.75s/it, avg loss=179.1174]Checkpoint at iteration 537 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 179.1174289703369

Training iteration:  54%|█████▎    | 537/1001 [27:03<13:33,  1.75s/it, avg loss=214.4278]
Training iteration:  54%|█████▎    | 538/1001 [27:03<13:31,  1.75s/it, avg loss=214.4278]Checkpoint at iteration 538 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 214.42780609130858

Training iteration:  54%|█████▎    | 538/1001 [27:05<13:31,  1.75s/it, avg loss=142.8540]
Training iteration:  54%|█████▍    | 539/1001 [27:05<13:29,  1.75s/it, avg loss=142.8540]Checkpoint at iteration 539 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 142.85400390625

Training iteration:  54%|█████▍    | 539/1001 [27:07<13:29,  1.75s/it, avg loss=151.7183]
Training iteration:  54%|█████▍    | 540/1001 [27:07<13:28,  1.75s/it, avg loss=151.7183]Checkpoint at iteration 540 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 151.71834716796874

Training iteration:  54%|█████▍    | 540/1001 [27:08<13:28,  1.75s/it, avg loss=119.0835]
Training iteration:  54%|█████▍    | 541/1001 [27:08<13:26,  1.75s/it, avg loss=119.0835]Checkpoint at iteration 541 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 119.08353309631347

Training iteration:  54%|█████▍    | 541/1001 [27:10<13:26,  1.75s/it, avg loss=163.1178]
Training iteration:  54%|█████▍    | 542/1001 [27:10<13:25,  1.76s/it, avg loss=163.1178]Checkpoint at iteration 542 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 163.11776123046874

Training iteration:  54%|█████▍    | 542/1001 [27:12<13:25,  1.76s/it, avg loss=101.5517]
Training iteration:  54%|█████▍    | 543/1001 [27:12<13:23,  1.75s/it, avg loss=101.5517]Checkpoint at iteration 543 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 101.55168418884277

Training iteration:  54%|█████▍    | 543/1001 [27:14<13:23,  1.75s/it, avg loss=196.3535]
Training iteration:  54%|█████▍    | 544/1001 [27:14<13:21,  1.75s/it, avg loss=196.3535]Checkpoint at iteration 544 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 196.35352020263673

Training iteration:  54%|█████▍    | 544/1001 [27:16<13:21,  1.75s/it, avg loss=187.5553]
Training iteration:  54%|█████▍    | 545/1001 [27:16<13:19,  1.75s/it, avg loss=187.5553]Checkpoint at iteration 545 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 187.55525093078614

Training iteration:  54%|█████▍    | 545/1001 [27:17<13:19,  1.75s/it, avg loss=174.1303]
Training iteration:  55%|█████▍    | 546/1001 [27:17<13:17,  1.75s/it, avg loss=174.1303]Checkpoint at iteration 546 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 174.13027801513672

Training iteration:  55%|█████▍    | 546/1001 [27:19<13:17,  1.75s/it, avg loss=167.3066]
Training iteration:  55%|█████▍    | 547/1001 [27:19<13:15,  1.75s/it, avg loss=167.3066]Checkpoint at iteration 547 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 167.306640625

Training iteration:  55%|█████▍    | 547/1001 [27:21<13:15,  1.75s/it, avg loss=179.9210]
Training iteration:  55%|█████▍    | 548/1001 [27:21<13:14,  1.75s/it, avg loss=179.9210]Checkpoint at iteration 548 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 179.92101516723633

Training iteration:  55%|█████▍    | 548/1001 [27:23<13:14,  1.75s/it, avg loss=159.0972]
Training iteration:  55%|█████▍    | 549/1001 [27:23<13:12,  1.75s/it, avg loss=159.0972]Checkpoint at iteration 549 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 159.09717254638673

Training iteration:  55%|█████▍    | 549/1001 [27:24<13:12,  1.75s/it, avg loss=184.6959]
Training iteration:  55%|█████▍    | 550/1001 [27:24<13:10,  1.75s/it, avg loss=184.6959]Checkpoint at iteration 550 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 184.69589233398438

Training iteration:  55%|█████▍    | 550/1001 [27:26<13:10,  1.75s/it, avg loss=229.9793]
Training iteration:  55%|█████▌    | 551/1001 [27:26<13:09,  1.75s/it, avg loss=229.9793]Checkpoint at iteration 551 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 229.9792907714844

Training iteration:  55%|█████▌    | 551/1001 [27:28<13:09,  1.75s/it, avg loss=191.1025]
Training iteration:  55%|█████▌    | 552/1001 [27:28<13:07,  1.75s/it, avg loss=191.1025]Checkpoint at iteration 552 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 191.10248794555665

Training iteration:  55%|█████▌    | 552/1001 [27:30<13:07,  1.75s/it, avg loss=149.2367]
Training iteration:  55%|█████▌    | 553/1001 [27:30<13:06,  1.75s/it, avg loss=149.2367]Checkpoint at iteration 553 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 149.23670692443847

Training iteration:  55%|█████▌    | 553/1001 [27:31<13:06,  1.75s/it, avg loss=205.9620]
Training iteration:  55%|█████▌    | 554/1001 [27:31<13:04,  1.76s/it, avg loss=205.9620]Checkpoint at iteration 554 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 205.96198348999025

Training iteration:  55%|█████▌    | 554/1001 [27:33<13:04,  1.76s/it, avg loss=125.8702]
Training iteration:  55%|█████▌    | 555/1001 [27:33<13:02,  1.76s/it, avg loss=125.8702]Checkpoint at iteration 555 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 125.87017211914062

Training iteration:  55%|█████▌    | 555/1001 [27:35<13:02,  1.76s/it, avg loss=172.1956]
Training iteration:  56%|█████▌    | 556/1001 [27:35<13:01,  1.76s/it, avg loss=172.1956]Checkpoint at iteration 556 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 172.19560737609862

Training iteration:  56%|█████▌    | 556/1001 [27:37<13:01,  1.76s/it, avg loss=189.1673]
Training iteration:  56%|█████▌    | 557/1001 [27:37<12:58,  1.75s/it, avg loss=189.1673]Checkpoint at iteration 557 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 189.16732635498047

Training iteration:  56%|█████▌    | 557/1001 [27:38<12:58,  1.75s/it, avg loss=128.9904]
Training iteration:  56%|█████▌    | 558/1001 [27:38<12:56,  1.75s/it, avg loss=128.9904]Checkpoint at iteration 558 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 128.9904384613037

Training iteration:  56%|█████▌    | 558/1001 [27:40<12:56,  1.75s/it, avg loss=99.4578] 
Training iteration:  56%|█████▌    | 559/1001 [27:40<12:55,  1.75s/it, avg loss=99.4578]Checkpoint at iteration 559 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 99.45781555175782

Training iteration:  56%|█████▌    | 559/1001 [27:42<12:55,  1.75s/it, avg loss=128.0526]
Training iteration:  56%|█████▌    | 560/1001 [27:42<12:53,  1.75s/it, avg loss=128.0526]Checkpoint at iteration 560 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 128.05263595581056

Training iteration:  56%|█████▌    | 560/1001 [27:44<12:53,  1.75s/it, avg loss=215.9063]
Training iteration:  56%|█████▌    | 561/1001 [27:44<12:51,  1.75s/it, avg loss=215.9063]Checkpoint at iteration 561 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 215.90626754760743

Training iteration:  56%|█████▌    | 561/1001 [27:45<12:51,  1.75s/it, avg loss=105.9634]
Training iteration:  56%|█████▌    | 562/1001 [27:45<12:50,  1.75s/it, avg loss=105.9634]Checkpoint at iteration 562 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 105.96339149475098

Training iteration:  56%|█████▌    | 562/1001 [27:47<12:50,  1.75s/it, avg loss=237.3700]
Training iteration:  56%|█████▌    | 563/1001 [27:47<12:48,  1.75s/it, avg loss=237.3700]Checkpoint at iteration 563 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 237.3700180053711

Training iteration:  56%|█████▌    | 563/1001 [27:49<12:48,  1.75s/it, avg loss=104.5117]
Training iteration:  56%|█████▋    | 564/1001 [27:49<12:46,  1.75s/it, avg loss=104.5117]Checkpoint at iteration 564 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 104.51173896789551

Training iteration:  56%|█████▋    | 564/1001 [27:51<12:46,  1.75s/it, avg loss=124.8060]
Training iteration:  56%|█████▋    | 565/1001 [27:51<12:44,  1.75s/it, avg loss=124.8060]Checkpoint at iteration 565 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 124.8060459136963

Training iteration:  56%|█████▋    | 565/1001 [27:52<12:44,  1.75s/it, avg loss=206.9090]
Training iteration:  57%|█████▋    | 566/1001 [27:52<12:42,  1.75s/it, avg loss=206.9090]Checkpoint at iteration 566 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 206.90898742675782

Training iteration:  57%|█████▋    | 566/1001 [27:54<12:42,  1.75s/it, avg loss=214.3125]
Training iteration:  57%|█████▋    | 567/1001 [27:54<12:40,  1.75s/it, avg loss=214.3125]Checkpoint at iteration 567 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 214.31254348754882

Training iteration:  57%|█████▋    | 567/1001 [27:56<12:40,  1.75s/it, avg loss=143.1154]
Training iteration:  57%|█████▋    | 568/1001 [27:56<12:38,  1.75s/it, avg loss=143.1154]Checkpoint at iteration 568 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 143.11537399291993

Training iteration:  57%|█████▋    | 568/1001 [27:58<12:38,  1.75s/it, avg loss=180.3020]
Training iteration:  57%|█████▋    | 569/1001 [27:58<12:36,  1.75s/it, avg loss=180.3020]Checkpoint at iteration 569 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 180.30198364257814

Training iteration:  57%|█████▋    | 569/1001 [27:59<12:36,  1.75s/it, avg loss=138.2259]
Training iteration:  57%|█████▋    | 570/1001 [27:59<12:34,  1.75s/it, avg loss=138.2259]Checkpoint at iteration 570 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 138.22591819763184

Training iteration:  57%|█████▋    | 570/1001 [28:01<12:34,  1.75s/it, avg loss=195.7477]
Training iteration:  57%|█████▋    | 571/1001 [28:01<12:32,  1.75s/it, avg loss=195.7477]Checkpoint at iteration 571 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 195.74770278930663

Training iteration:  57%|█████▋    | 571/1001 [28:03<12:32,  1.75s/it, avg loss=181.1559]
Training iteration:  57%|█████▋    | 572/1001 [28:03<12:30,  1.75s/it, avg loss=181.1559]Checkpoint at iteration 572 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 181.15586700439454

Training iteration:  57%|█████▋    | 572/1001 [28:05<12:30,  1.75s/it, avg loss=216.5148]
Training iteration:  57%|█████▋    | 573/1001 [28:05<12:28,  1.75s/it, avg loss=216.5148]Checkpoint at iteration 573 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 216.514794921875

Training iteration:  57%|█████▋    | 573/1001 [28:06<12:28,  1.75s/it, avg loss=188.3319]
Training iteration:  57%|█████▋    | 574/1001 [28:06<12:27,  1.75s/it, avg loss=188.3319]Checkpoint at iteration 574 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 188.33194732666016

Training iteration:  57%|█████▋    | 574/1001 [28:08<12:27,  1.75s/it, avg loss=101.5262]
Training iteration:  57%|█████▋    | 575/1001 [28:08<12:25,  1.75s/it, avg loss=101.5262]Checkpoint at iteration 575 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 101.52620544433594

Training iteration:  57%|█████▋    | 575/1001 [28:10<12:25,  1.75s/it, avg loss=211.8251]
Training iteration:  58%|█████▊    | 576/1001 [28:10<12:24,  1.75s/it, avg loss=211.8251]Checkpoint at iteration 576 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 211.82506103515624

Training iteration:  58%|█████▊    | 576/1001 [28:12<12:24,  1.75s/it, avg loss=163.2468]
Training iteration:  58%|█████▊    | 577/1001 [28:12<12:22,  1.75s/it, avg loss=163.2468]Checkpoint at iteration 577 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 163.24683532714843

Training iteration:  58%|█████▊    | 577/1001 [28:13<12:22,  1.75s/it, avg loss=206.7233]
Training iteration:  58%|█████▊    | 578/1001 [28:13<12:21,  1.75s/it, avg loss=206.7233]Checkpoint at iteration 578 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 206.72328033447266

Training iteration:  58%|█████▊    | 578/1001 [28:15<12:21,  1.75s/it, avg loss=162.9259]
Training iteration:  58%|█████▊    | 579/1001 [28:15<12:19,  1.75s/it, avg loss=162.9259]Checkpoint at iteration 579 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 162.92590408325196

Training iteration:  58%|█████▊    | 579/1001 [28:17<12:19,  1.75s/it, avg loss=165.9426]
Training iteration:  58%|█████▊    | 580/1001 [28:17<12:17,  1.75s/it, avg loss=165.9426]Checkpoint at iteration 580 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 165.942635345459

Training iteration:  58%|█████▊    | 580/1001 [28:19<12:17,  1.75s/it, avg loss=185.9239]
Training iteration:  58%|█████▊    | 581/1001 [28:19<12:14,  1.75s/it, avg loss=185.9239]Checkpoint at iteration 581 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 185.92394256591797

Training iteration:  58%|█████▊    | 581/1001 [28:20<12:14,  1.75s/it, avg loss=239.3235]
Training iteration:  58%|█████▊    | 582/1001 [28:20<12:12,  1.75s/it, avg loss=239.3235]Checkpoint at iteration 582 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 239.32348403930663

Training iteration:  58%|█████▊    | 582/1001 [28:22<12:12,  1.75s/it, avg loss=303.9681]
Training iteration:  58%|█████▊    | 583/1001 [28:22<12:10,  1.75s/it, avg loss=303.9681]Checkpoint at iteration 583 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 303.968091583252

Training iteration:  58%|█████▊    | 583/1001 [28:24<12:10,  1.75s/it, avg loss=170.0597]
Training iteration:  58%|█████▊    | 584/1001 [28:24<12:09,  1.75s/it, avg loss=170.0597]Checkpoint at iteration 584 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 170.05974273681642

Training iteration:  58%|█████▊    | 584/1001 [28:26<12:09,  1.75s/it, avg loss=111.8704]
Training iteration:  58%|█████▊    | 585/1001 [28:26<12:07,  1.75s/it, avg loss=111.8704]Checkpoint at iteration 585 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 111.87044372558594

Training iteration:  58%|█████▊    | 585/1001 [28:27<12:07,  1.75s/it, avg loss=133.5276]
Training iteration:  59%|█████▊    | 586/1001 [28:27<12:05,  1.75s/it, avg loss=133.5276]Checkpoint at iteration 586 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 133.52760314941406

Training iteration:  59%|█████▊    | 586/1001 [28:29<12:05,  1.75s/it, avg loss=167.8228]
Training iteration:  59%|█████▊    | 587/1001 [28:29<12:03,  1.75s/it, avg loss=167.8228]Checkpoint at iteration 587 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 167.82275848388673

Training iteration:  59%|█████▊    | 587/1001 [28:31<12:03,  1.75s/it, avg loss=138.0676]
Training iteration:  59%|█████▊    | 588/1001 [28:31<12:01,  1.75s/it, avg loss=138.0676]Checkpoint at iteration 588 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 138.06763153076173

Training iteration:  59%|█████▊    | 588/1001 [28:33<12:01,  1.75s/it, avg loss=197.0721]
Training iteration:  59%|█████▉    | 589/1001 [28:33<11:59,  1.75s/it, avg loss=197.0721]Checkpoint at iteration 589 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 197.07214584350587

Training iteration:  59%|█████▉    | 589/1001 [28:34<11:59,  1.75s/it, avg loss=147.8033]
Training iteration:  59%|█████▉    | 590/1001 [28:34<11:57,  1.75s/it, avg loss=147.8033]Checkpoint at iteration 590 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 147.80334281921387

Training iteration:  59%|█████▉    | 590/1001 [28:36<11:57,  1.75s/it, avg loss=175.7780]
Training iteration:  59%|█████▉    | 591/1001 [28:36<11:55,  1.75s/it, avg loss=175.7780]Checkpoint at iteration 591 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 175.77800216674805

Training iteration:  59%|█████▉    | 591/1001 [28:38<11:55,  1.75s/it, avg loss=175.4213]
Training iteration:  59%|█████▉    | 592/1001 [28:38<11:54,  1.75s/it, avg loss=175.4213]Checkpoint at iteration 592 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 175.42125396728517

Training iteration:  59%|█████▉    | 592/1001 [28:40<11:54,  1.75s/it, avg loss=136.2434]
Training iteration:  59%|█████▉    | 593/1001 [28:40<11:52,  1.75s/it, avg loss=136.2434]Checkpoint at iteration 593 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 136.24343872070312

Training iteration:  59%|█████▉    | 593/1001 [28:41<11:52,  1.75s/it, avg loss=127.1575]
Training iteration:  59%|█████▉    | 594/1001 [28:41<11:50,  1.75s/it, avg loss=127.1575]Checkpoint at iteration 594 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 127.15752792358398

Training iteration:  59%|█████▉    | 594/1001 [28:43<11:50,  1.75s/it, avg loss=162.1562]
Training iteration:  59%|█████▉    | 595/1001 [28:43<11:48,  1.75s/it, avg loss=162.1562]Checkpoint at iteration 595 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 162.15618858337402

Training iteration:  59%|█████▉    | 595/1001 [28:45<11:48,  1.75s/it, avg loss=111.1610]
Training iteration:  60%|█████▉    | 596/1001 [28:45<11:47,  1.75s/it, avg loss=111.1610]Checkpoint at iteration 596 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 111.16096801757813

Training iteration:  60%|█████▉    | 596/1001 [28:47<11:47,  1.75s/it, avg loss=173.5382]
Training iteration:  60%|█████▉    | 597/1001 [28:47<11:45,  1.75s/it, avg loss=173.5382]Checkpoint at iteration 597 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 173.53817329406738

Training iteration:  60%|█████▉    | 597/1001 [28:48<11:45,  1.75s/it, avg loss=242.8582]
Training iteration:  60%|█████▉    | 598/1001 [28:48<11:43,  1.75s/it, avg loss=242.8582]Checkpoint at iteration 598 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 242.8581527709961

Training iteration:  60%|█████▉    | 598/1001 [28:50<11:43,  1.75s/it, avg loss=177.3402]
Training iteration:  60%|█████▉    | 599/1001 [28:50<11:41,  1.74s/it, avg loss=177.3402]Checkpoint at iteration 599 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 177.34015731811525

Training iteration:  60%|█████▉    | 599/1001 [28:52<11:41,  1.74s/it, avg loss=201.9571]
Training iteration:  60%|█████▉    | 600/1001 [28:52<11:39,  1.75s/it, avg loss=201.9571]Optimization iteration 600 evaluation begins...
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
A new evaluation visualization has been saved: ./saved_data/20240110-063719/it600.png
Training network 0 for evaluation...
Training network 1 for evaluation...
Training network 2 for evaluation...
Training network 3 for evaluation...
Testing network 0 on real datasets for evaluation...
Testing network 1 on real datasets for evaluation...
Testing network 2 on real datasets for evaluation...
Testing network 3 on real datasets for evaluation...
Optimization iteration 600, eval auroc score (train): 20006.6843, eval auroc score (test): 20685.6159
Checkpoint at iteration 600 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 201.95708084106445

Training iteration:  60%|█████▉    | 600/1001 [35:54<11:39,  1.75s/it, avg loss=128.5300]
Training iteration:  60%|██████    | 601/1001 [35:54<14:13:33, 128.03s/it, avg loss=128.5300]Checkpoint at iteration 601 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 128.53000144958497

Training iteration:  60%|██████    | 601/1001 [35:56<14:13:33, 128.03s/it, avg loss=172.0164]
Training iteration:  60%|██████    | 602/1001 [35:56<9:59:56, 90.22s/it, avg loss=172.0164]  Checkpoint at iteration 602 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 172.01635818481446

Training iteration:  60%|██████    | 602/1001 [35:58<9:59:56, 90.22s/it, avg loss=143.9708]
Training iteration:  60%|██████    | 603/1001 [35:58<7:02:50, 63.75s/it, avg loss=143.9708]Checkpoint at iteration 603 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 143.97075119018555

Training iteration:  60%|██████    | 603/1001 [36:00<7:02:50, 63.75s/it, avg loss=161.3080]
Training iteration:  60%|██████    | 604/1001 [36:00<4:59:10, 45.22s/it, avg loss=161.3080]Checkpoint at iteration 604 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 161.30799446105956

Training iteration:  60%|██████    | 604/1001 [36:02<4:59:10, 45.22s/it, avg loss=195.6270]
Training iteration:  60%|██████    | 605/1001 [36:02<3:32:47, 32.24s/it, avg loss=195.6270]Checkpoint at iteration 605 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 195.62697372436523

Training iteration:  60%|██████    | 605/1001 [36:04<3:32:47, 32.24s/it, avg loss=152.3480]
Training iteration:  61%|██████    | 606/1001 [36:04<2:32:29, 23.16s/it, avg loss=152.3480]Checkpoint at iteration 606 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 152.34797897338868

Training iteration:  61%|██████    | 606/1001 [36:06<2:32:29, 23.16s/it, avg loss=166.6947]
Training iteration:  61%|██████    | 607/1001 [36:06<1:50:21, 16.81s/it, avg loss=166.6947]Checkpoint at iteration 607 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 166.69466171264648

Training iteration:  61%|██████    | 607/1001 [36:08<1:50:21, 16.81s/it, avg loss=221.0896]
Training iteration:  61%|██████    | 608/1001 [36:08<1:20:56, 12.36s/it, avg loss=221.0896]Checkpoint at iteration 608 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 221.0895637512207

Training iteration:  61%|██████    | 608/1001 [36:10<1:20:56, 12.36s/it, avg loss=115.5104]
Training iteration:  61%|██████    | 609/1001 [36:10<1:00:24,  9.25s/it, avg loss=115.5104]Checkpoint at iteration 609 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 115.5104148864746

Training iteration:  61%|██████    | 609/1001 [36:12<1:00:24,  9.25s/it, avg loss=221.7519]
Training iteration:  61%|██████    | 610/1001 [36:12<46:02,  7.07s/it, avg loss=221.7519]  Checkpoint at iteration 610 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 221.75191650390624

Training iteration:  61%|██████    | 610/1001 [36:14<46:02,  7.07s/it, avg loss=139.1922]
Training iteration:  61%|██████    | 611/1001 [36:14<36:00,  5.54s/it, avg loss=139.1922]Checkpoint at iteration 611 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 139.19217071533203

Training iteration:  61%|██████    | 611/1001 [36:16<36:00,  5.54s/it, avg loss=157.1973]
Training iteration:  61%|██████    | 612/1001 [36:16<28:58,  4.47s/it, avg loss=157.1973]Checkpoint at iteration 612 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 157.19728317260743

Training iteration:  61%|██████    | 612/1001 [36:18<28:58,  4.47s/it, avg loss=130.3819]
Training iteration:  61%|██████    | 613/1001 [36:18<24:04,  3.72s/it, avg loss=130.3819]Checkpoint at iteration 613 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 130.38185119628906

Training iteration:  61%|██████    | 613/1001 [36:20<24:04,  3.72s/it, avg loss=169.0024]
Training iteration:  61%|██████▏   | 614/1001 [36:20<20:38,  3.20s/it, avg loss=169.0024]Checkpoint at iteration 614 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 169.00242614746094

Training iteration:  61%|██████▏   | 614/1001 [36:22<20:38,  3.20s/it, avg loss=144.8336]
Training iteration:  61%|██████▏   | 615/1001 [36:22<18:13,  2.83s/it, avg loss=144.8336]Checkpoint at iteration 615 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 144.83364334106446

Training iteration:  61%|██████▏   | 615/1001 [36:24<18:13,  2.83s/it, avg loss=176.6968]
Training iteration:  62%|██████▏   | 616/1001 [36:24<16:31,  2.58s/it, avg loss=176.6968]Checkpoint at iteration 616 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 176.6967617034912

Training iteration:  62%|██████▏   | 616/1001 [36:26<16:31,  2.58s/it, avg loss=130.4740]
Training iteration:  62%|██████▏   | 617/1001 [36:26<15:20,  2.40s/it, avg loss=130.4740]Checkpoint at iteration 617 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 130.4740135192871

Training iteration:  62%|██████▏   | 617/1001 [36:28<15:20,  2.40s/it, avg loss=152.7353]
Training iteration:  62%|██████▏   | 618/1001 [36:28<14:30,  2.27s/it, avg loss=152.7353]Checkpoint at iteration 618 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 152.73527984619142

Training iteration:  62%|██████▏   | 618/1001 [36:30<14:30,  2.27s/it, avg loss=198.4132]
Training iteration:  62%|██████▏   | 619/1001 [36:30<13:54,  2.19s/it, avg loss=198.4132]Checkpoint at iteration 619 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 198.41321487426757

Training iteration:  62%|██████▏   | 619/1001 [36:32<13:54,  2.19s/it, avg loss=214.6344]
Training iteration:  62%|██████▏   | 620/1001 [36:32<13:28,  2.12s/it, avg loss=214.6344]Checkpoint at iteration 620 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 214.6344467163086

Training iteration:  62%|██████▏   | 620/1001 [36:34<13:28,  2.12s/it, avg loss=210.6813]
Training iteration:  62%|██████▏   | 621/1001 [36:34<13:10,  2.08s/it, avg loss=210.6813]Checkpoint at iteration 621 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 210.68130645751953

Training iteration:  62%|██████▏   | 621/1001 [36:36<13:10,  2.08s/it, avg loss=168.4948]
Training iteration:  62%|██████▏   | 622/1001 [36:36<12:56,  2.05s/it, avg loss=168.4948]Checkpoint at iteration 622 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 168.4947681427002

Training iteration:  62%|██████▏   | 622/1001 [36:38<12:56,  2.05s/it, avg loss=223.5943]
Training iteration:  62%|██████▏   | 623/1001 [36:38<12:46,  2.03s/it, avg loss=223.5943]Checkpoint at iteration 623 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 223.59432830810547

Training iteration:  62%|██████▏   | 623/1001 [36:40<12:46,  2.03s/it, avg loss=196.5630]
Training iteration:  62%|██████▏   | 624/1001 [36:40<12:38,  2.01s/it, avg loss=196.5630]Checkpoint at iteration 624 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 196.56298332214357

Training iteration:  62%|██████▏   | 624/1001 [36:42<12:38,  2.01s/it, avg loss=223.6373]
Training iteration:  62%|██████▏   | 625/1001 [36:42<12:33,  2.00s/it, avg loss=223.6373]Checkpoint at iteration 625 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 223.6373306274414

Training iteration:  62%|██████▏   | 625/1001 [36:44<12:33,  2.00s/it, avg loss=139.2196]
Training iteration:  63%|██████▎   | 626/1001 [36:44<12:28,  2.00s/it, avg loss=139.2196]Checkpoint at iteration 626 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 139.2195831298828

Training iteration:  63%|██████▎   | 626/1001 [36:46<12:28,  2.00s/it, avg loss=171.8664]
Training iteration:  63%|██████▎   | 627/1001 [36:46<12:24,  1.99s/it, avg loss=171.8664]Checkpoint at iteration 627 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 171.8663558959961

Training iteration:  63%|██████▎   | 627/1001 [36:48<12:24,  1.99s/it, avg loss=154.1779]
Training iteration:  63%|██████▎   | 628/1001 [36:48<12:21,  1.99s/it, avg loss=154.1779]Checkpoint at iteration 628 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 154.17791748046875

Training iteration:  63%|██████▎   | 628/1001 [36:50<12:21,  1.99s/it, avg loss=218.5061]
Training iteration:  63%|██████▎   | 629/1001 [36:50<12:18,  1.98s/it, avg loss=218.5061]Checkpoint at iteration 629 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 218.50605812072754

Training iteration:  63%|██████▎   | 629/1001 [36:52<12:18,  1.98s/it, avg loss=152.2380]
Training iteration:  63%|██████▎   | 630/1001 [36:52<12:15,  1.98s/it, avg loss=152.2380]Checkpoint at iteration 630 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 152.2380470275879

Training iteration:  63%|██████▎   | 630/1001 [36:54<12:15,  1.98s/it, avg loss=150.9199]
Training iteration:  63%|██████▎   | 631/1001 [36:54<12:13,  1.98s/it, avg loss=150.9199]Checkpoint at iteration 631 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 150.91985549926758

Training iteration:  63%|██████▎   | 631/1001 [36:56<12:13,  1.98s/it, avg loss=203.1562]
Training iteration:  63%|██████▎   | 632/1001 [36:56<12:10,  1.98s/it, avg loss=203.1562]Checkpoint at iteration 632 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 203.15624046325684

Training iteration:  63%|██████▎   | 632/1001 [36:58<12:10,  1.98s/it, avg loss=138.3910]
Training iteration:  63%|██████▎   | 633/1001 [36:58<12:08,  1.98s/it, avg loss=138.3910]Checkpoint at iteration 633 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 138.39095077514648

Training iteration:  63%|██████▎   | 633/1001 [37:00<12:08,  1.98s/it, avg loss=120.1403]
Training iteration:  63%|██████▎   | 634/1001 [37:00<12:06,  1.98s/it, avg loss=120.1403]Checkpoint at iteration 634 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 120.14034957885742

Training iteration:  63%|██████▎   | 634/1001 [37:02<12:06,  1.98s/it, avg loss=155.2948]
Training iteration:  63%|██████▎   | 635/1001 [37:02<12:04,  1.98s/it, avg loss=155.2948]Checkpoint at iteration 635 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 155.2948341369629

Training iteration:  63%|██████▎   | 635/1001 [37:04<12:04,  1.98s/it, avg loss=185.1485]
Training iteration:  64%|██████▎   | 636/1001 [37:04<12:02,  1.98s/it, avg loss=185.1485]Checkpoint at iteration 636 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 185.14853439331054

Training iteration:  64%|██████▎   | 636/1001 [37:06<12:02,  1.98s/it, avg loss=225.8505]
Training iteration:  64%|██████▎   | 637/1001 [37:06<12:00,  1.98s/it, avg loss=225.8505]Checkpoint at iteration 637 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 225.85049362182616

Training iteration:  64%|██████▎   | 637/1001 [37:08<12:00,  1.98s/it, avg loss=159.5171]
Training iteration:  64%|██████▎   | 638/1001 [37:08<11:58,  1.98s/it, avg loss=159.5171]Checkpoint at iteration 638 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 159.51707763671874

Training iteration:  64%|██████▎   | 638/1001 [37:10<11:58,  1.98s/it, avg loss=118.1157]
Training iteration:  64%|██████▍   | 639/1001 [37:10<11:56,  1.98s/it, avg loss=118.1157]Checkpoint at iteration 639 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 118.11568679809571

Training iteration:  64%|██████▍   | 639/1001 [37:12<11:56,  1.98s/it, avg loss=231.7227]
Training iteration:  64%|██████▍   | 640/1001 [37:12<11:54,  1.98s/it, avg loss=231.7227]Checkpoint at iteration 640 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 231.72266998291016

Training iteration:  64%|██████▍   | 640/1001 [37:14<11:54,  1.98s/it, avg loss=153.8918]
Training iteration:  64%|██████▍   | 641/1001 [37:14<11:52,  1.98s/it, avg loss=153.8918]Checkpoint at iteration 641 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 153.89180068969728

Training iteration:  64%|██████▍   | 641/1001 [37:16<11:52,  1.98s/it, avg loss=255.2990]
Training iteration:  64%|██████▍   | 642/1001 [37:16<11:50,  1.98s/it, avg loss=255.2990]Checkpoint at iteration 642 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 255.29899826049805

Training iteration:  64%|██████▍   | 642/1001 [37:18<11:50,  1.98s/it, avg loss=143.6603]
Training iteration:  64%|██████▍   | 643/1001 [37:18<11:48,  1.98s/it, avg loss=143.6603]Checkpoint at iteration 643 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 143.66034622192382

Training iteration:  64%|██████▍   | 643/1001 [37:20<11:48,  1.98s/it, avg loss=123.3351]
Training iteration:  64%|██████▍   | 644/1001 [37:20<11:46,  1.98s/it, avg loss=123.3351]Checkpoint at iteration 644 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 123.33506660461425

Training iteration:  64%|██████▍   | 644/1001 [37:22<11:46,  1.98s/it, avg loss=263.5050]
Training iteration:  64%|██████▍   | 645/1001 [37:22<11:44,  1.98s/it, avg loss=263.5050]Checkpoint at iteration 645 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 263.50502700805663

Training iteration:  64%|██████▍   | 645/1001 [37:24<11:44,  1.98s/it, avg loss=189.0688]
Training iteration:  65%|██████▍   | 646/1001 [37:24<11:42,  1.98s/it, avg loss=189.0688]Checkpoint at iteration 646 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 189.06878356933595

Training iteration:  65%|██████▍   | 646/1001 [37:25<11:42,  1.98s/it, avg loss=139.2156]
Training iteration:  65%|██████▍   | 647/1001 [37:25<11:40,  1.98s/it, avg loss=139.2156]Checkpoint at iteration 647 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 139.21562118530272

Training iteration:  65%|██████▍   | 647/1001 [37:27<11:40,  1.98s/it, avg loss=230.7893]
Training iteration:  65%|██████▍   | 648/1001 [37:27<11:38,  1.98s/it, avg loss=230.7893]Checkpoint at iteration 648 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 230.7893253326416

Training iteration:  65%|██████▍   | 648/1001 [37:29<11:38,  1.98s/it, avg loss=131.1107]
Training iteration:  65%|██████▍   | 649/1001 [37:29<11:36,  1.98s/it, avg loss=131.1107]Checkpoint at iteration 649 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 131.110737991333

Training iteration:  65%|██████▍   | 649/1001 [37:31<11:36,  1.98s/it, avg loss=95.9249] 
Training iteration:  65%|██████▍   | 650/1001 [37:31<11:35,  1.98s/it, avg loss=95.9249]Checkpoint at iteration 650 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 95.92490463256836

Training iteration:  65%|██████▍   | 650/1001 [37:33<11:35,  1.98s/it, avg loss=186.4790]
Training iteration:  65%|██████▌   | 651/1001 [37:33<11:33,  1.98s/it, avg loss=186.4790]Checkpoint at iteration 651 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 186.47902030944823

Training iteration:  65%|██████▌   | 651/1001 [37:35<11:33,  1.98s/it, avg loss=134.2641]
Training iteration:  65%|██████▌   | 652/1001 [37:35<11:30,  1.98s/it, avg loss=134.2641]Checkpoint at iteration 652 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 134.2641273498535

Training iteration:  65%|██████▌   | 652/1001 [37:37<11:30,  1.98s/it, avg loss=203.2545]
Training iteration:  65%|██████▌   | 653/1001 [37:37<11:28,  1.98s/it, avg loss=203.2545]Checkpoint at iteration 653 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 203.25449600219727

Training iteration:  65%|██████▌   | 653/1001 [37:39<11:28,  1.98s/it, avg loss=145.7599]
Training iteration:  65%|██████▌   | 654/1001 [37:39<11:26,  1.98s/it, avg loss=145.7599]Checkpoint at iteration 654 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 145.75988121032714

Training iteration:  65%|██████▌   | 654/1001 [37:41<11:26,  1.98s/it, avg loss=230.7112]
Training iteration:  65%|██████▌   | 655/1001 [37:41<11:23,  1.98s/it, avg loss=230.7112]Checkpoint at iteration 655 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 230.71124954223632

Training iteration:  65%|██████▌   | 655/1001 [37:43<11:23,  1.98s/it, avg loss=178.0996]
Training iteration:  66%|██████▌   | 656/1001 [37:43<11:21,  1.98s/it, avg loss=178.0996]Checkpoint at iteration 656 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 178.09955215454102

Training iteration:  66%|██████▌   | 656/1001 [37:45<11:21,  1.98s/it, avg loss=139.3731]
Training iteration:  66%|██████▌   | 657/1001 [37:45<11:20,  1.98s/it, avg loss=139.3731]Checkpoint at iteration 657 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 139.37307434082032

Training iteration:  66%|██████▌   | 657/1001 [37:47<11:20,  1.98s/it, avg loss=117.6459]
Training iteration:  66%|██████▌   | 658/1001 [37:47<11:18,  1.98s/it, avg loss=117.6459]Checkpoint at iteration 658 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 117.64590263366699

Training iteration:  66%|██████▌   | 658/1001 [37:49<11:18,  1.98s/it, avg loss=197.8312]
Training iteration:  66%|██████▌   | 659/1001 [37:49<11:16,  1.98s/it, avg loss=197.8312]Checkpoint at iteration 659 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 197.83120727539062

Training iteration:  66%|██████▌   | 659/1001 [37:51<11:16,  1.98s/it, avg loss=157.5081]
Training iteration:  66%|██████▌   | 660/1001 [37:51<11:14,  1.98s/it, avg loss=157.5081]Checkpoint at iteration 660 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 157.50808563232422

Training iteration:  66%|██████▌   | 660/1001 [37:53<11:14,  1.98s/it, avg loss=153.3963]
Training iteration:  66%|██████▌   | 661/1001 [37:53<11:12,  1.98s/it, avg loss=153.3963]Checkpoint at iteration 661 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 153.39629440307618

Training iteration:  66%|██████▌   | 661/1001 [37:55<11:12,  1.98s/it, avg loss=164.5963]
Training iteration:  66%|██████▌   | 662/1001 [37:55<11:10,  1.98s/it, avg loss=164.5963]Checkpoint at iteration 662 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 164.59627685546874

Training iteration:  66%|██████▌   | 662/1001 [37:57<11:10,  1.98s/it, avg loss=207.8950]
Training iteration:  66%|██████▌   | 663/1001 [37:57<11:08,  1.98s/it, avg loss=207.8950]Checkpoint at iteration 663 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 207.8950050354004

Training iteration:  66%|██████▌   | 663/1001 [37:59<11:08,  1.98s/it, avg loss=126.6129]
Training iteration:  66%|██████▋   | 664/1001 [37:59<11:06,  1.98s/it, avg loss=126.6129]Checkpoint at iteration 664 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 126.61288414001464

Training iteration:  66%|██████▋   | 664/1001 [38:01<11:06,  1.98s/it, avg loss=156.1230]
Training iteration:  66%|██████▋   | 665/1001 [38:01<11:04,  1.98s/it, avg loss=156.1230]Checkpoint at iteration 665 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 156.12301902770997

Training iteration:  66%|██████▋   | 665/1001 [38:03<11:04,  1.98s/it, avg loss=172.0487]
Training iteration:  67%|██████▋   | 666/1001 [38:03<11:02,  1.98s/it, avg loss=172.0487]Checkpoint at iteration 666 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 172.0486686706543

Training iteration:  67%|██████▋   | 666/1001 [38:05<11:02,  1.98s/it, avg loss=187.0162]
Training iteration:  67%|██████▋   | 667/1001 [38:05<11:00,  1.98s/it, avg loss=187.0162]Checkpoint at iteration 667 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 187.016202545166

Training iteration:  67%|██████▋   | 667/1001 [38:07<11:00,  1.98s/it, avg loss=185.2712]
Training iteration:  67%|██████▋   | 668/1001 [38:07<10:58,  1.98s/it, avg loss=185.2712]Checkpoint at iteration 668 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 185.27122192382814

Training iteration:  67%|██████▋   | 668/1001 [38:09<10:58,  1.98s/it, avg loss=128.5067]
Training iteration:  67%|██████▋   | 669/1001 [38:09<10:56,  1.98s/it, avg loss=128.5067]Checkpoint at iteration 669 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 128.5067279815674

Training iteration:  67%|██████▋   | 669/1001 [38:11<10:56,  1.98s/it, avg loss=181.4097]
Training iteration:  67%|██████▋   | 670/1001 [38:11<10:54,  1.98s/it, avg loss=181.4097]Checkpoint at iteration 670 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 181.4096908569336

Training iteration:  67%|██████▋   | 670/1001 [38:13<10:54,  1.98s/it, avg loss=210.8149]
Training iteration:  67%|██████▋   | 671/1001 [38:13<10:52,  1.98s/it, avg loss=210.8149]Checkpoint at iteration 671 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 210.81491622924804

Training iteration:  67%|██████▋   | 671/1001 [38:15<10:52,  1.98s/it, avg loss=175.3838]
Training iteration:  67%|██████▋   | 672/1001 [38:15<10:51,  1.98s/it, avg loss=175.3838]Checkpoint at iteration 672 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 175.38382797241212

Training iteration:  67%|██████▋   | 672/1001 [38:17<10:51,  1.98s/it, avg loss=106.6900]
Training iteration:  67%|██████▋   | 673/1001 [38:17<10:49,  1.98s/it, avg loss=106.6900]Checkpoint at iteration 673 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 106.68996505737304

Training iteration:  67%|██████▋   | 673/1001 [38:19<10:49,  1.98s/it, avg loss=234.3547]
Training iteration:  67%|██████▋   | 674/1001 [38:19<10:47,  1.98s/it, avg loss=234.3547]Checkpoint at iteration 674 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 234.35470962524414

Training iteration:  67%|██████▋   | 674/1001 [38:21<10:47,  1.98s/it, avg loss=175.2926]
Training iteration:  67%|██████▋   | 675/1001 [38:21<10:45,  1.98s/it, avg loss=175.2926]Checkpoint at iteration 675 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 175.29257583618164

Training iteration:  67%|██████▋   | 675/1001 [38:23<10:45,  1.98s/it, avg loss=139.2321]
Training iteration:  68%|██████▊   | 676/1001 [38:23<10:43,  1.98s/it, avg loss=139.2321]Checkpoint at iteration 676 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 139.23214263916014

Training iteration:  68%|██████▊   | 676/1001 [38:25<10:43,  1.98s/it, avg loss=143.1792]
Training iteration:  68%|██████▊   | 677/1001 [38:25<10:41,  1.98s/it, avg loss=143.1792]Checkpoint at iteration 677 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 143.17919540405273

Training iteration:  68%|██████▊   | 677/1001 [38:27<10:41,  1.98s/it, avg loss=196.2720]
Training iteration:  68%|██████▊   | 678/1001 [38:27<10:39,  1.98s/it, avg loss=196.2720]Checkpoint at iteration 678 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 196.27204360961915

Training iteration:  68%|██████▊   | 678/1001 [38:29<10:39,  1.98s/it, avg loss=200.3041]
Training iteration:  68%|██████▊   | 679/1001 [38:29<10:37,  1.98s/it, avg loss=200.3041]Checkpoint at iteration 679 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 200.3040740966797

Training iteration:  68%|██████▊   | 679/1001 [38:31<10:37,  1.98s/it, avg loss=107.8818]
Training iteration:  68%|██████▊   | 680/1001 [38:31<10:35,  1.98s/it, avg loss=107.8818]Checkpoint at iteration 680 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 107.88183937072753

Training iteration:  68%|██████▊   | 680/1001 [38:33<10:35,  1.98s/it, avg loss=207.5987]
Training iteration:  68%|██████▊   | 681/1001 [38:33<10:33,  1.98s/it, avg loss=207.5987]Checkpoint at iteration 681 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 207.59866943359376

Training iteration:  68%|██████▊   | 681/1001 [38:35<10:33,  1.98s/it, avg loss=144.6699]
Training iteration:  68%|██████▊   | 682/1001 [38:35<10:31,  1.98s/it, avg loss=144.6699]Checkpoint at iteration 682 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 144.66990432739257

Training iteration:  68%|██████▊   | 682/1001 [38:37<10:31,  1.98s/it, avg loss=202.3920]
Training iteration:  68%|██████▊   | 683/1001 [38:37<10:28,  1.98s/it, avg loss=202.3920]Checkpoint at iteration 683 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 202.3919834136963

Training iteration:  68%|██████▊   | 683/1001 [38:39<10:28,  1.98s/it, avg loss=163.5863]
Training iteration:  68%|██████▊   | 684/1001 [38:39<10:27,  1.98s/it, avg loss=163.5863]Checkpoint at iteration 684 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 163.58633041381836

Training iteration:  68%|██████▊   | 684/1001 [38:41<10:27,  1.98s/it, avg loss=189.7133]
Training iteration:  68%|██████▊   | 685/1001 [38:41<10:25,  1.98s/it, avg loss=189.7133]Checkpoint at iteration 685 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 189.7133026123047

Training iteration:  68%|██████▊   | 685/1001 [38:43<10:25,  1.98s/it, avg loss=190.2764]
Training iteration:  69%|██████▊   | 686/1001 [38:43<10:23,  1.98s/it, avg loss=190.2764]Checkpoint at iteration 686 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 190.2763816833496

Training iteration:  69%|██████▊   | 686/1001 [38:45<10:23,  1.98s/it, avg loss=163.1466]
Training iteration:  69%|██████▊   | 687/1001 [38:45<10:21,  1.98s/it, avg loss=163.1466]Checkpoint at iteration 687 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 163.1466194152832

Training iteration:  69%|██████▊   | 687/1001 [38:47<10:21,  1.98s/it, avg loss=124.9674]
Training iteration:  69%|██████▊   | 688/1001 [38:47<10:19,  1.98s/it, avg loss=124.9674]Checkpoint at iteration 688 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 124.96737785339356

Training iteration:  69%|██████▊   | 688/1001 [38:49<10:19,  1.98s/it, avg loss=177.8971]
Training iteration:  69%|██████▉   | 689/1001 [38:49<10:16,  1.98s/it, avg loss=177.8971]Checkpoint at iteration 689 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 177.89712371826172

Training iteration:  69%|██████▉   | 689/1001 [38:51<10:16,  1.98s/it, avg loss=117.4285]
Training iteration:  69%|██████▉   | 690/1001 [38:51<10:15,  1.98s/it, avg loss=117.4285]Checkpoint at iteration 690 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 117.42853317260742

Training iteration:  69%|██████▉   | 690/1001 [38:53<10:15,  1.98s/it, avg loss=167.9920]
Training iteration:  69%|██████▉   | 691/1001 [38:53<10:13,  1.98s/it, avg loss=167.9920]Checkpoint at iteration 691 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 167.99199905395508

Training iteration:  69%|██████▉   | 691/1001 [38:55<10:13,  1.98s/it, avg loss=117.9711]
Training iteration:  69%|██████▉   | 692/1001 [38:55<10:11,  1.98s/it, avg loss=117.9711]Checkpoint at iteration 692 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 117.9710678100586

Training iteration:  69%|██████▉   | 692/1001 [38:57<10:11,  1.98s/it, avg loss=157.0560]
Training iteration:  69%|██████▉   | 693/1001 [38:57<10:09,  1.98s/it, avg loss=157.0560]Checkpoint at iteration 693 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 157.05599517822264

Training iteration:  69%|██████▉   | 693/1001 [38:58<10:09,  1.98s/it, avg loss=121.6186]
Training iteration:  69%|██████▉   | 694/1001 [38:58<10:07,  1.98s/it, avg loss=121.6186]Checkpoint at iteration 694 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 121.61861038208008

Training iteration:  69%|██████▉   | 694/1001 [39:00<10:07,  1.98s/it, avg loss=189.3699]
Training iteration:  69%|██████▉   | 695/1001 [39:00<10:05,  1.98s/it, avg loss=189.3699]Checkpoint at iteration 695 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 189.36986656188964

Training iteration:  69%|██████▉   | 695/1001 [39:02<10:05,  1.98s/it, avg loss=137.1035]
Training iteration:  70%|██████▉   | 696/1001 [39:02<10:03,  1.98s/it, avg loss=137.1035]Checkpoint at iteration 696 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 137.10349960327147

Training iteration:  70%|██████▉   | 696/1001 [39:04<10:03,  1.98s/it, avg loss=122.8394]
Training iteration:  70%|██████▉   | 697/1001 [39:04<10:00,  1.98s/it, avg loss=122.8394]Checkpoint at iteration 697 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 122.8394115447998

Training iteration:  70%|██████▉   | 697/1001 [39:06<10:00,  1.98s/it, avg loss=121.1393]
Training iteration:  70%|██████▉   | 698/1001 [39:06<09:58,  1.98s/it, avg loss=121.1393]Checkpoint at iteration 698 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 121.1392692565918

Training iteration:  70%|██████▉   | 698/1001 [39:08<09:58,  1.98s/it, avg loss=116.5673]
Training iteration:  70%|██████▉   | 699/1001 [39:08<09:57,  1.98s/it, avg loss=116.5673]Checkpoint at iteration 699 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 116.56734580993653

Training iteration:  70%|██████▉   | 699/1001 [39:10<09:57,  1.98s/it, avg loss=197.0866]
Training iteration:  70%|██████▉   | 700/1001 [39:10<09:55,  1.98s/it, avg loss=197.0866]Optimization iteration 700 evaluation begins...
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
A new evaluation visualization has been saved: ./saved_data/20240110-063719/it700.png
Training network 0 for evaluation...
Training network 1 for evaluation...
Training network 2 for evaluation...
Training network 3 for evaluation...
Testing network 0 on real datasets for evaluation...
Testing network 1 on real datasets for evaluation...
Testing network 2 on real datasets for evaluation...
Testing network 3 on real datasets for evaluation...
Optimization iteration 700, eval auroc score (train): 19838.7481, eval auroc score (test): 20688.7990
Checkpoint at iteration 700 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 197.08661575317382

Training iteration:  70%|██████▉   | 700/1001 [47:33<09:55,  1.98s/it, avg loss=110.9918]
Training iteration:  70%|███████   | 701/1001 [47:33<12:40:57, 152.19s/it, avg loss=110.9918]Checkpoint at iteration 701 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 110.99175071716309

Training iteration:  70%|███████   | 701/1001 [47:35<12:40:57, 152.19s/it, avg loss=145.7441]
Training iteration:  70%|███████   | 702/1001 [47:35<8:54:10, 107.19s/it, avg loss=145.7441] Checkpoint at iteration 702 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 145.74407577514648

Training iteration:  70%|███████   | 702/1001 [47:37<8:54:10, 107.19s/it, avg loss=173.0876]
Training iteration:  70%|███████   | 703/1001 [47:37<6:15:57, 75.70s/it, avg loss=173.0876] Checkpoint at iteration 703 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 173.08761596679688

Training iteration:  70%|███████   | 703/1001 [47:40<6:15:57, 75.70s/it, avg loss=123.3213]
Training iteration:  70%|███████   | 704/1001 [47:40<4:25:32, 53.65s/it, avg loss=123.3213]Checkpoint at iteration 704 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 123.32129440307617

Training iteration:  70%|███████   | 704/1001 [47:42<4:25:32, 53.65s/it, avg loss=172.4981]
Training iteration:  70%|███████   | 705/1001 [47:42<3:08:30, 38.21s/it, avg loss=172.4981]Checkpoint at iteration 705 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 172.49810829162598

Training iteration:  70%|███████   | 705/1001 [47:44<3:08:30, 38.21s/it, avg loss=168.0295]
Training iteration:  71%|███████   | 706/1001 [47:44<2:14:44, 27.41s/it, avg loss=168.0295]Checkpoint at iteration 706 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 168.0295322418213

Training iteration:  71%|███████   | 706/1001 [47:46<2:14:44, 27.41s/it, avg loss=152.0978]
Training iteration:  71%|███████   | 707/1001 [47:46<1:37:14, 19.84s/it, avg loss=152.0978]Checkpoint at iteration 707 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 152.09781799316406

Training iteration:  71%|███████   | 707/1001 [47:48<1:37:14, 19.84s/it, avg loss=139.2912]
Training iteration:  71%|███████   | 708/1001 [47:48<1:11:03, 14.55s/it, avg loss=139.2912]Checkpoint at iteration 708 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 139.2911735534668

Training iteration:  71%|███████   | 708/1001 [47:51<1:11:03, 14.55s/it, avg loss=130.0305]
Training iteration:  71%|███████   | 709/1001 [47:51<52:46, 10.85s/it, avg loss=130.0305]  Checkpoint at iteration 709 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 130.03045463562012

Training iteration:  71%|███████   | 709/1001 [47:53<52:46, 10.85s/it, avg loss=182.5048]
Training iteration:  71%|███████   | 710/1001 [47:53<40:00,  8.25s/it, avg loss=182.5048]Checkpoint at iteration 710 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 182.50479278564453

Training iteration:  71%|███████   | 710/1001 [47:55<40:00,  8.25s/it, avg loss=133.1412]
Training iteration:  71%|███████   | 711/1001 [47:55<31:06,  6.43s/it, avg loss=133.1412]Checkpoint at iteration 711 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 133.14120635986328

Training iteration:  71%|███████   | 711/1001 [47:57<31:06,  6.43s/it, avg loss=177.7307]
Training iteration:  71%|███████   | 712/1001 [47:57<24:52,  5.17s/it, avg loss=177.7307]Checkpoint at iteration 712 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 177.73067893981934

Training iteration:  71%|███████   | 712/1001 [47:59<24:52,  5.17s/it, avg loss=186.5571]
Training iteration:  71%|███████   | 713/1001 [47:59<20:31,  4.28s/it, avg loss=186.5571]Checkpoint at iteration 713 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 186.55706481933595

Training iteration:  71%|███████   | 713/1001 [48:02<20:31,  4.28s/it, avg loss=185.3968]
Training iteration:  71%|███████▏  | 714/1001 [48:02<17:28,  3.65s/it, avg loss=185.3968]Checkpoint at iteration 714 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 185.39682846069337

Training iteration:  71%|███████▏  | 714/1001 [48:04<17:28,  3.65s/it, avg loss=167.3998]
Training iteration:  71%|███████▏  | 715/1001 [48:04<15:19,  3.21s/it, avg loss=167.3998]Checkpoint at iteration 715 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 167.39980354309083

Training iteration:  71%|███████▏  | 715/1001 [48:06<15:19,  3.21s/it, avg loss=205.7593]
Training iteration:  72%|███████▏  | 716/1001 [48:06<13:48,  2.91s/it, avg loss=205.7593]Checkpoint at iteration 716 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 205.7593017578125

Training iteration:  72%|███████▏  | 716/1001 [48:08<13:48,  2.91s/it, avg loss=219.0533]
Training iteration:  72%|███████▏  | 717/1001 [48:08<12:45,  2.69s/it, avg loss=219.0533]Checkpoint at iteration 717 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 219.05325012207032

Training iteration:  72%|███████▏  | 717/1001 [48:10<12:45,  2.69s/it, avg loss=182.8730]
Training iteration:  72%|███████▏  | 718/1001 [48:10<11:59,  2.54s/it, avg loss=182.8730]Checkpoint at iteration 718 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 182.87303733825684

Training iteration:  72%|███████▏  | 718/1001 [48:13<11:59,  2.54s/it, avg loss=199.2774]
Training iteration:  72%|███████▏  | 719/1001 [48:13<11:27,  2.44s/it, avg loss=199.2774]Checkpoint at iteration 719 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 199.27742767333984

Training iteration:  72%|███████▏  | 719/1001 [48:15<11:27,  2.44s/it, avg loss=101.4850]
Training iteration:  72%|███████▏  | 720/1001 [48:15<11:04,  2.36s/it, avg loss=101.4850]Checkpoint at iteration 720 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 101.4849739074707

Training iteration:  72%|███████▏  | 720/1001 [48:17<11:04,  2.36s/it, avg loss=104.8315]
Training iteration:  72%|███████▏  | 721/1001 [48:17<10:47,  2.31s/it, avg loss=104.8315]Checkpoint at iteration 721 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 104.83152809143067

Training iteration:  72%|███████▏  | 721/1001 [48:19<10:47,  2.31s/it, avg loss=206.9637]
Training iteration:  72%|███████▏  | 722/1001 [48:19<10:35,  2.28s/it, avg loss=206.9637]Checkpoint at iteration 722 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 206.96369705200195

Training iteration:  72%|███████▏  | 722/1001 [48:21<10:35,  2.28s/it, avg loss=149.9839]
Training iteration:  72%|███████▏  | 723/1001 [48:21<10:25,  2.25s/it, avg loss=149.9839]Checkpoint at iteration 723 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 149.9838665008545

Training iteration:  72%|███████▏  | 723/1001 [48:24<10:25,  2.25s/it, avg loss=174.5533]
Training iteration:  72%|███████▏  | 724/1001 [48:24<10:19,  2.23s/it, avg loss=174.5533]Checkpoint at iteration 724 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 174.55330505371094

Training iteration:  72%|███████▏  | 724/1001 [48:26<10:19,  2.23s/it, avg loss=135.4000]
Training iteration:  72%|███████▏  | 725/1001 [48:26<10:13,  2.22s/it, avg loss=135.4000]Checkpoint at iteration 725 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 135.40002899169923

Training iteration:  72%|███████▏  | 725/1001 [48:28<10:13,  2.22s/it, avg loss=161.9526]
Training iteration:  73%|███████▎  | 726/1001 [48:28<10:09,  2.22s/it, avg loss=161.9526]Checkpoint at iteration 726 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 161.95262985229493

Training iteration:  73%|███████▎  | 726/1001 [48:30<10:09,  2.22s/it, avg loss=130.5337]
Training iteration:  73%|███████▎  | 727/1001 [48:30<10:05,  2.21s/it, avg loss=130.5337]Checkpoint at iteration 727 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 130.53368682861327

Training iteration:  73%|███████▎  | 727/1001 [48:32<10:05,  2.21s/it, avg loss=201.6548]
Training iteration:  73%|███████▎  | 728/1001 [48:32<10:03,  2.21s/it, avg loss=201.6548]Checkpoint at iteration 728 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 201.65481033325196

Training iteration:  73%|███████▎  | 728/1001 [48:35<10:03,  2.21s/it, avg loss=220.9773]
Training iteration:  73%|███████▎  | 729/1001 [48:35<10:00,  2.21s/it, avg loss=220.9773]Checkpoint at iteration 729 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 220.97729110717773

Training iteration:  73%|███████▎  | 729/1001 [48:37<10:00,  2.21s/it, avg loss=193.4895]
Training iteration:  73%|███████▎  | 730/1001 [48:37<09:57,  2.20s/it, avg loss=193.4895]Checkpoint at iteration 730 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 193.48952140808106

Training iteration:  73%|███████▎  | 730/1001 [48:39<09:57,  2.20s/it, avg loss=171.7661]
Training iteration:  73%|███████▎  | 731/1001 [48:39<09:55,  2.20s/it, avg loss=171.7661]Checkpoint at iteration 731 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 171.7661220550537

Training iteration:  73%|███████▎  | 731/1001 [48:41<09:55,  2.20s/it, avg loss=177.4080]
Training iteration:  73%|███████▎  | 732/1001 [48:41<09:52,  2.20s/it, avg loss=177.4080]Checkpoint at iteration 732 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 177.40802764892578

Training iteration:  73%|███████▎  | 732/1001 [48:43<09:52,  2.20s/it, avg loss=241.1095]
Training iteration:  73%|███████▎  | 733/1001 [48:43<09:50,  2.20s/it, avg loss=241.1095]Checkpoint at iteration 733 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 241.10945358276368

Training iteration:  73%|███████▎  | 733/1001 [48:46<09:50,  2.20s/it, avg loss=215.5386]
Training iteration:  73%|███████▎  | 734/1001 [48:46<09:47,  2.20s/it, avg loss=215.5386]Checkpoint at iteration 734 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 215.53863143920898

Training iteration:  73%|███████▎  | 734/1001 [48:48<09:47,  2.20s/it, avg loss=183.6744]
Training iteration:  73%|███████▎  | 735/1001 [48:48<09:44,  2.20s/it, avg loss=183.6744]Checkpoint at iteration 735 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 183.67436294555665

Training iteration:  73%|███████▎  | 735/1001 [48:50<09:44,  2.20s/it, avg loss=206.1264]
Training iteration:  74%|███████▎  | 736/1001 [48:50<09:42,  2.20s/it, avg loss=206.1264]Checkpoint at iteration 736 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 206.1263916015625

Training iteration:  74%|███████▎  | 736/1001 [48:52<09:42,  2.20s/it, avg loss=119.5322]
Training iteration:  74%|███████▎  | 737/1001 [48:52<09:40,  2.20s/it, avg loss=119.5322]Checkpoint at iteration 737 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 119.5322395324707

Training iteration:  74%|███████▎  | 737/1001 [48:54<09:40,  2.20s/it, avg loss=166.9124]
Training iteration:  74%|███████▎  | 738/1001 [48:54<09:38,  2.20s/it, avg loss=166.9124]Checkpoint at iteration 738 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 166.91236267089843

Training iteration:  74%|███████▎  | 738/1001 [48:57<09:38,  2.20s/it, avg loss=119.4578]
Training iteration:  74%|███████▍  | 739/1001 [48:57<09:36,  2.20s/it, avg loss=119.4578]Checkpoint at iteration 739 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 119.4578254699707

Training iteration:  74%|███████▍  | 739/1001 [48:59<09:36,  2.20s/it, avg loss=181.9682]
Training iteration:  74%|███████▍  | 740/1001 [48:59<09:34,  2.20s/it, avg loss=181.9682]Checkpoint at iteration 740 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 181.96820068359375

Training iteration:  74%|███████▍  | 740/1001 [49:01<09:34,  2.20s/it, avg loss=173.5240]
Training iteration:  74%|███████▍  | 741/1001 [49:01<09:31,  2.20s/it, avg loss=173.5240]Checkpoint at iteration 741 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 173.52404098510743

Training iteration:  74%|███████▍  | 741/1001 [49:03<09:31,  2.20s/it, avg loss=173.3142]
Training iteration:  74%|███████▍  | 742/1001 [49:03<09:29,  2.20s/it, avg loss=173.3142]Checkpoint at iteration 742 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 173.31417388916014

Training iteration:  74%|███████▍  | 742/1001 [49:05<09:29,  2.20s/it, avg loss=88.6467] 
Training iteration:  74%|███████▍  | 743/1001 [49:05<09:27,  2.20s/it, avg loss=88.6467]Checkpoint at iteration 743 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 88.64665756225585

Training iteration:  74%|███████▍  | 743/1001 [49:08<09:27,  2.20s/it, avg loss=95.6919]
Training iteration:  74%|███████▍  | 744/1001 [49:08<09:25,  2.20s/it, avg loss=95.6919]Checkpoint at iteration 744 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 95.69187774658204

Training iteration:  74%|███████▍  | 744/1001 [49:10<09:25,  2.20s/it, avg loss=125.0528]
Training iteration:  74%|███████▍  | 745/1001 [49:10<09:23,  2.20s/it, avg loss=125.0528]Checkpoint at iteration 745 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 125.05275077819825

Training iteration:  74%|███████▍  | 745/1001 [49:12<09:23,  2.20s/it, avg loss=145.7925]
Training iteration:  75%|███████▍  | 746/1001 [49:12<09:20,  2.20s/it, avg loss=145.7925]Checkpoint at iteration 746 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 145.79251937866212

Training iteration:  75%|███████▍  | 746/1001 [49:14<09:20,  2.20s/it, avg loss=197.1187]
Training iteration:  75%|███████▍  | 747/1001 [49:14<09:18,  2.20s/it, avg loss=197.1187]Checkpoint at iteration 747 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 197.11868858337402

Training iteration:  75%|███████▍  | 747/1001 [49:16<09:18,  2.20s/it, avg loss=116.9390]
Training iteration:  75%|███████▍  | 748/1001 [49:16<09:16,  2.20s/it, avg loss=116.9390]Checkpoint at iteration 748 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 116.93904685974121

Training iteration:  75%|███████▍  | 748/1001 [49:19<09:16,  2.20s/it, avg loss=185.8988]
Training iteration:  75%|███████▍  | 749/1001 [49:19<09:13,  2.20s/it, avg loss=185.8988]Checkpoint at iteration 749 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 185.89883728027343

Training iteration:  75%|███████▍  | 749/1001 [49:21<09:13,  2.20s/it, avg loss=217.0625]
Training iteration:  75%|███████▍  | 750/1001 [49:21<09:11,  2.20s/it, avg loss=217.0625]Checkpoint at iteration 750 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 217.0625244140625

Training iteration:  75%|███████▍  | 750/1001 [49:23<09:11,  2.20s/it, avg loss=181.6559]
Training iteration:  75%|███████▌  | 751/1001 [49:23<09:09,  2.20s/it, avg loss=181.6559]Checkpoint at iteration 751 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 181.6558525085449

Training iteration:  75%|███████▌  | 751/1001 [49:25<09:09,  2.20s/it, avg loss=186.8372]
Training iteration:  75%|███████▌  | 752/1001 [49:25<09:07,  2.20s/it, avg loss=186.8372]Checkpoint at iteration 752 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 186.83721313476562

Training iteration:  75%|███████▌  | 752/1001 [49:27<09:07,  2.20s/it, avg loss=172.1249]
Training iteration:  75%|███████▌  | 753/1001 [49:27<09:04,  2.20s/it, avg loss=172.1249]Checkpoint at iteration 753 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 172.12493286132812

Training iteration:  75%|███████▌  | 753/1001 [49:30<09:04,  2.20s/it, avg loss=153.5606]
Training iteration:  75%|███████▌  | 754/1001 [49:30<09:02,  2.20s/it, avg loss=153.5606]Checkpoint at iteration 754 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 153.56062774658204

Training iteration:  75%|███████▌  | 754/1001 [49:32<09:02,  2.20s/it, avg loss=151.8339]
Training iteration:  75%|███████▌  | 755/1001 [49:32<09:00,  2.20s/it, avg loss=151.8339]Checkpoint at iteration 755 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 151.8338764190674

Training iteration:  75%|███████▌  | 755/1001 [49:34<09:00,  2.20s/it, avg loss=217.8976]
Training iteration:  76%|███████▌  | 756/1001 [49:34<08:58,  2.20s/it, avg loss=217.8976]Checkpoint at iteration 756 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 217.89757385253907

Training iteration:  76%|███████▌  | 756/1001 [49:36<08:58,  2.20s/it, avg loss=178.4403]
Training iteration:  76%|███████▌  | 757/1001 [49:36<08:56,  2.20s/it, avg loss=178.4403]Checkpoint at iteration 757 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 178.44034423828126

Training iteration:  76%|███████▌  | 757/1001 [49:38<08:56,  2.20s/it, avg loss=172.9124]
Training iteration:  76%|███████▌  | 758/1001 [49:38<08:54,  2.20s/it, avg loss=172.9124]Checkpoint at iteration 758 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 172.91235466003417

Training iteration:  76%|███████▌  | 758/1001 [49:41<08:54,  2.20s/it, avg loss=220.9817]
Training iteration:  76%|███████▌  | 759/1001 [49:41<08:51,  2.20s/it, avg loss=220.9817]Checkpoint at iteration 759 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 220.9817352294922

Training iteration:  76%|███████▌  | 759/1001 [49:43<08:51,  2.20s/it, avg loss=236.8329]
Training iteration:  76%|███████▌  | 760/1001 [49:43<08:49,  2.20s/it, avg loss=236.8329]Checkpoint at iteration 760 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 236.83290176391603

Training iteration:  76%|███████▌  | 760/1001 [49:45<08:49,  2.20s/it, avg loss=115.3297]
Training iteration:  76%|███████▌  | 761/1001 [49:45<08:47,  2.20s/it, avg loss=115.3297]Checkpoint at iteration 761 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 115.32968673706054

Training iteration:  76%|███████▌  | 761/1001 [49:47<08:47,  2.20s/it, avg loss=163.1276]
Training iteration:  76%|███████▌  | 762/1001 [49:47<08:45,  2.20s/it, avg loss=163.1276]Checkpoint at iteration 762 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 163.12757377624513

Training iteration:  76%|███████▌  | 762/1001 [49:49<08:45,  2.20s/it, avg loss=161.2717]
Training iteration:  76%|███████▌  | 763/1001 [49:49<08:43,  2.20s/it, avg loss=161.2717]Checkpoint at iteration 763 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 161.2716884613037

Training iteration:  76%|███████▌  | 763/1001 [49:51<08:43,  2.20s/it, avg loss=191.1636]
Training iteration:  76%|███████▋  | 764/1001 [49:51<08:41,  2.20s/it, avg loss=191.1636]Checkpoint at iteration 764 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 191.16363906860352

Training iteration:  76%|███████▋  | 764/1001 [49:54<08:41,  2.20s/it, avg loss=178.6220]
Training iteration:  76%|███████▋  | 765/1001 [49:54<08:38,  2.20s/it, avg loss=178.6220]Checkpoint at iteration 765 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 178.62195587158203

Training iteration:  76%|███████▋  | 765/1001 [49:56<08:38,  2.20s/it, avg loss=185.3907]
Training iteration:  77%|███████▋  | 766/1001 [49:56<08:36,  2.20s/it, avg loss=185.3907]Checkpoint at iteration 766 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 185.39068756103515

Training iteration:  77%|███████▋  | 766/1001 [49:58<08:36,  2.20s/it, avg loss=222.7214]
Training iteration:  77%|███████▋  | 767/1001 [49:58<08:34,  2.20s/it, avg loss=222.7214]Checkpoint at iteration 767 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 222.7213592529297

Training iteration:  77%|███████▋  | 767/1001 [50:00<08:34,  2.20s/it, avg loss=126.7431]
Training iteration:  77%|███████▋  | 768/1001 [50:00<08:31,  2.20s/it, avg loss=126.7431]Checkpoint at iteration 768 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 126.74312286376953

Training iteration:  77%|███████▋  | 768/1001 [50:02<08:31,  2.20s/it, avg loss=160.7738]
Training iteration:  77%|███████▋  | 769/1001 [50:02<08:29,  2.20s/it, avg loss=160.7738]Checkpoint at iteration 769 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 160.77377853393554

Training iteration:  77%|███████▋  | 769/1001 [50:05<08:29,  2.20s/it, avg loss=209.9228]
Training iteration:  77%|███████▋  | 770/1001 [50:05<08:27,  2.20s/it, avg loss=209.9228]Checkpoint at iteration 770 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 209.92280807495118

Training iteration:  77%|███████▋  | 770/1001 [50:07<08:27,  2.20s/it, avg loss=144.7993]
Training iteration:  77%|███████▋  | 771/1001 [50:07<08:25,  2.20s/it, avg loss=144.7993]Checkpoint at iteration 771 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 144.79927825927734

Training iteration:  77%|███████▋  | 771/1001 [50:09<08:25,  2.20s/it, avg loss=204.2239]
Training iteration:  77%|███████▋  | 772/1001 [50:09<08:23,  2.20s/it, avg loss=204.2239]Checkpoint at iteration 772 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 204.22387619018554

Training iteration:  77%|███████▋  | 772/1001 [50:11<08:23,  2.20s/it, avg loss=183.6227]
Training iteration:  77%|███████▋  | 773/1001 [50:11<08:20,  2.20s/it, avg loss=183.6227]Checkpoint at iteration 773 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 183.62274093627929

Training iteration:  77%|███████▋  | 773/1001 [50:13<08:20,  2.20s/it, avg loss=154.9936]
Training iteration:  77%|███████▋  | 774/1001 [50:13<08:18,  2.20s/it, avg loss=154.9936]Checkpoint at iteration 774 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 154.99355392456056

Training iteration:  77%|███████▋  | 774/1001 [50:16<08:18,  2.20s/it, avg loss=217.1334]
Training iteration:  77%|███████▋  | 775/1001 [50:16<08:16,  2.20s/it, avg loss=217.1334]Checkpoint at iteration 775 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 217.1334259033203

Training iteration:  77%|███████▋  | 775/1001 [50:18<08:16,  2.20s/it, avg loss=103.2950]
Training iteration:  78%|███████▊  | 776/1001 [50:18<08:14,  2.20s/it, avg loss=103.2950]Checkpoint at iteration 776 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 103.29501533508301

Training iteration:  78%|███████▊  | 776/1001 [50:20<08:14,  2.20s/it, avg loss=178.1219]
Training iteration:  78%|███████▊  | 777/1001 [50:20<08:12,  2.20s/it, avg loss=178.1219]Checkpoint at iteration 777 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 178.1219367980957

Training iteration:  78%|███████▊  | 777/1001 [50:22<08:12,  2.20s/it, avg loss=221.5035]
Training iteration:  78%|███████▊  | 778/1001 [50:22<08:10,  2.20s/it, avg loss=221.5035]Checkpoint at iteration 778 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 221.50349807739258

Training iteration:  78%|███████▊  | 778/1001 [50:24<08:10,  2.20s/it, avg loss=157.4975]
Training iteration:  78%|███████▊  | 779/1001 [50:24<08:07,  2.20s/it, avg loss=157.4975]Checkpoint at iteration 779 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 157.49745407104493

Training iteration:  78%|███████▊  | 779/1001 [50:27<08:07,  2.20s/it, avg loss=196.6878]
Training iteration:  78%|███████▊  | 780/1001 [50:27<08:05,  2.20s/it, avg loss=196.6878]Checkpoint at iteration 780 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 196.68783645629884

Training iteration:  78%|███████▊  | 780/1001 [50:29<08:05,  2.20s/it, avg loss=191.5392]
Training iteration:  78%|███████▊  | 781/1001 [50:29<08:03,  2.20s/it, avg loss=191.5392]Checkpoint at iteration 781 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 191.53921508789062

Training iteration:  78%|███████▊  | 781/1001 [50:31<08:03,  2.20s/it, avg loss=196.0024]
Training iteration:  78%|███████▊  | 782/1001 [50:31<08:00,  2.20s/it, avg loss=196.0024]Checkpoint at iteration 782 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 196.00241241455078

Training iteration:  78%|███████▊  | 782/1001 [50:33<08:00,  2.20s/it, avg loss=166.1950]
Training iteration:  78%|███████▊  | 783/1001 [50:33<07:58,  2.20s/it, avg loss=166.1950]Checkpoint at iteration 783 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 166.19502868652344

Training iteration:  78%|███████▊  | 783/1001 [50:35<07:58,  2.20s/it, avg loss=177.6733]
Training iteration:  78%|███████▊  | 784/1001 [50:35<07:56,  2.20s/it, avg loss=177.6733]Checkpoint at iteration 784 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 177.67333068847657

Training iteration:  78%|███████▊  | 784/1001 [50:38<07:56,  2.20s/it, avg loss=128.2825]
Training iteration:  78%|███████▊  | 785/1001 [50:38<07:54,  2.20s/it, avg loss=128.2825]Checkpoint at iteration 785 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 128.28254241943358

Training iteration:  78%|███████▊  | 785/1001 [50:40<07:54,  2.20s/it, avg loss=137.5779]
Training iteration:  79%|███████▊  | 786/1001 [50:40<07:52,  2.20s/it, avg loss=137.5779]Checkpoint at iteration 786 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 137.5778953552246

Training iteration:  79%|███████▊  | 786/1001 [50:42<07:52,  2.20s/it, avg loss=141.4590]
Training iteration:  79%|███████▊  | 787/1001 [50:42<07:50,  2.20s/it, avg loss=141.4590]Checkpoint at iteration 787 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 141.45902481079102

Training iteration:  79%|███████▊  | 787/1001 [50:44<07:50,  2.20s/it, avg loss=134.2554]
Training iteration:  79%|███████▊  | 788/1001 [50:44<07:48,  2.20s/it, avg loss=134.2554]Checkpoint at iteration 788 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 134.25537796020507

Training iteration:  79%|███████▊  | 788/1001 [50:46<07:48,  2.20s/it, avg loss=185.0357]
Training iteration:  79%|███████▉  | 789/1001 [50:46<07:45,  2.20s/it, avg loss=185.0357]Checkpoint at iteration 789 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 185.03567199707032

Training iteration:  79%|███████▉  | 789/1001 [50:49<07:45,  2.20s/it, avg loss=176.5581]
Training iteration:  79%|███████▉  | 790/1001 [50:49<07:43,  2.20s/it, avg loss=176.5581]Checkpoint at iteration 790 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 176.5580638885498

Training iteration:  79%|███████▉  | 790/1001 [50:51<07:43,  2.20s/it, avg loss=206.9332]
Training iteration:  79%|███████▉  | 791/1001 [50:51<07:41,  2.20s/it, avg loss=206.9332]Checkpoint at iteration 791 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 206.9332046508789

Training iteration:  79%|███████▉  | 791/1001 [50:53<07:41,  2.20s/it, avg loss=189.0463]
Training iteration:  79%|███████▉  | 792/1001 [50:53<07:39,  2.20s/it, avg loss=189.0463]Checkpoint at iteration 792 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 189.04630126953126

Training iteration:  79%|███████▉  | 792/1001 [50:55<07:39,  2.20s/it, avg loss=120.0526]
Training iteration:  79%|███████▉  | 793/1001 [50:55<07:37,  2.20s/it, avg loss=120.0526]Checkpoint at iteration 793 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 120.05258407592774

Training iteration:  79%|███████▉  | 793/1001 [50:57<07:37,  2.20s/it, avg loss=236.2602]
Training iteration:  79%|███████▉  | 794/1001 [50:57<07:35,  2.20s/it, avg loss=236.2602]Checkpoint at iteration 794 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 236.26021423339844

Training iteration:  79%|███████▉  | 794/1001 [51:00<07:35,  2.20s/it, avg loss=200.8911]
Training iteration:  79%|███████▉  | 795/1001 [51:00<07:33,  2.20s/it, avg loss=200.8911]Checkpoint at iteration 795 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 200.89105148315429

Training iteration:  79%|███████▉  | 795/1001 [51:02<07:33,  2.20s/it, avg loss=166.0130]
Training iteration:  80%|███████▉  | 796/1001 [51:02<07:30,  2.20s/it, avg loss=166.0130]Checkpoint at iteration 796 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 166.01296157836913

Training iteration:  80%|███████▉  | 796/1001 [51:04<07:30,  2.20s/it, avg loss=184.0830]
Training iteration:  80%|███████▉  | 797/1001 [51:04<07:28,  2.20s/it, avg loss=184.0830]Checkpoint at iteration 797 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 184.0830093383789

Training iteration:  80%|███████▉  | 797/1001 [51:06<07:28,  2.20s/it, avg loss=240.3523]
Training iteration:  80%|███████▉  | 798/1001 [51:06<07:26,  2.20s/it, avg loss=240.3523]Checkpoint at iteration 798 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 240.35225296020508

Training iteration:  80%|███████▉  | 798/1001 [51:08<07:26,  2.20s/it, avg loss=200.7584]
Training iteration:  80%|███████▉  | 799/1001 [51:08<07:24,  2.20s/it, avg loss=200.7584]Checkpoint at iteration 799 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 200.7583984375

Training iteration:  80%|███████▉  | 799/1001 [51:11<07:24,  2.20s/it, avg loss=189.6543]
Training iteration:  80%|███████▉  | 800/1001 [51:11<07:21,  2.20s/it, avg loss=189.6543]Optimization iteration 800 evaluation begins...
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
A new evaluation visualization has been saved: ./saved_data/20240110-063719/it800.png
Training network 0 for evaluation...
Training network 1 for evaluation...
Training network 2 for evaluation...
Training network 3 for evaluation...
Testing network 0 on real datasets for evaluation...
Testing network 1 on real datasets for evaluation...
Testing network 2 on real datasets for evaluation...
Testing network 3 on real datasets for evaluation...
Optimization iteration 800, eval auroc score (train): 20053.9981, eval auroc score (test): 20934.7575
Checkpoint at iteration 800 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 189.65425643920898

Training iteration:  80%|███████▉  | 800/1001 [1:00:52<07:21,  2.20s/it, avg loss=207.4462]
Training iteration:  80%|████████  | 801/1001 [1:00:52<9:46:36, 175.98s/it, avg loss=207.4462]Checkpoint at iteration 801 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 207.4462043762207

Training iteration:  80%|████████  | 801/1001 [1:00:55<9:46:36, 175.98s/it, avg loss=235.6096]
Training iteration:  80%|████████  | 802/1001 [1:00:55<6:50:58, 123.91s/it, avg loss=235.6096]Checkpoint at iteration 802 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 235.60961532592773

Training iteration:  80%|████████  | 802/1001 [1:00:57<6:50:58, 123.91s/it, avg loss=219.6835]
Training iteration:  80%|████████  | 803/1001 [1:00:57<4:48:38, 87.47s/it, avg loss=219.6835] Checkpoint at iteration 803 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 219.68351211547852

Training iteration:  80%|████████  | 803/1001 [1:00:59<4:48:38, 87.47s/it, avg loss=165.7470]
Training iteration:  80%|████████  | 804/1001 [1:00:59<3:23:24, 61.95s/it, avg loss=165.7470]Checkpoint at iteration 804 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 165.74701843261718

Training iteration:  80%|████████  | 804/1001 [1:01:02<3:23:24, 61.95s/it, avg loss=145.3631]
Training iteration:  80%|████████  | 805/1001 [1:01:02<2:24:02, 44.09s/it, avg loss=145.3631]Checkpoint at iteration 805 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 145.3631446838379

Training iteration:  80%|████████  | 805/1001 [1:01:04<2:24:02, 44.09s/it, avg loss=100.0811]
Training iteration:  81%|████████  | 806/1001 [1:01:04<1:42:40, 31.59s/it, avg loss=100.0811]Checkpoint at iteration 806 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 100.0811393737793

Training iteration:  81%|████████  | 806/1001 [1:01:07<1:42:40, 31.59s/it, avg loss=154.9741]
Training iteration:  81%|████████  | 807/1001 [1:01:07<1:13:51, 22.84s/it, avg loss=154.9741]Checkpoint at iteration 807 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 154.9740882873535

Training iteration:  81%|████████  | 807/1001 [1:01:09<1:13:51, 22.84s/it, avg loss=195.7043]
Training iteration:  81%|████████  | 808/1001 [1:01:09<53:45, 16.71s/it, avg loss=195.7043]  Checkpoint at iteration 808 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 195.70430450439454

Training iteration:  81%|████████  | 808/1001 [1:01:11<53:45, 16.71s/it, avg loss=161.5241]
Training iteration:  81%|████████  | 809/1001 [1:01:11<39:45, 12.43s/it, avg loss=161.5241]Checkpoint at iteration 809 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 161.52408828735352

Training iteration:  81%|████████  | 809/1001 [1:01:14<39:45, 12.43s/it, avg loss=152.6317]
Training iteration:  81%|████████  | 810/1001 [1:01:14<30:00,  9.42s/it, avg loss=152.6317]Checkpoint at iteration 810 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 152.6317337036133

Training iteration:  81%|████████  | 810/1001 [1:01:16<30:00,  9.42s/it, avg loss=209.6638]
Training iteration:  81%|████████  | 811/1001 [1:01:16<23:11,  7.32s/it, avg loss=209.6638]Checkpoint at iteration 811 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 209.66377716064454

Training iteration:  81%|████████  | 811/1001 [1:01:19<23:11,  7.32s/it, avg loss=181.4851]
Training iteration:  81%|████████  | 812/1001 [1:01:19<18:26,  5.85s/it, avg loss=181.4851]Checkpoint at iteration 812 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 181.4851203918457

Training iteration:  81%|████████  | 812/1001 [1:01:21<18:26,  5.85s/it, avg loss=147.8803]
Training iteration:  81%|████████  | 813/1001 [1:01:21<15:06,  4.82s/it, avg loss=147.8803]Checkpoint at iteration 813 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 147.88028793334962

Training iteration:  81%|████████  | 813/1001 [1:01:24<15:06,  4.82s/it, avg loss=186.9154]
Training iteration:  81%|████████▏ | 814/1001 [1:01:24<12:47,  4.10s/it, avg loss=186.9154]Checkpoint at iteration 814 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 186.9153839111328

Training iteration:  81%|████████▏ | 814/1001 [1:01:26<12:47,  4.10s/it, avg loss=151.8957]
Training iteration:  81%|████████▏ | 815/1001 [1:01:26<11:09,  3.60s/it, avg loss=151.8957]Checkpoint at iteration 815 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 151.89574508666993

Training iteration:  81%|████████▏ | 815/1001 [1:01:28<11:09,  3.60s/it, avg loss=137.8846]
Training iteration:  82%|████████▏ | 816/1001 [1:01:28<10:00,  3.25s/it, avg loss=137.8846]Checkpoint at iteration 816 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 137.88464431762696

Training iteration:  82%|████████▏ | 816/1001 [1:01:31<10:00,  3.25s/it, avg loss=165.6156]
Training iteration:  82%|████████▏ | 817/1001 [1:01:31<09:11,  3.00s/it, avg loss=165.6156]Checkpoint at iteration 817 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 165.6156448364258

Training iteration:  82%|████████▏ | 817/1001 [1:01:33<09:11,  3.00s/it, avg loss=164.0888]
Training iteration:  82%|████████▏ | 818/1001 [1:01:33<08:37,  2.83s/it, avg loss=164.0888]Checkpoint at iteration 818 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 164.0888214111328

Training iteration:  82%|████████▏ | 818/1001 [1:01:36<08:37,  2.83s/it, avg loss=178.6509]
Training iteration:  82%|████████▏ | 819/1001 [1:01:36<08:12,  2.70s/it, avg loss=178.6509]Checkpoint at iteration 819 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 178.6508987426758

Training iteration:  82%|████████▏ | 819/1001 [1:01:38<08:12,  2.70s/it, avg loss=222.7863]
Training iteration:  82%|████████▏ | 820/1001 [1:01:38<07:54,  2.62s/it, avg loss=222.7863]Checkpoint at iteration 820 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 222.78631286621095

Training iteration:  82%|████████▏ | 820/1001 [1:01:41<07:54,  2.62s/it, avg loss=210.0686]
Training iteration:  82%|████████▏ | 821/1001 [1:01:41<07:40,  2.56s/it, avg loss=210.0686]Checkpoint at iteration 821 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 210.0686248779297

Training iteration:  82%|████████▏ | 821/1001 [1:01:43<07:40,  2.56s/it, avg loss=183.7178]
Training iteration:  82%|████████▏ | 822/1001 [1:01:43<07:30,  2.52s/it, avg loss=183.7178]Checkpoint at iteration 822 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 183.71777954101563

Training iteration:  82%|████████▏ | 822/1001 [1:01:45<07:30,  2.52s/it, avg loss=189.3504]
Training iteration:  82%|████████▏ | 823/1001 [1:01:45<07:22,  2.49s/it, avg loss=189.3504]Checkpoint at iteration 823 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 189.35037231445312

Training iteration:  82%|████████▏ | 823/1001 [1:01:48<07:22,  2.49s/it, avg loss=183.3765]
Training iteration:  82%|████████▏ | 824/1001 [1:01:48<07:16,  2.47s/it, avg loss=183.3765]Checkpoint at iteration 824 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 183.37651138305665

Training iteration:  82%|████████▏ | 824/1001 [1:01:50<07:16,  2.47s/it, avg loss=224.4211]
Training iteration:  82%|████████▏ | 825/1001 [1:01:50<07:11,  2.45s/it, avg loss=224.4211]Checkpoint at iteration 825 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 224.4210693359375

Training iteration:  82%|████████▏ | 825/1001 [1:01:53<07:11,  2.45s/it, avg loss=207.1880]
Training iteration:  83%|████████▎ | 826/1001 [1:01:53<07:07,  2.44s/it, avg loss=207.1880]Checkpoint at iteration 826 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 207.18796157836914

Training iteration:  83%|████████▎ | 826/1001 [1:01:55<07:07,  2.44s/it, avg loss=199.9959]
Training iteration:  83%|████████▎ | 827/1001 [1:01:55<07:03,  2.43s/it, avg loss=199.9959]Checkpoint at iteration 827 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 199.99590682983398

Training iteration:  83%|████████▎ | 827/1001 [1:01:57<07:03,  2.43s/it, avg loss=195.7839]
Training iteration:  83%|████████▎ | 828/1001 [1:01:57<07:00,  2.43s/it, avg loss=195.7839]Checkpoint at iteration 828 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 195.783927154541

Training iteration:  83%|████████▎ | 828/1001 [1:02:00<07:00,  2.43s/it, avg loss=156.6003]
Training iteration:  83%|████████▎ | 829/1001 [1:02:00<06:57,  2.43s/it, avg loss=156.6003]Checkpoint at iteration 829 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 156.60032119750977

Training iteration:  83%|████████▎ | 829/1001 [1:02:02<06:57,  2.43s/it, avg loss=177.6161]
Training iteration:  83%|████████▎ | 830/1001 [1:02:02<06:54,  2.42s/it, avg loss=177.6161]Checkpoint at iteration 830 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 177.61614303588868

Training iteration:  83%|████████▎ | 830/1001 [1:02:05<06:54,  2.42s/it, avg loss=143.9908]
Training iteration:  83%|████████▎ | 831/1001 [1:02:05<06:52,  2.42s/it, avg loss=143.9908]Checkpoint at iteration 831 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 143.99082107543944

Training iteration:  83%|████████▎ | 831/1001 [1:02:07<06:52,  2.42s/it, avg loss=134.2503]
Training iteration:  83%|████████▎ | 832/1001 [1:02:07<06:49,  2.42s/it, avg loss=134.2503]Checkpoint at iteration 832 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 134.25034942626954

Training iteration:  83%|████████▎ | 832/1001 [1:02:10<06:49,  2.42s/it, avg loss=108.9656]
Training iteration:  83%|████████▎ | 833/1001 [1:02:10<06:46,  2.42s/it, avg loss=108.9656]Checkpoint at iteration 833 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 108.96558074951172

Training iteration:  83%|████████▎ | 833/1001 [1:02:12<06:46,  2.42s/it, avg loss=158.1146]
Training iteration:  83%|████████▎ | 834/1001 [1:02:12<06:44,  2.42s/it, avg loss=158.1146]Checkpoint at iteration 834 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 158.11459426879884

Training iteration:  83%|████████▎ | 834/1001 [1:02:14<06:44,  2.42s/it, avg loss=219.7279]
Training iteration:  83%|████████▎ | 835/1001 [1:02:14<06:41,  2.42s/it, avg loss=219.7279]Checkpoint at iteration 835 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 219.7279411315918

Training iteration:  83%|████████▎ | 835/1001 [1:02:17<06:41,  2.42s/it, avg loss=174.5638]
Training iteration:  84%|████████▎ | 836/1001 [1:02:17<06:39,  2.42s/it, avg loss=174.5638]Checkpoint at iteration 836 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 174.56381607055664

Training iteration:  84%|████████▎ | 836/1001 [1:02:19<06:39,  2.42s/it, avg loss=233.7638]
Training iteration:  84%|████████▎ | 837/1001 [1:02:19<06:36,  2.42s/it, avg loss=233.7638]Checkpoint at iteration 837 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 233.76375045776368

Training iteration:  84%|████████▎ | 837/1001 [1:02:22<06:36,  2.42s/it, avg loss=200.6150]
Training iteration:  84%|████████▎ | 838/1001 [1:02:22<06:34,  2.42s/it, avg loss=200.6150]Checkpoint at iteration 838 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 200.61495208740234

Training iteration:  84%|████████▎ | 838/1001 [1:02:24<06:34,  2.42s/it, avg loss=132.1109]
Training iteration:  84%|████████▍ | 839/1001 [1:02:24<06:32,  2.42s/it, avg loss=132.1109]Checkpoint at iteration 839 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 132.11091842651368

Training iteration:  84%|████████▍ | 839/1001 [1:02:26<06:32,  2.42s/it, avg loss=186.3297]
Training iteration:  84%|████████▍ | 840/1001 [1:02:26<06:29,  2.42s/it, avg loss=186.3297]Checkpoint at iteration 840 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 186.32973937988282

Training iteration:  84%|████████▍ | 840/1001 [1:02:29<06:29,  2.42s/it, avg loss=199.3420]
Training iteration:  84%|████████▍ | 841/1001 [1:02:29<06:27,  2.42s/it, avg loss=199.3420]Checkpoint at iteration 841 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 199.34199066162108

Training iteration:  84%|████████▍ | 841/1001 [1:02:31<06:27,  2.42s/it, avg loss=222.6822]
Training iteration:  84%|████████▍ | 842/1001 [1:02:31<06:25,  2.42s/it, avg loss=222.6822]Checkpoint at iteration 842 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 222.68223190307617

Training iteration:  84%|████████▍ | 842/1001 [1:02:34<06:25,  2.42s/it, avg loss=216.7289]
Training iteration:  84%|████████▍ | 843/1001 [1:02:34<06:22,  2.42s/it, avg loss=216.7289]Checkpoint at iteration 843 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 216.72894058227538

Training iteration:  84%|████████▍ | 843/1001 [1:02:36<06:22,  2.42s/it, avg loss=199.4163]
Training iteration:  84%|████████▍ | 844/1001 [1:02:36<06:20,  2.42s/it, avg loss=199.4163]Checkpoint at iteration 844 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 199.4162971496582

Training iteration:  84%|████████▍ | 844/1001 [1:02:39<06:20,  2.42s/it, avg loss=235.1208]
Training iteration:  84%|████████▍ | 845/1001 [1:02:39<06:17,  2.42s/it, avg loss=235.1208]Checkpoint at iteration 845 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 235.12077789306642

Training iteration:  84%|████████▍ | 845/1001 [1:02:41<06:17,  2.42s/it, avg loss=180.1727]
Training iteration:  85%|████████▍ | 846/1001 [1:02:41<06:15,  2.42s/it, avg loss=180.1727]Checkpoint at iteration 846 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 180.17271041870117

Training iteration:  85%|████████▍ | 846/1001 [1:02:43<06:15,  2.42s/it, avg loss=178.9221]
Training iteration:  85%|████████▍ | 847/1001 [1:02:43<06:12,  2.42s/it, avg loss=178.9221]Checkpoint at iteration 847 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 178.92213134765626

Training iteration:  85%|████████▍ | 847/1001 [1:02:46<06:12,  2.42s/it, avg loss=163.6112]
Training iteration:  85%|████████▍ | 848/1001 [1:02:46<06:10,  2.42s/it, avg loss=163.6112]Checkpoint at iteration 848 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 163.61122131347656

Training iteration:  85%|████████▍ | 848/1001 [1:02:48<06:10,  2.42s/it, avg loss=211.9763]
Training iteration:  85%|████████▍ | 849/1001 [1:02:48<06:07,  2.42s/it, avg loss=211.9763]Checkpoint at iteration 849 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 211.97630310058594

Training iteration:  85%|████████▍ | 849/1001 [1:02:51<06:07,  2.42s/it, avg loss=203.0223]
Training iteration:  85%|████████▍ | 850/1001 [1:02:51<06:05,  2.42s/it, avg loss=203.0223]Checkpoint at iteration 850 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 203.0223487854004

Training iteration:  85%|████████▍ | 850/1001 [1:02:53<06:05,  2.42s/it, avg loss=162.4682]
Training iteration:  85%|████████▌ | 851/1001 [1:02:53<06:03,  2.42s/it, avg loss=162.4682]Checkpoint at iteration 851 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 162.4681709289551

Training iteration:  85%|████████▌ | 851/1001 [1:02:56<06:03,  2.42s/it, avg loss=195.6361]
Training iteration:  85%|████████▌ | 852/1001 [1:02:56<06:00,  2.42s/it, avg loss=195.6361]Checkpoint at iteration 852 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 195.63605499267578

Training iteration:  85%|████████▌ | 852/1001 [1:02:58<06:00,  2.42s/it, avg loss=219.7574]
Training iteration:  85%|████████▌ | 853/1001 [1:02:58<05:58,  2.42s/it, avg loss=219.7574]Checkpoint at iteration 853 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 219.75738143920898

Training iteration:  85%|████████▌ | 853/1001 [1:03:00<05:58,  2.42s/it, avg loss=224.3189]
Training iteration:  85%|████████▌ | 854/1001 [1:03:00<05:56,  2.42s/it, avg loss=224.3189]Checkpoint at iteration 854 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 224.3188949584961

Training iteration:  85%|████████▌ | 854/1001 [1:03:03<05:56,  2.42s/it, avg loss=207.8863]
Training iteration:  85%|████████▌ | 855/1001 [1:03:03<05:53,  2.42s/it, avg loss=207.8863]Checkpoint at iteration 855 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 207.88630218505858

Training iteration:  85%|████████▌ | 855/1001 [1:03:05<05:53,  2.42s/it, avg loss=204.5915]
Training iteration:  86%|████████▌ | 856/1001 [1:03:05<05:51,  2.42s/it, avg loss=204.5915]Checkpoint at iteration 856 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 204.5914520263672

Training iteration:  86%|████████▌ | 856/1001 [1:03:08<05:51,  2.42s/it, avg loss=196.2995]
Training iteration:  86%|████████▌ | 857/1001 [1:03:08<05:48,  2.42s/it, avg loss=196.2995]Checkpoint at iteration 857 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 196.2994644165039

Training iteration:  86%|████████▌ | 857/1001 [1:03:10<05:48,  2.42s/it, avg loss=155.3072]
Training iteration:  86%|████████▌ | 858/1001 [1:03:10<05:46,  2.42s/it, avg loss=155.3072]Checkpoint at iteration 858 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 155.30715255737306

Training iteration:  86%|████████▌ | 858/1001 [1:03:12<05:46,  2.42s/it, avg loss=125.5303]
Training iteration:  86%|████████▌ | 859/1001 [1:03:12<05:43,  2.42s/it, avg loss=125.5303]Checkpoint at iteration 859 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 125.5303466796875

Training iteration:  86%|████████▌ | 859/1001 [1:03:15<05:43,  2.42s/it, avg loss=177.8002]
Training iteration:  86%|████████▌ | 860/1001 [1:03:15<05:41,  2.42s/it, avg loss=177.8002]Checkpoint at iteration 860 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 177.8001907348633

Training iteration:  86%|████████▌ | 860/1001 [1:03:17<05:41,  2.42s/it, avg loss=196.4807]
Training iteration:  86%|████████▌ | 861/1001 [1:03:17<05:38,  2.42s/it, avg loss=196.4807]Checkpoint at iteration 861 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 196.48073654174806

Training iteration:  86%|████████▌ | 861/1001 [1:03:20<05:38,  2.42s/it, avg loss=171.6793]
Training iteration:  86%|████████▌ | 862/1001 [1:03:20<05:36,  2.42s/it, avg loss=171.6793]Checkpoint at iteration 862 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 171.6793128967285

Training iteration:  86%|████████▌ | 862/1001 [1:03:22<05:36,  2.42s/it, avg loss=164.8492]
Training iteration:  86%|████████▌ | 863/1001 [1:03:22<05:33,  2.42s/it, avg loss=164.8492]Checkpoint at iteration 863 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 164.84918670654298

Training iteration:  86%|████████▌ | 863/1001 [1:03:25<05:33,  2.42s/it, avg loss=173.4292]
Training iteration:  86%|████████▋ | 864/1001 [1:03:25<05:31,  2.42s/it, avg loss=173.4292]Checkpoint at iteration 864 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 173.42917098999024

Training iteration:  86%|████████▋ | 864/1001 [1:03:27<05:31,  2.42s/it, avg loss=178.1921]
Training iteration:  86%|████████▋ | 865/1001 [1:03:27<05:28,  2.42s/it, avg loss=178.1921]Checkpoint at iteration 865 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 178.19206771850585

Training iteration:  86%|████████▋ | 865/1001 [1:03:29<05:28,  2.42s/it, avg loss=187.8471]
Training iteration:  87%|████████▋ | 866/1001 [1:03:29<05:26,  2.42s/it, avg loss=187.8471]Checkpoint at iteration 866 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 187.8470916748047

Training iteration:  87%|████████▋ | 866/1001 [1:03:32<05:26,  2.42s/it, avg loss=211.8155]
Training iteration:  87%|████████▋ | 867/1001 [1:03:32<05:23,  2.42s/it, avg loss=211.8155]Checkpoint at iteration 867 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 211.81551132202148

Training iteration:  87%|████████▋ | 867/1001 [1:03:34<05:23,  2.42s/it, avg loss=163.3995]
Training iteration:  87%|████████▋ | 868/1001 [1:03:34<05:21,  2.42s/it, avg loss=163.3995]Checkpoint at iteration 868 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 163.39950942993164

Training iteration:  87%|████████▋ | 868/1001 [1:03:37<05:21,  2.42s/it, avg loss=153.6300]
Training iteration:  87%|████████▋ | 869/1001 [1:03:37<05:19,  2.42s/it, avg loss=153.6300]Checkpoint at iteration 869 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 153.62996368408204

Training iteration:  87%|████████▋ | 869/1001 [1:03:39<05:19,  2.42s/it, avg loss=186.1056]
Training iteration:  87%|████████▋ | 870/1001 [1:03:39<05:16,  2.42s/it, avg loss=186.1056]Checkpoint at iteration 870 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 186.10564346313475

Training iteration:  87%|████████▋ | 870/1001 [1:03:42<05:16,  2.42s/it, avg loss=170.7824]
Training iteration:  87%|████████▋ | 871/1001 [1:03:42<05:14,  2.42s/it, avg loss=170.7824]Checkpoint at iteration 871 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 170.7824378967285

Training iteration:  87%|████████▋ | 871/1001 [1:03:44<05:14,  2.42s/it, avg loss=182.4269]
Training iteration:  87%|████████▋ | 872/1001 [1:03:44<05:11,  2.42s/it, avg loss=182.4269]Checkpoint at iteration 872 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 182.42688064575196

Training iteration:  87%|████████▋ | 872/1001 [1:03:46<05:11,  2.42s/it, avg loss=225.7649]
Training iteration:  87%|████████▋ | 873/1001 [1:03:46<05:09,  2.42s/it, avg loss=225.7649]Checkpoint at iteration 873 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 225.76486358642578

Training iteration:  87%|████████▋ | 873/1001 [1:03:49<05:09,  2.42s/it, avg loss=147.8427]
Training iteration:  87%|████████▋ | 874/1001 [1:03:49<05:07,  2.42s/it, avg loss=147.8427]Checkpoint at iteration 874 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 147.8427490234375

Training iteration:  87%|████████▋ | 874/1001 [1:03:51<05:07,  2.42s/it, avg loss=180.4481]
Training iteration:  87%|████████▋ | 875/1001 [1:03:51<05:04,  2.42s/it, avg loss=180.4481]Checkpoint at iteration 875 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 180.44813537597656

Training iteration:  87%|████████▋ | 875/1001 [1:03:54<05:04,  2.42s/it, avg loss=193.8812]
Training iteration:  88%|████████▊ | 876/1001 [1:03:54<05:02,  2.42s/it, avg loss=193.8812]Checkpoint at iteration 876 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 193.88120727539064

Training iteration:  88%|████████▊ | 876/1001 [1:03:56<05:02,  2.42s/it, avg loss=207.6705]
Training iteration:  88%|████████▊ | 877/1001 [1:03:56<05:00,  2.42s/it, avg loss=207.6705]Checkpoint at iteration 877 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 207.67053298950196

Training iteration:  88%|████████▊ | 877/1001 [1:03:58<05:00,  2.42s/it, avg loss=172.5754]
Training iteration:  88%|████████▊ | 878/1001 [1:03:58<04:57,  2.42s/it, avg loss=172.5754]Checkpoint at iteration 878 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 172.5754264831543

Training iteration:  88%|████████▊ | 878/1001 [1:04:01<04:57,  2.42s/it, avg loss=149.7628]
Training iteration:  88%|████████▊ | 879/1001 [1:04:01<04:55,  2.42s/it, avg loss=149.7628]Checkpoint at iteration 879 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 149.76276779174805

Training iteration:  88%|████████▊ | 879/1001 [1:04:03<04:55,  2.42s/it, avg loss=185.6696]
Training iteration:  88%|████████▊ | 880/1001 [1:04:03<04:52,  2.42s/it, avg loss=185.6696]Checkpoint at iteration 880 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 185.6695930480957

Training iteration:  88%|████████▊ | 880/1001 [1:04:06<04:52,  2.42s/it, avg loss=180.3273]
Training iteration:  88%|████████▊ | 881/1001 [1:04:06<04:50,  2.42s/it, avg loss=180.3273]Checkpoint at iteration 881 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 180.32728881835936

Training iteration:  88%|████████▊ | 881/1001 [1:04:08<04:50,  2.42s/it, avg loss=156.5235]
Training iteration:  88%|████████▊ | 882/1001 [1:04:08<04:48,  2.42s/it, avg loss=156.5235]Checkpoint at iteration 882 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 156.52349090576172

Training iteration:  88%|████████▊ | 882/1001 [1:04:11<04:48,  2.42s/it, avg loss=205.7255]
Training iteration:  88%|████████▊ | 883/1001 [1:04:11<04:45,  2.42s/it, avg loss=205.7255]Checkpoint at iteration 883 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 205.72551727294922

Training iteration:  88%|████████▊ | 883/1001 [1:04:13<04:45,  2.42s/it, avg loss=151.1245]
Training iteration:  88%|████████▊ | 884/1001 [1:04:13<04:43,  2.42s/it, avg loss=151.1245]Checkpoint at iteration 884 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 151.12445831298828

Training iteration:  88%|████████▊ | 884/1001 [1:04:15<04:43,  2.42s/it, avg loss=202.9372]
Training iteration:  88%|████████▊ | 885/1001 [1:04:15<04:40,  2.42s/it, avg loss=202.9372]Checkpoint at iteration 885 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 202.9372116088867

Training iteration:  88%|████████▊ | 885/1001 [1:04:18<04:40,  2.42s/it, avg loss=155.8685]
Training iteration:  89%|████████▊ | 886/1001 [1:04:18<04:38,  2.42s/it, avg loss=155.8685]Checkpoint at iteration 886 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 155.86852264404297

Training iteration:  89%|████████▊ | 886/1001 [1:04:20<04:38,  2.42s/it, avg loss=167.9183]
Training iteration:  89%|████████▊ | 887/1001 [1:04:20<04:35,  2.42s/it, avg loss=167.9183]Checkpoint at iteration 887 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 167.91834564208983

Training iteration:  89%|████████▊ | 887/1001 [1:04:23<04:35,  2.42s/it, avg loss=155.9510]
Training iteration:  89%|████████▊ | 888/1001 [1:04:23<04:33,  2.42s/it, avg loss=155.9510]Checkpoint at iteration 888 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 155.95101776123047

Training iteration:  89%|████████▊ | 888/1001 [1:04:25<04:33,  2.42s/it, avg loss=190.8479]
Training iteration:  89%|████████▉ | 889/1001 [1:04:25<04:30,  2.42s/it, avg loss=190.8479]Checkpoint at iteration 889 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 190.84788818359374

Training iteration:  89%|████████▉ | 889/1001 [1:04:27<04:30,  2.42s/it, avg loss=270.5100]
Training iteration:  89%|████████▉ | 890/1001 [1:04:27<04:28,  2.42s/it, avg loss=270.5100]Checkpoint at iteration 890 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 270.5100402832031

Training iteration:  89%|████████▉ | 890/1001 [1:04:30<04:28,  2.42s/it, avg loss=220.8066]
Training iteration:  89%|████████▉ | 891/1001 [1:04:30<04:26,  2.42s/it, avg loss=220.8066]Checkpoint at iteration 891 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 220.80662994384767

Training iteration:  89%|████████▉ | 891/1001 [1:04:32<04:26,  2.42s/it, avg loss=241.6026]
Training iteration:  89%|████████▉ | 892/1001 [1:04:32<04:24,  2.42s/it, avg loss=241.6026]Checkpoint at iteration 892 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 241.60255584716796

Training iteration:  89%|████████▉ | 892/1001 [1:04:35<04:24,  2.42s/it, avg loss=196.4440]
Training iteration:  89%|████████▉ | 893/1001 [1:04:35<04:21,  2.42s/it, avg loss=196.4440]Checkpoint at iteration 893 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 196.44396286010743

Training iteration:  89%|████████▉ | 893/1001 [1:04:37<04:21,  2.42s/it, avg loss=169.5098]
Training iteration:  89%|████████▉ | 894/1001 [1:04:37<04:19,  2.42s/it, avg loss=169.5098]Checkpoint at iteration 894 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 169.50983276367188

Training iteration:  89%|████████▉ | 894/1001 [1:04:40<04:19,  2.42s/it, avg loss=207.2887]
Training iteration:  89%|████████▉ | 895/1001 [1:04:40<04:16,  2.42s/it, avg loss=207.2887]Checkpoint at iteration 895 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 207.28868865966797

Training iteration:  89%|████████▉ | 895/1001 [1:04:42<04:16,  2.42s/it, avg loss=157.0000]
Training iteration:  90%|████████▉ | 896/1001 [1:04:42<04:14,  2.42s/it, avg loss=157.0000]Checkpoint at iteration 896 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 157.00004196166992

Training iteration:  90%|████████▉ | 896/1001 [1:04:44<04:14,  2.42s/it, avg loss=206.7983]
Training iteration:  90%|████████▉ | 897/1001 [1:04:44<04:11,  2.42s/it, avg loss=206.7983]Checkpoint at iteration 897 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 206.79828872680665

Training iteration:  90%|████████▉ | 897/1001 [1:04:47<04:11,  2.42s/it, avg loss=221.9907]
Training iteration:  90%|████████▉ | 898/1001 [1:04:47<04:09,  2.42s/it, avg loss=221.9907]Checkpoint at iteration 898 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 221.9907325744629

Training iteration:  90%|████████▉ | 898/1001 [1:04:49<04:09,  2.42s/it, avg loss=164.3739]
Training iteration:  90%|████████▉ | 899/1001 [1:04:49<04:06,  2.42s/it, avg loss=164.3739]Checkpoint at iteration 899 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 164.3738800048828

Training iteration:  90%|████████▉ | 899/1001 [1:04:52<04:06,  2.42s/it, avg loss=177.0623]
Training iteration:  90%|████████▉ | 900/1001 [1:04:52<04:04,  2.42s/it, avg loss=177.0623]Optimization iteration 900 evaluation begins...
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
A new evaluation visualization has been saved: ./saved_data/20240110-063719/it900.png
Training network 0 for evaluation...
Training network 1 for evaluation...
Training network 2 for evaluation...
Training network 3 for evaluation...
Testing network 0 on real datasets for evaluation...
Testing network 1 on real datasets for evaluation...
Testing network 2 on real datasets for evaluation...
Testing network 3 on real datasets for evaluation...
Optimization iteration 900, eval auroc score (train): 20346.5757, eval auroc score (test): 21111.1747
Checkpoint at iteration 900 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 177.06230545043945

Training iteration:  90%|████████▉ | 900/1001 [1:15:52<04:04,  2.42s/it, avg loss=160.1812]
Training iteration:  90%|█████████ | 901/1001 [1:15:52<5:33:13, 199.93s/it, avg loss=160.1812]Checkpoint at iteration 901 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 160.18122100830078

Training iteration:  90%|█████████ | 901/1001 [1:15:55<5:33:13, 199.93s/it, avg loss=215.3755]
Training iteration:  90%|█████████ | 902/1001 [1:15:55<3:52:13, 140.75s/it, avg loss=215.3755]Checkpoint at iteration 902 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 215.37547454833984

Training iteration:  90%|█████████ | 902/1001 [1:15:58<3:52:13, 140.75s/it, avg loss=179.2561]
Training iteration:  90%|█████████ | 903/1001 [1:15:58<2:42:13, 99.32s/it, avg loss=179.2561] Checkpoint at iteration 903 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 179.25612411499023

Training iteration:  90%|█████████ | 903/1001 [1:16:00<2:42:13, 99.32s/it, avg loss=173.8394]
Training iteration:  90%|█████████ | 904/1001 [1:16:00<1:53:40, 70.31s/it, avg loss=173.8394]Checkpoint at iteration 904 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 173.8393913269043

Training iteration:  90%|█████████ | 904/1001 [1:16:03<1:53:40, 70.31s/it, avg loss=196.0682]
Training iteration:  90%|█████████ | 905/1001 [1:16:03<1:20:01, 50.01s/it, avg loss=196.0682]Checkpoint at iteration 905 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 196.06818084716798

Training iteration:  90%|█████████ | 905/1001 [1:16:06<1:20:01, 50.01s/it, avg loss=151.7756]
Training iteration:  91%|█████████ | 906/1001 [1:16:06<56:41, 35.80s/it, avg loss=151.7756]  Checkpoint at iteration 906 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 151.77559432983398

Training iteration:  91%|█████████ | 906/1001 [1:16:08<56:41, 35.80s/it, avg loss=172.4293]
Training iteration:  91%|█████████ | 907/1001 [1:16:08<40:30, 25.86s/it, avg loss=172.4293]Checkpoint at iteration 907 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 172.429288482666

Training iteration:  91%|█████████ | 907/1001 [1:16:11<40:30, 25.86s/it, avg loss=182.2186]
Training iteration:  91%|█████████ | 908/1001 [1:16:11<29:17, 18.90s/it, avg loss=182.2186]Checkpoint at iteration 908 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 182.2186264038086

Training iteration:  91%|█████████ | 908/1001 [1:16:14<29:17, 18.90s/it, avg loss=185.5293]
Training iteration:  91%|█████████ | 909/1001 [1:16:14<21:29, 14.02s/it, avg loss=185.5293]Checkpoint at iteration 909 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 185.52928161621094

Training iteration:  91%|█████████ | 909/1001 [1:16:16<21:29, 14.02s/it, avg loss=176.4236]
Training iteration:  91%|█████████ | 910/1001 [1:16:16<16:05, 10.61s/it, avg loss=176.4236]Checkpoint at iteration 910 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 176.42359313964843

Training iteration:  91%|█████████ | 910/1001 [1:16:19<16:05, 10.61s/it, avg loss=184.2009]
Training iteration:  91%|█████████ | 911/1001 [1:16:19<12:19,  8.22s/it, avg loss=184.2009]Checkpoint at iteration 911 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 184.20089874267578

Training iteration:  91%|█████████ | 911/1001 [1:16:22<12:19,  8.22s/it, avg loss=159.7039]
Training iteration:  91%|█████████ | 912/1001 [1:16:22<09:42,  6.55s/it, avg loss=159.7039]Checkpoint at iteration 912 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 159.7039016723633

Training iteration:  91%|█████████ | 912/1001 [1:16:24<09:42,  6.55s/it, avg loss=235.7478]
Training iteration:  91%|█████████ | 913/1001 [1:16:24<07:53,  5.38s/it, avg loss=235.7478]Checkpoint at iteration 913 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 235.74782180786133

Training iteration:  91%|█████████ | 913/1001 [1:16:27<07:53,  5.38s/it, avg loss=205.7119]
Training iteration:  91%|█████████▏| 914/1001 [1:16:27<06:36,  4.56s/it, avg loss=205.7119]Checkpoint at iteration 914 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 205.71189346313477

Training iteration:  91%|█████████▏| 914/1001 [1:16:30<06:36,  4.56s/it, avg loss=186.6202]
Training iteration:  91%|█████████▏| 915/1001 [1:16:30<05:42,  3.98s/it, avg loss=186.6202]Checkpoint at iteration 915 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 186.62023391723633

Training iteration:  91%|█████████▏| 915/1001 [1:16:32<05:42,  3.98s/it, avg loss=259.8705]
Training iteration:  92%|█████████▏| 916/1001 [1:16:32<05:04,  3.58s/it, avg loss=259.8705]Checkpoint at iteration 916 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 259.8705001831055

Training iteration:  92%|█████████▏| 916/1001 [1:16:35<05:04,  3.58s/it, avg loss=184.3209]
Training iteration:  92%|█████████▏| 917/1001 [1:16:35<04:37,  3.30s/it, avg loss=184.3209]Checkpoint at iteration 917 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 184.32088241577148

Training iteration:  92%|█████████▏| 917/1001 [1:16:37<04:37,  3.30s/it, avg loss=202.1232]
Training iteration:  92%|█████████▏| 918/1001 [1:16:37<04:17,  3.11s/it, avg loss=202.1232]Checkpoint at iteration 918 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 202.1231658935547

Training iteration:  92%|█████████▏| 918/1001 [1:16:40<04:17,  3.11s/it, avg loss=200.8770]
Training iteration:  92%|█████████▏| 919/1001 [1:16:40<04:03,  2.97s/it, avg loss=200.8770]Checkpoint at iteration 919 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 200.87704620361328

Training iteration:  92%|█████████▏| 919/1001 [1:16:43<04:03,  2.97s/it, avg loss=199.9146]
Training iteration:  92%|█████████▏| 920/1001 [1:16:43<03:52,  2.87s/it, avg loss=199.9146]Checkpoint at iteration 920 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 199.91462936401368

Training iteration:  92%|█████████▏| 920/1001 [1:16:45<03:52,  2.87s/it, avg loss=151.8960]
Training iteration:  92%|█████████▏| 921/1001 [1:16:45<03:44,  2.81s/it, avg loss=151.8960]Checkpoint at iteration 921 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 151.89601135253906

Training iteration:  92%|█████████▏| 921/1001 [1:16:48<03:44,  2.81s/it, avg loss=142.4785]
Training iteration:  92%|█████████▏| 922/1001 [1:16:48<03:37,  2.76s/it, avg loss=142.4785]Checkpoint at iteration 922 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 142.47845306396485

Training iteration:  92%|█████████▏| 922/1001 [1:16:51<03:37,  2.76s/it, avg loss=182.4178]
Training iteration:  92%|█████████▏| 923/1001 [1:16:51<03:32,  2.72s/it, avg loss=182.4178]Checkpoint at iteration 923 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 182.41778182983398

Training iteration:  92%|█████████▏| 923/1001 [1:16:53<03:32,  2.72s/it, avg loss=189.9714]
Training iteration:  92%|█████████▏| 924/1001 [1:16:53<03:28,  2.70s/it, avg loss=189.9714]Checkpoint at iteration 924 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 189.97140197753907

Training iteration:  92%|█████████▏| 924/1001 [1:16:56<03:28,  2.70s/it, avg loss=133.3097]
Training iteration:  92%|█████████▏| 925/1001 [1:16:56<03:24,  2.69s/it, avg loss=133.3097]Checkpoint at iteration 925 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 133.30966796875

Training iteration:  92%|█████████▏| 925/1001 [1:16:59<03:24,  2.69s/it, avg loss=182.0945]
Training iteration:  93%|█████████▎| 926/1001 [1:16:59<03:20,  2.67s/it, avg loss=182.0945]Checkpoint at iteration 926 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 182.09452209472656

Training iteration:  93%|█████████▎| 926/1001 [1:17:01<03:20,  2.67s/it, avg loss=151.8488]
Training iteration:  93%|█████████▎| 927/1001 [1:17:01<03:17,  2.67s/it, avg loss=151.8488]Checkpoint at iteration 927 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 151.84880676269532

Training iteration:  93%|█████████▎| 927/1001 [1:17:04<03:17,  2.67s/it, avg loss=213.1604]
Training iteration:  93%|█████████▎| 928/1001 [1:17:04<03:14,  2.66s/it, avg loss=213.1604]Checkpoint at iteration 928 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 213.16042556762696

Training iteration:  93%|█████████▎| 928/1001 [1:17:07<03:14,  2.66s/it, avg loss=178.0269]
Training iteration:  93%|█████████▎| 929/1001 [1:17:07<03:11,  2.66s/it, avg loss=178.0269]Checkpoint at iteration 929 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 178.02691802978515

Training iteration:  93%|█████████▎| 929/1001 [1:17:09<03:11,  2.66s/it, avg loss=182.5879]
Training iteration:  93%|█████████▎| 930/1001 [1:17:09<03:08,  2.65s/it, avg loss=182.5879]Checkpoint at iteration 930 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 182.5879119873047

Training iteration:  93%|█████████▎| 930/1001 [1:17:12<03:08,  2.65s/it, avg loss=159.6220]
Training iteration:  93%|█████████▎| 931/1001 [1:17:12<03:05,  2.65s/it, avg loss=159.6220]Checkpoint at iteration 931 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 159.6219924926758

Training iteration:  93%|█████████▎| 931/1001 [1:17:15<03:05,  2.65s/it, avg loss=152.7717]
Training iteration:  93%|█████████▎| 932/1001 [1:17:15<03:02,  2.65s/it, avg loss=152.7717]Checkpoint at iteration 932 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 152.7716972351074

Training iteration:  93%|█████████▎| 932/1001 [1:17:17<03:02,  2.65s/it, avg loss=150.5630]
Training iteration:  93%|█████████▎| 933/1001 [1:17:17<03:00,  2.65s/it, avg loss=150.5630]Checkpoint at iteration 933 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 150.5630310058594

Training iteration:  93%|█████████▎| 933/1001 [1:17:20<03:00,  2.65s/it, avg loss=161.3122]
Training iteration:  93%|█████████▎| 934/1001 [1:17:20<02:57,  2.65s/it, avg loss=161.3122]Checkpoint at iteration 934 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 161.31217727661132

Training iteration:  93%|█████████▎| 934/1001 [1:17:22<02:57,  2.65s/it, avg loss=207.9582]
Training iteration:  93%|█████████▎| 935/1001 [1:17:22<02:54,  2.65s/it, avg loss=207.9582]Checkpoint at iteration 935 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 207.95821838378907

Training iteration:  93%|█████████▎| 935/1001 [1:17:25<02:54,  2.65s/it, avg loss=186.6844]
Training iteration:  94%|█████████▎| 936/1001 [1:17:25<02:52,  2.65s/it, avg loss=186.6844]Checkpoint at iteration 936 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 186.68442764282227

Training iteration:  94%|█████████▎| 936/1001 [1:17:28<02:52,  2.65s/it, avg loss=201.3931]
Training iteration:  94%|█████████▎| 937/1001 [1:17:28<02:49,  2.65s/it, avg loss=201.3931]Checkpoint at iteration 937 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 201.39310760498046

Training iteration:  94%|█████████▎| 937/1001 [1:17:30<02:49,  2.65s/it, avg loss=223.5505]
Training iteration:  94%|█████████▎| 938/1001 [1:17:30<02:46,  2.65s/it, avg loss=223.5505]Checkpoint at iteration 938 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 223.5505027770996

Training iteration:  94%|█████████▎| 938/1001 [1:17:33<02:46,  2.65s/it, avg loss=169.7504]
Training iteration:  94%|█████████▍| 939/1001 [1:17:33<02:44,  2.65s/it, avg loss=169.7504]Checkpoint at iteration 939 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 169.75040283203126

Training iteration:  94%|█████████▍| 939/1001 [1:17:36<02:44,  2.65s/it, avg loss=171.6152]
Training iteration:  94%|█████████▍| 940/1001 [1:17:36<02:41,  2.65s/it, avg loss=171.6152]Checkpoint at iteration 940 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 171.61516494750975

Training iteration:  94%|█████████▍| 940/1001 [1:17:38<02:41,  2.65s/it, avg loss=197.3602]
Training iteration:  94%|█████████▍| 941/1001 [1:17:38<02:38,  2.65s/it, avg loss=197.3602]Checkpoint at iteration 941 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 197.3602279663086

Training iteration:  94%|█████████▍| 941/1001 [1:17:41<02:38,  2.65s/it, avg loss=210.9933]
Training iteration:  94%|█████████▍| 942/1001 [1:17:41<02:36,  2.65s/it, avg loss=210.9933]Checkpoint at iteration 942 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 210.9933219909668

Training iteration:  94%|█████████▍| 942/1001 [1:17:44<02:36,  2.65s/it, avg loss=160.1235]
Training iteration:  94%|█████████▍| 943/1001 [1:17:44<02:33,  2.65s/it, avg loss=160.1235]Checkpoint at iteration 943 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 160.12354431152343

Training iteration:  94%|█████████▍| 943/1001 [1:17:46<02:33,  2.65s/it, avg loss=198.2894]
Training iteration:  94%|█████████▍| 944/1001 [1:17:46<02:31,  2.65s/it, avg loss=198.2894]Checkpoint at iteration 944 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 198.28940048217774

Training iteration:  94%|█████████▍| 944/1001 [1:17:49<02:31,  2.65s/it, avg loss=213.9411]
Training iteration:  94%|█████████▍| 945/1001 [1:17:49<02:28,  2.65s/it, avg loss=213.9411]Checkpoint at iteration 945 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 213.94111709594728

Training iteration:  94%|█████████▍| 945/1001 [1:17:52<02:28,  2.65s/it, avg loss=188.3872]
Training iteration:  95%|█████████▍| 946/1001 [1:17:52<02:25,  2.65s/it, avg loss=188.3872]Checkpoint at iteration 946 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 188.38721771240233

Training iteration:  95%|█████████▍| 946/1001 [1:17:54<02:25,  2.65s/it, avg loss=134.8302]
Training iteration:  95%|█████████▍| 947/1001 [1:17:54<02:23,  2.65s/it, avg loss=134.8302]Checkpoint at iteration 947 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 134.83020401000977

Training iteration:  95%|█████████▍| 947/1001 [1:17:57<02:23,  2.65s/it, avg loss=183.1493]
Training iteration:  95%|█████████▍| 948/1001 [1:17:57<02:20,  2.65s/it, avg loss=183.1493]Checkpoint at iteration 948 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 183.14933090209962

Training iteration:  95%|█████████▍| 948/1001 [1:18:00<02:20,  2.65s/it, avg loss=158.2269]
Training iteration:  95%|█████████▍| 949/1001 [1:18:00<02:17,  2.65s/it, avg loss=158.2269]Checkpoint at iteration 949 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 158.22694473266603

Training iteration:  95%|█████████▍| 949/1001 [1:18:02<02:17,  2.65s/it, avg loss=214.2278]
Training iteration:  95%|█████████▍| 950/1001 [1:18:02<02:15,  2.65s/it, avg loss=214.2278]Checkpoint at iteration 950 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 214.22775344848634

Training iteration:  95%|█████████▍| 950/1001 [1:18:05<02:15,  2.65s/it, avg loss=205.1412]
Training iteration:  95%|█████████▌| 951/1001 [1:18:05<02:12,  2.65s/it, avg loss=205.1412]Checkpoint at iteration 951 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 205.14120864868164

Training iteration:  95%|█████████▌| 951/1001 [1:18:08<02:12,  2.65s/it, avg loss=169.1225]
Training iteration:  95%|█████████▌| 952/1001 [1:18:08<02:09,  2.65s/it, avg loss=169.1225]Checkpoint at iteration 952 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 169.1225357055664

Training iteration:  95%|█████████▌| 952/1001 [1:18:10<02:09,  2.65s/it, avg loss=193.4795]
Training iteration:  95%|█████████▌| 953/1001 [1:18:10<02:07,  2.65s/it, avg loss=193.4795]Checkpoint at iteration 953 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 193.4794952392578

Training iteration:  95%|█████████▌| 953/1001 [1:18:13<02:07,  2.65s/it, avg loss=182.4617]
Training iteration:  95%|█████████▌| 954/1001 [1:18:13<02:04,  2.65s/it, avg loss=182.4617]Checkpoint at iteration 954 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 182.4616844177246

Training iteration:  95%|█████████▌| 954/1001 [1:18:15<02:04,  2.65s/it, avg loss=178.5741]
Training iteration:  95%|█████████▌| 955/1001 [1:18:15<02:01,  2.64s/it, avg loss=178.5741]Checkpoint at iteration 955 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 178.57408065795897

Training iteration:  95%|█████████▌| 955/1001 [1:18:18<02:01,  2.64s/it, avg loss=149.9064]
Training iteration:  96%|█████████▌| 956/1001 [1:18:18<01:58,  2.64s/it, avg loss=149.9064]Checkpoint at iteration 956 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 149.9063865661621

Training iteration:  96%|█████████▌| 956/1001 [1:18:21<01:58,  2.64s/it, avg loss=216.6394]
Training iteration:  96%|█████████▌| 957/1001 [1:18:21<01:56,  2.64s/it, avg loss=216.6394]Checkpoint at iteration 957 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 216.63936767578124

Training iteration:  96%|█████████▌| 957/1001 [1:18:23<01:56,  2.64s/it, avg loss=223.8733]
Training iteration:  96%|█████████▌| 958/1001 [1:18:23<01:53,  2.64s/it, avg loss=223.8733]Checkpoint at iteration 958 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 223.8732582092285

Training iteration:  96%|█████████▌| 958/1001 [1:18:26<01:53,  2.64s/it, avg loss=162.0317]
Training iteration:  96%|█████████▌| 959/1001 [1:18:26<01:50,  2.64s/it, avg loss=162.0317]Checkpoint at iteration 959 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 162.03170776367188

Training iteration:  96%|█████████▌| 959/1001 [1:18:29<01:50,  2.64s/it, avg loss=166.7645]
Training iteration:  96%|█████████▌| 960/1001 [1:18:29<01:48,  2.64s/it, avg loss=166.7645]Checkpoint at iteration 960 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 166.76445388793945

Training iteration:  96%|█████████▌| 960/1001 [1:18:31<01:48,  2.64s/it, avg loss=181.8502]
Training iteration:  96%|█████████▌| 961/1001 [1:18:31<01:45,  2.64s/it, avg loss=181.8502]Checkpoint at iteration 961 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 181.85016479492188

Training iteration:  96%|█████████▌| 961/1001 [1:18:34<01:45,  2.64s/it, avg loss=195.9438]
Training iteration:  96%|█████████▌| 962/1001 [1:18:34<01:43,  2.64s/it, avg loss=195.9438]Checkpoint at iteration 962 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 195.9438247680664

Training iteration:  96%|█████████▌| 962/1001 [1:18:37<01:43,  2.64s/it, avg loss=172.0725]
Training iteration:  96%|█████████▌| 963/1001 [1:18:37<01:40,  2.64s/it, avg loss=172.0725]Checkpoint at iteration 963 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 172.0725425720215

Training iteration:  96%|█████████▌| 963/1001 [1:18:39<01:40,  2.64s/it, avg loss=218.1683]
Training iteration:  96%|█████████▋| 964/1001 [1:18:39<01:37,  2.64s/it, avg loss=218.1683]Checkpoint at iteration 964 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 218.16825332641602

Training iteration:  96%|█████████▋| 964/1001 [1:18:42<01:37,  2.64s/it, avg loss=197.9324]
Training iteration:  96%|█████████▋| 965/1001 [1:18:42<01:35,  2.64s/it, avg loss=197.9324]Checkpoint at iteration 965 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 197.9323745727539

Training iteration:  96%|█████████▋| 965/1001 [1:18:45<01:35,  2.64s/it, avg loss=171.9093]
Training iteration:  97%|█████████▋| 966/1001 [1:18:45<01:32,  2.64s/it, avg loss=171.9093]Checkpoint at iteration 966 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 171.9093147277832

Training iteration:  97%|█████████▋| 966/1001 [1:18:47<01:32,  2.64s/it, avg loss=189.7156]
Training iteration:  97%|█████████▋| 967/1001 [1:18:47<01:29,  2.64s/it, avg loss=189.7156]Checkpoint at iteration 967 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 189.71557540893554

Training iteration:  97%|█████████▋| 967/1001 [1:18:50<01:29,  2.64s/it, avg loss=178.3395]
Training iteration:  97%|█████████▋| 968/1001 [1:18:50<01:27,  2.64s/it, avg loss=178.3395]Checkpoint at iteration 968 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 178.33946533203124

Training iteration:  97%|█████████▋| 968/1001 [1:18:52<01:27,  2.64s/it, avg loss=162.2584]
Training iteration:  97%|█████████▋| 969/1001 [1:18:52<01:24,  2.64s/it, avg loss=162.2584]Checkpoint at iteration 969 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 162.25836410522462

Training iteration:  97%|█████████▋| 969/1001 [1:18:55<01:24,  2.64s/it, avg loss=187.9292]
Training iteration:  97%|█████████▋| 970/1001 [1:18:55<01:21,  2.64s/it, avg loss=187.9292]Checkpoint at iteration 970 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 187.9292137145996

Training iteration:  97%|█████████▋| 970/1001 [1:18:58<01:21,  2.64s/it, avg loss=189.5544]
Training iteration:  97%|█████████▋| 971/1001 [1:18:58<01:19,  2.64s/it, avg loss=189.5544]Checkpoint at iteration 971 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 189.55438537597655

Training iteration:  97%|█████████▋| 971/1001 [1:19:00<01:19,  2.64s/it, avg loss=179.8223]
Training iteration:  97%|█████████▋| 972/1001 [1:19:00<01:16,  2.64s/it, avg loss=179.8223]Checkpoint at iteration 972 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 179.82232894897462

Training iteration:  97%|█████████▋| 972/1001 [1:19:03<01:16,  2.64s/it, avg loss=165.2966]
Training iteration:  97%|█████████▋| 973/1001 [1:19:03<01:14,  2.64s/it, avg loss=165.2966]Checkpoint at iteration 973 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 165.29657897949218

Training iteration:  97%|█████████▋| 973/1001 [1:19:06<01:14,  2.64s/it, avg loss=180.7686]
Training iteration:  97%|█████████▋| 974/1001 [1:19:06<01:11,  2.64s/it, avg loss=180.7686]Checkpoint at iteration 974 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 180.76862182617188

Training iteration:  97%|█████████▋| 974/1001 [1:19:08<01:11,  2.64s/it, avg loss=198.6076]
Training iteration:  97%|█████████▋| 975/1001 [1:19:08<01:08,  2.64s/it, avg loss=198.6076]Checkpoint at iteration 975 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 198.60759658813475

Training iteration:  97%|█████████▋| 975/1001 [1:19:11<01:08,  2.64s/it, avg loss=181.8384]
Training iteration:  98%|█████████▊| 976/1001 [1:19:11<01:06,  2.65s/it, avg loss=181.8384]Checkpoint at iteration 976 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 181.8383544921875

Training iteration:  98%|█████████▊| 976/1001 [1:19:14<01:06,  2.65s/it, avg loss=213.3900]
Training iteration:  98%|█████████▊| 977/1001 [1:19:14<01:03,  2.65s/it, avg loss=213.3900]Checkpoint at iteration 977 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 213.39000091552734

Training iteration:  98%|█████████▊| 977/1001 [1:19:16<01:03,  2.65s/it, avg loss=183.6858]
Training iteration:  98%|█████████▊| 978/1001 [1:19:16<01:00,  2.65s/it, avg loss=183.6858]Checkpoint at iteration 978 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 183.68583297729492

Training iteration:  98%|█████████▊| 978/1001 [1:19:19<01:00,  2.65s/it, avg loss=192.2768]
Training iteration:  98%|█████████▊| 979/1001 [1:19:19<00:58,  2.65s/it, avg loss=192.2768]Checkpoint at iteration 979 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 192.27679672241212

Training iteration:  98%|█████████▊| 979/1001 [1:19:22<00:58,  2.65s/it, avg loss=165.5660]
Training iteration:  98%|█████████▊| 980/1001 [1:19:22<00:55,  2.65s/it, avg loss=165.5660]Checkpoint at iteration 980 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 165.56601943969727

Training iteration:  98%|█████████▊| 980/1001 [1:19:24<00:55,  2.65s/it, avg loss=150.5709]
Training iteration:  98%|█████████▊| 981/1001 [1:19:24<00:52,  2.65s/it, avg loss=150.5709]Checkpoint at iteration 981 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 150.5709228515625

Training iteration:  98%|█████████▊| 981/1001 [1:19:27<00:52,  2.65s/it, avg loss=214.8443]
Training iteration:  98%|█████████▊| 982/1001 [1:19:27<00:50,  2.65s/it, avg loss=214.8443]Checkpoint at iteration 982 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 214.84429092407225

Training iteration:  98%|█████████▊| 982/1001 [1:19:30<00:50,  2.65s/it, avg loss=138.1680]
Training iteration:  98%|█████████▊| 983/1001 [1:19:30<00:47,  2.65s/it, avg loss=138.1680]Checkpoint at iteration 983 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 138.16795959472657

Training iteration:  98%|█████████▊| 983/1001 [1:19:32<00:47,  2.65s/it, avg loss=151.7979]
Training iteration:  98%|█████████▊| 984/1001 [1:19:32<00:45,  2.65s/it, avg loss=151.7979]Checkpoint at iteration 984 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 151.79785842895507

Training iteration:  98%|█████████▊| 984/1001 [1:19:35<00:45,  2.65s/it, avg loss=155.5158]
Training iteration:  98%|█████████▊| 985/1001 [1:19:35<00:42,  2.65s/it, avg loss=155.5158]Checkpoint at iteration 985 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 155.51579208374022

Training iteration:  98%|█████████▊| 985/1001 [1:19:37<00:42,  2.65s/it, avg loss=217.6653]
Training iteration:  99%|█████████▊| 986/1001 [1:19:37<00:39,  2.65s/it, avg loss=217.6653]Checkpoint at iteration 986 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 217.6652618408203

Training iteration:  99%|█████████▊| 986/1001 [1:19:40<00:39,  2.65s/it, avg loss=186.6002]
Training iteration:  99%|█████████▊| 987/1001 [1:19:40<00:37,  2.65s/it, avg loss=186.6002]Checkpoint at iteration 987 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 186.60015945434571

Training iteration:  99%|█████████▊| 987/1001 [1:19:43<00:37,  2.65s/it, avg loss=119.8340]
Training iteration:  99%|█████████▊| 988/1001 [1:19:43<00:34,  2.65s/it, avg loss=119.8340]Checkpoint at iteration 988 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 119.83403549194335

Training iteration:  99%|█████████▊| 988/1001 [1:19:45<00:34,  2.65s/it, avg loss=183.0612]
Training iteration:  99%|█████████▉| 989/1001 [1:19:45<00:31,  2.65s/it, avg loss=183.0612]Checkpoint at iteration 989 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 183.0611541748047

Training iteration:  99%|█████████▉| 989/1001 [1:19:48<00:31,  2.65s/it, avg loss=157.1909]
Training iteration:  99%|█████████▉| 990/1001 [1:19:48<00:29,  2.65s/it, avg loss=157.1909]Checkpoint at iteration 990 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 157.19086151123048

Training iteration:  99%|█████████▉| 990/1001 [1:19:51<00:29,  2.65s/it, avg loss=191.6163]
Training iteration:  99%|█████████▉| 991/1001 [1:19:51<00:26,  2.65s/it, avg loss=191.6163]Checkpoint at iteration 991 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 191.6162582397461

Training iteration:  99%|█████████▉| 991/1001 [1:19:53<00:26,  2.65s/it, avg loss=210.9318]
Training iteration:  99%|█████████▉| 992/1001 [1:19:53<00:23,  2.65s/it, avg loss=210.9318]Checkpoint at iteration 992 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 210.93184585571288

Training iteration:  99%|█████████▉| 992/1001 [1:19:56<00:23,  2.65s/it, avg loss=205.4458]
Training iteration:  99%|█████████▉| 993/1001 [1:19:56<00:21,  2.65s/it, avg loss=205.4458]Checkpoint at iteration 993 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 205.44580764770507

Training iteration:  99%|█████████▉| 993/1001 [1:19:59<00:21,  2.65s/it, avg loss=168.8403]
Training iteration:  99%|█████████▉| 994/1001 [1:19:59<00:18,  2.65s/it, avg loss=168.8403]Checkpoint at iteration 994 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 168.84030303955078

Training iteration:  99%|█████████▉| 994/1001 [1:20:01<00:18,  2.65s/it, avg loss=178.5994]
Training iteration:  99%|█████████▉| 995/1001 [1:20:01<00:15,  2.65s/it, avg loss=178.5994]Checkpoint at iteration 995 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 178.59944839477538

Training iteration:  99%|█████████▉| 995/1001 [1:20:04<00:15,  2.65s/it, avg loss=134.6971]
Training iteration: 100%|█████████▉| 996/1001 [1:20:04<00:13,  2.65s/it, avg loss=134.6971]Checkpoint at iteration 996 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 134.69710006713868

Training iteration: 100%|█████████▉| 996/1001 [1:20:07<00:13,  2.65s/it, avg loss=199.5039]
Training iteration: 100%|█████████▉| 997/1001 [1:20:07<00:10,  2.65s/it, avg loss=199.5039]Checkpoint at iteration 997 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 199.5038948059082

Training iteration: 100%|█████████▉| 997/1001 [1:20:09<00:10,  2.65s/it, avg loss=239.4580]
Training iteration: 100%|█████████▉| 998/1001 [1:20:09<00:07,  2.65s/it, avg loss=239.4580]Checkpoint at iteration 998 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 239.45798950195314

Training iteration: 100%|█████████▉| 998/1001 [1:20:12<00:07,  2.65s/it, avg loss=160.5570]
Training iteration: 100%|█████████▉| 999/1001 [1:20:12<00:05,  2.65s/it, avg loss=160.5570]Checkpoint at iteration 999 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 160.5570426940918

Training iteration: 100%|█████████▉| 999/1001 [1:20:15<00:05,  2.65s/it, avg loss=184.0872]
Training iteration: 100%|█████████▉| 1000/1001 [1:20:15<00:02,  2.65s/it, avg loss=184.0872]Optimization iteration 1000 evaluation begins...
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
A new evaluation visualization has been saved: ./saved_data/20240110-063719/it1000.png
Training network 0 for evaluation...
Training network 1 for evaluation...
Training network 2 for evaluation...
Training network 3 for evaluation...
Testing network 0 on real datasets for evaluation...
Testing network 1 on real datasets for evaluation...
Testing network 2 on real datasets for evaluation...
Testing network 3 on real datasets for evaluation...
Optimization iteration 1000, eval auroc score (train): 21356.3476, eval auroc score (test): 22491.4375
Checkpoint at iteration 1000 saved at ./saved_data/20240110-063719/chckpnt_los_10samples.pth. Loss = 184.08720169067382

Training iteration: 100%|█████████▉| 1000/1001 [1:32:30<00:05,  5.55s/it, avg loss=184.0872]
All data will be output to ./saved_data/20240110-081107
Running on device: CUDA
Objective has been set to ihm
Initializing train set for ihm objective...
Loading dataset to RAM...
Loading from file ./data/mimic3/multitask_preliminary/train/all.pkl, skipping individuals...
Preprocessing dataset...
Computing dataset statistics...
First item in the dataset: 
(tensor([[ 1.0000,  0.0000,  0.1069,  ...,  0.0000,  0.0000,  0.0000],
        [ 1.0000,  0.0000,  0.0802,  ...,  0.0000,  0.0000,  0.0000],
        [ 1.0000,  0.0000,  0.0980,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 1.0000,  0.0000, -0.0583,  ...,  0.1849, -0.2451,  0.0219],
        [ 1.0000,  0.0000, -0.0672,  ...,  0.2056, -0.2451,  0.0219],
        [ 1.0000,  0.0000, -0.0806,  ...,  0.2159, -0.2451,  0.0219]]), tensor(1))
Feature tensor shape: torch.Size([48, 42])
Objective has been set to ihm
Initializing test set for ihm objective...
Loading dataset to RAM...
Loading from file ./data/mimic3/multitask_preliminary/test/all.pkl, skipping individuals...
Preprocessing dataset...
Computing dataset statistics...
First item in the dataset: 
(tensor([[ 1.0000,  0.0000, -0.0538,  ...,  0.0000,  0.0000,  0.0000],
        [ 1.0000,  0.0000, -0.0806,  ..., -0.0698,  0.0000,  0.0000],
        [ 1.0000,  0.0000, -0.0717,  ..., -0.0698,  0.0000, -0.3360],
        ...,
        [ 1.0000,  0.0000, -0.0627,  ..., -0.0698,  0.0000,  0.0823],
        [ 1.0000,  0.0000, -0.0627,  ..., -0.0698,  0.0000,  0.0823],
        [ 1.0000,  0.0000, -0.0627,  ..., -0.0698,  0.0000,  0.0823]]), tensor(1))
Feature tensor shape: torch.Size([48, 42])
Input tensor shape: torch.Size([48, 42])
Initializing synthetic dataset. Number of samples in total = 100
Objective has been set to los
Objective has been set to los
Synthetic feature shape: torch.Size([100, 48, 42])
Synthetic label shape: torch.Size([100])
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Ready for training

Training iteration:   0%|          | 0/1001 [00:00<?, ?it/s]Optimization iteration 0 evaluation begins...
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
A new evaluation visualization has been saved: ./saved_data/20240110-081107/it0.png
Training network 0 for evaluation...
Training network 1 for evaluation...
Training network 2 for evaluation...
Training network 3 for evaluation...
Testing network 0 on real datasets for evaluation...
Testing network 1 on real datasets for evaluation...
Testing network 2 on real datasets for evaluation...
Testing network 3 on real datasets for evaluation...
Optimization iteration 0, eval auroc score (train): 41803.3078, eval auroc score (test): 41786.2356
Checkpoint at iteration 0 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = None
/home1/dingyini/.conda/envs/playground/lib/python3.11/site-packages/torch/nn/utils/clip_grad.py:39: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /opt/conda/conda-bld/pytorch_1695392026823/work/build/aten/src/ATen/core/TensorBody.h:489.)
  grads = [p.grad for p in parameters if p.grad is not None]

Training iteration:   0%|          | 0/1001 [00:46<?, ?it/s, avg loss=248.9914]New best at iteratoin 0!

Training iteration:   0%|          | 1/1001 [00:46<12:50:21, 46.22s/it, avg loss=248.9914]Checkpoint at iteration 1 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 248.99135818481446

Training iteration:   0%|          | 1/1001 [00:46<12:50:21, 46.22s/it, avg loss=197.6942]New best at iteratoin 1!

Training iteration:   0%|          | 2/1001 [00:46<5:24:26, 19.49s/it, avg loss=197.6942] Checkpoint at iteration 2 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 197.6941825866699

Training iteration:   0%|          | 2/1001 [00:47<5:24:26, 19.49s/it, avg loss=216.7126]
Training iteration:   0%|          | 3/1001 [00:47<3:01:59, 10.94s/it, avg loss=216.7126]Checkpoint at iteration 3 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 216.71256103515626

Training iteration:   0%|          | 3/1001 [00:48<3:01:59, 10.94s/it, avg loss=161.8651]New best at iteratoin 3!

Training iteration:   0%|          | 4/1001 [00:48<1:55:05,  6.93s/it, avg loss=161.8651]Checkpoint at iteration 4 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 161.8651138305664

Training iteration:   0%|          | 4/1001 [00:49<1:55:05,  6.93s/it, avg loss=158.0982]New best at iteratoin 4!

Training iteration:   0%|          | 5/1001 [00:49<1:18:08,  4.71s/it, avg loss=158.0982]Checkpoint at iteration 5 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 158.09818572998046

Training iteration:   0%|          | 5/1001 [00:50<1:18:08,  4.71s/it, avg loss=249.5338]
Training iteration:   1%|          | 6/1001 [00:50<55:52,  3.37s/it, avg loss=249.5338]  Checkpoint at iteration 6 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 249.53377990722657

Training iteration:   1%|          | 6/1001 [00:50<55:52,  3.37s/it, avg loss=207.6537]
Training iteration:   1%|          | 7/1001 [00:50<41:44,  2.52s/it, avg loss=207.6537]Checkpoint at iteration 7 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 207.65370178222656

Training iteration:   1%|          | 7/1001 [00:51<41:44,  2.52s/it, avg loss=184.3802]
Training iteration:   1%|          | 8/1001 [00:51<32:29,  1.96s/it, avg loss=184.3802]Checkpoint at iteration 8 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 184.38019332885742

Training iteration:   1%|          | 8/1001 [00:52<32:29,  1.96s/it, avg loss=174.5714]
Training iteration:   1%|          | 9/1001 [00:52<26:17,  1.59s/it, avg loss=174.5714]Checkpoint at iteration 9 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 174.57141571044923

Training iteration:   1%|          | 9/1001 [00:53<26:17,  1.59s/it, avg loss=194.6471]
Training iteration:   1%|          | 10/1001 [00:53<22:05,  1.34s/it, avg loss=194.6471]Checkpoint at iteration 10 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 194.64706802368164

Training iteration:   1%|          | 10/1001 [00:53<22:05,  1.34s/it, avg loss=208.4377]
Training iteration:   1%|          | 11/1001 [00:53<19:12,  1.16s/it, avg loss=208.4377]Checkpoint at iteration 11 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 208.43773880004883

Training iteration:   1%|          | 11/1001 [00:54<19:12,  1.16s/it, avg loss=178.5640]
Training iteration:   1%|          | 12/1001 [00:54<17:13,  1.04s/it, avg loss=178.5640]Checkpoint at iteration 12 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 178.5640441894531

Training iteration:   1%|          | 12/1001 [00:55<17:13,  1.04s/it, avg loss=158.4662]
Training iteration:   1%|▏         | 13/1001 [00:55<15:50,  1.04it/s, avg loss=158.4662]Checkpoint at iteration 13 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 158.46624908447265

Training iteration:   1%|▏         | 13/1001 [00:56<15:50,  1.04it/s, avg loss=165.8025]
Training iteration:   1%|▏         | 14/1001 [00:56<14:52,  1.11it/s, avg loss=165.8025]Checkpoint at iteration 14 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 165.8025260925293

Training iteration:   1%|▏         | 14/1001 [00:57<14:52,  1.11it/s, avg loss=188.2113]
Training iteration:   1%|▏         | 15/1001 [00:57<14:12,  1.16it/s, avg loss=188.2113]Checkpoint at iteration 15 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 188.2113296508789

Training iteration:   1%|▏         | 15/1001 [00:57<14:12,  1.16it/s, avg loss=186.3233]
Training iteration:   2%|▏         | 16/1001 [00:57<13:43,  1.20it/s, avg loss=186.3233]Checkpoint at iteration 16 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 186.32328567504882

Training iteration:   2%|▏         | 16/1001 [00:58<13:43,  1.20it/s, avg loss=144.9716]New best at iteratoin 16!

Training iteration:   2%|▏         | 17/1001 [00:58<13:23,  1.22it/s, avg loss=144.9716]Checkpoint at iteration 17 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 144.97162551879882

Training iteration:   2%|▏         | 17/1001 [00:59<13:23,  1.22it/s, avg loss=155.6313]
Training iteration:   2%|▏         | 18/1001 [00:59<13:09,  1.25it/s, avg loss=155.6313]Checkpoint at iteration 18 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 155.63127212524415

Training iteration:   2%|▏         | 18/1001 [01:00<13:09,  1.25it/s, avg loss=210.3980]
Training iteration:   2%|▏         | 19/1001 [01:00<12:59,  1.26it/s, avg loss=210.3980]Checkpoint at iteration 19 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 210.3979721069336

Training iteration:   2%|▏         | 19/1001 [01:00<12:59,  1.26it/s, avg loss=208.0541]
Training iteration:   2%|▏         | 20/1001 [01:00<12:52,  1.27it/s, avg loss=208.0541]Checkpoint at iteration 20 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 208.05410461425782

Training iteration:   2%|▏         | 20/1001 [01:01<12:52,  1.27it/s, avg loss=247.9577]
Training iteration:   2%|▏         | 21/1001 [01:01<12:47,  1.28it/s, avg loss=247.9577]Checkpoint at iteration 21 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 247.95772247314454

Training iteration:   2%|▏         | 21/1001 [01:02<12:47,  1.28it/s, avg loss=188.7240]
Training iteration:   2%|▏         | 22/1001 [01:02<12:43,  1.28it/s, avg loss=188.7240]Checkpoint at iteration 22 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 188.7240432739258

Training iteration:   2%|▏         | 22/1001 [01:03<12:43,  1.28it/s, avg loss=213.1549]
Training iteration:   2%|▏         | 23/1001 [01:03<12:41,  1.28it/s, avg loss=213.1549]Checkpoint at iteration 23 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 213.15486907958984

Training iteration:   2%|▏         | 23/1001 [01:03<12:41,  1.28it/s, avg loss=208.7140]
Training iteration:   2%|▏         | 24/1001 [01:03<12:39,  1.29it/s, avg loss=208.7140]Checkpoint at iteration 24 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 208.7140350341797

Training iteration:   2%|▏         | 24/1001 [01:04<12:39,  1.29it/s, avg loss=194.6103]
Training iteration:   2%|▏         | 25/1001 [01:04<12:37,  1.29it/s, avg loss=194.6103]Checkpoint at iteration 25 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 194.61025009155273

Training iteration:   2%|▏         | 25/1001 [01:05<12:37,  1.29it/s, avg loss=184.3961]
Training iteration:   3%|▎         | 26/1001 [01:05<12:35,  1.29it/s, avg loss=184.3961]Checkpoint at iteration 26 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 184.39611358642577

Training iteration:   3%|▎         | 26/1001 [01:06<12:35,  1.29it/s, avg loss=288.2697]
Training iteration:   3%|▎         | 27/1001 [01:06<12:34,  1.29it/s, avg loss=288.2697]Checkpoint at iteration 27 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 288.26967849731443

Training iteration:   3%|▎         | 27/1001 [01:07<12:34,  1.29it/s, avg loss=146.6922]
Training iteration:   3%|▎         | 28/1001 [01:07<12:33,  1.29it/s, avg loss=146.6922]Checkpoint at iteration 28 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 146.69220046997071

Training iteration:   3%|▎         | 28/1001 [01:07<12:33,  1.29it/s, avg loss=175.5633]
Training iteration:   3%|▎         | 29/1001 [01:07<12:32,  1.29it/s, avg loss=175.5633]Checkpoint at iteration 29 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 175.56325912475586

Training iteration:   3%|▎         | 29/1001 [01:08<12:32,  1.29it/s, avg loss=228.0769]
Training iteration:   3%|▎         | 30/1001 [01:08<12:30,  1.29it/s, avg loss=228.0769]Checkpoint at iteration 30 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 228.07685317993165

Training iteration:   3%|▎         | 30/1001 [01:09<12:30,  1.29it/s, avg loss=211.4595]
Training iteration:   3%|▎         | 31/1001 [01:09<12:29,  1.29it/s, avg loss=211.4595]Checkpoint at iteration 31 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 211.4595085144043

Training iteration:   3%|▎         | 31/1001 [01:10<12:29,  1.29it/s, avg loss=207.7758]
Training iteration:   3%|▎         | 32/1001 [01:10<12:29,  1.29it/s, avg loss=207.7758]Checkpoint at iteration 32 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 207.77575454711913

Training iteration:   3%|▎         | 32/1001 [01:10<12:29,  1.29it/s, avg loss=203.2577]
Training iteration:   3%|▎         | 33/1001 [01:10<12:27,  1.29it/s, avg loss=203.2577]Checkpoint at iteration 33 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 203.25767974853517

Training iteration:   3%|▎         | 33/1001 [01:11<12:27,  1.29it/s, avg loss=262.9460]
Training iteration:   3%|▎         | 34/1001 [01:11<12:26,  1.30it/s, avg loss=262.9460]Checkpoint at iteration 34 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 262.94603424072267

Training iteration:   3%|▎         | 34/1001 [01:12<12:26,  1.30it/s, avg loss=228.2301]
Training iteration:   3%|▎         | 35/1001 [01:12<12:27,  1.29it/s, avg loss=228.2301]Checkpoint at iteration 35 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 228.2301055908203

Training iteration:   3%|▎         | 35/1001 [01:13<12:27,  1.29it/s, avg loss=174.6513]
Training iteration:   4%|▎         | 36/1001 [01:13<12:28,  1.29it/s, avg loss=174.6513]Checkpoint at iteration 36 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 174.65130462646485

Training iteration:   4%|▎         | 36/1001 [01:14<12:28,  1.29it/s, avg loss=148.7354]
Training iteration:   4%|▎         | 37/1001 [01:14<12:27,  1.29it/s, avg loss=148.7354]Checkpoint at iteration 37 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 148.7353775024414

Training iteration:   4%|▎         | 37/1001 [01:14<12:27,  1.29it/s, avg loss=187.4096]
Training iteration:   4%|▍         | 38/1001 [01:14<12:26,  1.29it/s, avg loss=187.4096]Checkpoint at iteration 38 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 187.40959548950195

Training iteration:   4%|▍         | 38/1001 [01:15<12:26,  1.29it/s, avg loss=184.1122]
Training iteration:   4%|▍         | 39/1001 [01:15<12:25,  1.29it/s, avg loss=184.1122]Checkpoint at iteration 39 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 184.11224670410155

Training iteration:   4%|▍         | 39/1001 [01:16<12:25,  1.29it/s, avg loss=179.3833]
Training iteration:   4%|▍         | 40/1001 [01:16<12:24,  1.29it/s, avg loss=179.3833]Checkpoint at iteration 40 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 179.38325576782228

Training iteration:   4%|▍         | 40/1001 [01:17<12:24,  1.29it/s, avg loss=162.3293]
Training iteration:   4%|▍         | 41/1001 [01:17<12:24,  1.29it/s, avg loss=162.3293]Checkpoint at iteration 41 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 162.32929153442382

Training iteration:   4%|▍         | 41/1001 [01:17<12:24,  1.29it/s, avg loss=194.7901]
Training iteration:   4%|▍         | 42/1001 [01:17<12:22,  1.29it/s, avg loss=194.7901]Checkpoint at iteration 42 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 194.79010467529298

Training iteration:   4%|▍         | 42/1001 [01:18<12:22,  1.29it/s, avg loss=212.4004]
Training iteration:   4%|▍         | 43/1001 [01:18<12:21,  1.29it/s, avg loss=212.4004]Checkpoint at iteration 43 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 212.40044097900392

Training iteration:   4%|▍         | 43/1001 [01:19<12:21,  1.29it/s, avg loss=201.9993]
Training iteration:   4%|▍         | 44/1001 [01:19<12:20,  1.29it/s, avg loss=201.9993]Checkpoint at iteration 44 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 201.9993034362793

Training iteration:   4%|▍         | 44/1001 [01:20<12:20,  1.29it/s, avg loss=186.8834]
Training iteration:   4%|▍         | 45/1001 [01:20<12:19,  1.29it/s, avg loss=186.8834]Checkpoint at iteration 45 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 186.8834259033203

Training iteration:   4%|▍         | 45/1001 [01:20<12:19,  1.29it/s, avg loss=162.7972]
Training iteration:   5%|▍         | 46/1001 [01:21<12:18,  1.29it/s, avg loss=162.7972]Checkpoint at iteration 46 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 162.79724197387696

Training iteration:   5%|▍         | 46/1001 [01:21<12:18,  1.29it/s, avg loss=263.0825]
Training iteration:   5%|▍         | 47/1001 [01:21<12:17,  1.29it/s, avg loss=263.0825]Checkpoint at iteration 47 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 263.08248977661134

Training iteration:   5%|▍         | 47/1001 [01:22<12:17,  1.29it/s, avg loss=178.6585]
Training iteration:   5%|▍         | 48/1001 [01:22<12:17,  1.29it/s, avg loss=178.6585]Checkpoint at iteration 48 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 178.65853881835938

Training iteration:   5%|▍         | 48/1001 [01:23<12:17,  1.29it/s, avg loss=252.1847]
Training iteration:   5%|▍         | 49/1001 [01:23<12:16,  1.29it/s, avg loss=252.1847]Checkpoint at iteration 49 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 252.184659576416

Training iteration:   5%|▍         | 49/1001 [01:24<12:16,  1.29it/s, avg loss=216.1971]
Training iteration:   5%|▍         | 50/1001 [01:24<12:15,  1.29it/s, avg loss=216.1971]Checkpoint at iteration 50 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 216.19705810546876

Training iteration:   5%|▍         | 50/1001 [01:24<12:15,  1.29it/s, avg loss=195.0204]
Training iteration:   5%|▌         | 51/1001 [01:24<12:14,  1.29it/s, avg loss=195.0204]Checkpoint at iteration 51 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 195.02036743164064

Training iteration:   5%|▌         | 51/1001 [01:25<12:14,  1.29it/s, avg loss=212.8491]
Training iteration:   5%|▌         | 52/1001 [01:25<12:13,  1.29it/s, avg loss=212.8491]Checkpoint at iteration 52 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 212.84908142089844

Training iteration:   5%|▌         | 52/1001 [01:26<12:13,  1.29it/s, avg loss=174.1430]
Training iteration:   5%|▌         | 53/1001 [01:26<12:12,  1.29it/s, avg loss=174.1430]Checkpoint at iteration 53 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 174.14296875

Training iteration:   5%|▌         | 53/1001 [01:27<12:12,  1.29it/s, avg loss=148.3891]
Training iteration:   5%|▌         | 54/1001 [01:27<12:11,  1.30it/s, avg loss=148.3891]Checkpoint at iteration 54 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 148.3891273498535

Training iteration:   5%|▌         | 54/1001 [01:27<12:11,  1.30it/s, avg loss=163.6127]
Training iteration:   5%|▌         | 55/1001 [01:27<12:10,  1.29it/s, avg loss=163.6127]Checkpoint at iteration 55 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 163.6127052307129

Training iteration:   5%|▌         | 55/1001 [01:28<12:10,  1.29it/s, avg loss=168.3741]
Training iteration:   6%|▌         | 56/1001 [01:28<12:09,  1.29it/s, avg loss=168.3741]Checkpoint at iteration 56 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 168.3741485595703

Training iteration:   6%|▌         | 56/1001 [01:29<12:09,  1.29it/s, avg loss=216.1982]
Training iteration:   6%|▌         | 57/1001 [01:29<12:08,  1.30it/s, avg loss=216.1982]Checkpoint at iteration 57 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 216.1981544494629

Training iteration:   6%|▌         | 57/1001 [01:30<12:08,  1.30it/s, avg loss=161.7864]
Training iteration:   6%|▌         | 58/1001 [01:30<12:07,  1.30it/s, avg loss=161.7864]Checkpoint at iteration 58 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 161.78636016845704

Training iteration:   6%|▌         | 58/1001 [01:31<12:07,  1.30it/s, avg loss=195.5351]
Training iteration:   6%|▌         | 59/1001 [01:31<12:07,  1.30it/s, avg loss=195.5351]Checkpoint at iteration 59 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 195.5350715637207

Training iteration:   6%|▌         | 59/1001 [01:31<12:07,  1.30it/s, avg loss=189.0427]
Training iteration:   6%|▌         | 60/1001 [01:31<12:05,  1.30it/s, avg loss=189.0427]Checkpoint at iteration 60 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 189.0426788330078

Training iteration:   6%|▌         | 60/1001 [01:32<12:05,  1.30it/s, avg loss=197.7011]
Training iteration:   6%|▌         | 61/1001 [01:32<12:05,  1.30it/s, avg loss=197.7011]Checkpoint at iteration 61 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 197.70110855102538

Training iteration:   6%|▌         | 61/1001 [01:33<12:05,  1.30it/s, avg loss=177.6709]
Training iteration:   6%|▌         | 62/1001 [01:33<12:04,  1.30it/s, avg loss=177.6709]Checkpoint at iteration 62 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 177.67092742919922

Training iteration:   6%|▌         | 62/1001 [01:34<12:04,  1.30it/s, avg loss=153.4628]
Training iteration:   6%|▋         | 63/1001 [01:34<12:03,  1.30it/s, avg loss=153.4628]Checkpoint at iteration 63 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 153.46281890869142

Training iteration:   6%|▋         | 63/1001 [01:34<12:03,  1.30it/s, avg loss=221.5962]
Training iteration:   6%|▋         | 64/1001 [01:34<12:02,  1.30it/s, avg loss=221.5962]Checkpoint at iteration 64 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 221.59617233276367

Training iteration:   6%|▋         | 64/1001 [01:35<12:02,  1.30it/s, avg loss=200.7102]
Training iteration:   6%|▋         | 65/1001 [01:35<12:02,  1.30it/s, avg loss=200.7102]Checkpoint at iteration 65 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 200.71024475097656

Training iteration:   6%|▋         | 65/1001 [01:36<12:02,  1.30it/s, avg loss=181.9118]
Training iteration:   7%|▋         | 66/1001 [01:36<12:01,  1.30it/s, avg loss=181.9118]Checkpoint at iteration 66 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 181.91180114746095

Training iteration:   7%|▋         | 66/1001 [01:37<12:01,  1.30it/s, avg loss=228.3657]
Training iteration:   7%|▋         | 67/1001 [01:37<12:01,  1.29it/s, avg loss=228.3657]Checkpoint at iteration 67 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 228.36570892333984

Training iteration:   7%|▋         | 67/1001 [01:37<12:01,  1.29it/s, avg loss=195.2248]
Training iteration:   7%|▋         | 68/1001 [01:37<12:01,  1.29it/s, avg loss=195.2248]Checkpoint at iteration 68 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 195.2248420715332

Training iteration:   7%|▋         | 68/1001 [01:38<12:01,  1.29it/s, avg loss=184.4918]
Training iteration:   7%|▋         | 69/1001 [01:38<12:00,  1.29it/s, avg loss=184.4918]Checkpoint at iteration 69 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 184.49184036254883

Training iteration:   7%|▋         | 69/1001 [01:39<12:00,  1.29it/s, avg loss=190.9344]
Training iteration:   7%|▋         | 70/1001 [01:39<11:59,  1.29it/s, avg loss=190.9344]Checkpoint at iteration 70 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 190.9344451904297

Training iteration:   7%|▋         | 70/1001 [01:40<11:59,  1.29it/s, avg loss=183.3626]
Training iteration:   7%|▋         | 71/1001 [01:40<11:59,  1.29it/s, avg loss=183.3626]Checkpoint at iteration 71 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 183.36256637573243

Training iteration:   7%|▋         | 71/1001 [01:41<11:59,  1.29it/s, avg loss=211.7898]
Training iteration:   7%|▋         | 72/1001 [01:41<11:58,  1.29it/s, avg loss=211.7898]Checkpoint at iteration 72 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 211.78979034423827

Training iteration:   7%|▋         | 72/1001 [01:41<11:58,  1.29it/s, avg loss=148.7166]
Training iteration:   7%|▋         | 73/1001 [01:41<11:58,  1.29it/s, avg loss=148.7166]Checkpoint at iteration 73 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 148.71655654907227

Training iteration:   7%|▋         | 73/1001 [01:42<11:58,  1.29it/s, avg loss=210.0709]
Training iteration:   7%|▋         | 74/1001 [01:42<11:57,  1.29it/s, avg loss=210.0709]Checkpoint at iteration 74 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 210.0709114074707

Training iteration:   7%|▋         | 74/1001 [01:43<11:57,  1.29it/s, avg loss=161.2133]
Training iteration:   7%|▋         | 75/1001 [01:43<11:56,  1.29it/s, avg loss=161.2133]Checkpoint at iteration 75 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 161.21334228515624

Training iteration:   7%|▋         | 75/1001 [01:44<11:56,  1.29it/s, avg loss=162.8018]
Training iteration:   8%|▊         | 76/1001 [01:44<11:55,  1.29it/s, avg loss=162.8018]Checkpoint at iteration 76 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 162.80176239013673

Training iteration:   8%|▊         | 76/1001 [01:44<11:55,  1.29it/s, avg loss=145.6447]
Training iteration:   8%|▊         | 77/1001 [01:44<11:54,  1.29it/s, avg loss=145.6447]Checkpoint at iteration 77 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 145.64467391967773

Training iteration:   8%|▊         | 77/1001 [01:45<11:54,  1.29it/s, avg loss=200.4029]
Training iteration:   8%|▊         | 78/1001 [01:45<11:53,  1.29it/s, avg loss=200.4029]Checkpoint at iteration 78 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 200.40291595458984

Training iteration:   8%|▊         | 78/1001 [01:46<11:53,  1.29it/s, avg loss=197.1150]
Training iteration:   8%|▊         | 79/1001 [01:46<11:52,  1.29it/s, avg loss=197.1150]Checkpoint at iteration 79 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 197.1150230407715

Training iteration:   8%|▊         | 79/1001 [01:47<11:52,  1.29it/s, avg loss=163.2459]
Training iteration:   8%|▊         | 80/1001 [01:47<11:52,  1.29it/s, avg loss=163.2459]Checkpoint at iteration 80 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 163.245947265625

Training iteration:   8%|▊         | 80/1001 [01:48<11:52,  1.29it/s, avg loss=160.0487]
Training iteration:   8%|▊         | 81/1001 [01:48<11:51,  1.29it/s, avg loss=160.0487]Checkpoint at iteration 81 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 160.04865036010742

Training iteration:   8%|▊         | 81/1001 [01:48<11:51,  1.29it/s, avg loss=202.8123]
Training iteration:   8%|▊         | 82/1001 [01:48<11:50,  1.29it/s, avg loss=202.8123]Checkpoint at iteration 82 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 202.81231536865235

Training iteration:   8%|▊         | 82/1001 [01:49<11:50,  1.29it/s, avg loss=218.0392]
Training iteration:   8%|▊         | 83/1001 [01:49<11:50,  1.29it/s, avg loss=218.0392]Checkpoint at iteration 83 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 218.0391731262207

Training iteration:   8%|▊         | 83/1001 [01:50<11:50,  1.29it/s, avg loss=194.7049]
Training iteration:   8%|▊         | 84/1001 [01:50<11:49,  1.29it/s, avg loss=194.7049]Checkpoint at iteration 84 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 194.7049415588379

Training iteration:   8%|▊         | 84/1001 [01:51<11:49,  1.29it/s, avg loss=197.5532]
Training iteration:   8%|▊         | 85/1001 [01:51<11:49,  1.29it/s, avg loss=197.5532]Checkpoint at iteration 85 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 197.5532012939453

Training iteration:   8%|▊         | 85/1001 [01:51<11:49,  1.29it/s, avg loss=190.8405]
Training iteration:   9%|▊         | 86/1001 [01:51<11:48,  1.29it/s, avg loss=190.8405]Checkpoint at iteration 86 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 190.8404800415039

Training iteration:   9%|▊         | 86/1001 [01:52<11:48,  1.29it/s, avg loss=210.9109]
Training iteration:   9%|▊         | 87/1001 [01:52<11:47,  1.29it/s, avg loss=210.9109]Checkpoint at iteration 87 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 210.9109199523926

Training iteration:   9%|▊         | 87/1001 [01:53<11:47,  1.29it/s, avg loss=211.7055]
Training iteration:   9%|▉         | 88/1001 [01:53<11:46,  1.29it/s, avg loss=211.7055]Checkpoint at iteration 88 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 211.70550003051758

Training iteration:   9%|▉         | 88/1001 [01:54<11:46,  1.29it/s, avg loss=166.6703]
Training iteration:   9%|▉         | 89/1001 [01:54<11:45,  1.29it/s, avg loss=166.6703]Checkpoint at iteration 89 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 166.6703239440918

Training iteration:   9%|▉         | 89/1001 [01:55<11:45,  1.29it/s, avg loss=196.3386]
Training iteration:   9%|▉         | 90/1001 [01:55<11:45,  1.29it/s, avg loss=196.3386]Checkpoint at iteration 90 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 196.33863830566406

Training iteration:   9%|▉         | 90/1001 [01:55<11:45,  1.29it/s, avg loss=167.1704]
Training iteration:   9%|▉         | 91/1001 [01:55<11:44,  1.29it/s, avg loss=167.1704]Checkpoint at iteration 91 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 167.17042083740233

Training iteration:   9%|▉         | 91/1001 [01:56<11:44,  1.29it/s, avg loss=178.7641]
Training iteration:   9%|▉         | 92/1001 [01:56<11:43,  1.29it/s, avg loss=178.7641]Checkpoint at iteration 92 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 178.7641227722168

Training iteration:   9%|▉         | 92/1001 [01:57<11:43,  1.29it/s, avg loss=168.4248]
Training iteration:   9%|▉         | 93/1001 [01:57<11:42,  1.29it/s, avg loss=168.4248]Checkpoint at iteration 93 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 168.42479553222657

Training iteration:   9%|▉         | 93/1001 [01:58<11:42,  1.29it/s, avg loss=148.8483]
Training iteration:   9%|▉         | 94/1001 [01:58<11:41,  1.29it/s, avg loss=148.8483]Checkpoint at iteration 94 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 148.84834518432618

Training iteration:   9%|▉         | 94/1001 [01:58<11:41,  1.29it/s, avg loss=215.7600]
Training iteration:   9%|▉         | 95/1001 [01:58<11:41,  1.29it/s, avg loss=215.7600]Checkpoint at iteration 95 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 215.75997009277344

Training iteration:   9%|▉         | 95/1001 [01:59<11:41,  1.29it/s, avg loss=213.8916]
Training iteration:  10%|▉         | 96/1001 [01:59<11:40,  1.29it/s, avg loss=213.8916]Checkpoint at iteration 96 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 213.89159774780273

Training iteration:  10%|▉         | 96/1001 [02:00<11:40,  1.29it/s, avg loss=201.1346]
Training iteration:  10%|▉         | 97/1001 [02:00<11:41,  1.29it/s, avg loss=201.1346]Checkpoint at iteration 97 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 201.13460235595704

Training iteration:  10%|▉         | 97/1001 [02:01<11:41,  1.29it/s, avg loss=149.9894]
Training iteration:  10%|▉         | 98/1001 [02:01<11:40,  1.29it/s, avg loss=149.9894]Checkpoint at iteration 98 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 149.9893714904785

Training iteration:  10%|▉         | 98/1001 [02:01<11:40,  1.29it/s, avg loss=178.9771]
Training iteration:  10%|▉         | 99/1001 [02:01<11:38,  1.29it/s, avg loss=178.9771]Checkpoint at iteration 99 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 178.9770622253418

Training iteration:  10%|▉         | 99/1001 [02:02<11:38,  1.29it/s, avg loss=176.4403]
Training iteration:  10%|▉         | 100/1001 [02:02<11:37,  1.29it/s, avg loss=176.4403]Optimization iteration 100 evaluation begins...
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
A new evaluation visualization has been saved: ./saved_data/20240110-081107/it100.png
Training network 0 for evaluation...
Training network 1 for evaluation...
Training network 2 for evaluation...
Training network 3 for evaluation...
Testing network 0 on real datasets for evaluation...
Testing network 1 on real datasets for evaluation...
Testing network 2 on real datasets for evaluation...
Testing network 3 on real datasets for evaluation...
Optimization iteration 100, eval auroc score (train): 20191.1329, eval auroc score (test): 21196.5826
Checkpoint at iteration 100 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 176.44032516479493

Training iteration:  10%|▉         | 100/1001 [02:49<11:37,  1.29it/s, avg loss=233.7278]
Training iteration:  10%|█         | 101/1001 [02:49<3:39:49, 14.65s/it, avg loss=233.7278]Checkpoint at iteration 101 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 233.72783355712892

Training iteration:  10%|█         | 101/1001 [02:50<3:39:49, 14.65s/it, avg loss=197.8746]
Training iteration:  10%|█         | 102/1001 [02:50<2:37:50, 10.53s/it, avg loss=197.8746]Checkpoint at iteration 102 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 197.8746124267578

Training iteration:  10%|█         | 102/1001 [02:51<2:37:50, 10.53s/it, avg loss=187.0085]
Training iteration:  10%|█         | 103/1001 [02:51<1:54:27,  7.65s/it, avg loss=187.0085]Checkpoint at iteration 103 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 187.00849227905275

Training iteration:  10%|█         | 103/1001 [02:52<1:54:27,  7.65s/it, avg loss=237.0567]
Training iteration:  10%|█         | 104/1001 [02:52<1:24:06,  5.63s/it, avg loss=237.0567]Checkpoint at iteration 104 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 237.05671081542968

Training iteration:  10%|█         | 104/1001 [02:53<1:24:06,  5.63s/it, avg loss=191.0354]
Training iteration:  10%|█         | 105/1001 [02:53<1:02:53,  4.21s/it, avg loss=191.0354]Checkpoint at iteration 105 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 191.03541412353516

Training iteration:  10%|█         | 105/1001 [02:54<1:02:53,  4.21s/it, avg loss=164.4341]
Training iteration:  11%|█         | 106/1001 [02:54<48:02,  3.22s/it, avg loss=164.4341]  Checkpoint at iteration 106 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 164.43409729003906

Training iteration:  11%|█         | 106/1001 [02:55<48:02,  3.22s/it, avg loss=157.0913]
Training iteration:  11%|█         | 107/1001 [02:55<37:39,  2.53s/it, avg loss=157.0913]Checkpoint at iteration 107 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 157.09132537841796

Training iteration:  11%|█         | 107/1001 [02:56<37:39,  2.53s/it, avg loss=167.5562]
Training iteration:  11%|█         | 108/1001 [02:56<30:23,  2.04s/it, avg loss=167.5562]Checkpoint at iteration 108 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 167.55622406005858

Training iteration:  11%|█         | 108/1001 [02:57<30:23,  2.04s/it, avg loss=173.9207]
Training iteration:  11%|█         | 109/1001 [02:57<25:18,  1.70s/it, avg loss=173.9207]Checkpoint at iteration 109 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 173.92070617675782

Training iteration:  11%|█         | 109/1001 [02:58<25:18,  1.70s/it, avg loss=179.7978]
Training iteration:  11%|█         | 110/1001 [02:58<21:45,  1.46s/it, avg loss=179.7978]Checkpoint at iteration 110 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 179.79775924682616

Training iteration:  11%|█         | 110/1001 [02:58<21:45,  1.46s/it, avg loss=208.2299]
Training iteration:  11%|█         | 111/1001 [02:58<19:15,  1.30s/it, avg loss=208.2299]Checkpoint at iteration 111 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 208.22985382080077

Training iteration:  11%|█         | 111/1001 [02:59<19:15,  1.30s/it, avg loss=208.1087]
Training iteration:  11%|█         | 112/1001 [02:59<17:31,  1.18s/it, avg loss=208.1087]Checkpoint at iteration 112 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 208.10872497558594

Training iteration:  11%|█         | 112/1001 [03:00<17:31,  1.18s/it, avg loss=200.3136]
Training iteration:  11%|█▏        | 113/1001 [03:00<16:17,  1.10s/it, avg loss=200.3136]Checkpoint at iteration 113 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 200.3135887145996

Training iteration:  11%|█▏        | 113/1001 [03:01<16:17,  1.10s/it, avg loss=211.1259]
Training iteration:  11%|█▏        | 114/1001 [03:01<15:25,  1.04s/it, avg loss=211.1259]Checkpoint at iteration 114 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 211.12590866088868

Training iteration:  11%|█▏        | 114/1001 [03:02<15:25,  1.04s/it, avg loss=188.4820]
Training iteration:  11%|█▏        | 115/1001 [03:02<14:49,  1.00s/it, avg loss=188.4820]Checkpoint at iteration 115 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 188.48204956054687

Training iteration:  11%|█▏        | 115/1001 [03:03<14:49,  1.00s/it, avg loss=173.7345]
Training iteration:  12%|█▏        | 116/1001 [03:03<14:23,  1.02it/s, avg loss=173.7345]Checkpoint at iteration 116 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 173.73449172973633

Training iteration:  12%|█▏        | 116/1001 [03:04<14:23,  1.02it/s, avg loss=160.3526]
Training iteration:  12%|█▏        | 117/1001 [03:04<14:05,  1.05it/s, avg loss=160.3526]Checkpoint at iteration 117 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 160.3526351928711

Training iteration:  12%|█▏        | 117/1001 [03:05<14:05,  1.05it/s, avg loss=214.4611]
Training iteration:  12%|█▏        | 118/1001 [03:05<13:51,  1.06it/s, avg loss=214.4611]Checkpoint at iteration 118 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 214.4610626220703

Training iteration:  12%|█▏        | 118/1001 [03:06<13:51,  1.06it/s, avg loss=223.5437]
Training iteration:  12%|█▏        | 119/1001 [03:06<13:42,  1.07it/s, avg loss=223.5437]Checkpoint at iteration 119 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 223.54371948242186

Training iteration:  12%|█▏        | 119/1001 [03:07<13:42,  1.07it/s, avg loss=174.7559]
Training iteration:  12%|█▏        | 120/1001 [03:07<13:35,  1.08it/s, avg loss=174.7559]Checkpoint at iteration 120 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 174.7558578491211

Training iteration:  12%|█▏        | 120/1001 [03:08<13:35,  1.08it/s, avg loss=174.7642]
Training iteration:  12%|█▏        | 121/1001 [03:08<13:30,  1.09it/s, avg loss=174.7642]Checkpoint at iteration 121 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 174.7642478942871

Training iteration:  12%|█▏        | 121/1001 [03:08<13:30,  1.09it/s, avg loss=192.3133]
Training iteration:  12%|█▏        | 122/1001 [03:08<13:25,  1.09it/s, avg loss=192.3133]Checkpoint at iteration 122 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 192.31329498291015

Training iteration:  12%|█▏        | 122/1001 [03:09<13:25,  1.09it/s, avg loss=173.8299]
Training iteration:  12%|█▏        | 123/1001 [03:09<13:22,  1.09it/s, avg loss=173.8299]Checkpoint at iteration 123 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 173.82988357543945

Training iteration:  12%|█▏        | 123/1001 [03:10<13:22,  1.09it/s, avg loss=234.8046]
Training iteration:  12%|█▏        | 124/1001 [03:10<13:20,  1.10it/s, avg loss=234.8046]Checkpoint at iteration 124 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 234.80458068847656

Training iteration:  12%|█▏        | 124/1001 [03:11<13:20,  1.10it/s, avg loss=160.0289]
Training iteration:  12%|█▏        | 125/1001 [03:11<13:18,  1.10it/s, avg loss=160.0289]Checkpoint at iteration 125 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 160.02886276245118

Training iteration:  12%|█▏        | 125/1001 [03:12<13:18,  1.10it/s, avg loss=213.0743]
Training iteration:  13%|█▎        | 126/1001 [03:12<13:17,  1.10it/s, avg loss=213.0743]Checkpoint at iteration 126 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 213.07432708740234

Training iteration:  13%|█▎        | 126/1001 [03:13<13:17,  1.10it/s, avg loss=173.1732]
Training iteration:  13%|█▎        | 127/1001 [03:13<13:15,  1.10it/s, avg loss=173.1732]Checkpoint at iteration 127 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 173.17317390441895

Training iteration:  13%|█▎        | 127/1001 [03:14<13:15,  1.10it/s, avg loss=181.6924]
Training iteration:  13%|█▎        | 128/1001 [03:14<13:14,  1.10it/s, avg loss=181.6924]Checkpoint at iteration 128 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 181.69243621826172

Training iteration:  13%|█▎        | 128/1001 [03:15<13:14,  1.10it/s, avg loss=180.6828]
Training iteration:  13%|█▎        | 129/1001 [03:15<13:14,  1.10it/s, avg loss=180.6828]Checkpoint at iteration 129 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 180.68276672363282

Training iteration:  13%|█▎        | 129/1001 [03:16<13:14,  1.10it/s, avg loss=238.6686]
Training iteration:  13%|█▎        | 130/1001 [03:16<13:12,  1.10it/s, avg loss=238.6686]Checkpoint at iteration 130 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 238.6685531616211

Training iteration:  13%|█▎        | 130/1001 [03:17<13:12,  1.10it/s, avg loss=168.8344]
Training iteration:  13%|█▎        | 131/1001 [03:17<13:11,  1.10it/s, avg loss=168.8344]Checkpoint at iteration 131 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 168.83439178466796

Training iteration:  13%|█▎        | 131/1001 [03:18<13:11,  1.10it/s, avg loss=177.4626]
Training iteration:  13%|█▎        | 132/1001 [03:18<13:10,  1.10it/s, avg loss=177.4626]Checkpoint at iteration 132 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 177.46263732910157

Training iteration:  13%|█▎        | 132/1001 [03:18<13:10,  1.10it/s, avg loss=201.9297]
Training iteration:  13%|█▎        | 133/1001 [03:18<13:09,  1.10it/s, avg loss=201.9297]Checkpoint at iteration 133 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 201.92967681884767

Training iteration:  13%|█▎        | 133/1001 [03:19<13:09,  1.10it/s, avg loss=174.4331]
Training iteration:  13%|█▎        | 134/1001 [03:19<13:08,  1.10it/s, avg loss=174.4331]Checkpoint at iteration 134 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 174.43311920166016

Training iteration:  13%|█▎        | 134/1001 [03:20<13:08,  1.10it/s, avg loss=169.3677]
Training iteration:  13%|█▎        | 135/1001 [03:20<13:07,  1.10it/s, avg loss=169.3677]Checkpoint at iteration 135 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 169.36767196655273

Training iteration:  13%|█▎        | 135/1001 [03:21<13:07,  1.10it/s, avg loss=215.0638]
Training iteration:  14%|█▎        | 136/1001 [03:21<13:06,  1.10it/s, avg loss=215.0638]Checkpoint at iteration 136 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 215.06376724243165

Training iteration:  14%|█▎        | 136/1001 [03:22<13:06,  1.10it/s, avg loss=192.3117]
Training iteration:  14%|█▎        | 137/1001 [03:22<13:05,  1.10it/s, avg loss=192.3117]Checkpoint at iteration 137 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 192.31174087524414

Training iteration:  14%|█▎        | 137/1001 [03:23<13:05,  1.10it/s, avg loss=147.1441]
Training iteration:  14%|█▍        | 138/1001 [03:23<13:04,  1.10it/s, avg loss=147.1441]Checkpoint at iteration 138 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 147.14412155151368

Training iteration:  14%|█▍        | 138/1001 [03:24<13:04,  1.10it/s, avg loss=135.3203]New best at iteratoin 138!

Training iteration:  14%|█▍        | 139/1001 [03:24<13:04,  1.10it/s, avg loss=135.3203]Checkpoint at iteration 139 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 135.3203254699707

Training iteration:  14%|█▍        | 139/1001 [03:25<13:04,  1.10it/s, avg loss=205.5108]
Training iteration:  14%|█▍        | 140/1001 [03:25<13:02,  1.10it/s, avg loss=205.5108]Checkpoint at iteration 140 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 205.51080703735352

Training iteration:  14%|█▍        | 140/1001 [03:26<13:02,  1.10it/s, avg loss=207.2103]
Training iteration:  14%|█▍        | 141/1001 [03:26<13:02,  1.10it/s, avg loss=207.2103]Checkpoint at iteration 141 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 207.21031341552734

Training iteration:  14%|█▍        | 141/1001 [03:27<13:02,  1.10it/s, avg loss=182.4322]
Training iteration:  14%|█▍        | 142/1001 [03:27<13:01,  1.10it/s, avg loss=182.4322]Checkpoint at iteration 142 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 182.43222732543944

Training iteration:  14%|█▍        | 142/1001 [03:28<13:01,  1.10it/s, avg loss=167.2969]
Training iteration:  14%|█▍        | 143/1001 [03:28<13:00,  1.10it/s, avg loss=167.2969]Checkpoint at iteration 143 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 167.29685821533204

Training iteration:  14%|█▍        | 143/1001 [03:28<13:00,  1.10it/s, avg loss=230.4930]
Training iteration:  14%|█▍        | 144/1001 [03:28<12:59,  1.10it/s, avg loss=230.4930]Checkpoint at iteration 144 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 230.49295616149902

Training iteration:  14%|█▍        | 144/1001 [03:29<12:59,  1.10it/s, avg loss=176.8886]
Training iteration:  14%|█▍        | 145/1001 [03:29<12:59,  1.10it/s, avg loss=176.8886]Checkpoint at iteration 145 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 176.88861846923828

Training iteration:  14%|█▍        | 145/1001 [03:30<12:59,  1.10it/s, avg loss=129.8506]New best at iteratoin 145!

Training iteration:  15%|█▍        | 146/1001 [03:30<12:58,  1.10it/s, avg loss=129.8506]Checkpoint at iteration 146 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 129.85062408447266

Training iteration:  15%|█▍        | 146/1001 [03:31<12:58,  1.10it/s, avg loss=164.5978]
Training iteration:  15%|█▍        | 147/1001 [03:31<12:58,  1.10it/s, avg loss=164.5978]Checkpoint at iteration 147 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 164.59780502319336

Training iteration:  15%|█▍        | 147/1001 [03:32<12:58,  1.10it/s, avg loss=143.1902]
Training iteration:  15%|█▍        | 148/1001 [03:32<12:58,  1.10it/s, avg loss=143.1902]Checkpoint at iteration 148 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 143.19021072387696

Training iteration:  15%|█▍        | 148/1001 [03:33<12:58,  1.10it/s, avg loss=207.4402]
Training iteration:  15%|█▍        | 149/1001 [03:33<12:57,  1.10it/s, avg loss=207.4402]Checkpoint at iteration 149 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 207.44019775390626

Training iteration:  15%|█▍        | 149/1001 [03:34<12:57,  1.10it/s, avg loss=156.0559]
Training iteration:  15%|█▍        | 150/1001 [03:34<12:56,  1.10it/s, avg loss=156.0559]Checkpoint at iteration 150 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 156.05588417053224

Training iteration:  15%|█▍        | 150/1001 [03:35<12:56,  1.10it/s, avg loss=169.7487]
Training iteration:  15%|█▌        | 151/1001 [03:35<12:55,  1.10it/s, avg loss=169.7487]Checkpoint at iteration 151 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 169.74870834350585

Training iteration:  15%|█▌        | 151/1001 [03:36<12:55,  1.10it/s, avg loss=161.8371]
Training iteration:  15%|█▌        | 152/1001 [03:36<12:54,  1.10it/s, avg loss=161.8371]Checkpoint at iteration 152 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 161.8371269226074

Training iteration:  15%|█▌        | 152/1001 [03:37<12:54,  1.10it/s, avg loss=142.1650]
Training iteration:  15%|█▌        | 153/1001 [03:37<12:54,  1.09it/s, avg loss=142.1650]Checkpoint at iteration 153 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 142.1649528503418

Training iteration:  15%|█▌        | 153/1001 [03:38<12:54,  1.09it/s, avg loss=214.6972]
Training iteration:  15%|█▌        | 154/1001 [03:38<12:54,  1.09it/s, avg loss=214.6972]Checkpoint at iteration 154 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 214.6971534729004

Training iteration:  15%|█▌        | 154/1001 [03:38<12:54,  1.09it/s, avg loss=192.5317]
Training iteration:  15%|█▌        | 155/1001 [03:38<12:52,  1.09it/s, avg loss=192.5317]Checkpoint at iteration 155 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 192.53167266845702

Training iteration:  15%|█▌        | 155/1001 [03:39<12:52,  1.09it/s, avg loss=172.0847]
Training iteration:  16%|█▌        | 156/1001 [03:39<12:51,  1.09it/s, avg loss=172.0847]Checkpoint at iteration 156 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 172.08466720581055

Training iteration:  16%|█▌        | 156/1001 [03:40<12:51,  1.09it/s, avg loss=165.7042]
Training iteration:  16%|█▌        | 157/1001 [03:40<12:50,  1.09it/s, avg loss=165.7042]Checkpoint at iteration 157 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 165.7042137145996

Training iteration:  16%|█▌        | 157/1001 [03:41<12:50,  1.09it/s, avg loss=126.2098]New best at iteratoin 157!

Training iteration:  16%|█▌        | 158/1001 [03:41<12:49,  1.10it/s, avg loss=126.2098]Checkpoint at iteration 158 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 126.20976638793945

Training iteration:  16%|█▌        | 158/1001 [03:42<12:49,  1.10it/s, avg loss=189.4618]
Training iteration:  16%|█▌        | 159/1001 [03:42<12:49,  1.09it/s, avg loss=189.4618]Checkpoint at iteration 159 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 189.46181945800782

Training iteration:  16%|█▌        | 159/1001 [03:43<12:49,  1.09it/s, avg loss=182.5115]
Training iteration:  16%|█▌        | 160/1001 [03:43<12:49,  1.09it/s, avg loss=182.5115]Checkpoint at iteration 160 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 182.5114776611328

Training iteration:  16%|█▌        | 160/1001 [03:44<12:49,  1.09it/s, avg loss=210.5075]
Training iteration:  16%|█▌        | 161/1001 [03:44<12:48,  1.09it/s, avg loss=210.5075]Checkpoint at iteration 161 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 210.50751800537108

Training iteration:  16%|█▌        | 161/1001 [03:45<12:48,  1.09it/s, avg loss=189.9435]
Training iteration:  16%|█▌        | 162/1001 [03:45<12:46,  1.09it/s, avg loss=189.9435]Checkpoint at iteration 162 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 189.94345245361328

Training iteration:  16%|█▌        | 162/1001 [03:46<12:46,  1.09it/s, avg loss=134.7731]
Training iteration:  16%|█▋        | 163/1001 [03:46<12:45,  1.09it/s, avg loss=134.7731]Checkpoint at iteration 163 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 134.7730728149414

Training iteration:  16%|█▋        | 163/1001 [03:47<12:45,  1.09it/s, avg loss=187.7697]
Training iteration:  16%|█▋        | 164/1001 [03:47<12:44,  1.09it/s, avg loss=187.7697]Checkpoint at iteration 164 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 187.76966705322266

Training iteration:  16%|█▋        | 164/1001 [03:48<12:44,  1.09it/s, avg loss=170.1625]
Training iteration:  16%|█▋        | 165/1001 [03:48<12:43,  1.09it/s, avg loss=170.1625]Checkpoint at iteration 165 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 170.16251106262206

Training iteration:  16%|█▋        | 165/1001 [03:49<12:43,  1.09it/s, avg loss=164.3275]
Training iteration:  17%|█▋        | 166/1001 [03:49<12:43,  1.09it/s, avg loss=164.3275]Checkpoint at iteration 166 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 164.32745437622071

Training iteration:  17%|█▋        | 166/1001 [03:49<12:43,  1.09it/s, avg loss=174.2692]
Training iteration:  17%|█▋        | 167/1001 [03:49<12:42,  1.09it/s, avg loss=174.2692]Checkpoint at iteration 167 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 174.2691764831543

Training iteration:  17%|█▋        | 167/1001 [03:50<12:42,  1.09it/s, avg loss=148.1816]
Training iteration:  17%|█▋        | 168/1001 [03:50<12:41,  1.09it/s, avg loss=148.1816]Checkpoint at iteration 168 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 148.1815601348877

Training iteration:  17%|█▋        | 168/1001 [03:51<12:41,  1.09it/s, avg loss=173.5917]
Training iteration:  17%|█▋        | 169/1001 [03:51<12:40,  1.09it/s, avg loss=173.5917]Checkpoint at iteration 169 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 173.59173927307128

Training iteration:  17%|█▋        | 169/1001 [03:52<12:40,  1.09it/s, avg loss=120.8926]New best at iteratoin 169!

Training iteration:  17%|█▋        | 170/1001 [03:52<12:38,  1.10it/s, avg loss=120.8926]Checkpoint at iteration 170 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 120.89255638122559

Training iteration:  17%|█▋        | 170/1001 [03:53<12:38,  1.10it/s, avg loss=188.9731]
Training iteration:  17%|█▋        | 171/1001 [03:53<12:37,  1.10it/s, avg loss=188.9731]Checkpoint at iteration 171 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 188.97307510375975

Training iteration:  17%|█▋        | 171/1001 [03:54<12:37,  1.10it/s, avg loss=196.0186]
Training iteration:  17%|█▋        | 172/1001 [03:54<12:36,  1.10it/s, avg loss=196.0186]Checkpoint at iteration 172 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 196.0186340332031

Training iteration:  17%|█▋        | 172/1001 [03:55<12:36,  1.10it/s, avg loss=195.8886]
Training iteration:  17%|█▋        | 173/1001 [03:55<12:36,  1.10it/s, avg loss=195.8886]Checkpoint at iteration 173 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 195.88864822387694

Training iteration:  17%|█▋        | 173/1001 [03:56<12:36,  1.10it/s, avg loss=181.0876]
Training iteration:  17%|█▋        | 174/1001 [03:56<12:34,  1.10it/s, avg loss=181.0876]Checkpoint at iteration 174 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 181.08757972717285

Training iteration:  17%|█▋        | 174/1001 [03:57<12:34,  1.10it/s, avg loss=200.2446]
Training iteration:  17%|█▋        | 175/1001 [03:57<12:33,  1.10it/s, avg loss=200.2446]Checkpoint at iteration 175 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 200.24463577270507

Training iteration:  17%|█▋        | 175/1001 [03:58<12:33,  1.10it/s, avg loss=163.8559]
Training iteration:  18%|█▊        | 176/1001 [03:58<12:32,  1.10it/s, avg loss=163.8559]Checkpoint at iteration 176 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 163.85588912963868

Training iteration:  18%|█▊        | 176/1001 [03:59<12:32,  1.10it/s, avg loss=173.8248]
Training iteration:  18%|█▊        | 177/1001 [03:59<12:32,  1.09it/s, avg loss=173.8248]Checkpoint at iteration 177 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 173.8247917175293

Training iteration:  18%|█▊        | 177/1001 [03:59<12:32,  1.09it/s, avg loss=170.4240]
Training iteration:  18%|█▊        | 178/1001 [03:59<12:31,  1.10it/s, avg loss=170.4240]Checkpoint at iteration 178 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 170.42396278381347

Training iteration:  18%|█▊        | 178/1001 [04:00<12:31,  1.10it/s, avg loss=153.6917]
Training iteration:  18%|█▊        | 179/1001 [04:00<12:29,  1.10it/s, avg loss=153.6917]Checkpoint at iteration 179 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 153.69170265197755

Training iteration:  18%|█▊        | 179/1001 [04:01<12:29,  1.10it/s, avg loss=127.0193]
Training iteration:  18%|█▊        | 180/1001 [04:01<12:27,  1.10it/s, avg loss=127.0193]Checkpoint at iteration 180 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 127.01934432983398

Training iteration:  18%|█▊        | 180/1001 [04:02<12:27,  1.10it/s, avg loss=128.3631]
Training iteration:  18%|█▊        | 181/1001 [04:02<12:26,  1.10it/s, avg loss=128.3631]Checkpoint at iteration 181 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 128.3631118774414

Training iteration:  18%|█▊        | 181/1001 [04:03<12:26,  1.10it/s, avg loss=195.2299]
Training iteration:  18%|█▊        | 182/1001 [04:03<12:24,  1.10it/s, avg loss=195.2299]Checkpoint at iteration 182 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 195.2299430847168

Training iteration:  18%|█▊        | 182/1001 [04:04<12:24,  1.10it/s, avg loss=167.1404]
Training iteration:  18%|█▊        | 183/1001 [04:04<12:23,  1.10it/s, avg loss=167.1404]Checkpoint at iteration 183 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 167.14043655395508

Training iteration:  18%|█▊        | 183/1001 [04:05<12:23,  1.10it/s, avg loss=167.9959]
Training iteration:  18%|█▊        | 184/1001 [04:05<12:22,  1.10it/s, avg loss=167.9959]Checkpoint at iteration 184 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 167.99594116210938

Training iteration:  18%|█▊        | 184/1001 [04:06<12:22,  1.10it/s, avg loss=212.7615]
Training iteration:  18%|█▊        | 185/1001 [04:06<12:21,  1.10it/s, avg loss=212.7615]Checkpoint at iteration 185 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 212.7614532470703

Training iteration:  18%|█▊        | 185/1001 [04:07<12:21,  1.10it/s, avg loss=198.7728]
Training iteration:  19%|█▊        | 186/1001 [04:07<12:20,  1.10it/s, avg loss=198.7728]Checkpoint at iteration 186 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 198.77276763916015

Training iteration:  19%|█▊        | 186/1001 [04:08<12:20,  1.10it/s, avg loss=216.0175]
Training iteration:  19%|█▊        | 187/1001 [04:08<12:19,  1.10it/s, avg loss=216.0175]Checkpoint at iteration 187 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 216.0174575805664

Training iteration:  19%|█▊        | 187/1001 [04:09<12:19,  1.10it/s, avg loss=200.9300]
Training iteration:  19%|█▉        | 188/1001 [04:09<12:18,  1.10it/s, avg loss=200.9300]Checkpoint at iteration 188 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 200.92998085021972

Training iteration:  19%|█▉        | 188/1001 [04:09<12:18,  1.10it/s, avg loss=230.8624]
Training iteration:  19%|█▉        | 189/1001 [04:09<12:17,  1.10it/s, avg loss=230.8624]Checkpoint at iteration 189 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 230.8623908996582

Training iteration:  19%|█▉        | 189/1001 [04:10<12:17,  1.10it/s, avg loss=182.6255]
Training iteration:  19%|█▉        | 190/1001 [04:10<12:16,  1.10it/s, avg loss=182.6255]Checkpoint at iteration 190 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 182.6254539489746

Training iteration:  19%|█▉        | 190/1001 [04:11<12:16,  1.10it/s, avg loss=203.0527]
Training iteration:  19%|█▉        | 191/1001 [04:11<12:15,  1.10it/s, avg loss=203.0527]Checkpoint at iteration 191 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 203.0527145385742

Training iteration:  19%|█▉        | 191/1001 [04:12<12:15,  1.10it/s, avg loss=172.4230]
Training iteration:  19%|█▉        | 192/1001 [04:12<12:14,  1.10it/s, avg loss=172.4230]Checkpoint at iteration 192 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 172.42297286987304

Training iteration:  19%|█▉        | 192/1001 [04:13<12:14,  1.10it/s, avg loss=170.8335]
Training iteration:  19%|█▉        | 193/1001 [04:13<12:13,  1.10it/s, avg loss=170.8335]Checkpoint at iteration 193 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 170.8334747314453

Training iteration:  19%|█▉        | 193/1001 [04:14<12:13,  1.10it/s, avg loss=110.0516]New best at iteratoin 193!

Training iteration:  19%|█▉        | 194/1001 [04:14<12:12,  1.10it/s, avg loss=110.0516]Checkpoint at iteration 194 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 110.05160408020019

Training iteration:  19%|█▉        | 194/1001 [04:15<12:12,  1.10it/s, avg loss=165.4478]
Training iteration:  19%|█▉        | 195/1001 [04:15<12:11,  1.10it/s, avg loss=165.4478]Checkpoint at iteration 195 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 165.44777450561523

Training iteration:  19%|█▉        | 195/1001 [04:16<12:11,  1.10it/s, avg loss=172.7055]
Training iteration:  20%|█▉        | 196/1001 [04:16<12:10,  1.10it/s, avg loss=172.7055]Checkpoint at iteration 196 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 172.70549697875975

Training iteration:  20%|█▉        | 196/1001 [04:17<12:10,  1.10it/s, avg loss=162.2721]
Training iteration:  20%|█▉        | 197/1001 [04:17<12:09,  1.10it/s, avg loss=162.2721]Checkpoint at iteration 197 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 162.2721321105957

Training iteration:  20%|█▉        | 197/1001 [04:18<12:09,  1.10it/s, avg loss=188.9998]
Training iteration:  20%|█▉        | 198/1001 [04:18<12:08,  1.10it/s, avg loss=188.9998]Checkpoint at iteration 198 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 188.9997917175293

Training iteration:  20%|█▉        | 198/1001 [04:19<12:08,  1.10it/s, avg loss=211.3859]
Training iteration:  20%|█▉        | 199/1001 [04:19<12:09,  1.10it/s, avg loss=211.3859]Checkpoint at iteration 199 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 211.38591232299805

Training iteration:  20%|█▉        | 199/1001 [04:19<12:09,  1.10it/s, avg loss=123.1097]
Training iteration:  20%|█▉        | 200/1001 [04:19<12:07,  1.10it/s, avg loss=123.1097]Optimization iteration 200 evaluation begins...
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
A new evaluation visualization has been saved: ./saved_data/20240110-081107/it200.png
Training network 0 for evaluation...
Training network 1 for evaluation...
Training network 2 for evaluation...
Training network 3 for evaluation...
Testing network 0 on real datasets for evaluation...
Testing network 1 on real datasets for evaluation...
Testing network 2 on real datasets for evaluation...
Testing network 3 on real datasets for evaluation...
Optimization iteration 200, eval auroc score (train): 19948.8024, eval auroc score (test): 20788.3366
Checkpoint at iteration 200 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 123.10969619750976

Training iteration:  20%|█▉        | 200/1001 [06:11<12:07,  1.10it/s, avg loss=165.7683]
Training iteration:  20%|██        | 201/1001 [06:11<7:33:06, 33.98s/it, avg loss=165.7683]Checkpoint at iteration 201 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 165.7683319091797

Training iteration:  20%|██        | 201/1001 [06:12<7:33:06, 33.98s/it, avg loss=211.9569]
Training iteration:  20%|██        | 202/1001 [06:12<5:21:11, 24.12s/it, avg loss=211.9569]Checkpoint at iteration 202 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 211.95692291259766

Training iteration:  20%|██        | 202/1001 [06:13<5:21:11, 24.12s/it, avg loss=203.5143]
Training iteration:  20%|██        | 203/1001 [06:13<3:48:56, 17.21s/it, avg loss=203.5143]Checkpoint at iteration 203 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 203.51432037353516

Training iteration:  20%|██        | 203/1001 [06:14<3:48:56, 17.21s/it, avg loss=238.2752]
Training iteration:  20%|██        | 204/1001 [06:14<2:44:26, 12.38s/it, avg loss=238.2752]Checkpoint at iteration 204 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 238.27522888183594

Training iteration:  20%|██        | 204/1001 [06:15<2:44:26, 12.38s/it, avg loss=139.7300]
Training iteration:  20%|██        | 205/1001 [06:15<1:59:21,  9.00s/it, avg loss=139.7300]Checkpoint at iteration 205 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 139.72996368408204

Training iteration:  20%|██        | 205/1001 [06:16<1:59:21,  9.00s/it, avg loss=159.6347]
Training iteration:  21%|██        | 206/1001 [06:16<1:27:49,  6.63s/it, avg loss=159.6347]Checkpoint at iteration 206 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 159.6347229003906

Training iteration:  21%|██        | 206/1001 [06:17<1:27:49,  6.63s/it, avg loss=159.8018]
Training iteration:  21%|██        | 207/1001 [06:17<1:05:46,  4.97s/it, avg loss=159.8018]Checkpoint at iteration 207 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 159.8017608642578

Training iteration:  21%|██        | 207/1001 [06:18<1:05:46,  4.97s/it, avg loss=147.8827]
Training iteration:  21%|██        | 208/1001 [06:18<50:21,  3.81s/it, avg loss=147.8827]  Checkpoint at iteration 208 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 147.88272705078126

Training iteration:  21%|██        | 208/1001 [06:19<50:21,  3.81s/it, avg loss=174.7474]
Training iteration:  21%|██        | 209/1001 [06:19<39:33,  3.00s/it, avg loss=174.7474]Checkpoint at iteration 209 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 174.7474052429199

Training iteration:  21%|██        | 209/1001 [06:21<39:33,  3.00s/it, avg loss=148.7745]
Training iteration:  21%|██        | 210/1001 [06:21<32:00,  2.43s/it, avg loss=148.7745]Checkpoint at iteration 210 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 148.7745319366455

Training iteration:  21%|██        | 210/1001 [06:22<32:00,  2.43s/it, avg loss=164.0154]
Training iteration:  21%|██        | 211/1001 [06:22<26:44,  2.03s/it, avg loss=164.0154]Checkpoint at iteration 211 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 164.01540756225586

Training iteration:  21%|██        | 211/1001 [06:23<26:44,  2.03s/it, avg loss=173.3973]
Training iteration:  21%|██        | 212/1001 [06:23<23:02,  1.75s/it, avg loss=173.3973]Checkpoint at iteration 212 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 173.3972526550293

Training iteration:  21%|██        | 212/1001 [06:24<23:02,  1.75s/it, avg loss=181.1630]
Training iteration:  21%|██▏       | 213/1001 [06:24<20:26,  1.56s/it, avg loss=181.1630]Checkpoint at iteration 213 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 181.16303520202638

Training iteration:  21%|██▏       | 213/1001 [06:25<20:26,  1.56s/it, avg loss=190.3900]
Training iteration:  21%|██▏       | 214/1001 [06:25<18:37,  1.42s/it, avg loss=190.3900]Checkpoint at iteration 214 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 190.39003105163573

Training iteration:  21%|██▏       | 214/1001 [06:26<18:37,  1.42s/it, avg loss=169.9712]
Training iteration:  21%|██▏       | 215/1001 [06:26<17:20,  1.32s/it, avg loss=169.9712]Checkpoint at iteration 215 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 169.97115936279297

Training iteration:  21%|██▏       | 215/1001 [06:27<17:20,  1.32s/it, avg loss=181.0317]
Training iteration:  22%|██▏       | 216/1001 [06:27<16:26,  1.26s/it, avg loss=181.0317]Checkpoint at iteration 216 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 181.03170776367188

Training iteration:  22%|██▏       | 216/1001 [06:28<16:26,  1.26s/it, avg loss=147.7384]
Training iteration:  22%|██▏       | 217/1001 [06:28<15:48,  1.21s/it, avg loss=147.7384]Checkpoint at iteration 217 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 147.73837814331054

Training iteration:  22%|██▏       | 217/1001 [06:29<15:48,  1.21s/it, avg loss=206.6827]
Training iteration:  22%|██▏       | 218/1001 [06:29<15:22,  1.18s/it, avg loss=206.6827]Checkpoint at iteration 218 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 206.6827465057373

Training iteration:  22%|██▏       | 218/1001 [06:30<15:22,  1.18s/it, avg loss=195.2682]
Training iteration:  22%|██▏       | 219/1001 [06:30<15:05,  1.16s/it, avg loss=195.2682]Checkpoint at iteration 219 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 195.26816329956054

Training iteration:  22%|██▏       | 219/1001 [06:32<15:05,  1.16s/it, avg loss=192.6726]
Training iteration:  22%|██▏       | 220/1001 [06:32<14:53,  1.14s/it, avg loss=192.6726]Checkpoint at iteration 220 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 192.67255783081055

Training iteration:  22%|██▏       | 220/1001 [06:33<14:53,  1.14s/it, avg loss=186.5072]
Training iteration:  22%|██▏       | 221/1001 [06:33<14:44,  1.13s/it, avg loss=186.5072]Checkpoint at iteration 221 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 186.50716018676758

Training iteration:  22%|██▏       | 221/1001 [06:34<14:44,  1.13s/it, avg loss=154.8173]
Training iteration:  22%|██▏       | 222/1001 [06:34<14:37,  1.13s/it, avg loss=154.8173]Checkpoint at iteration 222 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 154.8172721862793

Training iteration:  22%|██▏       | 222/1001 [06:35<14:37,  1.13s/it, avg loss=161.3073]
Training iteration:  22%|██▏       | 223/1001 [06:35<14:32,  1.12s/it, avg loss=161.3073]Checkpoint at iteration 223 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 161.3072982788086

Training iteration:  22%|██▏       | 223/1001 [06:36<14:32,  1.12s/it, avg loss=215.7356]
Training iteration:  22%|██▏       | 224/1001 [06:36<14:28,  1.12s/it, avg loss=215.7356]Checkpoint at iteration 224 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 215.7356056213379

Training iteration:  22%|██▏       | 224/1001 [06:37<14:28,  1.12s/it, avg loss=196.5259]
Training iteration:  22%|██▏       | 225/1001 [06:37<14:25,  1.12s/it, avg loss=196.5259]Checkpoint at iteration 225 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 196.52593116760255

Training iteration:  22%|██▏       | 225/1001 [06:38<14:25,  1.12s/it, avg loss=165.8349]
Training iteration:  23%|██▎       | 226/1001 [06:38<14:22,  1.11s/it, avg loss=165.8349]Checkpoint at iteration 226 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 165.83494148254394

Training iteration:  23%|██▎       | 226/1001 [06:39<14:22,  1.11s/it, avg loss=193.4693]
Training iteration:  23%|██▎       | 227/1001 [06:39<14:20,  1.11s/it, avg loss=193.4693]Checkpoint at iteration 227 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 193.46925430297853

Training iteration:  23%|██▎       | 227/1001 [06:40<14:20,  1.11s/it, avg loss=183.4384]
Training iteration:  23%|██▎       | 228/1001 [06:40<14:19,  1.11s/it, avg loss=183.4384]Checkpoint at iteration 228 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 183.43839797973632

Training iteration:  23%|██▎       | 228/1001 [06:42<14:19,  1.11s/it, avg loss=160.9105]
Training iteration:  23%|██▎       | 229/1001 [06:42<14:19,  1.11s/it, avg loss=160.9105]Checkpoint at iteration 229 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 160.91052932739257

Training iteration:  23%|██▎       | 229/1001 [06:43<14:19,  1.11s/it, avg loss=141.8655]
Training iteration:  23%|██▎       | 230/1001 [06:43<14:17,  1.11s/it, avg loss=141.8655]Checkpoint at iteration 230 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 141.86549530029296

Training iteration:  23%|██▎       | 230/1001 [06:44<14:17,  1.11s/it, avg loss=233.4082]
Training iteration:  23%|██▎       | 231/1001 [06:44<14:16,  1.11s/it, avg loss=233.4082]Checkpoint at iteration 231 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 233.40821075439453

Training iteration:  23%|██▎       | 231/1001 [06:45<14:16,  1.11s/it, avg loss=242.4310]
Training iteration:  23%|██▎       | 232/1001 [06:45<14:13,  1.11s/it, avg loss=242.4310]Checkpoint at iteration 232 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 242.43098678588868

Training iteration:  23%|██▎       | 232/1001 [06:46<14:13,  1.11s/it, avg loss=119.0207]
Training iteration:  23%|██▎       | 233/1001 [06:46<14:10,  1.11s/it, avg loss=119.0207]Checkpoint at iteration 233 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 119.02073287963867

Training iteration:  23%|██▎       | 233/1001 [06:47<14:10,  1.11s/it, avg loss=183.3133]
Training iteration:  23%|██▎       | 234/1001 [06:47<14:08,  1.11s/it, avg loss=183.3133]Checkpoint at iteration 234 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 183.31327705383302

Training iteration:  23%|██▎       | 234/1001 [06:48<14:08,  1.11s/it, avg loss=171.0868]
Training iteration:  23%|██▎       | 235/1001 [06:48<14:06,  1.11s/it, avg loss=171.0868]Checkpoint at iteration 235 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 171.0867778778076

Training iteration:  23%|██▎       | 235/1001 [06:49<14:06,  1.11s/it, avg loss=216.2242]
Training iteration:  24%|██▎       | 236/1001 [06:49<14:04,  1.10s/it, avg loss=216.2242]Checkpoint at iteration 236 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 216.2241523742676

Training iteration:  24%|██▎       | 236/1001 [06:50<14:04,  1.10s/it, avg loss=200.1535]
Training iteration:  24%|██▎       | 237/1001 [06:50<14:02,  1.10s/it, avg loss=200.1535]Checkpoint at iteration 237 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 200.15352401733398

Training iteration:  24%|██▎       | 237/1001 [06:51<14:02,  1.10s/it, avg loss=167.8239]
Training iteration:  24%|██▍       | 238/1001 [06:51<14:01,  1.10s/it, avg loss=167.8239]Checkpoint at iteration 238 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 167.82387008666993

Training iteration:  24%|██▍       | 238/1001 [06:53<14:01,  1.10s/it, avg loss=130.7355]
Training iteration:  24%|██▍       | 239/1001 [06:53<13:59,  1.10s/it, avg loss=130.7355]Checkpoint at iteration 239 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 130.7355224609375

Training iteration:  24%|██▍       | 239/1001 [06:54<13:59,  1.10s/it, avg loss=135.4967]
Training iteration:  24%|██▍       | 240/1001 [06:54<13:58,  1.10s/it, avg loss=135.4967]Checkpoint at iteration 240 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 135.49665145874025

Training iteration:  24%|██▍       | 240/1001 [06:55<13:58,  1.10s/it, avg loss=180.8598]
Training iteration:  24%|██▍       | 241/1001 [06:55<13:57,  1.10s/it, avg loss=180.8598]Checkpoint at iteration 241 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 180.85982208251954

Training iteration:  24%|██▍       | 241/1001 [06:56<13:57,  1.10s/it, avg loss=166.7330]
Training iteration:  24%|██▍       | 242/1001 [06:56<13:56,  1.10s/it, avg loss=166.7330]Checkpoint at iteration 242 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 166.7330322265625

Training iteration:  24%|██▍       | 242/1001 [06:57<13:56,  1.10s/it, avg loss=170.3396]
Training iteration:  24%|██▍       | 243/1001 [06:57<13:55,  1.10s/it, avg loss=170.3396]Checkpoint at iteration 243 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 170.33960723876953

Training iteration:  24%|██▍       | 243/1001 [06:58<13:55,  1.10s/it, avg loss=161.6929]
Training iteration:  24%|██▍       | 244/1001 [06:58<13:54,  1.10s/it, avg loss=161.6929]Checkpoint at iteration 244 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 161.69292068481445

Training iteration:  24%|██▍       | 244/1001 [06:59<13:54,  1.10s/it, avg loss=150.2714]
Training iteration:  24%|██▍       | 245/1001 [06:59<13:53,  1.10s/it, avg loss=150.2714]Checkpoint at iteration 245 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 150.27142333984375

Training iteration:  24%|██▍       | 245/1001 [07:00<13:53,  1.10s/it, avg loss=201.4009]
Training iteration:  25%|██▍       | 246/1001 [07:00<13:52,  1.10s/it, avg loss=201.4009]Checkpoint at iteration 246 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 201.40094680786132

Training iteration:  25%|██▍       | 246/1001 [07:01<13:52,  1.10s/it, avg loss=137.3016]
Training iteration:  25%|██▍       | 247/1001 [07:01<13:50,  1.10s/it, avg loss=137.3016]Checkpoint at iteration 247 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 137.30157165527345

Training iteration:  25%|██▍       | 247/1001 [07:03<13:50,  1.10s/it, avg loss=187.1415]
Training iteration:  25%|██▍       | 248/1001 [07:03<13:49,  1.10s/it, avg loss=187.1415]Checkpoint at iteration 248 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 187.14146270751954

Training iteration:  25%|██▍       | 248/1001 [07:04<13:49,  1.10s/it, avg loss=160.0116]
Training iteration:  25%|██▍       | 249/1001 [07:04<13:47,  1.10s/it, avg loss=160.0116]Checkpoint at iteration 249 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 160.0116107940674

Training iteration:  25%|██▍       | 249/1001 [07:05<13:47,  1.10s/it, avg loss=166.9429]
Training iteration:  25%|██▍       | 250/1001 [07:05<13:47,  1.10s/it, avg loss=166.9429]Checkpoint at iteration 250 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 166.94291763305665

Training iteration:  25%|██▍       | 250/1001 [07:06<13:47,  1.10s/it, avg loss=176.1788]
Training iteration:  25%|██▌       | 251/1001 [07:06<13:46,  1.10s/it, avg loss=176.1788]Checkpoint at iteration 251 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 176.1787567138672

Training iteration:  25%|██▌       | 251/1001 [07:07<13:46,  1.10s/it, avg loss=154.6458]
Training iteration:  25%|██▌       | 252/1001 [07:07<13:44,  1.10s/it, avg loss=154.6458]Checkpoint at iteration 252 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 154.64577026367186

Training iteration:  25%|██▌       | 252/1001 [07:08<13:44,  1.10s/it, avg loss=162.5777]
Training iteration:  25%|██▌       | 253/1001 [07:08<13:43,  1.10s/it, avg loss=162.5777]Checkpoint at iteration 253 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 162.57765884399413

Training iteration:  25%|██▌       | 253/1001 [07:09<13:43,  1.10s/it, avg loss=173.3735]
Training iteration:  25%|██▌       | 254/1001 [07:09<13:42,  1.10s/it, avg loss=173.3735]Checkpoint at iteration 254 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 173.3735382080078

Training iteration:  25%|██▌       | 254/1001 [07:10<13:42,  1.10s/it, avg loss=178.3518]
Training iteration:  25%|██▌       | 255/1001 [07:10<13:42,  1.10s/it, avg loss=178.3518]Checkpoint at iteration 255 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 178.3518123626709

Training iteration:  25%|██▌       | 255/1001 [07:11<13:42,  1.10s/it, avg loss=169.9855]
Training iteration:  26%|██▌       | 256/1001 [07:11<13:40,  1.10s/it, avg loss=169.9855]Checkpoint at iteration 256 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 169.98553314208985

Training iteration:  26%|██▌       | 256/1001 [07:12<13:40,  1.10s/it, avg loss=150.7318]
Training iteration:  26%|██▌       | 257/1001 [07:12<13:39,  1.10s/it, avg loss=150.7318]Checkpoint at iteration 257 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 150.73175048828125

Training iteration:  26%|██▌       | 257/1001 [07:14<13:39,  1.10s/it, avg loss=173.5819]
Training iteration:  26%|██▌       | 258/1001 [07:14<13:38,  1.10s/it, avg loss=173.5819]Checkpoint at iteration 258 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 173.5819076538086

Training iteration:  26%|██▌       | 258/1001 [07:15<13:38,  1.10s/it, avg loss=126.7494]
Training iteration:  26%|██▌       | 259/1001 [07:15<13:37,  1.10s/it, avg loss=126.7494]Checkpoint at iteration 259 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 126.7494400024414

Training iteration:  26%|██▌       | 259/1001 [07:16<13:37,  1.10s/it, avg loss=135.7112]
Training iteration:  26%|██▌       | 260/1001 [07:16<13:36,  1.10s/it, avg loss=135.7112]Checkpoint at iteration 260 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 135.711177444458

Training iteration:  26%|██▌       | 260/1001 [07:17<13:36,  1.10s/it, avg loss=174.4248]
Training iteration:  26%|██▌       | 261/1001 [07:17<13:35,  1.10s/it, avg loss=174.4248]Checkpoint at iteration 261 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 174.4247787475586

Training iteration:  26%|██▌       | 261/1001 [07:18<13:35,  1.10s/it, avg loss=241.0989]
Training iteration:  26%|██▌       | 262/1001 [07:18<13:34,  1.10s/it, avg loss=241.0989]Checkpoint at iteration 262 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 241.09888916015626

Training iteration:  26%|██▌       | 262/1001 [07:19<13:34,  1.10s/it, avg loss=163.6921]
Training iteration:  26%|██▋       | 263/1001 [07:19<13:34,  1.10s/it, avg loss=163.6921]Checkpoint at iteration 263 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 163.69205780029296

Training iteration:  26%|██▋       | 263/1001 [07:20<13:34,  1.10s/it, avg loss=163.9891]
Training iteration:  26%|██▋       | 264/1001 [07:20<13:33,  1.10s/it, avg loss=163.9891]Checkpoint at iteration 264 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 163.98909606933594

Training iteration:  26%|██▋       | 264/1001 [07:21<13:33,  1.10s/it, avg loss=153.4726]
Training iteration:  26%|██▋       | 265/1001 [07:21<13:32,  1.10s/it, avg loss=153.4726]Checkpoint at iteration 265 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 153.47263412475587

Training iteration:  26%|██▋       | 265/1001 [07:22<13:32,  1.10s/it, avg loss=187.3584]
Training iteration:  27%|██▋       | 266/1001 [07:22<13:30,  1.10s/it, avg loss=187.3584]Checkpoint at iteration 266 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 187.35842590332032

Training iteration:  27%|██▋       | 266/1001 [07:23<13:30,  1.10s/it, avg loss=181.8424]
Training iteration:  27%|██▋       | 267/1001 [07:23<13:29,  1.10s/it, avg loss=181.8424]Checkpoint at iteration 267 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 181.84241790771483

Training iteration:  27%|██▋       | 267/1001 [07:25<13:29,  1.10s/it, avg loss=165.2326]
Training iteration:  27%|██▋       | 268/1001 [07:25<13:27,  1.10s/it, avg loss=165.2326]Checkpoint at iteration 268 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 165.23255882263183

Training iteration:  27%|██▋       | 268/1001 [07:26<13:27,  1.10s/it, avg loss=151.1707]
Training iteration:  27%|██▋       | 269/1001 [07:26<13:26,  1.10s/it, avg loss=151.1707]Checkpoint at iteration 269 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 151.17069244384766

Training iteration:  27%|██▋       | 269/1001 [07:27<13:26,  1.10s/it, avg loss=145.5186]
Training iteration:  27%|██▋       | 270/1001 [07:27<13:25,  1.10s/it, avg loss=145.5186]Checkpoint at iteration 270 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 145.51860275268555

Training iteration:  27%|██▋       | 270/1001 [07:28<13:25,  1.10s/it, avg loss=179.9163]
Training iteration:  27%|██▋       | 271/1001 [07:28<13:23,  1.10s/it, avg loss=179.9163]Checkpoint at iteration 271 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 179.91632766723632

Training iteration:  27%|██▋       | 271/1001 [07:29<13:23,  1.10s/it, avg loss=214.7734]
Training iteration:  27%|██▋       | 272/1001 [07:29<13:22,  1.10s/it, avg loss=214.7734]Checkpoint at iteration 272 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 214.7734344482422

Training iteration:  27%|██▋       | 272/1001 [07:30<13:22,  1.10s/it, avg loss=170.5441]
Training iteration:  27%|██▋       | 273/1001 [07:30<13:21,  1.10s/it, avg loss=170.5441]Checkpoint at iteration 273 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 170.5440658569336

Training iteration:  27%|██▋       | 273/1001 [07:31<13:21,  1.10s/it, avg loss=194.9651]
Training iteration:  27%|██▋       | 274/1001 [07:31<13:20,  1.10s/it, avg loss=194.9651]Checkpoint at iteration 274 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 194.9650634765625

Training iteration:  27%|██▋       | 274/1001 [07:32<13:20,  1.10s/it, avg loss=161.3958]
Training iteration:  27%|██▋       | 275/1001 [07:32<13:19,  1.10s/it, avg loss=161.3958]Checkpoint at iteration 275 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 161.39582786560058

Training iteration:  27%|██▋       | 275/1001 [07:33<13:19,  1.10s/it, avg loss=222.3738]
Training iteration:  28%|██▊       | 276/1001 [07:33<13:18,  1.10s/it, avg loss=222.3738]Checkpoint at iteration 276 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 222.37384567260742

Training iteration:  28%|██▊       | 276/1001 [07:34<13:18,  1.10s/it, avg loss=162.8825]
Training iteration:  28%|██▊       | 277/1001 [07:34<13:17,  1.10s/it, avg loss=162.8825]Checkpoint at iteration 277 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 162.88250160217285

Training iteration:  28%|██▊       | 277/1001 [07:36<13:17,  1.10s/it, avg loss=142.7180]
Training iteration:  28%|██▊       | 278/1001 [07:36<13:15,  1.10s/it, avg loss=142.7180]Checkpoint at iteration 278 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 142.7180477142334

Training iteration:  28%|██▊       | 278/1001 [07:37<13:15,  1.10s/it, avg loss=150.4729]
Training iteration:  28%|██▊       | 279/1001 [07:37<13:14,  1.10s/it, avg loss=150.4729]Checkpoint at iteration 279 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 150.47288131713867

Training iteration:  28%|██▊       | 279/1001 [07:38<13:14,  1.10s/it, avg loss=135.8880]
Training iteration:  28%|██▊       | 280/1001 [07:38<13:13,  1.10s/it, avg loss=135.8880]Checkpoint at iteration 280 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 135.88804512023927

Training iteration:  28%|██▊       | 280/1001 [07:39<13:13,  1.10s/it, avg loss=165.6847]
Training iteration:  28%|██▊       | 281/1001 [07:39<13:12,  1.10s/it, avg loss=165.6847]Checkpoint at iteration 281 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 165.6847064971924

Training iteration:  28%|██▊       | 281/1001 [07:40<13:12,  1.10s/it, avg loss=183.3636]
Training iteration:  28%|██▊       | 282/1001 [07:40<13:11,  1.10s/it, avg loss=183.3636]Checkpoint at iteration 282 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 183.3636215209961

Training iteration:  28%|██▊       | 282/1001 [07:41<13:11,  1.10s/it, avg loss=155.4113]
Training iteration:  28%|██▊       | 283/1001 [07:41<13:10,  1.10s/it, avg loss=155.4113]Checkpoint at iteration 283 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 155.41126823425293

Training iteration:  28%|██▊       | 283/1001 [07:42<13:10,  1.10s/it, avg loss=215.7280]
Training iteration:  28%|██▊       | 284/1001 [07:42<13:09,  1.10s/it, avg loss=215.7280]Checkpoint at iteration 284 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 215.72796554565429

Training iteration:  28%|██▊       | 284/1001 [07:43<13:09,  1.10s/it, avg loss=170.5084]
Training iteration:  28%|██▊       | 285/1001 [07:43<13:09,  1.10s/it, avg loss=170.5084]Checkpoint at iteration 285 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 170.50839614868164

Training iteration:  28%|██▊       | 285/1001 [07:44<13:09,  1.10s/it, avg loss=114.1992]
Training iteration:  29%|██▊       | 286/1001 [07:44<13:09,  1.10s/it, avg loss=114.1992]Checkpoint at iteration 286 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 114.19917221069336

Training iteration:  29%|██▊       | 286/1001 [07:45<13:09,  1.10s/it, avg loss=233.7327]
Training iteration:  29%|██▊       | 287/1001 [07:45<13:09,  1.11s/it, avg loss=233.7327]Checkpoint at iteration 287 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 233.73267822265626

Training iteration:  29%|██▊       | 287/1001 [07:47<13:09,  1.11s/it, avg loss=140.0772]
Training iteration:  29%|██▉       | 288/1001 [07:47<13:09,  1.11s/it, avg loss=140.0772]Checkpoint at iteration 288 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 140.07719650268555

Training iteration:  29%|██▉       | 288/1001 [07:48<13:09,  1.11s/it, avg loss=158.3300]
Training iteration:  29%|██▉       | 289/1001 [07:48<13:08,  1.11s/it, avg loss=158.3300]Checkpoint at iteration 289 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 158.3300048828125

Training iteration:  29%|██▉       | 289/1001 [07:49<13:08,  1.11s/it, avg loss=139.6112]
Training iteration:  29%|██▉       | 290/1001 [07:49<13:07,  1.11s/it, avg loss=139.6112]Checkpoint at iteration 290 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 139.611169052124

Training iteration:  29%|██▉       | 290/1001 [07:50<13:07,  1.11s/it, avg loss=206.3256]
Training iteration:  29%|██▉       | 291/1001 [07:50<13:06,  1.11s/it, avg loss=206.3256]Checkpoint at iteration 291 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 206.3255531311035

Training iteration:  29%|██▉       | 291/1001 [07:51<13:06,  1.11s/it, avg loss=203.0388]
Training iteration:  29%|██▉       | 292/1001 [07:51<13:05,  1.11s/it, avg loss=203.0388]Checkpoint at iteration 292 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 203.0387939453125

Training iteration:  29%|██▉       | 292/1001 [07:52<13:05,  1.11s/it, avg loss=174.4791]
Training iteration:  29%|██▉       | 293/1001 [07:52<13:04,  1.11s/it, avg loss=174.4791]Checkpoint at iteration 293 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 174.47914199829103

Training iteration:  29%|██▉       | 293/1001 [07:53<13:04,  1.11s/it, avg loss=135.4197]
Training iteration:  29%|██▉       | 294/1001 [07:53<13:03,  1.11s/it, avg loss=135.4197]Checkpoint at iteration 294 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 135.41968383789063

Training iteration:  29%|██▉       | 294/1001 [07:54<13:03,  1.11s/it, avg loss=124.5210]
Training iteration:  29%|██▉       | 295/1001 [07:54<13:02,  1.11s/it, avg loss=124.5210]Checkpoint at iteration 295 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 124.52096443176269

Training iteration:  29%|██▉       | 295/1001 [07:55<13:02,  1.11s/it, avg loss=171.9520]
Training iteration:  30%|██▉       | 296/1001 [07:55<13:01,  1.11s/it, avg loss=171.9520]Checkpoint at iteration 296 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 171.95202560424804

Training iteration:  30%|██▉       | 296/1001 [07:57<13:01,  1.11s/it, avg loss=111.1253]
Training iteration:  30%|██▉       | 297/1001 [07:57<13:00,  1.11s/it, avg loss=111.1253]Checkpoint at iteration 297 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 111.1253448486328

Training iteration:  30%|██▉       | 297/1001 [07:58<13:00,  1.11s/it, avg loss=127.3638]
Training iteration:  30%|██▉       | 298/1001 [07:58<12:58,  1.11s/it, avg loss=127.3638]Checkpoint at iteration 298 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 127.36382369995117

Training iteration:  30%|██▉       | 298/1001 [07:59<12:58,  1.11s/it, avg loss=174.2654]
Training iteration:  30%|██▉       | 299/1001 [07:59<12:57,  1.11s/it, avg loss=174.2654]Checkpoint at iteration 299 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 174.26538772583007

Training iteration:  30%|██▉       | 299/1001 [08:00<12:57,  1.11s/it, avg loss=210.1852]
Training iteration:  30%|██▉       | 300/1001 [08:00<12:57,  1.11s/it, avg loss=210.1852]Optimization iteration 300 evaluation begins...
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
A new evaluation visualization has been saved: ./saved_data/20240110-081107/it300.png
Training network 0 for evaluation...
Training network 1 for evaluation...
Training network 2 for evaluation...
Training network 3 for evaluation...
Testing network 0 on real datasets for evaluation...
Testing network 1 on real datasets for evaluation...
Testing network 2 on real datasets for evaluation...
Testing network 3 on real datasets for evaluation...
Optimization iteration 300, eval auroc score (train): 19879.9243, eval auroc score (test): 20827.2859
Checkpoint at iteration 300 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 210.18523635864258

Training iteration:  30%|██▉       | 300/1001 [11:01<12:57,  1.11s/it, avg loss=169.2245]
Training iteration:  30%|███       | 301/1001 [11:01<10:43:53, 55.19s/it, avg loss=169.2245]Checkpoint at iteration 301 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 169.2245002746582

Training iteration:  30%|███       | 301/1001 [11:03<10:43:53, 55.19s/it, avg loss=120.0427]
Training iteration:  30%|███       | 302/1001 [11:03<7:34:37, 39.02s/it, avg loss=120.0427] Checkpoint at iteration 302 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 120.04272003173828

Training iteration:  30%|███       | 302/1001 [11:04<7:34:37, 39.02s/it, avg loss=136.3610]
Training iteration:  30%|███       | 303/1001 [11:04<5:22:18, 27.71s/it, avg loss=136.3610]Checkpoint at iteration 303 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 136.3609992980957

Training iteration:  30%|███       | 303/1001 [11:05<5:22:18, 27.71s/it, avg loss=157.7709]
Training iteration:  30%|███       | 304/1001 [11:05<3:49:48, 19.78s/it, avg loss=157.7709]Checkpoint at iteration 304 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 157.77094383239745

Training iteration:  30%|███       | 304/1001 [11:06<3:49:48, 19.78s/it, avg loss=158.4189]
Training iteration:  30%|███       | 305/1001 [11:06<2:45:08, 14.24s/it, avg loss=158.4189]Checkpoint at iteration 305 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 158.41894721984863

Training iteration:  30%|███       | 305/1001 [11:08<2:45:08, 14.24s/it, avg loss=173.6775]
Training iteration:  31%|███       | 306/1001 [11:08<1:59:56, 10.35s/it, avg loss=173.6775]Checkpoint at iteration 306 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 173.67753257751465

Training iteration:  31%|███       | 306/1001 [11:09<1:59:56, 10.35s/it, avg loss=231.1633]
Training iteration:  31%|███       | 307/1001 [11:09<1:28:20,  7.64s/it, avg loss=231.1633]Checkpoint at iteration 307 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 231.1632858276367

Training iteration:  31%|███       | 307/1001 [11:10<1:28:20,  7.64s/it, avg loss=154.3824]
Training iteration:  31%|███       | 308/1001 [11:10<1:06:14,  5.74s/it, avg loss=154.3824]Checkpoint at iteration 308 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 154.3823513031006

Training iteration:  31%|███       | 308/1001 [11:12<1:06:14,  5.74s/it, avg loss=178.2500]
Training iteration:  31%|███       | 309/1001 [11:12<50:47,  4.40s/it, avg loss=178.2500]  Checkpoint at iteration 309 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 178.24996795654297

Training iteration:  31%|███       | 309/1001 [11:13<50:47,  4.40s/it, avg loss=156.7246]
Training iteration:  31%|███       | 310/1001 [11:13<39:59,  3.47s/it, avg loss=156.7246]Checkpoint at iteration 310 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 156.7246036529541

Training iteration:  31%|███       | 310/1001 [11:14<39:59,  3.47s/it, avg loss=201.0832]
Training iteration:  31%|███       | 311/1001 [11:14<32:25,  2.82s/it, avg loss=201.0832]Checkpoint at iteration 311 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 201.08323974609374

Training iteration:  31%|███       | 311/1001 [11:16<32:25,  2.82s/it, avg loss=118.7374]
Training iteration:  31%|███       | 312/1001 [11:16<27:08,  2.36s/it, avg loss=118.7374]Checkpoint at iteration 312 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 118.73736228942872

Training iteration:  31%|███       | 312/1001 [11:17<27:08,  2.36s/it, avg loss=171.8985]
Training iteration:  31%|███▏      | 313/1001 [11:17<23:26,  2.04s/it, avg loss=171.8985]Checkpoint at iteration 313 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 171.89846115112306

Training iteration:  31%|███▏      | 313/1001 [11:18<23:26,  2.04s/it, avg loss=178.7491]
Training iteration:  31%|███▏      | 314/1001 [11:18<20:50,  1.82s/it, avg loss=178.7491]Checkpoint at iteration 314 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 178.74908485412598

Training iteration:  31%|███▏      | 314/1001 [11:19<20:50,  1.82s/it, avg loss=180.2229]
Training iteration:  31%|███▏      | 315/1001 [11:19<19:02,  1.67s/it, avg loss=180.2229]Checkpoint at iteration 315 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 180.222904586792

Training iteration:  31%|███▏      | 315/1001 [11:21<19:02,  1.67s/it, avg loss=122.9825]
Training iteration:  32%|███▏      | 316/1001 [11:21<17:45,  1.56s/it, avg loss=122.9825]Checkpoint at iteration 316 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 122.98245048522949

Training iteration:  32%|███▏      | 316/1001 [11:22<17:45,  1.56s/it, avg loss=210.0118]
Training iteration:  32%|███▏      | 317/1001 [11:22<16:50,  1.48s/it, avg loss=210.0118]Checkpoint at iteration 317 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 210.01181297302247

Training iteration:  32%|███▏      | 317/1001 [11:23<16:50,  1.48s/it, avg loss=158.1491]
Training iteration:  32%|███▏      | 318/1001 [11:23<16:12,  1.42s/it, avg loss=158.1491]Checkpoint at iteration 318 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 158.1490665435791

Training iteration:  32%|███▏      | 318/1001 [11:25<16:12,  1.42s/it, avg loss=203.8523]
Training iteration:  32%|███▏      | 319/1001 [11:25<15:45,  1.39s/it, avg loss=203.8523]Checkpoint at iteration 319 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 203.8522850036621

Training iteration:  32%|███▏      | 319/1001 [11:26<15:45,  1.39s/it, avg loss=174.7586]
Training iteration:  32%|███▏      | 320/1001 [11:26<15:26,  1.36s/it, avg loss=174.7586]Checkpoint at iteration 320 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 174.75862655639648

Training iteration:  32%|███▏      | 320/1001 [11:27<15:26,  1.36s/it, avg loss=186.9830]
Training iteration:  32%|███▏      | 321/1001 [11:27<15:12,  1.34s/it, avg loss=186.9830]Checkpoint at iteration 321 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 186.98297805786132

Training iteration:  32%|███▏      | 321/1001 [11:29<15:12,  1.34s/it, avg loss=130.1904]
Training iteration:  32%|███▏      | 322/1001 [11:29<15:01,  1.33s/it, avg loss=130.1904]Checkpoint at iteration 322 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 130.19036331176758

Training iteration:  32%|███▏      | 322/1001 [11:30<15:01,  1.33s/it, avg loss=156.6087]
Training iteration:  32%|███▏      | 323/1001 [11:30<14:54,  1.32s/it, avg loss=156.6087]Checkpoint at iteration 323 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 156.60865364074706

Training iteration:  32%|███▏      | 323/1001 [11:31<14:54,  1.32s/it, avg loss=210.3714]
Training iteration:  32%|███▏      | 324/1001 [11:31<14:48,  1.31s/it, avg loss=210.3714]Checkpoint at iteration 324 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 210.37135696411133

Training iteration:  32%|███▏      | 324/1001 [11:32<14:48,  1.31s/it, avg loss=150.3452]
Training iteration:  32%|███▏      | 325/1001 [11:32<14:43,  1.31s/it, avg loss=150.3452]Checkpoint at iteration 325 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 150.34521713256837

Training iteration:  32%|███▏      | 325/1001 [11:34<14:43,  1.31s/it, avg loss=130.3235]
Training iteration:  33%|███▎      | 326/1001 [11:34<14:40,  1.30s/it, avg loss=130.3235]Checkpoint at iteration 326 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 130.3234764099121

Training iteration:  33%|███▎      | 326/1001 [11:35<14:40,  1.30s/it, avg loss=123.3018]
Training iteration:  33%|███▎      | 327/1001 [11:35<14:37,  1.30s/it, avg loss=123.3018]Checkpoint at iteration 327 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 123.30180740356445

Training iteration:  33%|███▎      | 327/1001 [11:36<14:37,  1.30s/it, avg loss=157.3561]
Training iteration:  33%|███▎      | 328/1001 [11:36<14:34,  1.30s/it, avg loss=157.3561]Checkpoint at iteration 328 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 157.35605659484864

Training iteration:  33%|███▎      | 328/1001 [11:38<14:34,  1.30s/it, avg loss=226.6608]
Training iteration:  33%|███▎      | 329/1001 [11:38<14:32,  1.30s/it, avg loss=226.6608]Checkpoint at iteration 329 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 226.66075973510743

Training iteration:  33%|███▎      | 329/1001 [11:39<14:32,  1.30s/it, avg loss=128.8939]
Training iteration:  33%|███▎      | 330/1001 [11:39<14:30,  1.30s/it, avg loss=128.8939]Checkpoint at iteration 330 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 128.8939121246338

Training iteration:  33%|███▎      | 330/1001 [11:40<14:30,  1.30s/it, avg loss=123.3493]
Training iteration:  33%|███▎      | 331/1001 [11:40<14:29,  1.30s/it, avg loss=123.3493]Checkpoint at iteration 331 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 123.34926795959473

Training iteration:  33%|███▎      | 331/1001 [11:42<14:29,  1.30s/it, avg loss=140.9660]
Training iteration:  33%|███▎      | 332/1001 [11:42<14:27,  1.30s/it, avg loss=140.9660]Checkpoint at iteration 332 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 140.96599769592285

Training iteration:  33%|███▎      | 332/1001 [11:43<14:27,  1.30s/it, avg loss=217.4097]
Training iteration:  33%|███▎      | 333/1001 [11:43<14:26,  1.30s/it, avg loss=217.4097]Checkpoint at iteration 333 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 217.40965156555177

Training iteration:  33%|███▎      | 333/1001 [11:44<14:26,  1.30s/it, avg loss=184.5149]
Training iteration:  33%|███▎      | 334/1001 [11:44<14:25,  1.30s/it, avg loss=184.5149]Checkpoint at iteration 334 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 184.5148597717285

Training iteration:  33%|███▎      | 334/1001 [11:45<14:25,  1.30s/it, avg loss=136.1516]
Training iteration:  33%|███▎      | 335/1001 [11:45<14:23,  1.30s/it, avg loss=136.1516]Checkpoint at iteration 335 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 136.1516014099121

Training iteration:  33%|███▎      | 335/1001 [11:47<14:23,  1.30s/it, avg loss=122.9592]
Training iteration:  34%|███▎      | 336/1001 [11:47<14:22,  1.30s/it, avg loss=122.9592]Checkpoint at iteration 336 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 122.95920677185059

Training iteration:  34%|███▎      | 336/1001 [11:48<14:22,  1.30s/it, avg loss=113.4888]
Training iteration:  34%|███▎      | 337/1001 [11:48<14:21,  1.30s/it, avg loss=113.4888]Checkpoint at iteration 337 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 113.48882865905762

Training iteration:  34%|███▎      | 337/1001 [11:49<14:21,  1.30s/it, avg loss=211.6575]
Training iteration:  34%|███▍      | 338/1001 [11:49<14:19,  1.30s/it, avg loss=211.6575]Checkpoint at iteration 338 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 211.65753135681152

Training iteration:  34%|███▍      | 338/1001 [11:51<14:19,  1.30s/it, avg loss=129.4863]
Training iteration:  34%|███▍      | 339/1001 [11:51<14:18,  1.30s/it, avg loss=129.4863]Checkpoint at iteration 339 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 129.48626327514648

Training iteration:  34%|███▍      | 339/1001 [11:52<14:18,  1.30s/it, avg loss=195.2296]
Training iteration:  34%|███▍      | 340/1001 [11:52<14:18,  1.30s/it, avg loss=195.2296]Checkpoint at iteration 340 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 195.2295886993408

Training iteration:  34%|███▍      | 340/1001 [11:53<14:18,  1.30s/it, avg loss=175.5738]
Training iteration:  34%|███▍      | 341/1001 [11:53<14:16,  1.30s/it, avg loss=175.5738]Checkpoint at iteration 341 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 175.573832321167

Training iteration:  34%|███▍      | 341/1001 [11:54<14:16,  1.30s/it, avg loss=158.4439]
Training iteration:  34%|███▍      | 342/1001 [11:54<14:15,  1.30s/it, avg loss=158.4439]Checkpoint at iteration 342 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 158.44388847351075

Training iteration:  34%|███▍      | 342/1001 [11:56<14:15,  1.30s/it, avg loss=140.4219]
Training iteration:  34%|███▍      | 343/1001 [11:56<14:13,  1.30s/it, avg loss=140.4219]Checkpoint at iteration 343 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 140.42193222045898

Training iteration:  34%|███▍      | 343/1001 [11:57<14:13,  1.30s/it, avg loss=162.2195]
Training iteration:  34%|███▍      | 344/1001 [11:57<14:12,  1.30s/it, avg loss=162.2195]Checkpoint at iteration 344 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 162.21953048706055

Training iteration:  34%|███▍      | 344/1001 [11:58<14:12,  1.30s/it, avg loss=219.6086]
Training iteration:  34%|███▍      | 345/1001 [11:58<14:11,  1.30s/it, avg loss=219.6086]Checkpoint at iteration 345 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 219.60861053466797

Training iteration:  34%|███▍      | 345/1001 [12:00<14:11,  1.30s/it, avg loss=169.1135]
Training iteration:  35%|███▍      | 346/1001 [12:00<14:10,  1.30s/it, avg loss=169.1135]Checkpoint at iteration 346 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 169.11349220275878

Training iteration:  35%|███▍      | 346/1001 [12:01<14:10,  1.30s/it, avg loss=155.0205]
Training iteration:  35%|███▍      | 347/1001 [12:01<14:10,  1.30s/it, avg loss=155.0205]Checkpoint at iteration 347 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 155.02052841186523

Training iteration:  35%|███▍      | 347/1001 [12:02<14:10,  1.30s/it, avg loss=182.1404]
Training iteration:  35%|███▍      | 348/1001 [12:02<14:08,  1.30s/it, avg loss=182.1404]Checkpoint at iteration 348 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 182.14036407470704

Training iteration:  35%|███▍      | 348/1001 [12:04<14:08,  1.30s/it, avg loss=147.9183]
Training iteration:  35%|███▍      | 349/1001 [12:04<14:06,  1.30s/it, avg loss=147.9183]Checkpoint at iteration 349 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 147.91834030151367

Training iteration:  35%|███▍      | 349/1001 [12:05<14:06,  1.30s/it, avg loss=180.2237]
Training iteration:  35%|███▍      | 350/1001 [12:05<14:05,  1.30s/it, avg loss=180.2237]Checkpoint at iteration 350 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 180.22365913391113

Training iteration:  35%|███▍      | 350/1001 [12:06<14:05,  1.30s/it, avg loss=160.0883]
Training iteration:  35%|███▌      | 351/1001 [12:06<14:03,  1.30s/it, avg loss=160.0883]Checkpoint at iteration 351 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 160.08833694458008

Training iteration:  35%|███▌      | 351/1001 [12:07<14:03,  1.30s/it, avg loss=160.2833]
Training iteration:  35%|███▌      | 352/1001 [12:07<14:02,  1.30s/it, avg loss=160.2833]Checkpoint at iteration 352 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 160.28329849243164

Training iteration:  35%|███▌      | 352/1001 [12:09<14:02,  1.30s/it, avg loss=216.3958]
Training iteration:  35%|███▌      | 353/1001 [12:09<14:01,  1.30s/it, avg loss=216.3958]Checkpoint at iteration 353 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 216.39576568603516

Training iteration:  35%|███▌      | 353/1001 [12:10<14:01,  1.30s/it, avg loss=155.8539]
Training iteration:  35%|███▌      | 354/1001 [12:10<13:59,  1.30s/it, avg loss=155.8539]Checkpoint at iteration 354 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 155.85385780334474

Training iteration:  35%|███▌      | 354/1001 [12:11<13:59,  1.30s/it, avg loss=122.5318]
Training iteration:  35%|███▌      | 355/1001 [12:11<13:58,  1.30s/it, avg loss=122.5318]Checkpoint at iteration 355 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 122.53181114196778

Training iteration:  35%|███▌      | 355/1001 [12:13<13:58,  1.30s/it, avg loss=165.8663]
Training iteration:  36%|███▌      | 356/1001 [12:13<13:58,  1.30s/it, avg loss=165.8663]Checkpoint at iteration 356 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 165.86633529663087

Training iteration:  36%|███▌      | 356/1001 [12:14<13:58,  1.30s/it, avg loss=174.3768]
Training iteration:  36%|███▌      | 357/1001 [12:14<13:56,  1.30s/it, avg loss=174.3768]Checkpoint at iteration 357 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 174.37675018310546

Training iteration:  36%|███▌      | 357/1001 [12:15<13:56,  1.30s/it, avg loss=146.0888]
Training iteration:  36%|███▌      | 358/1001 [12:15<13:55,  1.30s/it, avg loss=146.0888]Checkpoint at iteration 358 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 146.0887809753418

Training iteration:  36%|███▌      | 358/1001 [12:17<13:55,  1.30s/it, avg loss=147.8584]
Training iteration:  36%|███▌      | 359/1001 [12:17<13:54,  1.30s/it, avg loss=147.8584]Checkpoint at iteration 359 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 147.85837516784667

Training iteration:  36%|███▌      | 359/1001 [12:18<13:54,  1.30s/it, avg loss=245.9187]
Training iteration:  36%|███▌      | 360/1001 [12:18<13:53,  1.30s/it, avg loss=245.9187]Checkpoint at iteration 360 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 245.91865081787108

Training iteration:  36%|███▌      | 360/1001 [12:19<13:53,  1.30s/it, avg loss=181.0545]
Training iteration:  36%|███▌      | 361/1001 [12:19<13:51,  1.30s/it, avg loss=181.0545]Checkpoint at iteration 361 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 181.05447006225586

Training iteration:  36%|███▌      | 361/1001 [12:20<13:51,  1.30s/it, avg loss=186.8898]
Training iteration:  36%|███▌      | 362/1001 [12:20<13:51,  1.30s/it, avg loss=186.8898]Checkpoint at iteration 362 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 186.88982467651368

Training iteration:  36%|███▌      | 362/1001 [12:22<13:51,  1.30s/it, avg loss=229.8933]
Training iteration:  36%|███▋      | 363/1001 [12:22<13:50,  1.30s/it, avg loss=229.8933]Checkpoint at iteration 363 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 229.89330978393554

Training iteration:  36%|███▋      | 363/1001 [12:23<13:50,  1.30s/it, avg loss=163.1409]
Training iteration:  36%|███▋      | 364/1001 [12:23<13:49,  1.30s/it, avg loss=163.1409]Checkpoint at iteration 364 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 163.1408592224121

Training iteration:  36%|███▋      | 364/1001 [12:24<13:49,  1.30s/it, avg loss=130.6395]
Training iteration:  36%|███▋      | 365/1001 [12:24<13:47,  1.30s/it, avg loss=130.6395]Checkpoint at iteration 365 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 130.6394920349121

Training iteration:  36%|███▋      | 365/1001 [12:26<13:47,  1.30s/it, avg loss=171.0363]
Training iteration:  37%|███▋      | 366/1001 [12:26<13:45,  1.30s/it, avg loss=171.0363]Checkpoint at iteration 366 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 171.03628692626953

Training iteration:  37%|███▋      | 366/1001 [12:27<13:45,  1.30s/it, avg loss=111.4946]
Training iteration:  37%|███▋      | 367/1001 [12:27<13:44,  1.30s/it, avg loss=111.4946]Checkpoint at iteration 367 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 111.49464302062988

Training iteration:  37%|███▋      | 367/1001 [12:28<13:44,  1.30s/it, avg loss=167.2452]
Training iteration:  37%|███▋      | 368/1001 [12:28<13:42,  1.30s/it, avg loss=167.2452]Checkpoint at iteration 368 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 167.2452194213867

Training iteration:  37%|███▋      | 368/1001 [12:30<13:42,  1.30s/it, avg loss=234.9188]
Training iteration:  37%|███▋      | 369/1001 [12:30<13:41,  1.30s/it, avg loss=234.9188]Checkpoint at iteration 369 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 234.91883659362793

Training iteration:  37%|███▋      | 369/1001 [12:31<13:41,  1.30s/it, avg loss=194.1514]
Training iteration:  37%|███▋      | 370/1001 [12:31<13:40,  1.30s/it, avg loss=194.1514]Checkpoint at iteration 370 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 194.15135765075684

Training iteration:  37%|███▋      | 370/1001 [12:32<13:40,  1.30s/it, avg loss=203.2202]
Training iteration:  37%|███▋      | 371/1001 [12:32<13:39,  1.30s/it, avg loss=203.2202]Checkpoint at iteration 371 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 203.2202163696289

Training iteration:  37%|███▋      | 371/1001 [12:33<13:39,  1.30s/it, avg loss=145.2372]
Training iteration:  37%|███▋      | 372/1001 [12:33<13:37,  1.30s/it, avg loss=145.2372]Checkpoint at iteration 372 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 145.2372226715088

Training iteration:  37%|███▋      | 372/1001 [12:35<13:37,  1.30s/it, avg loss=174.6056]
Training iteration:  37%|███▋      | 373/1001 [12:35<13:36,  1.30s/it, avg loss=174.6056]Checkpoint at iteration 373 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 174.6056251525879

Training iteration:  37%|███▋      | 373/1001 [12:36<13:36,  1.30s/it, avg loss=186.3097]
Training iteration:  37%|███▋      | 374/1001 [12:36<13:34,  1.30s/it, avg loss=186.3097]Checkpoint at iteration 374 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 186.30967864990234

Training iteration:  37%|███▋      | 374/1001 [12:37<13:34,  1.30s/it, avg loss=167.2183]
Training iteration:  37%|███▋      | 375/1001 [12:37<13:33,  1.30s/it, avg loss=167.2183]Checkpoint at iteration 375 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 167.21829528808593

Training iteration:  37%|███▋      | 375/1001 [12:39<13:33,  1.30s/it, avg loss=117.9707]
Training iteration:  38%|███▊      | 376/1001 [12:39<13:32,  1.30s/it, avg loss=117.9707]Checkpoint at iteration 376 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 117.97071075439453

Training iteration:  38%|███▊      | 376/1001 [12:40<13:32,  1.30s/it, avg loss=114.3400]
Training iteration:  38%|███▊      | 377/1001 [12:40<13:30,  1.30s/it, avg loss=114.3400]Checkpoint at iteration 377 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 114.33995361328125

Training iteration:  38%|███▊      | 377/1001 [12:41<13:30,  1.30s/it, avg loss=145.4472]
Training iteration:  38%|███▊      | 378/1001 [12:41<13:29,  1.30s/it, avg loss=145.4472]Checkpoint at iteration 378 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 145.44722938537598

Training iteration:  38%|███▊      | 378/1001 [12:43<13:29,  1.30s/it, avg loss=109.1376]New best at iteratoin 378!

Training iteration:  38%|███▊      | 379/1001 [12:43<13:27,  1.30s/it, avg loss=109.1376]Checkpoint at iteration 379 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 109.13756217956544

Training iteration:  38%|███▊      | 379/1001 [12:44<13:27,  1.30s/it, avg loss=181.7340]
Training iteration:  38%|███▊      | 380/1001 [12:44<13:25,  1.30s/it, avg loss=181.7340]Checkpoint at iteration 380 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 181.73400268554687

Training iteration:  38%|███▊      | 380/1001 [12:45<13:25,  1.30s/it, avg loss=195.7899]
Training iteration:  38%|███▊      | 381/1001 [12:45<13:24,  1.30s/it, avg loss=195.7899]Checkpoint at iteration 381 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 195.7899139404297

Training iteration:  38%|███▊      | 381/1001 [12:46<13:24,  1.30s/it, avg loss=190.3809]
Training iteration:  38%|███▊      | 382/1001 [12:46<13:22,  1.30s/it, avg loss=190.3809]Checkpoint at iteration 382 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 190.38093185424805

Training iteration:  38%|███▊      | 382/1001 [12:48<13:22,  1.30s/it, avg loss=128.7338]
Training iteration:  38%|███▊      | 383/1001 [12:48<13:21,  1.30s/it, avg loss=128.7338]Checkpoint at iteration 383 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 128.73382225036622

Training iteration:  38%|███▊      | 383/1001 [12:49<13:21,  1.30s/it, avg loss=187.6072]
Training iteration:  38%|███▊      | 384/1001 [12:49<13:20,  1.30s/it, avg loss=187.6072]Checkpoint at iteration 384 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 187.607186126709

Training iteration:  38%|███▊      | 384/1001 [12:50<13:20,  1.30s/it, avg loss=213.2740]
Training iteration:  38%|███▊      | 385/1001 [12:50<13:19,  1.30s/it, avg loss=213.2740]Checkpoint at iteration 385 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 213.27404708862304

Training iteration:  38%|███▊      | 385/1001 [12:52<13:19,  1.30s/it, avg loss=95.1820] New best at iteratoin 385!

Training iteration:  39%|███▊      | 386/1001 [12:52<13:17,  1.30s/it, avg loss=95.1820]Checkpoint at iteration 386 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 95.18198661804199

Training iteration:  39%|███▊      | 386/1001 [12:53<13:17,  1.30s/it, avg loss=247.0907]
Training iteration:  39%|███▊      | 387/1001 [12:53<13:16,  1.30s/it, avg loss=247.0907]Checkpoint at iteration 387 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 247.09071197509766

Training iteration:  39%|███▊      | 387/1001 [12:54<13:16,  1.30s/it, avg loss=146.2851]
Training iteration:  39%|███▉      | 388/1001 [12:54<13:15,  1.30s/it, avg loss=146.2851]Checkpoint at iteration 388 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 146.2850597381592

Training iteration:  39%|███▉      | 388/1001 [12:56<13:15,  1.30s/it, avg loss=180.1515]
Training iteration:  39%|███▉      | 389/1001 [12:56<13:14,  1.30s/it, avg loss=180.1515]Checkpoint at iteration 389 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 180.15150451660156

Training iteration:  39%|███▉      | 389/1001 [12:57<13:14,  1.30s/it, avg loss=100.5554]
Training iteration:  39%|███▉      | 390/1001 [12:57<13:12,  1.30s/it, avg loss=100.5554]Checkpoint at iteration 390 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 100.55537490844726

Training iteration:  39%|███▉      | 390/1001 [12:58<13:12,  1.30s/it, avg loss=75.8951] New best at iteratoin 390!

Training iteration:  39%|███▉      | 391/1001 [12:58<13:11,  1.30s/it, avg loss=75.8951]Checkpoint at iteration 391 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 75.89510192871094

Training iteration:  39%|███▉      | 391/1001 [12:59<13:11,  1.30s/it, avg loss=252.0898]
Training iteration:  39%|███▉      | 392/1001 [12:59<13:10,  1.30s/it, avg loss=252.0898]Checkpoint at iteration 392 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 252.08982849121094

Training iteration:  39%|███▉      | 392/1001 [13:01<13:10,  1.30s/it, avg loss=162.7186]
Training iteration:  39%|███▉      | 393/1001 [13:01<13:09,  1.30s/it, avg loss=162.7186]Checkpoint at iteration 393 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 162.71856727600098

Training iteration:  39%|███▉      | 393/1001 [13:02<13:09,  1.30s/it, avg loss=176.4990]
Training iteration:  39%|███▉      | 394/1001 [13:02<13:08,  1.30s/it, avg loss=176.4990]Checkpoint at iteration 394 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 176.4990062713623

Training iteration:  39%|███▉      | 394/1001 [13:03<13:08,  1.30s/it, avg loss=223.1097]
Training iteration:  39%|███▉      | 395/1001 [13:03<13:07,  1.30s/it, avg loss=223.1097]Checkpoint at iteration 395 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 223.10971183776854

Training iteration:  39%|███▉      | 395/1001 [13:05<13:07,  1.30s/it, avg loss=145.6710]
Training iteration:  40%|███▉      | 396/1001 [13:05<13:05,  1.30s/it, avg loss=145.6710]Checkpoint at iteration 396 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 145.67104454040526

Training iteration:  40%|███▉      | 396/1001 [13:06<13:05,  1.30s/it, avg loss=129.8439]
Training iteration:  40%|███▉      | 397/1001 [13:06<13:04,  1.30s/it, avg loss=129.8439]Checkpoint at iteration 397 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 129.84388999938966

Training iteration:  40%|███▉      | 397/1001 [13:07<13:04,  1.30s/it, avg loss=171.2613]
Training iteration:  40%|███▉      | 398/1001 [13:07<13:02,  1.30s/it, avg loss=171.2613]Checkpoint at iteration 398 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 171.26134567260743

Training iteration:  40%|███▉      | 398/1001 [13:09<13:02,  1.30s/it, avg loss=165.4392]
Training iteration:  40%|███▉      | 399/1001 [13:09<13:01,  1.30s/it, avg loss=165.4392]Checkpoint at iteration 399 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 165.4392490386963

Training iteration:  40%|███▉      | 399/1001 [13:10<13:01,  1.30s/it, avg loss=204.5215]
Training iteration:  40%|███▉      | 400/1001 [13:10<12:59,  1.30s/it, avg loss=204.5215]Optimization iteration 400 evaluation begins...
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
A new evaluation visualization has been saved: ./saved_data/20240110-081107/it400.png
Training network 0 for evaluation...
Training network 1 for evaluation...
Training network 2 for evaluation...
Training network 3 for evaluation...
Testing network 0 on real datasets for evaluation...
Testing network 1 on real datasets for evaluation...
Testing network 2 on real datasets for evaluation...
Testing network 3 on real datasets for evaluation...
Optimization iteration 400, eval auroc score (train): 19675.2499, eval auroc score (test): 20706.4737
Checkpoint at iteration 400 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 204.5214942932129

Training iteration:  40%|███▉      | 400/1001 [17:25<12:59,  1.30s/it, avg loss=187.3138]
Training iteration:  40%|████      | 401/1001 [17:25<12:55:17, 77.53s/it, avg loss=187.3138]Checkpoint at iteration 401 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 187.31375617980956

Training iteration:  40%|████      | 401/1001 [17:27<12:55:17, 77.53s/it, avg loss=123.8960]
Training iteration:  40%|████      | 402/1001 [17:27<9:06:20, 54.73s/it, avg loss=123.8960] Checkpoint at iteration 402 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 123.8960075378418

Training iteration:  40%|████      | 402/1001 [17:28<9:06:20, 54.73s/it, avg loss=165.3255]
Training iteration:  40%|████      | 403/1001 [17:28<6:26:19, 38.76s/it, avg loss=165.3255]Checkpoint at iteration 403 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 165.32547760009766

Training iteration:  40%|████      | 403/1001 [17:30<6:26:19, 38.76s/it, avg loss=152.8628]
Training iteration:  40%|████      | 404/1001 [17:30<4:34:30, 27.59s/it, avg loss=152.8628]Checkpoint at iteration 404 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 152.8627685546875

Training iteration:  40%|████      | 404/1001 [17:31<4:34:30, 27.59s/it, avg loss=101.8756]
Training iteration:  40%|████      | 405/1001 [17:31<3:16:21, 19.77s/it, avg loss=101.8756]Checkpoint at iteration 405 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 101.87561569213867

Training iteration:  40%|████      | 405/1001 [17:33<3:16:21, 19.77s/it, avg loss=156.5333]
Training iteration:  41%|████      | 406/1001 [17:33<2:21:43, 14.29s/it, avg loss=156.5333]Checkpoint at iteration 406 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 156.53327674865722

Training iteration:  41%|████      | 406/1001 [17:34<2:21:43, 14.29s/it, avg loss=144.0383]
Training iteration:  41%|████      | 407/1001 [17:34<1:43:32, 10.46s/it, avg loss=144.0383]Checkpoint at iteration 407 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 144.03825263977052

Training iteration:  41%|████      | 407/1001 [17:36<1:43:32, 10.46s/it, avg loss=185.3171]
Training iteration:  41%|████      | 408/1001 [17:36<1:16:51,  7.78s/it, avg loss=185.3171]Checkpoint at iteration 408 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 185.31714668273926

Training iteration:  41%|████      | 408/1001 [17:37<1:16:51,  7.78s/it, avg loss=207.0910]
Training iteration:  41%|████      | 409/1001 [17:37<58:12,  5.90s/it, avg loss=207.0910]  Checkpoint at iteration 409 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 207.09102554321288

Training iteration:  41%|████      | 409/1001 [17:39<58:12,  5.90s/it, avg loss=143.3247]
Training iteration:  41%|████      | 410/1001 [17:39<45:09,  4.58s/it, avg loss=143.3247]Checkpoint at iteration 410 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 143.3246742248535

Training iteration:  41%|████      | 410/1001 [17:40<45:09,  4.58s/it, avg loss=210.4473]
Training iteration:  41%|████      | 411/1001 [17:40<36:01,  3.66s/it, avg loss=210.4473]Checkpoint at iteration 411 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 210.44733161926268

Training iteration:  41%|████      | 411/1001 [17:42<36:01,  3.66s/it, avg loss=160.0975]
Training iteration:  41%|████      | 412/1001 [17:42<29:38,  3.02s/it, avg loss=160.0975]Checkpoint at iteration 412 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 160.09746170043945

Training iteration:  41%|████      | 412/1001 [17:43<29:38,  3.02s/it, avg loss=173.9165]
Training iteration:  41%|████▏     | 413/1001 [17:43<25:11,  2.57s/it, avg loss=173.9165]Checkpoint at iteration 413 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 173.91651992797853

Training iteration:  41%|████▏     | 413/1001 [17:45<25:11,  2.57s/it, avg loss=202.0865]
Training iteration:  41%|████▏     | 414/1001 [17:45<22:02,  2.25s/it, avg loss=202.0865]Checkpoint at iteration 414 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 202.086474609375

Training iteration:  41%|████▏     | 414/1001 [17:46<22:02,  2.25s/it, avg loss=191.5934]
Training iteration:  41%|████▏     | 415/1001 [17:46<19:50,  2.03s/it, avg loss=191.5934]Checkpoint at iteration 415 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 191.5934093475342

Training iteration:  41%|████▏     | 415/1001 [17:48<19:50,  2.03s/it, avg loss=120.3181]
Training iteration:  42%|████▏     | 416/1001 [17:48<18:18,  1.88s/it, avg loss=120.3181]Checkpoint at iteration 416 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 120.3180534362793

Training iteration:  42%|████▏     | 416/1001 [17:49<18:18,  1.88s/it, avg loss=164.2470]
Training iteration:  42%|████▏     | 417/1001 [17:49<17:13,  1.77s/it, avg loss=164.2470]Checkpoint at iteration 417 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 164.24697151184083

Training iteration:  42%|████▏     | 417/1001 [17:51<17:13,  1.77s/it, avg loss=206.8854]
Training iteration:  42%|████▏     | 418/1001 [17:51<16:27,  1.69s/it, avg loss=206.8854]Checkpoint at iteration 418 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 206.88543472290038

Training iteration:  42%|████▏     | 418/1001 [17:53<16:27,  1.69s/it, avg loss=176.6104]
Training iteration:  42%|████▏     | 419/1001 [17:53<15:54,  1.64s/it, avg loss=176.6104]Checkpoint at iteration 419 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 176.61042404174805

Training iteration:  42%|████▏     | 419/1001 [17:54<15:54,  1.64s/it, avg loss=119.1816]
Training iteration:  42%|████▏     | 420/1001 [17:54<15:30,  1.60s/it, avg loss=119.1816]Checkpoint at iteration 420 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 119.18156204223632

Training iteration:  42%|████▏     | 420/1001 [17:56<15:30,  1.60s/it, avg loss=178.2543]
Training iteration:  42%|████▏     | 421/1001 [17:56<15:14,  1.58s/it, avg loss=178.2543]Checkpoint at iteration 421 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 178.25432243347169

Training iteration:  42%|████▏     | 421/1001 [17:57<15:14,  1.58s/it, avg loss=149.3917]
Training iteration:  42%|████▏     | 422/1001 [17:57<15:01,  1.56s/it, avg loss=149.3917]Checkpoint at iteration 422 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 149.39165267944335

Training iteration:  42%|████▏     | 422/1001 [17:59<15:01,  1.56s/it, avg loss=178.2293]
Training iteration:  42%|████▏     | 423/1001 [17:59<14:53,  1.55s/it, avg loss=178.2293]Checkpoint at iteration 423 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 178.22932891845704

Training iteration:  42%|████▏     | 423/1001 [18:00<14:53,  1.55s/it, avg loss=146.2231]
Training iteration:  42%|████▏     | 424/1001 [18:00<14:46,  1.54s/it, avg loss=146.2231]Checkpoint at iteration 424 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 146.22307777404785

Training iteration:  42%|████▏     | 424/1001 [18:02<14:46,  1.54s/it, avg loss=203.6283]
Training iteration:  42%|████▏     | 425/1001 [18:02<14:42,  1.53s/it, avg loss=203.6283]Checkpoint at iteration 425 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 203.62830543518066

Training iteration:  42%|████▏     | 425/1001 [18:03<14:42,  1.53s/it, avg loss=109.6434]
Training iteration:  43%|████▎     | 426/1001 [18:03<14:37,  1.53s/it, avg loss=109.6434]Checkpoint at iteration 426 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 109.64336013793945

Training iteration:  43%|████▎     | 426/1001 [18:05<14:37,  1.53s/it, avg loss=132.8565]
Training iteration:  43%|████▎     | 427/1001 [18:05<14:34,  1.52s/it, avg loss=132.8565]Checkpoint at iteration 427 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 132.8565475463867

Training iteration:  43%|████▎     | 427/1001 [18:06<14:34,  1.52s/it, avg loss=95.4301] 
Training iteration:  43%|████▎     | 428/1001 [18:06<14:30,  1.52s/it, avg loss=95.4301]Checkpoint at iteration 428 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 95.43007888793946

Training iteration:  43%|████▎     | 428/1001 [18:08<14:30,  1.52s/it, avg loss=166.5641]
Training iteration:  43%|████▎     | 429/1001 [18:08<14:28,  1.52s/it, avg loss=166.5641]Checkpoint at iteration 429 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 166.5640625

Training iteration:  43%|████▎     | 429/1001 [18:09<14:28,  1.52s/it, avg loss=206.3276]
Training iteration:  43%|████▎     | 430/1001 [18:09<14:26,  1.52s/it, avg loss=206.3276]Checkpoint at iteration 430 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 206.32763748168946

Training iteration:  43%|████▎     | 430/1001 [18:11<14:26,  1.52s/it, avg loss=139.9682]
Training iteration:  43%|████▎     | 431/1001 [18:11<14:24,  1.52s/it, avg loss=139.9682]Checkpoint at iteration 431 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 139.96822128295898

Training iteration:  43%|████▎     | 431/1001 [18:12<14:24,  1.52s/it, avg loss=161.0160]
Training iteration:  43%|████▎     | 432/1001 [18:12<14:22,  1.52s/it, avg loss=161.0160]Checkpoint at iteration 432 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 161.01598510742187

Training iteration:  43%|████▎     | 432/1001 [18:14<14:22,  1.52s/it, avg loss=113.4471]
Training iteration:  43%|████▎     | 433/1001 [18:14<14:20,  1.52s/it, avg loss=113.4471]Checkpoint at iteration 433 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 113.4471492767334

Training iteration:  43%|████▎     | 433/1001 [18:15<14:20,  1.52s/it, avg loss=170.7965]
Training iteration:  43%|████▎     | 434/1001 [18:15<14:19,  1.52s/it, avg loss=170.7965]Checkpoint at iteration 434 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 170.79646110534668

Training iteration:  43%|████▎     | 434/1001 [18:17<14:19,  1.52s/it, avg loss=113.9556]
Training iteration:  43%|████▎     | 435/1001 [18:17<14:17,  1.52s/it, avg loss=113.9556]Checkpoint at iteration 435 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 113.95564727783203

Training iteration:  43%|████▎     | 435/1001 [18:18<14:17,  1.52s/it, avg loss=170.5868]
Training iteration:  44%|████▎     | 436/1001 [18:18<14:16,  1.52s/it, avg loss=170.5868]Checkpoint at iteration 436 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 170.58678512573243

Training iteration:  44%|████▎     | 436/1001 [18:20<14:16,  1.52s/it, avg loss=198.3281]
Training iteration:  44%|████▎     | 437/1001 [18:20<14:14,  1.52s/it, avg loss=198.3281]Checkpoint at iteration 437 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 198.32806167602538

Training iteration:  44%|████▎     | 437/1001 [18:21<14:14,  1.52s/it, avg loss=143.4405]
Training iteration:  44%|████▍     | 438/1001 [18:21<14:12,  1.51s/it, avg loss=143.4405]Checkpoint at iteration 438 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 143.44049263000488

Training iteration:  44%|████▍     | 438/1001 [18:23<14:12,  1.51s/it, avg loss=191.8572]
Training iteration:  44%|████▍     | 439/1001 [18:23<14:11,  1.51s/it, avg loss=191.8572]Checkpoint at iteration 439 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 191.85716400146484

Training iteration:  44%|████▍     | 439/1001 [18:24<14:11,  1.51s/it, avg loss=156.2140]
Training iteration:  44%|████▍     | 440/1001 [18:24<14:09,  1.51s/it, avg loss=156.2140]Checkpoint at iteration 440 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 156.2140335083008

Training iteration:  44%|████▍     | 440/1001 [18:26<14:09,  1.51s/it, avg loss=209.7133]
Training iteration:  44%|████▍     | 441/1001 [18:26<14:08,  1.51s/it, avg loss=209.7133]Checkpoint at iteration 441 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 209.71325073242187

Training iteration:  44%|████▍     | 441/1001 [18:27<14:08,  1.51s/it, avg loss=188.0597]
Training iteration:  44%|████▍     | 442/1001 [18:27<14:06,  1.51s/it, avg loss=188.0597]Checkpoint at iteration 442 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 188.05969581604003

Training iteration:  44%|████▍     | 442/1001 [18:29<14:06,  1.51s/it, avg loss=148.6608]
Training iteration:  44%|████▍     | 443/1001 [18:29<14:04,  1.51s/it, avg loss=148.6608]Checkpoint at iteration 443 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 148.66079483032226

Training iteration:  44%|████▍     | 443/1001 [18:30<14:04,  1.51s/it, avg loss=188.5000]
Training iteration:  44%|████▍     | 444/1001 [18:30<14:02,  1.51s/it, avg loss=188.5000]Checkpoint at iteration 444 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 188.50002479553223

Training iteration:  44%|████▍     | 444/1001 [18:32<14:02,  1.51s/it, avg loss=170.3087]
Training iteration:  44%|████▍     | 445/1001 [18:32<14:01,  1.51s/it, avg loss=170.3087]Checkpoint at iteration 445 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 170.30866088867188

Training iteration:  44%|████▍     | 445/1001 [18:33<14:01,  1.51s/it, avg loss=151.3633]
Training iteration:  45%|████▍     | 446/1001 [18:33<13:59,  1.51s/it, avg loss=151.3633]Checkpoint at iteration 446 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 151.36329956054686

Training iteration:  45%|████▍     | 446/1001 [18:35<13:59,  1.51s/it, avg loss=163.3456]
Training iteration:  45%|████▍     | 447/1001 [18:35<13:58,  1.51s/it, avg loss=163.3456]Checkpoint at iteration 447 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 163.34559631347656

Training iteration:  45%|████▍     | 447/1001 [18:36<13:58,  1.51s/it, avg loss=215.0453]
Training iteration:  45%|████▍     | 448/1001 [18:36<13:57,  1.51s/it, avg loss=215.0453]Checkpoint at iteration 448 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 215.0453369140625

Training iteration:  45%|████▍     | 448/1001 [18:38<13:57,  1.51s/it, avg loss=123.9664]
Training iteration:  45%|████▍     | 449/1001 [18:38<13:55,  1.51s/it, avg loss=123.9664]Checkpoint at iteration 449 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 123.96639251708984

Training iteration:  45%|████▍     | 449/1001 [18:39<13:55,  1.51s/it, avg loss=145.7696]
Training iteration:  45%|████▍     | 450/1001 [18:39<13:54,  1.51s/it, avg loss=145.7696]Checkpoint at iteration 450 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 145.7695755004883

Training iteration:  45%|████▍     | 450/1001 [18:41<13:54,  1.51s/it, avg loss=199.4391]
Training iteration:  45%|████▌     | 451/1001 [18:41<13:52,  1.51s/it, avg loss=199.4391]Checkpoint at iteration 451 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 199.43914947509765

Training iteration:  45%|████▌     | 451/1001 [18:42<13:52,  1.51s/it, avg loss=139.9612]
Training iteration:  45%|████▌     | 452/1001 [18:42<13:50,  1.51s/it, avg loss=139.9612]Checkpoint at iteration 452 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 139.96118545532227

Training iteration:  45%|████▌     | 452/1001 [18:44<13:50,  1.51s/it, avg loss=138.4416]
Training iteration:  45%|████▌     | 453/1001 [18:44<13:49,  1.51s/it, avg loss=138.4416]Checkpoint at iteration 453 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 138.44162216186524

Training iteration:  45%|████▌     | 453/1001 [18:46<13:49,  1.51s/it, avg loss=150.4449]
Training iteration:  45%|████▌     | 454/1001 [18:46<13:47,  1.51s/it, avg loss=150.4449]Checkpoint at iteration 454 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 150.44486770629882

Training iteration:  45%|████▌     | 454/1001 [18:47<13:47,  1.51s/it, avg loss=169.0675]
Training iteration:  45%|████▌     | 455/1001 [18:47<13:46,  1.51s/it, avg loss=169.0675]Checkpoint at iteration 455 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 169.0675106048584

Training iteration:  45%|████▌     | 455/1001 [18:49<13:46,  1.51s/it, avg loss=227.8145]
Training iteration:  46%|████▌     | 456/1001 [18:49<13:45,  1.51s/it, avg loss=227.8145]Checkpoint at iteration 456 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 227.8144546508789

Training iteration:  46%|████▌     | 456/1001 [18:50<13:45,  1.51s/it, avg loss=98.6413] 
Training iteration:  46%|████▌     | 457/1001 [18:50<13:44,  1.52s/it, avg loss=98.6413]Checkpoint at iteration 457 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 98.64129409790038

Training iteration:  46%|████▌     | 457/1001 [18:52<13:44,  1.52s/it, avg loss=136.1398]
Training iteration:  46%|████▌     | 458/1001 [18:52<13:43,  1.52s/it, avg loss=136.1398]Checkpoint at iteration 458 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 136.13984146118165

Training iteration:  46%|████▌     | 458/1001 [18:53<13:43,  1.52s/it, avg loss=217.9753]
Training iteration:  46%|████▌     | 459/1001 [18:53<13:41,  1.52s/it, avg loss=217.9753]Checkpoint at iteration 459 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 217.97531280517578

Training iteration:  46%|████▌     | 459/1001 [18:55<13:41,  1.52s/it, avg loss=100.6992]
Training iteration:  46%|████▌     | 460/1001 [18:55<13:40,  1.52s/it, avg loss=100.6992]Checkpoint at iteration 460 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 100.69915809631348

Training iteration:  46%|████▌     | 460/1001 [18:56<13:40,  1.52s/it, avg loss=197.2264]
Training iteration:  46%|████▌     | 461/1001 [18:56<13:40,  1.52s/it, avg loss=197.2264]Checkpoint at iteration 461 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 197.22640419006348

Training iteration:  46%|████▌     | 461/1001 [18:58<13:40,  1.52s/it, avg loss=159.6050]
Training iteration:  46%|████▌     | 462/1001 [18:58<13:38,  1.52s/it, avg loss=159.6050]Checkpoint at iteration 462 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 159.60495376586914

Training iteration:  46%|████▌     | 462/1001 [18:59<13:38,  1.52s/it, avg loss=163.8764]
Training iteration:  46%|████▋     | 463/1001 [18:59<13:36,  1.52s/it, avg loss=163.8764]Checkpoint at iteration 463 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 163.87636032104493

Training iteration:  46%|████▋     | 463/1001 [19:01<13:36,  1.52s/it, avg loss=156.4575]
Training iteration:  46%|████▋     | 464/1001 [19:01<13:35,  1.52s/it, avg loss=156.4575]Checkpoint at iteration 464 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 156.45753173828126

Training iteration:  46%|████▋     | 464/1001 [19:02<13:35,  1.52s/it, avg loss=152.2453]
Training iteration:  46%|████▋     | 465/1001 [19:02<13:33,  1.52s/it, avg loss=152.2453]Checkpoint at iteration 465 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 152.24527282714843

Training iteration:  46%|████▋     | 465/1001 [19:04<13:33,  1.52s/it, avg loss=187.7503]
Training iteration:  47%|████▋     | 466/1001 [19:04<13:31,  1.52s/it, avg loss=187.7503]Checkpoint at iteration 466 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 187.7503234863281

Training iteration:  47%|████▋     | 466/1001 [19:05<13:31,  1.52s/it, avg loss=226.0662]
Training iteration:  47%|████▋     | 467/1001 [19:05<13:30,  1.52s/it, avg loss=226.0662]Checkpoint at iteration 467 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 226.06624298095704

Training iteration:  47%|████▋     | 467/1001 [19:07<13:30,  1.52s/it, avg loss=124.3356]
Training iteration:  47%|████▋     | 468/1001 [19:07<13:27,  1.52s/it, avg loss=124.3356]Checkpoint at iteration 468 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 124.33563461303712

Training iteration:  47%|████▋     | 468/1001 [19:08<13:27,  1.52s/it, avg loss=95.5182] 
Training iteration:  47%|████▋     | 469/1001 [19:08<13:26,  1.52s/it, avg loss=95.5182]Checkpoint at iteration 469 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 95.51820602416993

Training iteration:  47%|████▋     | 469/1001 [19:10<13:26,  1.52s/it, avg loss=120.5704]
Training iteration:  47%|████▋     | 470/1001 [19:10<13:24,  1.52s/it, avg loss=120.5704]Checkpoint at iteration 470 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 120.57044906616211

Training iteration:  47%|████▋     | 470/1001 [19:11<13:24,  1.52s/it, avg loss=191.8693]
Training iteration:  47%|████▋     | 471/1001 [19:11<13:23,  1.52s/it, avg loss=191.8693]Checkpoint at iteration 471 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 191.86930236816406

Training iteration:  47%|████▋     | 471/1001 [19:13<13:23,  1.52s/it, avg loss=170.4396]
Training iteration:  47%|████▋     | 472/1001 [19:13<13:22,  1.52s/it, avg loss=170.4396]Checkpoint at iteration 472 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 170.43963737487792

Training iteration:  47%|████▋     | 472/1001 [19:14<13:22,  1.52s/it, avg loss=148.6290]
Training iteration:  47%|████▋     | 473/1001 [19:14<13:20,  1.52s/it, avg loss=148.6290]Checkpoint at iteration 473 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 148.6290252685547

Training iteration:  47%|████▋     | 473/1001 [19:16<13:20,  1.52s/it, avg loss=171.8983]
Training iteration:  47%|████▋     | 474/1001 [19:16<13:18,  1.52s/it, avg loss=171.8983]Checkpoint at iteration 474 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 171.89829063415527

Training iteration:  47%|████▋     | 474/1001 [19:17<13:18,  1.52s/it, avg loss=175.9903]
Training iteration:  47%|████▋     | 475/1001 [19:17<13:17,  1.52s/it, avg loss=175.9903]Checkpoint at iteration 475 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 175.9902572631836

Training iteration:  47%|████▋     | 475/1001 [19:19<13:17,  1.52s/it, avg loss=113.6132]
Training iteration:  48%|████▊     | 476/1001 [19:19<13:15,  1.52s/it, avg loss=113.6132]Checkpoint at iteration 476 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 113.61321792602538

Training iteration:  48%|████▊     | 476/1001 [19:20<13:15,  1.52s/it, avg loss=125.4135]
Training iteration:  48%|████▊     | 477/1001 [19:20<13:14,  1.52s/it, avg loss=125.4135]Checkpoint at iteration 477 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 125.41348495483399

Training iteration:  48%|████▊     | 477/1001 [19:22<13:14,  1.52s/it, avg loss=124.7452]
Training iteration:  48%|████▊     | 478/1001 [19:22<13:13,  1.52s/it, avg loss=124.7452]Checkpoint at iteration 478 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 124.74522285461425

Training iteration:  48%|████▊     | 478/1001 [19:23<13:13,  1.52s/it, avg loss=225.5428]
Training iteration:  48%|████▊     | 479/1001 [19:23<13:11,  1.52s/it, avg loss=225.5428]Checkpoint at iteration 479 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 225.54279174804688

Training iteration:  48%|████▊     | 479/1001 [19:25<13:11,  1.52s/it, avg loss=134.3231]
Training iteration:  48%|████▊     | 480/1001 [19:25<13:09,  1.52s/it, avg loss=134.3231]Checkpoint at iteration 480 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 134.3231201171875

Training iteration:  48%|████▊     | 480/1001 [19:26<13:09,  1.52s/it, avg loss=121.8466]
Training iteration:  48%|████▊     | 481/1001 [19:26<13:08,  1.52s/it, avg loss=121.8466]Checkpoint at iteration 481 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 121.84663543701171

Training iteration:  48%|████▊     | 481/1001 [19:28<13:08,  1.52s/it, avg loss=181.6222]
Training iteration:  48%|████▊     | 482/1001 [19:28<13:06,  1.52s/it, avg loss=181.6222]Checkpoint at iteration 482 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 181.62221488952636

Training iteration:  48%|████▊     | 482/1001 [19:30<13:06,  1.52s/it, avg loss=191.7880]
Training iteration:  48%|████▊     | 483/1001 [19:30<13:05,  1.52s/it, avg loss=191.7880]Checkpoint at iteration 483 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 191.7879951477051

Training iteration:  48%|████▊     | 483/1001 [19:31<13:05,  1.52s/it, avg loss=163.0107]
Training iteration:  48%|████▊     | 484/1001 [19:31<13:03,  1.52s/it, avg loss=163.0107]Checkpoint at iteration 484 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 163.01068382263185

Training iteration:  48%|████▊     | 484/1001 [19:33<13:03,  1.52s/it, avg loss=197.1925]
Training iteration:  48%|████▊     | 485/1001 [19:33<13:02,  1.52s/it, avg loss=197.1925]Checkpoint at iteration 485 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 197.19253158569336

Training iteration:  48%|████▊     | 485/1001 [19:34<13:02,  1.52s/it, avg loss=234.8590]
Training iteration:  49%|████▊     | 486/1001 [19:34<13:00,  1.52s/it, avg loss=234.8590]Checkpoint at iteration 486 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 234.8589744567871

Training iteration:  49%|████▊     | 486/1001 [19:36<13:00,  1.52s/it, avg loss=122.8013]
Training iteration:  49%|████▊     | 487/1001 [19:36<12:59,  1.52s/it, avg loss=122.8013]Checkpoint at iteration 487 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 122.80134391784668

Training iteration:  49%|████▊     | 487/1001 [19:37<12:59,  1.52s/it, avg loss=141.9602]
Training iteration:  49%|████▉     | 488/1001 [19:37<12:57,  1.52s/it, avg loss=141.9602]Checkpoint at iteration 488 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 141.96015892028808

Training iteration:  49%|████▉     | 488/1001 [19:39<12:57,  1.52s/it, avg loss=162.4322]
Training iteration:  49%|████▉     | 489/1001 [19:39<12:55,  1.52s/it, avg loss=162.4322]Checkpoint at iteration 489 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 162.43223266601564

Training iteration:  49%|████▉     | 489/1001 [19:40<12:55,  1.52s/it, avg loss=180.2184]
Training iteration:  49%|████▉     | 490/1001 [19:40<12:54,  1.52s/it, avg loss=180.2184]Checkpoint at iteration 490 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 180.21844406127929

Training iteration:  49%|████▉     | 490/1001 [19:42<12:54,  1.52s/it, avg loss=190.3971]
Training iteration:  49%|████▉     | 491/1001 [19:42<12:53,  1.52s/it, avg loss=190.3971]Checkpoint at iteration 491 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 190.39714546203612

Training iteration:  49%|████▉     | 491/1001 [19:43<12:53,  1.52s/it, avg loss=138.8637]
Training iteration:  49%|████▉     | 492/1001 [19:43<12:51,  1.52s/it, avg loss=138.8637]Checkpoint at iteration 492 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 138.86367530822753

Training iteration:  49%|████▉     | 492/1001 [19:45<12:51,  1.52s/it, avg loss=225.2493]
Training iteration:  49%|████▉     | 493/1001 [19:45<12:50,  1.52s/it, avg loss=225.2493]Checkpoint at iteration 493 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 225.24931945800782

Training iteration:  49%|████▉     | 493/1001 [19:46<12:50,  1.52s/it, avg loss=116.3002]
Training iteration:  49%|████▉     | 494/1001 [19:46<12:47,  1.51s/it, avg loss=116.3002]Checkpoint at iteration 494 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 116.30015106201172

Training iteration:  49%|████▉     | 494/1001 [19:48<12:47,  1.51s/it, avg loss=132.0944]
Training iteration:  49%|████▉     | 495/1001 [19:48<12:44,  1.51s/it, avg loss=132.0944]Checkpoint at iteration 495 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 132.09437255859376

Training iteration:  49%|████▉     | 495/1001 [19:49<12:44,  1.51s/it, avg loss=145.3949]
Training iteration:  50%|████▉     | 496/1001 [19:49<12:41,  1.51s/it, avg loss=145.3949]Checkpoint at iteration 496 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 145.39493141174316

Training iteration:  50%|████▉     | 496/1001 [19:51<12:41,  1.51s/it, avg loss=108.3400]
Training iteration:  50%|████▉     | 497/1001 [19:51<12:39,  1.51s/it, avg loss=108.3400]Checkpoint at iteration 497 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 108.3400218963623

Training iteration:  50%|████▉     | 497/1001 [19:52<12:39,  1.51s/it, avg loss=218.8946]
Training iteration:  50%|████▉     | 498/1001 [19:52<12:37,  1.51s/it, avg loss=218.8946]Checkpoint at iteration 498 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 218.89456787109376

Training iteration:  50%|████▉     | 498/1001 [19:54<12:37,  1.51s/it, avg loss=132.8999]
Training iteration:  50%|████▉     | 499/1001 [19:54<12:35,  1.50s/it, avg loss=132.8999]Checkpoint at iteration 499 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 132.89987487792968

Training iteration:  50%|████▉     | 499/1001 [19:55<12:35,  1.50s/it, avg loss=96.9102] 
Training iteration:  50%|████▉     | 500/1001 [19:55<12:33,  1.50s/it, avg loss=96.9102]Optimization iteration 500 evaluation begins...
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
A new evaluation visualization has been saved: ./saved_data/20240110-081107/it500.png
Training network 0 for evaluation...
Training network 1 for evaluation...
Training network 2 for evaluation...
Training network 3 for evaluation...
Testing network 0 on real datasets for evaluation...
Testing network 1 on real datasets for evaluation...
Testing network 2 on real datasets for evaluation...
Testing network 3 on real datasets for evaluation...
Optimization iteration 500, eval auroc score (train): 19752.2242, eval auroc score (test): 20725.6066
Checkpoint at iteration 500 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 96.91022453308105

Training iteration:  50%|████▉     | 500/1001 [25:25<12:33,  1.50s/it, avg loss=141.8545]
Training iteration:  50%|█████     | 501/1001 [25:25<13:53:30, 100.02s/it, avg loss=141.8545]Checkpoint at iteration 501 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 141.85450134277343

Training iteration:  50%|█████     | 501/1001 [25:27<13:53:30, 100.02s/it, avg loss=240.5466]
Training iteration:  50%|█████     | 502/1001 [25:27<9:46:32, 70.53s/it, avg loss=240.5466]  Checkpoint at iteration 502 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 240.5465866088867

Training iteration:  50%|█████     | 502/1001 [25:28<9:46:32, 70.53s/it, avg loss=132.8450]
Training iteration:  50%|█████     | 503/1001 [25:28<6:53:59, 49.88s/it, avg loss=132.8450]Checkpoint at iteration 503 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 132.8450469970703

Training iteration:  50%|█████     | 503/1001 [25:30<6:53:59, 49.88s/it, avg loss=140.2596]
Training iteration:  50%|█████     | 504/1001 [25:30<4:53:27, 35.43s/it, avg loss=140.2596]Checkpoint at iteration 504 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 140.2596035003662

Training iteration:  50%|█████     | 504/1001 [25:32<4:53:27, 35.43s/it, avg loss=104.1578]
Training iteration:  50%|█████     | 505/1001 [25:32<3:29:13, 25.31s/it, avg loss=104.1578]Checkpoint at iteration 505 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 104.15784912109375

Training iteration:  50%|█████     | 505/1001 [25:34<3:29:13, 25.31s/it, avg loss=190.7326]
Training iteration:  51%|█████     | 506/1001 [25:34<2:30:23, 18.23s/it, avg loss=190.7326]Checkpoint at iteration 506 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 190.7325637817383

Training iteration:  51%|█████     | 506/1001 [25:35<2:30:23, 18.23s/it, avg loss=221.9439]
Training iteration:  51%|█████     | 507/1001 [25:35<1:49:15, 13.27s/it, avg loss=221.9439]Checkpoint at iteration 507 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 221.94390869140625

Training iteration:  51%|█████     | 507/1001 [25:37<1:49:15, 13.27s/it, avg loss=176.2635]
Training iteration:  51%|█████     | 508/1001 [25:37<1:20:31,  9.80s/it, avg loss=176.2635]Checkpoint at iteration 508 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 176.26351356506348

Training iteration:  51%|█████     | 508/1001 [25:39<1:20:31,  9.80s/it, avg loss=170.4034]
Training iteration:  51%|█████     | 509/1001 [25:39<1:00:26,  7.37s/it, avg loss=170.4034]Checkpoint at iteration 509 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 170.4034210205078

Training iteration:  51%|█████     | 509/1001 [25:40<1:00:26,  7.37s/it, avg loss=187.3797]
Training iteration:  51%|█████     | 510/1001 [25:40<46:24,  5.67s/it, avg loss=187.3797]  Checkpoint at iteration 510 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 187.37969398498535

Training iteration:  51%|█████     | 510/1001 [25:42<46:24,  5.67s/it, avg loss=182.0117]
Training iteration:  51%|█████     | 511/1001 [25:42<36:35,  4.48s/it, avg loss=182.0117]Checkpoint at iteration 511 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 182.01166534423828

Training iteration:  51%|█████     | 511/1001 [25:44<36:35,  4.48s/it, avg loss=248.4146]
Training iteration:  51%|█████     | 512/1001 [25:44<29:43,  3.65s/it, avg loss=248.4146]Checkpoint at iteration 512 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 248.41462478637695

Training iteration:  51%|█████     | 512/1001 [25:46<29:43,  3.65s/it, avg loss=111.5292]
Training iteration:  51%|█████     | 513/1001 [25:46<24:55,  3.06s/it, avg loss=111.5292]Checkpoint at iteration 513 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 111.5291618347168

Training iteration:  51%|█████     | 513/1001 [25:47<24:55,  3.06s/it, avg loss=122.7857]
Training iteration:  51%|█████▏    | 514/1001 [25:47<21:33,  2.66s/it, avg loss=122.7857]Checkpoint at iteration 514 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 122.78569145202637

Training iteration:  51%|█████▏    | 514/1001 [25:49<21:33,  2.66s/it, avg loss=167.4574]
Training iteration:  51%|█████▏    | 515/1001 [25:49<19:12,  2.37s/it, avg loss=167.4574]Checkpoint at iteration 515 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 167.45744514465332

Training iteration:  51%|█████▏    | 515/1001 [25:51<19:12,  2.37s/it, avg loss=199.1908]
Training iteration:  52%|█████▏    | 516/1001 [25:51<17:32,  2.17s/it, avg loss=199.1908]Checkpoint at iteration 516 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 199.19080352783203

Training iteration:  52%|█████▏    | 516/1001 [25:52<17:32,  2.17s/it, avg loss=195.3443]
Training iteration:  52%|█████▏    | 517/1001 [25:52<16:22,  2.03s/it, avg loss=195.3443]Checkpoint at iteration 517 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 195.3443115234375

Training iteration:  52%|█████▏    | 517/1001 [25:54<16:22,  2.03s/it, avg loss=186.1286]
Training iteration:  52%|█████▏    | 518/1001 [25:54<15:33,  1.93s/it, avg loss=186.1286]Checkpoint at iteration 518 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 186.128564453125

Training iteration:  52%|█████▏    | 518/1001 [25:56<15:33,  1.93s/it, avg loss=178.9284]
Training iteration:  52%|█████▏    | 519/1001 [25:56<14:58,  1.86s/it, avg loss=178.9284]Checkpoint at iteration 519 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 178.92840270996095

Training iteration:  52%|█████▏    | 519/1001 [25:57<14:58,  1.86s/it, avg loss=181.1307]
Training iteration:  52%|█████▏    | 520/1001 [25:57<14:33,  1.82s/it, avg loss=181.1307]Checkpoint at iteration 520 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 181.13074111938477

Training iteration:  52%|█████▏    | 520/1001 [25:59<14:33,  1.82s/it, avg loss=189.5391]
Training iteration:  52%|█████▏    | 521/1001 [25:59<14:15,  1.78s/it, avg loss=189.5391]Checkpoint at iteration 521 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 189.53909721374512

Training iteration:  52%|█████▏    | 521/1001 [26:01<14:15,  1.78s/it, avg loss=107.6434]
Training iteration:  52%|█████▏    | 522/1001 [26:01<14:02,  1.76s/it, avg loss=107.6434]Checkpoint at iteration 522 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 107.64337196350098

Training iteration:  52%|█████▏    | 522/1001 [26:03<14:02,  1.76s/it, avg loss=162.6184]
Training iteration:  52%|█████▏    | 523/1001 [26:03<13:52,  1.74s/it, avg loss=162.6184]Checkpoint at iteration 523 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 162.61842575073243

Training iteration:  52%|█████▏    | 523/1001 [26:04<13:52,  1.74s/it, avg loss=193.6247]
Training iteration:  52%|█████▏    | 524/1001 [26:04<13:45,  1.73s/it, avg loss=193.6247]Checkpoint at iteration 524 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 193.6246768951416

Training iteration:  52%|█████▏    | 524/1001 [26:06<13:45,  1.73s/it, avg loss=93.0649] 
Training iteration:  52%|█████▏    | 525/1001 [26:06<13:40,  1.72s/it, avg loss=93.0649]Checkpoint at iteration 525 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 93.06490936279297

Training iteration:  52%|█████▏    | 525/1001 [26:08<13:40,  1.72s/it, avg loss=154.9331]
Training iteration:  53%|█████▎    | 526/1001 [26:08<13:35,  1.72s/it, avg loss=154.9331]Checkpoint at iteration 526 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 154.93308029174804

Training iteration:  53%|█████▎    | 526/1001 [26:09<13:35,  1.72s/it, avg loss=137.8386]
Training iteration:  53%|█████▎    | 527/1001 [26:09<13:32,  1.71s/it, avg loss=137.8386]Checkpoint at iteration 527 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 137.83855667114258

Training iteration:  53%|█████▎    | 527/1001 [26:11<13:32,  1.71s/it, avg loss=194.6493]
Training iteration:  53%|█████▎    | 528/1001 [26:11<13:29,  1.71s/it, avg loss=194.6493]Checkpoint at iteration 528 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 194.64925842285157

Training iteration:  53%|█████▎    | 528/1001 [26:13<13:29,  1.71s/it, avg loss=164.2772]
Training iteration:  53%|█████▎    | 529/1001 [26:13<13:26,  1.71s/it, avg loss=164.2772]Checkpoint at iteration 529 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 164.2771789550781

Training iteration:  53%|█████▎    | 529/1001 [26:14<13:26,  1.71s/it, avg loss=143.6106]
Training iteration:  53%|█████▎    | 530/1001 [26:14<13:23,  1.71s/it, avg loss=143.6106]Checkpoint at iteration 530 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 143.61064186096192

Training iteration:  53%|█████▎    | 530/1001 [26:16<13:23,  1.71s/it, avg loss=188.3781]
Training iteration:  53%|█████▎    | 531/1001 [26:16<13:21,  1.71s/it, avg loss=188.3781]Checkpoint at iteration 531 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 188.37809219360352

Training iteration:  53%|█████▎    | 531/1001 [26:18<13:21,  1.71s/it, avg loss=105.3832]
Training iteration:  53%|█████▎    | 532/1001 [26:18<13:19,  1.70s/it, avg loss=105.3832]Checkpoint at iteration 532 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 105.38320579528809

Training iteration:  53%|█████▎    | 532/1001 [26:20<13:19,  1.70s/it, avg loss=219.1882]
Training iteration:  53%|█████▎    | 533/1001 [26:20<13:17,  1.70s/it, avg loss=219.1882]Checkpoint at iteration 533 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 219.1882209777832

Training iteration:  53%|█████▎    | 533/1001 [26:21<13:17,  1.70s/it, avg loss=188.9382]
Training iteration:  53%|█████▎    | 534/1001 [26:21<13:15,  1.70s/it, avg loss=188.9382]Checkpoint at iteration 534 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 188.9382251739502

Training iteration:  53%|█████▎    | 534/1001 [26:23<13:15,  1.70s/it, avg loss=150.5985]
Training iteration:  53%|█████▎    | 535/1001 [26:23<13:14,  1.70s/it, avg loss=150.5985]Checkpoint at iteration 535 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 150.59845466613768

Training iteration:  53%|█████▎    | 535/1001 [26:25<13:14,  1.70s/it, avg loss=121.5225]
Training iteration:  54%|█████▎    | 536/1001 [26:25<13:12,  1.70s/it, avg loss=121.5225]Checkpoint at iteration 536 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 121.5224998474121

Training iteration:  54%|█████▎    | 536/1001 [26:26<13:12,  1.70s/it, avg loss=180.8431]
Training iteration:  54%|█████▎    | 537/1001 [26:26<13:10,  1.70s/it, avg loss=180.8431]Checkpoint at iteration 537 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 180.84313468933107

Training iteration:  54%|█████▎    | 537/1001 [26:28<13:10,  1.70s/it, avg loss=194.1153]
Training iteration:  54%|█████▎    | 538/1001 [26:28<13:11,  1.71s/it, avg loss=194.1153]Checkpoint at iteration 538 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 194.11528244018555

Training iteration:  54%|█████▎    | 538/1001 [26:30<13:11,  1.71s/it, avg loss=151.9575]
Training iteration:  54%|█████▍    | 539/1001 [26:30<13:09,  1.71s/it, avg loss=151.9575]Checkpoint at iteration 539 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 151.95751838684083

Training iteration:  54%|█████▍    | 539/1001 [26:32<13:09,  1.71s/it, avg loss=154.8162]
Training iteration:  54%|█████▍    | 540/1001 [26:32<13:06,  1.71s/it, avg loss=154.8162]Checkpoint at iteration 540 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 154.81622772216798

Training iteration:  54%|█████▍    | 540/1001 [26:33<13:06,  1.71s/it, avg loss=185.1219]
Training iteration:  54%|█████▍    | 541/1001 [26:33<13:04,  1.71s/it, avg loss=185.1219]Checkpoint at iteration 541 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 185.12191772460938

Training iteration:  54%|█████▍    | 541/1001 [26:35<13:04,  1.71s/it, avg loss=196.4776]
Training iteration:  54%|█████▍    | 542/1001 [26:35<13:03,  1.71s/it, avg loss=196.4776]Checkpoint at iteration 542 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 196.477592086792

Training iteration:  54%|█████▍    | 542/1001 [26:37<13:03,  1.71s/it, avg loss=136.6286]
Training iteration:  54%|█████▍    | 543/1001 [26:37<13:01,  1.71s/it, avg loss=136.6286]Checkpoint at iteration 543 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 136.62862396240234

Training iteration:  54%|█████▍    | 543/1001 [26:38<13:01,  1.71s/it, avg loss=188.0051]
Training iteration:  54%|█████▍    | 544/1001 [26:38<12:59,  1.71s/it, avg loss=188.0051]Checkpoint at iteration 544 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 188.00510864257814

Training iteration:  54%|█████▍    | 544/1001 [26:40<12:59,  1.71s/it, avg loss=119.0712]
Training iteration:  54%|█████▍    | 545/1001 [26:40<12:57,  1.70s/it, avg loss=119.0712]Checkpoint at iteration 545 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 119.07117233276367

Training iteration:  54%|█████▍    | 545/1001 [26:42<12:57,  1.70s/it, avg loss=171.4225]
Training iteration:  55%|█████▍    | 546/1001 [26:42<12:55,  1.70s/it, avg loss=171.4225]Checkpoint at iteration 546 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 171.4225170135498

Training iteration:  55%|█████▍    | 546/1001 [26:43<12:55,  1.70s/it, avg loss=155.1317]
Training iteration:  55%|█████▍    | 547/1001 [26:43<12:53,  1.70s/it, avg loss=155.1317]Checkpoint at iteration 547 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 155.1317352294922

Training iteration:  55%|█████▍    | 547/1001 [26:45<12:53,  1.70s/it, avg loss=137.3730]
Training iteration:  55%|█████▍    | 548/1001 [26:45<12:51,  1.70s/it, avg loss=137.3730]Checkpoint at iteration 548 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 137.37297515869142

Training iteration:  55%|█████▍    | 548/1001 [26:47<12:51,  1.70s/it, avg loss=179.9027]
Training iteration:  55%|█████▍    | 549/1001 [26:47<12:50,  1.70s/it, avg loss=179.9027]Checkpoint at iteration 549 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 179.90271492004393

Training iteration:  55%|█████▍    | 549/1001 [26:49<12:50,  1.70s/it, avg loss=144.9194]
Training iteration:  55%|█████▍    | 550/1001 [26:49<12:48,  1.70s/it, avg loss=144.9194]Checkpoint at iteration 550 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 144.919425201416

Training iteration:  55%|█████▍    | 550/1001 [26:50<12:48,  1.70s/it, avg loss=145.1633]
Training iteration:  55%|█████▌    | 551/1001 [26:50<12:47,  1.71s/it, avg loss=145.1633]Checkpoint at iteration 551 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 145.163338470459

Training iteration:  55%|█████▌    | 551/1001 [26:52<12:47,  1.71s/it, avg loss=154.3907]
Training iteration:  55%|█████▌    | 552/1001 [26:52<12:45,  1.71s/it, avg loss=154.3907]Checkpoint at iteration 552 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 154.39065971374512

Training iteration:  55%|█████▌    | 552/1001 [26:54<12:45,  1.71s/it, avg loss=116.3481]
Training iteration:  55%|█████▌    | 553/1001 [26:54<12:43,  1.70s/it, avg loss=116.3481]Checkpoint at iteration 553 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 116.3480941772461

Training iteration:  55%|█████▌    | 553/1001 [26:55<12:43,  1.70s/it, avg loss=127.4024]
Training iteration:  55%|█████▌    | 554/1001 [26:55<12:41,  1.70s/it, avg loss=127.4024]Checkpoint at iteration 554 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 127.40242309570313

Training iteration:  55%|█████▌    | 554/1001 [26:57<12:41,  1.70s/it, avg loss=158.1106]
Training iteration:  55%|█████▌    | 555/1001 [26:57<12:40,  1.71s/it, avg loss=158.1106]Checkpoint at iteration 555 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 158.1105670928955

Training iteration:  55%|█████▌    | 555/1001 [26:59<12:40,  1.71s/it, avg loss=136.7307]
Training iteration:  56%|█████▌    | 556/1001 [26:59<12:38,  1.71s/it, avg loss=136.7307]Checkpoint at iteration 556 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 136.7307487487793

Training iteration:  56%|█████▌    | 556/1001 [27:01<12:38,  1.71s/it, avg loss=91.7022] 
Training iteration:  56%|█████▌    | 557/1001 [27:01<12:37,  1.71s/it, avg loss=91.7022]Checkpoint at iteration 557 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 91.70218353271484

Training iteration:  56%|█████▌    | 557/1001 [27:02<12:37,  1.71s/it, avg loss=176.3449]
Training iteration:  56%|█████▌    | 558/1001 [27:02<12:35,  1.71s/it, avg loss=176.3449]Checkpoint at iteration 558 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 176.34490242004395

Training iteration:  56%|█████▌    | 558/1001 [27:04<12:35,  1.71s/it, avg loss=167.0369]
Training iteration:  56%|█████▌    | 559/1001 [27:04<12:33,  1.71s/it, avg loss=167.0369]Checkpoint at iteration 559 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 167.0368824005127

Training iteration:  56%|█████▌    | 559/1001 [27:06<12:33,  1.71s/it, avg loss=223.6032]
Training iteration:  56%|█████▌    | 560/1001 [27:06<12:32,  1.71s/it, avg loss=223.6032]Checkpoint at iteration 560 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 223.60318412780762

Training iteration:  56%|█████▌    | 560/1001 [27:07<12:32,  1.71s/it, avg loss=171.9834]
Training iteration:  56%|█████▌    | 561/1001 [27:07<12:30,  1.71s/it, avg loss=171.9834]Checkpoint at iteration 561 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 171.98343772888182

Training iteration:  56%|█████▌    | 561/1001 [27:09<12:30,  1.71s/it, avg loss=232.2713]
Training iteration:  56%|█████▌    | 562/1001 [27:09<12:28,  1.71s/it, avg loss=232.2713]Checkpoint at iteration 562 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 232.27129898071288

Training iteration:  56%|█████▌    | 562/1001 [27:11<12:28,  1.71s/it, avg loss=239.3641]
Training iteration:  56%|█████▌    | 563/1001 [27:11<12:26,  1.71s/it, avg loss=239.3641]Checkpoint at iteration 563 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 239.36407737731935

Training iteration:  56%|█████▌    | 563/1001 [27:12<12:26,  1.71s/it, avg loss=161.8531]
Training iteration:  56%|█████▋    | 564/1001 [27:12<12:25,  1.71s/it, avg loss=161.8531]Checkpoint at iteration 564 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 161.85314331054687

Training iteration:  56%|█████▋    | 564/1001 [27:14<12:25,  1.71s/it, avg loss=155.1917]
Training iteration:  56%|█████▋    | 565/1001 [27:14<12:23,  1.70s/it, avg loss=155.1917]Checkpoint at iteration 565 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 155.19168395996093

Training iteration:  56%|█████▋    | 565/1001 [27:16<12:23,  1.70s/it, avg loss=161.2204]
Training iteration:  57%|█████▋    | 566/1001 [27:16<12:21,  1.70s/it, avg loss=161.2204]Checkpoint at iteration 566 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 161.22044944763184

Training iteration:  57%|█████▋    | 566/1001 [27:18<12:21,  1.70s/it, avg loss=216.3019]
Training iteration:  57%|█████▋    | 567/1001 [27:18<12:19,  1.70s/it, avg loss=216.3019]Checkpoint at iteration 567 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 216.30185775756837

Training iteration:  57%|█████▋    | 567/1001 [27:19<12:19,  1.70s/it, avg loss=146.7785]
Training iteration:  57%|█████▋    | 568/1001 [27:19<12:18,  1.70s/it, avg loss=146.7785]Checkpoint at iteration 568 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 146.7784652709961

Training iteration:  57%|█████▋    | 568/1001 [27:21<12:18,  1.70s/it, avg loss=204.0315]
Training iteration:  57%|█████▋    | 569/1001 [27:21<12:16,  1.70s/it, avg loss=204.0315]Checkpoint at iteration 569 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 204.0315082550049

Training iteration:  57%|█████▋    | 569/1001 [27:23<12:16,  1.70s/it, avg loss=211.2983]
Training iteration:  57%|█████▋    | 570/1001 [27:23<12:15,  1.71s/it, avg loss=211.2983]Checkpoint at iteration 570 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 211.29826278686522

Training iteration:  57%|█████▋    | 570/1001 [27:24<12:15,  1.71s/it, avg loss=203.7736]
Training iteration:  57%|█████▋    | 571/1001 [27:24<12:13,  1.71s/it, avg loss=203.7736]Checkpoint at iteration 571 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 203.77363204956055

Training iteration:  57%|█████▋    | 571/1001 [27:26<12:13,  1.71s/it, avg loss=153.0393]
Training iteration:  57%|█████▋    | 572/1001 [27:26<12:11,  1.71s/it, avg loss=153.0393]Checkpoint at iteration 572 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 153.03930130004883

Training iteration:  57%|█████▋    | 572/1001 [27:28<12:11,  1.71s/it, avg loss=136.1410]
Training iteration:  57%|█████▋    | 573/1001 [27:28<12:09,  1.70s/it, avg loss=136.1410]Checkpoint at iteration 573 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 136.14100761413573

Training iteration:  57%|█████▋    | 573/1001 [27:30<12:09,  1.70s/it, avg loss=138.5005]
Training iteration:  57%|█████▋    | 574/1001 [27:30<12:07,  1.70s/it, avg loss=138.5005]Checkpoint at iteration 574 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 138.50051803588866

Training iteration:  57%|█████▋    | 574/1001 [27:31<12:07,  1.70s/it, avg loss=209.1866]
Training iteration:  57%|█████▋    | 575/1001 [27:31<12:06,  1.70s/it, avg loss=209.1866]Checkpoint at iteration 575 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 209.18661575317384

Training iteration:  57%|█████▋    | 575/1001 [27:33<12:06,  1.70s/it, avg loss=92.9031] 
Training iteration:  58%|█████▊    | 576/1001 [27:33<12:04,  1.70s/it, avg loss=92.9031]Checkpoint at iteration 576 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 92.90305786132812

Training iteration:  58%|█████▊    | 576/1001 [27:35<12:04,  1.70s/it, avg loss=123.2570]
Training iteration:  58%|█████▊    | 577/1001 [27:35<12:02,  1.70s/it, avg loss=123.2570]Checkpoint at iteration 577 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 123.25698013305664

Training iteration:  58%|█████▊    | 577/1001 [27:36<12:02,  1.70s/it, avg loss=116.4143]
Training iteration:  58%|█████▊    | 578/1001 [27:36<12:00,  1.70s/it, avg loss=116.4143]Checkpoint at iteration 578 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 116.41425323486328

Training iteration:  58%|█████▊    | 578/1001 [27:38<12:00,  1.70s/it, avg loss=179.4879]
Training iteration:  58%|█████▊    | 579/1001 [27:38<11:58,  1.70s/it, avg loss=179.4879]Checkpoint at iteration 579 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 179.4878879547119

Training iteration:  58%|█████▊    | 579/1001 [27:40<11:58,  1.70s/it, avg loss=269.6517]
Training iteration:  58%|█████▊    | 580/1001 [27:40<11:57,  1.70s/it, avg loss=269.6517]Checkpoint at iteration 580 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 269.6516632080078

Training iteration:  58%|█████▊    | 580/1001 [27:41<11:57,  1.70s/it, avg loss=165.3569]
Training iteration:  58%|█████▊    | 581/1001 [27:41<11:55,  1.70s/it, avg loss=165.3569]Checkpoint at iteration 581 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 165.3569049835205

Training iteration:  58%|█████▊    | 581/1001 [27:43<11:55,  1.70s/it, avg loss=148.2768]
Training iteration:  58%|█████▊    | 582/1001 [27:43<11:54,  1.70s/it, avg loss=148.2768]Checkpoint at iteration 582 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 148.27684745788574

Training iteration:  58%|█████▊    | 582/1001 [27:45<11:54,  1.70s/it, avg loss=140.9171]
Training iteration:  58%|█████▊    | 583/1001 [27:45<11:52,  1.70s/it, avg loss=140.9171]Checkpoint at iteration 583 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 140.91708030700684

Training iteration:  58%|█████▊    | 583/1001 [27:47<11:52,  1.70s/it, avg loss=152.0925]
Training iteration:  58%|█████▊    | 584/1001 [27:47<11:50,  1.70s/it, avg loss=152.0925]Checkpoint at iteration 584 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 152.09249725341797

Training iteration:  58%|█████▊    | 584/1001 [27:48<11:50,  1.70s/it, avg loss=192.5724]
Training iteration:  58%|█████▊    | 585/1001 [27:48<11:49,  1.70s/it, avg loss=192.5724]Checkpoint at iteration 585 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 192.57236289978027

Training iteration:  58%|█████▊    | 585/1001 [27:50<11:49,  1.70s/it, avg loss=149.6312]
Training iteration:  59%|█████▊    | 586/1001 [27:50<11:47,  1.70s/it, avg loss=149.6312]Checkpoint at iteration 586 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 149.6311813354492

Training iteration:  59%|█████▊    | 586/1001 [27:52<11:47,  1.70s/it, avg loss=213.7680]
Training iteration:  59%|█████▊    | 587/1001 [27:52<11:45,  1.70s/it, avg loss=213.7680]Checkpoint at iteration 587 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 213.76798629760742

Training iteration:  59%|█████▊    | 587/1001 [27:53<11:45,  1.70s/it, avg loss=163.6911]
Training iteration:  59%|█████▊    | 588/1001 [27:53<11:44,  1.71s/it, avg loss=163.6911]Checkpoint at iteration 588 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 163.6910873413086

Training iteration:  59%|█████▊    | 588/1001 [27:55<11:44,  1.71s/it, avg loss=138.6175]
Training iteration:  59%|█████▉    | 589/1001 [27:55<11:42,  1.70s/it, avg loss=138.6175]Checkpoint at iteration 589 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 138.61749763488768

Training iteration:  59%|█████▉    | 589/1001 [27:57<11:42,  1.70s/it, avg loss=225.5468]
Training iteration:  59%|█████▉    | 590/1001 [27:57<11:40,  1.71s/it, avg loss=225.5468]Checkpoint at iteration 590 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 225.54679794311522

Training iteration:  59%|█████▉    | 590/1001 [27:58<11:40,  1.71s/it, avg loss=161.1497]
Training iteration:  59%|█████▉    | 591/1001 [27:58<11:38,  1.70s/it, avg loss=161.1497]Checkpoint at iteration 591 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 161.1497257232666

Training iteration:  59%|█████▉    | 591/1001 [28:00<11:38,  1.70s/it, avg loss=228.3624]
Training iteration:  59%|█████▉    | 592/1001 [28:00<11:37,  1.70s/it, avg loss=228.3624]Checkpoint at iteration 592 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 228.36237335205078

Training iteration:  59%|█████▉    | 592/1001 [28:02<11:37,  1.70s/it, avg loss=155.5273]
Training iteration:  59%|█████▉    | 593/1001 [28:02<11:37,  1.71s/it, avg loss=155.5273]Checkpoint at iteration 593 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 155.5273406982422

Training iteration:  59%|█████▉    | 593/1001 [28:04<11:37,  1.71s/it, avg loss=127.3713]
Training iteration:  59%|█████▉    | 594/1001 [28:04<11:37,  1.71s/it, avg loss=127.3713]Checkpoint at iteration 594 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 127.37126274108887

Training iteration:  59%|█████▉    | 594/1001 [28:05<11:37,  1.71s/it, avg loss=196.2131]
Training iteration:  59%|█████▉    | 595/1001 [28:05<11:37,  1.72s/it, avg loss=196.2131]Checkpoint at iteration 595 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 196.21313934326173

Training iteration:  59%|█████▉    | 595/1001 [28:07<11:37,  1.72s/it, avg loss=137.6117]
Training iteration:  60%|█████▉    | 596/1001 [28:07<11:35,  1.72s/it, avg loss=137.6117]Checkpoint at iteration 596 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 137.6116584777832

Training iteration:  60%|█████▉    | 596/1001 [28:09<11:35,  1.72s/it, avg loss=143.9297]
Training iteration:  60%|█████▉    | 597/1001 [28:09<11:34,  1.72s/it, avg loss=143.9297]Checkpoint at iteration 597 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 143.9296604156494

Training iteration:  60%|█████▉    | 597/1001 [28:11<11:34,  1.72s/it, avg loss=187.8403]
Training iteration:  60%|█████▉    | 598/1001 [28:11<11:33,  1.72s/it, avg loss=187.8403]Checkpoint at iteration 598 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 187.84029159545898

Training iteration:  60%|█████▉    | 598/1001 [28:12<11:33,  1.72s/it, avg loss=141.2606]
Training iteration:  60%|█████▉    | 599/1001 [28:12<11:31,  1.72s/it, avg loss=141.2606]Checkpoint at iteration 599 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 141.26058692932128

Training iteration:  60%|█████▉    | 599/1001 [28:14<11:31,  1.72s/it, avg loss=165.1413]
Training iteration:  60%|█████▉    | 600/1001 [28:14<11:30,  1.72s/it, avg loss=165.1413]Optimization iteration 600 evaluation begins...
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
A new evaluation visualization has been saved: ./saved_data/20240110-081107/it600.png
Training network 0 for evaluation...
Training network 1 for evaluation...
Training network 2 for evaluation...
Training network 3 for evaluation...
Testing network 0 on real datasets for evaluation...
Testing network 1 on real datasets for evaluation...
Testing network 2 on real datasets for evaluation...
Testing network 3 on real datasets for evaluation...
Optimization iteration 600, eval auroc score (train): 19743.4477, eval auroc score (test): 20797.8659
Checkpoint at iteration 600 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 165.1413230895996

Training iteration:  60%|█████▉    | 600/1001 [35:25<11:30,  1.72s/it, avg loss=83.5427] 
Training iteration:  60%|██████    | 601/1001 [35:25<14:29:21, 130.40s/it, avg loss=83.5427]Checkpoint at iteration 601 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 83.54273796081543

Training iteration:  60%|██████    | 601/1001 [35:27<14:29:21, 130.40s/it, avg loss=147.9670]
Training iteration:  60%|██████    | 602/1001 [35:27<10:10:54, 91.87s/it, avg loss=147.9670] Checkpoint at iteration 602 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 147.96704063415527

Training iteration:  60%|██████    | 602/1001 [35:29<10:10:54, 91.87s/it, avg loss=114.9651]
Training iteration:  60%|██████    | 603/1001 [35:29<7:10:26, 64.89s/it, avg loss=114.9651] Checkpoint at iteration 603 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 114.965132522583

Training iteration:  60%|██████    | 603/1001 [35:30<7:10:26, 64.89s/it, avg loss=145.8738]
Training iteration:  60%|██████    | 604/1001 [35:30<5:04:24, 46.01s/it, avg loss=145.8738]Checkpoint at iteration 604 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 145.87376708984374

Training iteration:  60%|██████    | 604/1001 [35:32<5:04:24, 46.01s/it, avg loss=140.7366]
Training iteration:  60%|██████    | 605/1001 [35:32<3:36:24, 32.79s/it, avg loss=140.7366]Checkpoint at iteration 605 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 140.73663825988768

Training iteration:  60%|██████    | 605/1001 [35:34<3:36:24, 32.79s/it, avg loss=195.2980]
Training iteration:  61%|██████    | 606/1001 [35:34<2:34:55, 23.53s/it, avg loss=195.2980]Checkpoint at iteration 606 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 195.29800758361816

Training iteration:  61%|██████    | 606/1001 [35:36<2:34:55, 23.53s/it, avg loss=141.0631]
Training iteration:  61%|██████    | 607/1001 [35:36<1:51:59, 17.05s/it, avg loss=141.0631]Checkpoint at iteration 607 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 141.0630718231201

Training iteration:  61%|██████    | 607/1001 [35:38<1:51:59, 17.05s/it, avg loss=88.4933] 
Training iteration:  61%|██████    | 608/1001 [35:38<1:22:00, 12.52s/it, avg loss=88.4933]Checkpoint at iteration 608 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 88.49326591491699

Training iteration:  61%|██████    | 608/1001 [35:40<1:22:00, 12.52s/it, avg loss=94.3653]
Training iteration:  61%|██████    | 609/1001 [35:40<1:01:02,  9.34s/it, avg loss=94.3653]Checkpoint at iteration 609 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 94.36532592773438

Training iteration:  61%|██████    | 609/1001 [35:42<1:01:02,  9.34s/it, avg loss=128.7187]
Training iteration:  61%|██████    | 610/1001 [35:42<46:24,  7.12s/it, avg loss=128.7187]  Checkpoint at iteration 610 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 128.71865768432616

Training iteration:  61%|██████    | 610/1001 [35:44<46:24,  7.12s/it, avg loss=162.3435]
Training iteration:  61%|██████    | 611/1001 [35:44<36:10,  5.57s/it, avg loss=162.3435]Checkpoint at iteration 611 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 162.343505859375

Training iteration:  61%|██████    | 611/1001 [35:46<36:10,  5.57s/it, avg loss=214.3066]
Training iteration:  61%|██████    | 612/1001 [35:46<29:01,  4.48s/it, avg loss=214.3066]Checkpoint at iteration 612 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 214.30655097961426

Training iteration:  61%|██████    | 612/1001 [35:48<29:01,  4.48s/it, avg loss=90.8672] 
Training iteration:  61%|██████    | 613/1001 [35:48<24:01,  3.71s/it, avg loss=90.8672]Checkpoint at iteration 613 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 90.86721153259278

Training iteration:  61%|██████    | 613/1001 [35:50<24:01,  3.71s/it, avg loss=125.5558]
Training iteration:  61%|██████▏   | 614/1001 [35:50<20:30,  3.18s/it, avg loss=125.5558]Checkpoint at iteration 614 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 125.55576934814454

Training iteration:  61%|██████▏   | 614/1001 [35:52<20:30,  3.18s/it, avg loss=211.2462]
Training iteration:  61%|██████▏   | 615/1001 [35:52<18:03,  2.81s/it, avg loss=211.2462]Checkpoint at iteration 615 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 211.24622611999513

Training iteration:  61%|██████▏   | 615/1001 [35:54<18:03,  2.81s/it, avg loss=175.5325]
Training iteration:  62%|██████▏   | 616/1001 [35:54<16:19,  2.54s/it, avg loss=175.5325]Checkpoint at iteration 616 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 175.5324565887451

Training iteration:  62%|██████▏   | 616/1001 [35:56<16:19,  2.54s/it, avg loss=154.8923]
Training iteration:  62%|██████▏   | 617/1001 [35:56<15:06,  2.36s/it, avg loss=154.8923]Checkpoint at iteration 617 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 154.892333984375

Training iteration:  62%|██████▏   | 617/1001 [35:58<15:06,  2.36s/it, avg loss=125.0958]
Training iteration:  62%|██████▏   | 618/1001 [35:58<14:14,  2.23s/it, avg loss=125.0958]Checkpoint at iteration 618 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 125.09582061767578

Training iteration:  62%|██████▏   | 618/1001 [36:00<14:14,  2.23s/it, avg loss=187.2271]
Training iteration:  62%|██████▏   | 619/1001 [36:00<13:38,  2.14s/it, avg loss=187.2271]Checkpoint at iteration 619 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 187.22706756591796

Training iteration:  62%|██████▏   | 619/1001 [36:01<13:38,  2.14s/it, avg loss=206.0618]
Training iteration:  62%|██████▏   | 620/1001 [36:01<13:12,  2.08s/it, avg loss=206.0618]Checkpoint at iteration 620 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 206.06176223754883

Training iteration:  62%|██████▏   | 620/1001 [36:03<13:12,  2.08s/it, avg loss=91.0216] 
Training iteration:  62%|██████▏   | 621/1001 [36:03<12:53,  2.04s/it, avg loss=91.0216]Checkpoint at iteration 621 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 91.02160682678223

Training iteration:  62%|██████▏   | 621/1001 [36:05<12:53,  2.04s/it, avg loss=146.7528]
Training iteration:  62%|██████▏   | 622/1001 [36:05<12:39,  2.00s/it, avg loss=146.7528]Checkpoint at iteration 622 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 146.75277671813964

Training iteration:  62%|██████▏   | 622/1001 [36:07<12:39,  2.00s/it, avg loss=152.2731]
Training iteration:  62%|██████▏   | 623/1001 [36:07<12:29,  1.98s/it, avg loss=152.2731]Checkpoint at iteration 623 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 152.27305450439454

Training iteration:  62%|██████▏   | 623/1001 [36:09<12:29,  1.98s/it, avg loss=141.2828]
Training iteration:  62%|██████▏   | 624/1001 [36:09<12:21,  1.97s/it, avg loss=141.2828]Checkpoint at iteration 624 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 141.2828109741211

Training iteration:  62%|██████▏   | 624/1001 [36:11<12:21,  1.97s/it, avg loss=108.3955]
Training iteration:  62%|██████▏   | 625/1001 [36:11<12:15,  1.96s/it, avg loss=108.3955]Checkpoint at iteration 625 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 108.39549751281739

Training iteration:  62%|██████▏   | 625/1001 [36:13<12:15,  1.96s/it, avg loss=158.4069]
Training iteration:  63%|██████▎   | 626/1001 [36:13<12:10,  1.95s/it, avg loss=158.4069]Checkpoint at iteration 626 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 158.40691680908202

Training iteration:  63%|██████▎   | 626/1001 [36:15<12:10,  1.95s/it, avg loss=178.2881]
Training iteration:  63%|██████▎   | 627/1001 [36:15<12:06,  1.94s/it, avg loss=178.2881]Checkpoint at iteration 627 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 178.28807411193847

Training iteration:  63%|██████▎   | 627/1001 [36:17<12:06,  1.94s/it, avg loss=188.7603]
Training iteration:  63%|██████▎   | 628/1001 [36:17<12:03,  1.94s/it, avg loss=188.7603]Checkpoint at iteration 628 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 188.7603286743164

Training iteration:  63%|██████▎   | 628/1001 [36:19<12:03,  1.94s/it, avg loss=147.8945]
Training iteration:  63%|██████▎   | 629/1001 [36:19<12:00,  1.94s/it, avg loss=147.8945]Checkpoint at iteration 629 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 147.8945053100586

Training iteration:  63%|██████▎   | 629/1001 [36:21<12:00,  1.94s/it, avg loss=133.8757]
Training iteration:  63%|██████▎   | 630/1001 [36:21<11:58,  1.94s/it, avg loss=133.8757]Checkpoint at iteration 630 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 133.8756866455078

Training iteration:  63%|██████▎   | 630/1001 [36:23<11:58,  1.94s/it, avg loss=164.8586]
Training iteration:  63%|██████▎   | 631/1001 [36:23<11:55,  1.93s/it, avg loss=164.8586]Checkpoint at iteration 631 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 164.8586181640625

Training iteration:  63%|██████▎   | 631/1001 [36:25<11:55,  1.93s/it, avg loss=112.5132]
Training iteration:  63%|██████▎   | 632/1001 [36:25<11:53,  1.93s/it, avg loss=112.5132]Checkpoint at iteration 632 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 112.5132064819336

Training iteration:  63%|██████▎   | 632/1001 [36:27<11:53,  1.93s/it, avg loss=92.3569] 
Training iteration:  63%|██████▎   | 633/1001 [36:27<11:51,  1.93s/it, avg loss=92.3569]Checkpoint at iteration 633 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 92.35685691833496

Training iteration:  63%|██████▎   | 633/1001 [36:28<11:51,  1.93s/it, avg loss=109.9143]
Training iteration:  63%|██████▎   | 634/1001 [36:28<11:49,  1.93s/it, avg loss=109.9143]Checkpoint at iteration 634 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 109.91425552368165

Training iteration:  63%|██████▎   | 634/1001 [36:30<11:49,  1.93s/it, avg loss=131.7536]
Training iteration:  63%|██████▎   | 635/1001 [36:30<11:47,  1.93s/it, avg loss=131.7536]Checkpoint at iteration 635 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 131.75358200073242

Training iteration:  63%|██████▎   | 635/1001 [36:32<11:47,  1.93s/it, avg loss=109.2359]
Training iteration:  64%|██████▎   | 636/1001 [36:32<11:45,  1.93s/it, avg loss=109.2359]Checkpoint at iteration 636 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 109.23591003417968

Training iteration:  64%|██████▎   | 636/1001 [36:34<11:45,  1.93s/it, avg loss=115.6571]
Training iteration:  64%|██████▎   | 637/1001 [36:34<11:43,  1.93s/it, avg loss=115.6571]Checkpoint at iteration 637 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 115.65713195800781

Training iteration:  64%|██████▎   | 637/1001 [36:36<11:43,  1.93s/it, avg loss=165.5403]
Training iteration:  64%|██████▎   | 638/1001 [36:36<11:41,  1.93s/it, avg loss=165.5403]Checkpoint at iteration 638 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 165.54034652709962

Training iteration:  64%|██████▎   | 638/1001 [36:38<11:41,  1.93s/it, avg loss=152.5887]
Training iteration:  64%|██████▍   | 639/1001 [36:38<11:39,  1.93s/it, avg loss=152.5887]Checkpoint at iteration 639 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 152.58868026733398

Training iteration:  64%|██████▍   | 639/1001 [36:40<11:39,  1.93s/it, avg loss=114.1625]
Training iteration:  64%|██████▍   | 640/1001 [36:40<11:37,  1.93s/it, avg loss=114.1625]Checkpoint at iteration 640 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 114.16249656677246

Training iteration:  64%|██████▍   | 640/1001 [36:42<11:37,  1.93s/it, avg loss=159.6186]
Training iteration:  64%|██████▍   | 641/1001 [36:42<11:35,  1.93s/it, avg loss=159.6186]Checkpoint at iteration 641 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 159.61856803894042

Training iteration:  64%|██████▍   | 641/1001 [36:44<11:35,  1.93s/it, avg loss=155.2894]
Training iteration:  64%|██████▍   | 642/1001 [36:44<11:33,  1.93s/it, avg loss=155.2894]Checkpoint at iteration 642 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 155.2894145965576

Training iteration:  64%|██████▍   | 642/1001 [36:46<11:33,  1.93s/it, avg loss=238.7905]
Training iteration:  64%|██████▍   | 643/1001 [36:46<11:31,  1.93s/it, avg loss=238.7905]Checkpoint at iteration 643 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 238.79047546386718

Training iteration:  64%|██████▍   | 643/1001 [36:48<11:31,  1.93s/it, avg loss=116.4730]
Training iteration:  64%|██████▍   | 644/1001 [36:48<11:29,  1.93s/it, avg loss=116.4730]Checkpoint at iteration 644 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 116.47302589416503

Training iteration:  64%|██████▍   | 644/1001 [36:50<11:29,  1.93s/it, avg loss=173.4264]
Training iteration:  64%|██████▍   | 645/1001 [36:50<11:27,  1.93s/it, avg loss=173.4264]Checkpoint at iteration 645 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 173.42642784118652

Training iteration:  64%|██████▍   | 645/1001 [36:52<11:27,  1.93s/it, avg loss=249.7005]
Training iteration:  65%|██████▍   | 646/1001 [36:52<11:25,  1.93s/it, avg loss=249.7005]Checkpoint at iteration 646 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 249.70053253173828

Training iteration:  65%|██████▍   | 646/1001 [36:54<11:25,  1.93s/it, avg loss=213.5131]
Training iteration:  65%|██████▍   | 647/1001 [36:54<11:23,  1.93s/it, avg loss=213.5131]Checkpoint at iteration 647 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 213.51306838989257

Training iteration:  65%|██████▍   | 647/1001 [36:56<11:23,  1.93s/it, avg loss=159.0196]
Training iteration:  65%|██████▍   | 648/1001 [36:56<11:21,  1.93s/it, avg loss=159.0196]Checkpoint at iteration 648 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 159.01960830688478

Training iteration:  65%|██████▍   | 648/1001 [36:57<11:21,  1.93s/it, avg loss=163.2359]
Training iteration:  65%|██████▍   | 649/1001 [36:57<11:19,  1.93s/it, avg loss=163.2359]Checkpoint at iteration 649 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 163.23594512939454

Training iteration:  65%|██████▍   | 649/1001 [36:59<11:19,  1.93s/it, avg loss=232.1333]
Training iteration:  65%|██████▍   | 650/1001 [36:59<11:17,  1.93s/it, avg loss=232.1333]Checkpoint at iteration 650 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 232.13329467773437

Training iteration:  65%|██████▍   | 650/1001 [37:01<11:17,  1.93s/it, avg loss=202.4777]
Training iteration:  65%|██████▌   | 651/1001 [37:01<11:15,  1.93s/it, avg loss=202.4777]Checkpoint at iteration 651 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 202.4777053833008

Training iteration:  65%|██████▌   | 651/1001 [37:03<11:15,  1.93s/it, avg loss=193.4612]
Training iteration:  65%|██████▌   | 652/1001 [37:03<11:14,  1.93s/it, avg loss=193.4612]Checkpoint at iteration 652 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 193.46116905212403

Training iteration:  65%|██████▌   | 652/1001 [37:05<11:14,  1.93s/it, avg loss=179.0043]
Training iteration:  65%|██████▌   | 653/1001 [37:05<11:12,  1.93s/it, avg loss=179.0043]Checkpoint at iteration 653 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 179.00428199768066

Training iteration:  65%|██████▌   | 653/1001 [37:07<11:12,  1.93s/it, avg loss=176.5367]
Training iteration:  65%|██████▌   | 654/1001 [37:07<11:10,  1.93s/it, avg loss=176.5367]Checkpoint at iteration 654 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 176.53667526245118

Training iteration:  65%|██████▌   | 654/1001 [37:09<11:10,  1.93s/it, avg loss=134.5570]
Training iteration:  65%|██████▌   | 655/1001 [37:09<11:08,  1.93s/it, avg loss=134.5570]Checkpoint at iteration 655 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 134.55704727172852

Training iteration:  65%|██████▌   | 655/1001 [37:11<11:08,  1.93s/it, avg loss=154.0709]
Training iteration:  66%|██████▌   | 656/1001 [37:11<11:06,  1.93s/it, avg loss=154.0709]Checkpoint at iteration 656 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 154.07091674804687

Training iteration:  66%|██████▌   | 656/1001 [37:13<11:06,  1.93s/it, avg loss=185.9201]
Training iteration:  66%|██████▌   | 657/1001 [37:13<11:04,  1.93s/it, avg loss=185.9201]Checkpoint at iteration 657 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 185.92013397216797

Training iteration:  66%|██████▌   | 657/1001 [37:15<11:04,  1.93s/it, avg loss=130.3252]
Training iteration:  66%|██████▌   | 658/1001 [37:15<11:02,  1.93s/it, avg loss=130.3252]Checkpoint at iteration 658 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 130.32520217895507

Training iteration:  66%|██████▌   | 658/1001 [37:17<11:02,  1.93s/it, avg loss=143.8332]
Training iteration:  66%|██████▌   | 659/1001 [37:17<11:00,  1.93s/it, avg loss=143.8332]Checkpoint at iteration 659 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 143.8332378387451

Training iteration:  66%|██████▌   | 659/1001 [37:19<11:00,  1.93s/it, avg loss=186.3391]
Training iteration:  66%|██████▌   | 660/1001 [37:19<10:58,  1.93s/it, avg loss=186.3391]Checkpoint at iteration 660 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 186.33913040161133

Training iteration:  66%|██████▌   | 660/1001 [37:21<10:58,  1.93s/it, avg loss=133.2630]
Training iteration:  66%|██████▌   | 661/1001 [37:21<10:56,  1.93s/it, avg loss=133.2630]Checkpoint at iteration 661 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 133.26300354003905

Training iteration:  66%|██████▌   | 661/1001 [37:23<10:56,  1.93s/it, avg loss=205.5942]
Training iteration:  66%|██████▌   | 662/1001 [37:23<10:54,  1.93s/it, avg loss=205.5942]Checkpoint at iteration 662 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 205.594234085083

Training iteration:  66%|██████▌   | 662/1001 [37:24<10:54,  1.93s/it, avg loss=144.0900]
Training iteration:  66%|██████▌   | 663/1001 [37:24<10:52,  1.93s/it, avg loss=144.0900]Checkpoint at iteration 663 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 144.09004325866698

Training iteration:  66%|██████▌   | 663/1001 [37:26<10:52,  1.93s/it, avg loss=164.5449]
Training iteration:  66%|██████▋   | 664/1001 [37:26<10:50,  1.93s/it, avg loss=164.5449]Checkpoint at iteration 664 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 164.54485931396485

Training iteration:  66%|██████▋   | 664/1001 [37:28<10:50,  1.93s/it, avg loss=102.3036]
Training iteration:  66%|██████▋   | 665/1001 [37:28<10:48,  1.93s/it, avg loss=102.3036]Checkpoint at iteration 665 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 102.30356941223144

Training iteration:  66%|██████▋   | 665/1001 [37:30<10:48,  1.93s/it, avg loss=175.8592]
Training iteration:  67%|██████▋   | 666/1001 [37:30<10:46,  1.93s/it, avg loss=175.8592]Checkpoint at iteration 666 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 175.85923690795897

Training iteration:  67%|██████▋   | 666/1001 [37:32<10:46,  1.93s/it, avg loss=133.2792]
Training iteration:  67%|██████▋   | 667/1001 [37:32<10:44,  1.93s/it, avg loss=133.2792]Checkpoint at iteration 667 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 133.27917442321777

Training iteration:  67%|██████▋   | 667/1001 [37:34<10:44,  1.93s/it, avg loss=164.4402]
Training iteration:  67%|██████▋   | 668/1001 [37:34<10:45,  1.94s/it, avg loss=164.4402]Checkpoint at iteration 668 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 164.44023094177246

Training iteration:  67%|██████▋   | 668/1001 [37:36<10:45,  1.94s/it, avg loss=163.7179]
Training iteration:  67%|██████▋   | 669/1001 [37:36<10:45,  1.94s/it, avg loss=163.7179]Checkpoint at iteration 669 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 163.71794013977052

Training iteration:  67%|██████▋   | 669/1001 [37:38<10:45,  1.94s/it, avg loss=170.2109]
Training iteration:  67%|██████▋   | 670/1001 [37:38<10:44,  1.95s/it, avg loss=170.2109]Checkpoint at iteration 670 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 170.21089553833008

Training iteration:  67%|██████▋   | 670/1001 [37:40<10:44,  1.95s/it, avg loss=226.1119]
Training iteration:  67%|██████▋   | 671/1001 [37:40<10:42,  1.95s/it, avg loss=226.1119]Checkpoint at iteration 671 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 226.11190643310547

Training iteration:  67%|██████▋   | 671/1001 [37:42<10:42,  1.95s/it, avg loss=193.1293]
Training iteration:  67%|██████▋   | 672/1001 [37:42<10:41,  1.95s/it, avg loss=193.1293]Checkpoint at iteration 672 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 193.12929420471193

Training iteration:  67%|██████▋   | 672/1001 [37:44<10:41,  1.95s/it, avg loss=224.5695]
Training iteration:  67%|██████▋   | 673/1001 [37:44<10:39,  1.95s/it, avg loss=224.5695]Checkpoint at iteration 673 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 224.5694522857666

Training iteration:  67%|██████▋   | 673/1001 [37:46<10:39,  1.95s/it, avg loss=144.0182]
Training iteration:  67%|██████▋   | 674/1001 [37:46<10:37,  1.95s/it, avg loss=144.0182]Checkpoint at iteration 674 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 144.01815299987794

Training iteration:  67%|██████▋   | 674/1001 [37:48<10:37,  1.95s/it, avg loss=210.6004]
Training iteration:  67%|██████▋   | 675/1001 [37:48<10:35,  1.95s/it, avg loss=210.6004]Checkpoint at iteration 675 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 210.6003562927246

Training iteration:  67%|██████▋   | 675/1001 [37:50<10:35,  1.95s/it, avg loss=106.4709]
Training iteration:  68%|██████▊   | 676/1001 [37:50<10:33,  1.95s/it, avg loss=106.4709]Checkpoint at iteration 676 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 106.4708812713623

Training iteration:  68%|██████▊   | 676/1001 [37:52<10:33,  1.95s/it, avg loss=171.7833]
Training iteration:  68%|██████▊   | 677/1001 [37:52<10:31,  1.95s/it, avg loss=171.7833]Checkpoint at iteration 677 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 171.78334121704103

Training iteration:  68%|██████▊   | 677/1001 [37:54<10:31,  1.95s/it, avg loss=107.2207]
Training iteration:  68%|██████▊   | 678/1001 [37:54<10:29,  1.95s/it, avg loss=107.2207]Checkpoint at iteration 678 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 107.2206802368164

Training iteration:  68%|██████▊   | 678/1001 [37:56<10:29,  1.95s/it, avg loss=79.3891] 
Training iteration:  68%|██████▊   | 679/1001 [37:56<10:28,  1.95s/it, avg loss=79.3891]Checkpoint at iteration 679 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 79.38912887573242

Training iteration:  68%|██████▊   | 679/1001 [37:58<10:28,  1.95s/it, avg loss=115.2526]
Training iteration:  68%|██████▊   | 680/1001 [37:58<10:26,  1.95s/it, avg loss=115.2526]Checkpoint at iteration 680 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 115.25255279541015

Training iteration:  68%|██████▊   | 680/1001 [38:00<10:26,  1.95s/it, avg loss=160.7060]
Training iteration:  68%|██████▊   | 681/1001 [38:00<10:25,  1.95s/it, avg loss=160.7060]Checkpoint at iteration 681 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 160.7060203552246

Training iteration:  68%|██████▊   | 681/1001 [38:02<10:25,  1.95s/it, avg loss=129.9587]
Training iteration:  68%|██████▊   | 682/1001 [38:02<10:23,  1.96s/it, avg loss=129.9587]Checkpoint at iteration 682 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 129.95873985290527

Training iteration:  68%|██████▊   | 682/1001 [38:03<10:23,  1.96s/it, avg loss=204.1954]
Training iteration:  68%|██████▊   | 683/1001 [38:03<10:21,  1.96s/it, avg loss=204.1954]Checkpoint at iteration 683 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 204.19540100097657

Training iteration:  68%|██████▊   | 683/1001 [38:05<10:21,  1.96s/it, avg loss=213.4496]
Training iteration:  68%|██████▊   | 684/1001 [38:05<10:20,  1.96s/it, avg loss=213.4496]Checkpoint at iteration 684 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 213.44962577819825

Training iteration:  68%|██████▊   | 684/1001 [38:07<10:20,  1.96s/it, avg loss=120.4864]
Training iteration:  68%|██████▊   | 685/1001 [38:07<10:18,  1.96s/it, avg loss=120.4864]Checkpoint at iteration 685 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 120.48636054992676

Training iteration:  68%|██████▊   | 685/1001 [38:09<10:18,  1.96s/it, avg loss=94.2664] 
Training iteration:  69%|██████▊   | 686/1001 [38:09<10:16,  1.96s/it, avg loss=94.2664]Checkpoint at iteration 686 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 94.26644363403321

Training iteration:  69%|██████▊   | 686/1001 [38:11<10:16,  1.96s/it, avg loss=146.3340]
Training iteration:  69%|██████▊   | 687/1001 [38:11<10:14,  1.96s/it, avg loss=146.3340]Checkpoint at iteration 687 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 146.3339874267578

Training iteration:  69%|██████▊   | 687/1001 [38:13<10:14,  1.96s/it, avg loss=135.2540]
Training iteration:  69%|██████▊   | 688/1001 [38:13<10:12,  1.96s/it, avg loss=135.2540]Checkpoint at iteration 688 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 135.25403213500977

Training iteration:  69%|██████▊   | 688/1001 [38:15<10:12,  1.96s/it, avg loss=209.1985]
Training iteration:  69%|██████▉   | 689/1001 [38:15<10:10,  1.96s/it, avg loss=209.1985]Checkpoint at iteration 689 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 209.1984764099121

Training iteration:  69%|██████▉   | 689/1001 [38:17<10:10,  1.96s/it, avg loss=191.3318]
Training iteration:  69%|██████▉   | 690/1001 [38:17<10:07,  1.95s/it, avg loss=191.3318]Checkpoint at iteration 690 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 191.33178176879883

Training iteration:  69%|██████▉   | 690/1001 [38:19<10:07,  1.95s/it, avg loss=187.9238]
Training iteration:  69%|██████▉   | 691/1001 [38:19<10:04,  1.95s/it, avg loss=187.9238]Checkpoint at iteration 691 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 187.9237575531006

Training iteration:  69%|██████▉   | 691/1001 [38:21<10:04,  1.95s/it, avg loss=219.9519]
Training iteration:  69%|██████▉   | 692/1001 [38:21<10:01,  1.95s/it, avg loss=219.9519]Checkpoint at iteration 692 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 219.95189361572267

Training iteration:  69%|██████▉   | 692/1001 [38:23<10:01,  1.95s/it, avg loss=154.3087]
Training iteration:  69%|██████▉   | 693/1001 [38:23<10:00,  1.95s/it, avg loss=154.3087]Checkpoint at iteration 693 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 154.30867958068848

Training iteration:  69%|██████▉   | 693/1001 [38:25<10:00,  1.95s/it, avg loss=198.3793]
Training iteration:  69%|██████▉   | 694/1001 [38:25<09:59,  1.95s/it, avg loss=198.3793]Checkpoint at iteration 694 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 198.37926483154297

Training iteration:  69%|██████▉   | 694/1001 [38:27<09:59,  1.95s/it, avg loss=101.3383]
Training iteration:  69%|██████▉   | 695/1001 [38:27<09:57,  1.95s/it, avg loss=101.3383]Checkpoint at iteration 695 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 101.3382957458496

Training iteration:  69%|██████▉   | 695/1001 [38:29<09:57,  1.95s/it, avg loss=172.5272]
Training iteration:  70%|██████▉   | 696/1001 [38:29<09:56,  1.95s/it, avg loss=172.5272]Checkpoint at iteration 696 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 172.52716674804688

Training iteration:  70%|██████▉   | 696/1001 [38:31<09:56,  1.95s/it, avg loss=101.3704]
Training iteration:  70%|██████▉   | 697/1001 [38:31<09:54,  1.96s/it, avg loss=101.3704]Checkpoint at iteration 697 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 101.37039604187012

Training iteration:  70%|██████▉   | 697/1001 [38:33<09:54,  1.96s/it, avg loss=141.1004]
Training iteration:  70%|██████▉   | 698/1001 [38:33<09:52,  1.96s/it, avg loss=141.1004]Checkpoint at iteration 698 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 141.10041580200195

Training iteration:  70%|██████▉   | 698/1001 [38:35<09:52,  1.96s/it, avg loss=202.6005]
Training iteration:  70%|██████▉   | 699/1001 [38:35<09:51,  1.96s/it, avg loss=202.6005]Checkpoint at iteration 699 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 202.60050010681152

Training iteration:  70%|██████▉   | 699/1001 [38:37<09:51,  1.96s/it, avg loss=217.6799]
Training iteration:  70%|██████▉   | 700/1001 [38:37<09:49,  1.96s/it, avg loss=217.6799]Optimization iteration 700 evaluation begins...
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
A new evaluation visualization has been saved: ./saved_data/20240110-081107/it700.png
Training network 0 for evaluation...
Training network 1 for evaluation...
Training network 2 for evaluation...
Training network 3 for evaluation...
Testing network 0 on real datasets for evaluation...
Testing network 1 on real datasets for evaluation...
Testing network 2 on real datasets for evaluation...
Testing network 3 on real datasets for evaluation...
Optimization iteration 700, eval auroc score (train): 19752.9362, eval auroc score (test): 20601.0436
Checkpoint at iteration 700 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 217.6799186706543

Training iteration:  70%|██████▉   | 700/1001 [46:52<09:49,  1.96s/it, avg loss=161.2176]
Training iteration:  70%|███████   | 701/1001 [46:52<12:29:52, 149.97s/it, avg loss=161.2176]Checkpoint at iteration 701 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 161.2176357269287

Training iteration:  70%|███████   | 701/1001 [46:54<12:29:52, 149.97s/it, avg loss=112.0770]
Training iteration:  70%|███████   | 702/1001 [46:54<8:46:24, 105.63s/it, avg loss=112.0770] Checkpoint at iteration 702 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 112.07701568603515

Training iteration:  70%|███████   | 702/1001 [46:56<8:46:24, 105.63s/it, avg loss=198.2026]
Training iteration:  70%|███████   | 703/1001 [46:56<6:10:28, 74.59s/it, avg loss=198.2026] Checkpoint at iteration 703 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 198.2026382446289

Training iteration:  70%|███████   | 703/1001 [46:59<6:10:28, 74.59s/it, avg loss=116.1253]
Training iteration:  70%|███████   | 704/1001 [46:59<4:21:41, 52.87s/it, avg loss=116.1253]Checkpoint at iteration 704 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 116.12527618408203

Training iteration:  70%|███████   | 704/1001 [47:01<4:21:41, 52.87s/it, avg loss=141.9875]
Training iteration:  70%|███████   | 705/1001 [47:01<3:05:46, 37.66s/it, avg loss=141.9875]Checkpoint at iteration 705 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 141.9875144958496

Training iteration:  70%|███████   | 705/1001 [47:03<3:05:46, 37.66s/it, avg loss=166.7895]
Training iteration:  71%|███████   | 706/1001 [47:03<2:12:47, 27.01s/it, avg loss=166.7895]Checkpoint at iteration 706 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 166.78949050903321

Training iteration:  71%|███████   | 706/1001 [47:05<2:12:47, 27.01s/it, avg loss=130.8702]
Training iteration:  71%|███████   | 707/1001 [47:05<1:35:48, 19.55s/it, avg loss=130.8702]Checkpoint at iteration 707 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 130.87020149230958

Training iteration:  71%|███████   | 707/1001 [47:07<1:35:48, 19.55s/it, avg loss=174.5131]
Training iteration:  71%|███████   | 708/1001 [47:07<1:09:59, 14.33s/it, avg loss=174.5131]Checkpoint at iteration 708 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 174.51306762695313

Training iteration:  71%|███████   | 708/1001 [47:09<1:09:59, 14.33s/it, avg loss=161.2568]
Training iteration:  71%|███████   | 709/1001 [47:09<51:57, 10.68s/it, avg loss=161.2568]  Checkpoint at iteration 709 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 161.25683555603027

Training iteration:  71%|███████   | 709/1001 [47:11<51:57, 10.68s/it, avg loss=114.9926]
Training iteration:  71%|███████   | 710/1001 [47:11<39:22,  8.12s/it, avg loss=114.9926]Checkpoint at iteration 710 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 114.99258079528809

Training iteration:  71%|███████   | 710/1001 [47:14<39:22,  8.12s/it, avg loss=197.5907]
Training iteration:  71%|███████   | 711/1001 [47:14<30:34,  6.33s/it, avg loss=197.5907]Checkpoint at iteration 711 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 197.59070625305176

Training iteration:  71%|███████   | 711/1001 [47:16<30:34,  6.33s/it, avg loss=122.9920]
Training iteration:  71%|███████   | 712/1001 [47:16<24:25,  5.07s/it, avg loss=122.9920]Checkpoint at iteration 712 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 122.99204025268554

Training iteration:  71%|███████   | 712/1001 [47:18<24:25,  5.07s/it, avg loss=148.4690]
Training iteration:  71%|███████   | 713/1001 [47:18<20:07,  4.19s/it, avg loss=148.4690]Checkpoint at iteration 713 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 148.4690258026123

Training iteration:  71%|███████   | 713/1001 [47:20<20:07,  4.19s/it, avg loss=165.1432]
Training iteration:  71%|███████▏  | 714/1001 [47:20<17:07,  3.58s/it, avg loss=165.1432]Checkpoint at iteration 714 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 165.143168258667

Training iteration:  71%|███████▏  | 714/1001 [47:22<17:07,  3.58s/it, avg loss=172.1552]
Training iteration:  71%|███████▏  | 715/1001 [47:22<15:00,  3.15s/it, avg loss=172.1552]Checkpoint at iteration 715 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 172.15521278381348

Training iteration:  71%|███████▏  | 715/1001 [47:24<15:00,  3.15s/it, avg loss=106.1279]
Training iteration:  72%|███████▏  | 716/1001 [47:24<13:31,  2.85s/it, avg loss=106.1279]Checkpoint at iteration 716 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 106.12790603637696

Training iteration:  72%|███████▏  | 716/1001 [47:26<13:31,  2.85s/it, avg loss=166.8243]
Training iteration:  72%|███████▏  | 717/1001 [47:26<12:28,  2.64s/it, avg loss=166.8243]Checkpoint at iteration 717 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 166.8242702484131

Training iteration:  72%|███████▏  | 717/1001 [47:29<12:28,  2.64s/it, avg loss=165.5484]
Training iteration:  72%|███████▏  | 718/1001 [47:29<11:44,  2.49s/it, avg loss=165.5484]Checkpoint at iteration 718 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 165.54838104248046

Training iteration:  72%|███████▏  | 718/1001 [47:31<11:44,  2.49s/it, avg loss=117.4706]
Training iteration:  72%|███████▏  | 719/1001 [47:31<11:12,  2.38s/it, avg loss=117.4706]Checkpoint at iteration 719 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 117.47056121826172

Training iteration:  72%|███████▏  | 719/1001 [47:33<11:12,  2.38s/it, avg loss=187.9573]
Training iteration:  72%|███████▏  | 720/1001 [47:33<10:49,  2.31s/it, avg loss=187.9573]Checkpoint at iteration 720 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 187.95728073120117

Training iteration:  72%|███████▏  | 720/1001 [47:35<10:49,  2.31s/it, avg loss=143.8998]
Training iteration:  72%|███████▏  | 721/1001 [47:35<10:33,  2.26s/it, avg loss=143.8998]Checkpoint at iteration 721 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 143.89975776672364

Training iteration:  72%|███████▏  | 721/1001 [47:37<10:33,  2.26s/it, avg loss=140.3828]
Training iteration:  72%|███████▏  | 722/1001 [47:37<10:21,  2.23s/it, avg loss=140.3828]Checkpoint at iteration 722 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 140.38275032043458

Training iteration:  72%|███████▏  | 722/1001 [47:39<10:21,  2.23s/it, avg loss=195.3904]
Training iteration:  72%|███████▏  | 723/1001 [47:39<10:12,  2.20s/it, avg loss=195.3904]Checkpoint at iteration 723 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 195.39037322998047

Training iteration:  72%|███████▏  | 723/1001 [47:42<10:12,  2.20s/it, avg loss=165.0107]
Training iteration:  72%|███████▏  | 724/1001 [47:42<10:05,  2.19s/it, avg loss=165.0107]Checkpoint at iteration 724 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 165.01072158813477

Training iteration:  72%|███████▏  | 724/1001 [47:44<10:05,  2.19s/it, avg loss=151.2839]
Training iteration:  72%|███████▏  | 725/1001 [47:44<09:59,  2.17s/it, avg loss=151.2839]Checkpoint at iteration 725 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 151.2838924407959

Training iteration:  72%|███████▏  | 725/1001 [47:46<09:59,  2.17s/it, avg loss=150.1221]
Training iteration:  73%|███████▎  | 726/1001 [47:46<09:55,  2.17s/it, avg loss=150.1221]Checkpoint at iteration 726 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 150.1221492767334

Training iteration:  73%|███████▎  | 726/1001 [47:48<09:55,  2.17s/it, avg loss=109.8640]
Training iteration:  73%|███████▎  | 727/1001 [47:48<09:51,  2.16s/it, avg loss=109.8640]Checkpoint at iteration 727 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 109.86398963928222

Training iteration:  73%|███████▎  | 727/1001 [47:50<09:51,  2.16s/it, avg loss=132.0570]
Training iteration:  73%|███████▎  | 728/1001 [47:50<09:50,  2.16s/it, avg loss=132.0570]Checkpoint at iteration 728 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 132.05695457458495

Training iteration:  73%|███████▎  | 728/1001 [47:52<09:50,  2.16s/it, avg loss=193.0093]
Training iteration:  73%|███████▎  | 729/1001 [47:52<09:48,  2.17s/it, avg loss=193.0093]Checkpoint at iteration 729 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 193.00927352905273

Training iteration:  73%|███████▎  | 729/1001 [47:54<09:48,  2.17s/it, avg loss=211.4024]
Training iteration:  73%|███████▎  | 730/1001 [47:54<09:47,  2.17s/it, avg loss=211.4024]Checkpoint at iteration 730 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 211.40243339538574

Training iteration:  73%|███████▎  | 730/1001 [47:57<09:47,  2.17s/it, avg loss=165.0645]
Training iteration:  73%|███████▎  | 731/1001 [47:57<09:46,  2.17s/it, avg loss=165.0645]Checkpoint at iteration 731 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 165.06451492309571

Training iteration:  73%|███████▎  | 731/1001 [47:59<09:46,  2.17s/it, avg loss=166.5235]
Training iteration:  73%|███████▎  | 732/1001 [47:59<09:44,  2.17s/it, avg loss=166.5235]Checkpoint at iteration 732 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 166.52354927062987

Training iteration:  73%|███████▎  | 732/1001 [48:01<09:44,  2.17s/it, avg loss=185.2066]
Training iteration:  73%|███████▎  | 733/1001 [48:01<09:42,  2.17s/it, avg loss=185.2066]Checkpoint at iteration 733 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 185.20661468505858

Training iteration:  73%|███████▎  | 733/1001 [48:03<09:42,  2.17s/it, avg loss=225.1520]
Training iteration:  73%|███████▎  | 734/1001 [48:03<09:40,  2.18s/it, avg loss=225.1520]Checkpoint at iteration 734 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 225.1519634246826

Training iteration:  73%|███████▎  | 734/1001 [48:05<09:40,  2.18s/it, avg loss=190.6922]
Training iteration:  73%|███████▎  | 735/1001 [48:05<09:38,  2.17s/it, avg loss=190.6922]Checkpoint at iteration 735 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 190.69220237731935

Training iteration:  73%|███████▎  | 735/1001 [48:08<09:38,  2.17s/it, avg loss=184.2540]
Training iteration:  74%|███████▎  | 736/1001 [48:08<09:36,  2.18s/it, avg loss=184.2540]Checkpoint at iteration 736 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 184.2540096282959

Training iteration:  74%|███████▎  | 736/1001 [48:10<09:36,  2.18s/it, avg loss=164.9199]
Training iteration:  74%|███████▎  | 737/1001 [48:10<09:34,  2.18s/it, avg loss=164.9199]Checkpoint at iteration 737 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 164.91987991333008

Training iteration:  74%|███████▎  | 737/1001 [48:12<09:34,  2.18s/it, avg loss=117.6846]
Training iteration:  74%|███████▎  | 738/1001 [48:12<09:32,  2.18s/it, avg loss=117.6846]Checkpoint at iteration 738 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 117.6845645904541

Training iteration:  74%|███████▎  | 738/1001 [48:14<09:32,  2.18s/it, avg loss=220.3194]
Training iteration:  74%|███████▍  | 739/1001 [48:14<09:30,  2.18s/it, avg loss=220.3194]Checkpoint at iteration 739 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 220.31935119628906

Training iteration:  74%|███████▍  | 739/1001 [48:16<09:30,  2.18s/it, avg loss=204.4779]
Training iteration:  74%|███████▍  | 740/1001 [48:16<09:28,  2.18s/it, avg loss=204.4779]Checkpoint at iteration 740 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 204.4778709411621

Training iteration:  74%|███████▍  | 740/1001 [48:18<09:28,  2.18s/it, avg loss=153.7874]
Training iteration:  74%|███████▍  | 741/1001 [48:18<09:26,  2.18s/it, avg loss=153.7874]Checkpoint at iteration 741 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 153.78740692138672

Training iteration:  74%|███████▍  | 741/1001 [48:21<09:26,  2.18s/it, avg loss=170.4289]
Training iteration:  74%|███████▍  | 742/1001 [48:21<09:24,  2.18s/it, avg loss=170.4289]Checkpoint at iteration 742 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 170.42886962890626

Training iteration:  74%|███████▍  | 742/1001 [48:23<09:24,  2.18s/it, avg loss=165.8982]
Training iteration:  74%|███████▍  | 743/1001 [48:23<09:21,  2.18s/it, avg loss=165.8982]Checkpoint at iteration 743 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 165.89817848205567

Training iteration:  74%|███████▍  | 743/1001 [48:25<09:21,  2.18s/it, avg loss=135.0358]
Training iteration:  74%|███████▍  | 744/1001 [48:25<09:19,  2.18s/it, avg loss=135.0358]Checkpoint at iteration 744 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 135.035786819458

Training iteration:  74%|███████▍  | 744/1001 [48:27<09:19,  2.18s/it, avg loss=150.8315]
Training iteration:  74%|███████▍  | 745/1001 [48:27<09:16,  2.17s/it, avg loss=150.8315]Checkpoint at iteration 745 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 150.83150100708008

Training iteration:  74%|███████▍  | 745/1001 [48:29<09:16,  2.17s/it, avg loss=165.2897]
Training iteration:  75%|███████▍  | 746/1001 [48:29<09:12,  2.17s/it, avg loss=165.2897]Checkpoint at iteration 746 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 165.28973541259765

Training iteration:  75%|███████▍  | 746/1001 [48:31<09:12,  2.17s/it, avg loss=165.0055]
Training iteration:  75%|███████▍  | 747/1001 [48:31<09:08,  2.16s/it, avg loss=165.0055]Checkpoint at iteration 747 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 165.00553779602052

Training iteration:  75%|███████▍  | 747/1001 [48:34<09:08,  2.16s/it, avg loss=131.8213]
Training iteration:  75%|███████▍  | 748/1001 [48:34<09:05,  2.16s/it, avg loss=131.8213]Checkpoint at iteration 748 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 131.82134437561035

Training iteration:  75%|███████▍  | 748/1001 [48:36<09:05,  2.16s/it, avg loss=174.9501]
Training iteration:  75%|███████▍  | 749/1001 [48:36<09:02,  2.15s/it, avg loss=174.9501]Checkpoint at iteration 749 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 174.95010643005372

Training iteration:  75%|███████▍  | 749/1001 [48:38<09:02,  2.15s/it, avg loss=137.4666]
Training iteration:  75%|███████▍  | 750/1001 [48:38<08:59,  2.15s/it, avg loss=137.4666]Checkpoint at iteration 750 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 137.46659469604492

Training iteration:  75%|███████▍  | 750/1001 [48:40<08:59,  2.15s/it, avg loss=138.8650]
Training iteration:  75%|███████▌  | 751/1001 [48:40<08:57,  2.15s/it, avg loss=138.8650]Checkpoint at iteration 751 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 138.8650089263916

Training iteration:  75%|███████▌  | 751/1001 [48:42<08:57,  2.15s/it, avg loss=193.2010]
Training iteration:  75%|███████▌  | 752/1001 [48:42<08:56,  2.15s/it, avg loss=193.2010]Checkpoint at iteration 752 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 193.2010482788086

Training iteration:  75%|███████▌  | 752/1001 [48:44<08:56,  2.15s/it, avg loss=153.6197]
Training iteration:  75%|███████▌  | 753/1001 [48:44<08:55,  2.16s/it, avg loss=153.6197]Checkpoint at iteration 753 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 153.6197311401367

Training iteration:  75%|███████▌  | 753/1001 [48:46<08:55,  2.16s/it, avg loss=132.9676]
Training iteration:  75%|███████▌  | 754/1001 [48:46<08:54,  2.16s/it, avg loss=132.9676]Checkpoint at iteration 754 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 132.96762390136718

Training iteration:  75%|███████▌  | 754/1001 [48:49<08:54,  2.16s/it, avg loss=130.0534]
Training iteration:  75%|███████▌  | 755/1001 [48:49<08:53,  2.17s/it, avg loss=130.0534]Checkpoint at iteration 755 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 130.0533561706543

Training iteration:  75%|███████▌  | 755/1001 [48:51<08:53,  2.17s/it, avg loss=127.4087]
Training iteration:  76%|███████▌  | 756/1001 [48:51<08:51,  2.17s/it, avg loss=127.4087]Checkpoint at iteration 756 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 127.40872535705566

Training iteration:  76%|███████▌  | 756/1001 [48:53<08:51,  2.17s/it, avg loss=163.5342]
Training iteration:  76%|███████▌  | 757/1001 [48:53<08:48,  2.17s/it, avg loss=163.5342]Checkpoint at iteration 757 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 163.53417358398437

Training iteration:  76%|███████▌  | 757/1001 [48:55<08:48,  2.17s/it, avg loss=152.8005]
Training iteration:  76%|███████▌  | 758/1001 [48:55<08:46,  2.17s/it, avg loss=152.8005]Checkpoint at iteration 758 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 152.80049667358398

Training iteration:  76%|███████▌  | 758/1001 [48:57<08:46,  2.17s/it, avg loss=112.9372]
Training iteration:  76%|███████▌  | 759/1001 [48:57<08:44,  2.17s/it, avg loss=112.9372]Checkpoint at iteration 759 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 112.93719482421875

Training iteration:  76%|███████▌  | 759/1001 [49:00<08:44,  2.17s/it, avg loss=158.6953]
Training iteration:  76%|███████▌  | 760/1001 [49:00<08:42,  2.17s/it, avg loss=158.6953]Checkpoint at iteration 760 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 158.69534072875976

Training iteration:  76%|███████▌  | 760/1001 [49:02<08:42,  2.17s/it, avg loss=137.6136]
Training iteration:  76%|███████▌  | 761/1001 [49:02<08:39,  2.17s/it, avg loss=137.6136]Checkpoint at iteration 761 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 137.61361198425294

Training iteration:  76%|███████▌  | 761/1001 [49:04<08:39,  2.17s/it, avg loss=219.5225]
Training iteration:  76%|███████▌  | 762/1001 [49:04<08:37,  2.17s/it, avg loss=219.5225]Checkpoint at iteration 762 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 219.52250175476075

Training iteration:  76%|███████▌  | 762/1001 [49:06<08:37,  2.17s/it, avg loss=191.9209]
Training iteration:  76%|███████▌  | 763/1001 [49:06<08:35,  2.17s/it, avg loss=191.9209]Checkpoint at iteration 763 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 191.92088012695314

Training iteration:  76%|███████▌  | 763/1001 [49:08<08:35,  2.17s/it, avg loss=143.2070]
Training iteration:  76%|███████▋  | 764/1001 [49:08<08:33,  2.17s/it, avg loss=143.2070]Checkpoint at iteration 764 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 143.20702209472657

Training iteration:  76%|███████▋  | 764/1001 [49:10<08:33,  2.17s/it, avg loss=243.7598]
Training iteration:  76%|███████▋  | 765/1001 [49:10<08:30,  2.16s/it, avg loss=243.7598]Checkpoint at iteration 765 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 243.7598098754883

Training iteration:  76%|███████▋  | 765/1001 [49:12<08:30,  2.16s/it, avg loss=184.3237]
Training iteration:  77%|███████▋  | 766/1001 [49:12<08:28,  2.16s/it, avg loss=184.3237]Checkpoint at iteration 766 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 184.32372245788574

Training iteration:  77%|███████▋  | 766/1001 [49:15<08:28,  2.16s/it, avg loss=200.2896]
Training iteration:  77%|███████▋  | 767/1001 [49:15<08:26,  2.16s/it, avg loss=200.2896]Checkpoint at iteration 767 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 200.28963890075684

Training iteration:  77%|███████▋  | 767/1001 [49:17<08:26,  2.16s/it, avg loss=195.9941]
Training iteration:  77%|███████▋  | 768/1001 [49:17<08:24,  2.16s/it, avg loss=195.9941]Checkpoint at iteration 768 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 195.99405822753906

Training iteration:  77%|███████▋  | 768/1001 [49:19<08:24,  2.16s/it, avg loss=144.5059]
Training iteration:  77%|███████▋  | 769/1001 [49:19<08:22,  2.17s/it, avg loss=144.5059]Checkpoint at iteration 769 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 144.50587196350097

Training iteration:  77%|███████▋  | 769/1001 [49:21<08:22,  2.17s/it, avg loss=224.8392]
Training iteration:  77%|███████▋  | 770/1001 [49:21<08:20,  2.17s/it, avg loss=224.8392]Checkpoint at iteration 770 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 224.83922386169434

Training iteration:  77%|███████▋  | 770/1001 [49:23<08:20,  2.17s/it, avg loss=127.7125]
Training iteration:  77%|███████▋  | 771/1001 [49:23<08:18,  2.17s/it, avg loss=127.7125]Checkpoint at iteration 771 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 127.71248435974121

Training iteration:  77%|███████▋  | 771/1001 [49:25<08:18,  2.17s/it, avg loss=130.8382]
Training iteration:  77%|███████▋  | 772/1001 [49:25<08:16,  2.17s/it, avg loss=130.8382]Checkpoint at iteration 772 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 130.8382255554199

Training iteration:  77%|███████▋  | 772/1001 [49:28<08:16,  2.17s/it, avg loss=197.2579]
Training iteration:  77%|███████▋  | 773/1001 [49:28<08:13,  2.17s/it, avg loss=197.2579]Checkpoint at iteration 773 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 197.25792541503907

Training iteration:  77%|███████▋  | 773/1001 [49:30<08:13,  2.17s/it, avg loss=211.0453]
Training iteration:  77%|███████▋  | 774/1001 [49:30<08:11,  2.17s/it, avg loss=211.0453]Checkpoint at iteration 774 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 211.0452781677246

Training iteration:  77%|███████▋  | 774/1001 [49:32<08:11,  2.17s/it, avg loss=172.9403]
Training iteration:  77%|███████▋  | 775/1001 [49:32<08:09,  2.17s/it, avg loss=172.9403]Checkpoint at iteration 775 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 172.9402675628662

Training iteration:  77%|███████▋  | 775/1001 [49:34<08:09,  2.17s/it, avg loss=152.0729]
Training iteration:  78%|███████▊  | 776/1001 [49:34<08:07,  2.17s/it, avg loss=152.0729]Checkpoint at iteration 776 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 152.07292785644532

Training iteration:  78%|███████▊  | 776/1001 [49:36<08:07,  2.17s/it, avg loss=89.5479] 
Training iteration:  78%|███████▊  | 777/1001 [49:36<08:05,  2.17s/it, avg loss=89.5479]Checkpoint at iteration 777 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 89.54788589477539

Training iteration:  78%|███████▊  | 777/1001 [49:38<08:05,  2.17s/it, avg loss=109.7614]
Training iteration:  78%|███████▊  | 778/1001 [49:38<08:03,  2.17s/it, avg loss=109.7614]Checkpoint at iteration 778 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 109.76140785217285

Training iteration:  78%|███████▊  | 778/1001 [49:41<08:03,  2.17s/it, avg loss=120.8132]
Training iteration:  78%|███████▊  | 779/1001 [49:41<08:00,  2.17s/it, avg loss=120.8132]Checkpoint at iteration 779 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 120.81321182250977

Training iteration:  78%|███████▊  | 779/1001 [49:43<08:00,  2.17s/it, avg loss=166.0069]
Training iteration:  78%|███████▊  | 780/1001 [49:43<07:58,  2.16s/it, avg loss=166.0069]Checkpoint at iteration 780 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 166.0068717956543

Training iteration:  78%|███████▊  | 780/1001 [49:45<07:58,  2.16s/it, avg loss=166.2334]
Training iteration:  78%|███████▊  | 781/1001 [49:45<07:56,  2.16s/it, avg loss=166.2334]Checkpoint at iteration 781 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 166.23336791992188

Training iteration:  78%|███████▊  | 781/1001 [49:47<07:56,  2.16s/it, avg loss=164.5152]
Training iteration:  78%|███████▊  | 782/1001 [49:47<07:53,  2.16s/it, avg loss=164.5152]Checkpoint at iteration 782 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 164.515234375

Training iteration:  78%|███████▊  | 782/1001 [49:49<07:53,  2.16s/it, avg loss=152.5024]
Training iteration:  78%|███████▊  | 783/1001 [49:49<07:51,  2.16s/it, avg loss=152.5024]Checkpoint at iteration 783 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 152.50241317749024

Training iteration:  78%|███████▊  | 783/1001 [49:51<07:51,  2.16s/it, avg loss=151.6022]
Training iteration:  78%|███████▊  | 784/1001 [49:51<07:49,  2.16s/it, avg loss=151.6022]Checkpoint at iteration 784 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 151.60222396850585

Training iteration:  78%|███████▊  | 784/1001 [49:54<07:49,  2.16s/it, avg loss=177.4330]
Training iteration:  78%|███████▊  | 785/1001 [49:54<07:47,  2.16s/it, avg loss=177.4330]Checkpoint at iteration 785 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 177.4329563140869

Training iteration:  78%|███████▊  | 785/1001 [49:56<07:47,  2.16s/it, avg loss=150.0204]
Training iteration:  79%|███████▊  | 786/1001 [49:56<07:45,  2.16s/it, avg loss=150.0204]Checkpoint at iteration 786 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 150.02043228149415

Training iteration:  79%|███████▊  | 786/1001 [49:58<07:45,  2.16s/it, avg loss=169.6577]
Training iteration:  79%|███████▊  | 787/1001 [49:58<07:43,  2.16s/it, avg loss=169.6577]Checkpoint at iteration 787 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 169.65773086547853

Training iteration:  79%|███████▊  | 787/1001 [50:00<07:43,  2.16s/it, avg loss=133.4159]
Training iteration:  79%|███████▊  | 788/1001 [50:00<07:41,  2.16s/it, avg loss=133.4159]Checkpoint at iteration 788 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 133.4159393310547

Training iteration:  79%|███████▊  | 788/1001 [50:02<07:41,  2.16s/it, avg loss=171.2333]
Training iteration:  79%|███████▉  | 789/1001 [50:02<07:38,  2.16s/it, avg loss=171.2333]Checkpoint at iteration 789 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 171.23334655761718

Training iteration:  79%|███████▉  | 789/1001 [50:04<07:38,  2.16s/it, avg loss=180.0898]
Training iteration:  79%|███████▉  | 790/1001 [50:04<07:36,  2.16s/it, avg loss=180.0898]Checkpoint at iteration 790 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 180.08977699279785

Training iteration:  79%|███████▉  | 790/1001 [50:07<07:36,  2.16s/it, avg loss=162.3728]
Training iteration:  79%|███████▉  | 791/1001 [50:07<07:34,  2.16s/it, avg loss=162.3728]Checkpoint at iteration 791 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 162.37281532287597

Training iteration:  79%|███████▉  | 791/1001 [50:09<07:34,  2.16s/it, avg loss=132.2338]
Training iteration:  79%|███████▉  | 792/1001 [50:09<07:31,  2.16s/it, avg loss=132.2338]Checkpoint at iteration 792 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 132.2337860107422

Training iteration:  79%|███████▉  | 792/1001 [50:11<07:31,  2.16s/it, avg loss=138.9473]
Training iteration:  79%|███████▉  | 793/1001 [50:11<07:29,  2.16s/it, avg loss=138.9473]Checkpoint at iteration 793 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 138.94733276367188

Training iteration:  79%|███████▉  | 793/1001 [50:13<07:29,  2.16s/it, avg loss=164.3379]
Training iteration:  79%|███████▉  | 794/1001 [50:13<07:27,  2.16s/it, avg loss=164.3379]Checkpoint at iteration 794 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 164.33791885375976

Training iteration:  79%|███████▉  | 794/1001 [50:15<07:27,  2.16s/it, avg loss=182.0335]
Training iteration:  79%|███████▉  | 795/1001 [50:15<07:25,  2.16s/it, avg loss=182.0335]Checkpoint at iteration 795 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 182.03351135253905

Training iteration:  79%|███████▉  | 795/1001 [50:17<07:25,  2.16s/it, avg loss=132.9136]
Training iteration:  80%|███████▉  | 796/1001 [50:17<07:23,  2.16s/it, avg loss=132.9136]Checkpoint at iteration 796 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 132.91363449096679

Training iteration:  80%|███████▉  | 796/1001 [50:20<07:23,  2.16s/it, avg loss=119.7079]
Training iteration:  80%|███████▉  | 797/1001 [50:20<07:21,  2.17s/it, avg loss=119.7079]Checkpoint at iteration 797 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 119.70787315368652

Training iteration:  80%|███████▉  | 797/1001 [50:22<07:21,  2.17s/it, avg loss=142.2958]
Training iteration:  80%|███████▉  | 798/1001 [50:22<07:19,  2.17s/it, avg loss=142.2958]Checkpoint at iteration 798 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 142.29579315185546

Training iteration:  80%|███████▉  | 798/1001 [50:24<07:19,  2.17s/it, avg loss=181.0424]
Training iteration:  80%|███████▉  | 799/1001 [50:24<07:17,  2.17s/it, avg loss=181.0424]Checkpoint at iteration 799 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 181.04236869812013

Training iteration:  80%|███████▉  | 799/1001 [50:26<07:17,  2.17s/it, avg loss=86.7528] 
Training iteration:  80%|███████▉  | 800/1001 [50:26<07:15,  2.17s/it, avg loss=86.7528]Optimization iteration 800 evaluation begins...
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
A new evaluation visualization has been saved: ./saved_data/20240110-081107/it800.png
Training network 0 for evaluation...
Training network 1 for evaluation...
Training network 2 for evaluation...
Training network 3 for evaluation...
Testing network 0 on real datasets for evaluation...
Testing network 1 on real datasets for evaluation...
Testing network 2 on real datasets for evaluation...
Testing network 3 on real datasets for evaluation...
Optimization iteration 800, eval auroc score (train): 19595.7188, eval auroc score (test): 20593.6986
Checkpoint at iteration 800 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 86.75280723571777

Training iteration:  80%|███████▉  | 800/1001 [59:53<07:15,  2.17s/it, avg loss=178.2311]
Training iteration:  80%|████████  | 801/1001 [59:53<9:32:09, 171.65s/it, avg loss=178.2311]Checkpoint at iteration 801 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 178.23111419677736

Training iteration:  80%|████████  | 801/1001 [59:56<9:32:09, 171.65s/it, avg loss=167.5534]
Training iteration:  80%|████████  | 802/1001 [59:56<6:40:51, 120.86s/it, avg loss=167.5534]Checkpoint at iteration 802 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 167.55337104797363

Training iteration:  80%|████████  | 802/1001 [59:58<6:40:51, 120.86s/it, avg loss=116.3797]
Training iteration:  80%|████████  | 803/1001 [59:58<4:41:32, 85.31s/it, avg loss=116.3797] Checkpoint at iteration 803 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 116.37973480224609

Training iteration:  80%|████████  | 803/1001 [1:00:00<4:41:32, 85.31s/it, avg loss=131.7952]
Training iteration:  80%|████████  | 804/1001 [1:00:00<3:18:24, 60.43s/it, avg loss=131.7952]Checkpoint at iteration 804 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 131.79522094726562

Training iteration:  80%|████████  | 804/1001 [1:00:03<3:18:24, 60.43s/it, avg loss=144.3929]
Training iteration:  80%|████████  | 805/1001 [1:00:03<2:20:30, 43.01s/it, avg loss=144.3929]Checkpoint at iteration 805 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 144.39288330078125

Training iteration:  80%|████████  | 805/1001 [1:00:05<2:20:30, 43.01s/it, avg loss=127.5453]
Training iteration:  81%|████████  | 806/1001 [1:00:05<1:40:10, 30.82s/it, avg loss=127.5453]Checkpoint at iteration 806 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 127.5452880859375

Training iteration:  81%|████████  | 806/1001 [1:00:07<1:40:10, 30.82s/it, avg loss=172.7713]
Training iteration:  81%|████████  | 807/1001 [1:00:07<1:12:03, 22.28s/it, avg loss=172.7713]Checkpoint at iteration 807 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 172.77133255004884

Training iteration:  81%|████████  | 807/1001 [1:00:10<1:12:03, 22.28s/it, avg loss=150.5175]
Training iteration:  81%|████████  | 808/1001 [1:00:10<52:28, 16.31s/it, avg loss=150.5175]  Checkpoint at iteration 808 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 150.51750144958496

Training iteration:  81%|████████  | 808/1001 [1:00:12<52:28, 16.31s/it, avg loss=163.2949]
Training iteration:  81%|████████  | 809/1001 [1:00:12<38:48, 12.13s/it, avg loss=163.2949]Checkpoint at iteration 809 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 163.29488677978514

Training iteration:  81%|████████  | 809/1001 [1:00:15<38:48, 12.13s/it, avg loss=178.0625]
Training iteration:  81%|████████  | 810/1001 [1:00:15<29:17,  9.20s/it, avg loss=178.0625]Checkpoint at iteration 810 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 178.0624572753906

Training iteration:  81%|████████  | 810/1001 [1:00:17<29:17,  9.20s/it, avg loss=153.3089]
Training iteration:  81%|████████  | 811/1001 [1:00:17<22:38,  7.15s/it, avg loss=153.3089]Checkpoint at iteration 811 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 153.30886993408203

Training iteration:  81%|████████  | 811/1001 [1:00:19<22:38,  7.15s/it, avg loss=217.0601]
Training iteration:  81%|████████  | 812/1001 [1:00:19<18:00,  5.71s/it, avg loss=217.0601]Checkpoint at iteration 812 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 217.06010627746582

Training iteration:  81%|████████  | 812/1001 [1:00:22<18:00,  5.71s/it, avg loss=197.0997]
Training iteration:  81%|████████  | 813/1001 [1:00:22<14:45,  4.71s/it, avg loss=197.0997]Checkpoint at iteration 813 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 197.09965858459472

Training iteration:  81%|████████  | 813/1001 [1:00:24<14:45,  4.71s/it, avg loss=131.7664]
Training iteration:  81%|████████▏ | 814/1001 [1:00:24<12:29,  4.01s/it, avg loss=131.7664]Checkpoint at iteration 814 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 131.76642036437988

Training iteration:  81%|████████▏ | 814/1001 [1:00:26<12:29,  4.01s/it, avg loss=162.2139]
Training iteration:  81%|████████▏ | 815/1001 [1:00:26<10:53,  3.51s/it, avg loss=162.2139]Checkpoint at iteration 815 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 162.21388931274413

Training iteration:  81%|████████▏ | 815/1001 [1:00:29<10:53,  3.51s/it, avg loss=127.4954]
Training iteration:  82%|████████▏ | 816/1001 [1:00:29<09:46,  3.17s/it, avg loss=127.4954]Checkpoint at iteration 816 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 127.49544067382813

Training iteration:  82%|████████▏ | 816/1001 [1:00:31<09:46,  3.17s/it, avg loss=127.7079]
Training iteration:  82%|████████▏ | 817/1001 [1:00:31<08:58,  2.93s/it, avg loss=127.7079]Checkpoint at iteration 817 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 127.70787239074707

Training iteration:  82%|████████▏ | 817/1001 [1:00:33<08:58,  2.93s/it, avg loss=213.7784]
Training iteration:  82%|████████▏ | 818/1001 [1:00:33<08:24,  2.76s/it, avg loss=213.7784]Checkpoint at iteration 818 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 213.77836990356445

Training iteration:  82%|████████▏ | 818/1001 [1:00:36<08:24,  2.76s/it, avg loss=147.0244]
Training iteration:  82%|████████▏ | 819/1001 [1:00:36<08:00,  2.64s/it, avg loss=147.0244]Checkpoint at iteration 819 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 147.02440910339357

Training iteration:  82%|████████▏ | 819/1001 [1:00:38<08:00,  2.64s/it, avg loss=144.7872]
Training iteration:  82%|████████▏ | 820/1001 [1:00:38<07:42,  2.56s/it, avg loss=144.7872]Checkpoint at iteration 820 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 144.78720741271974

Training iteration:  82%|████████▏ | 820/1001 [1:00:41<07:42,  2.56s/it, avg loss=174.1476]
Training iteration:  82%|████████▏ | 821/1001 [1:00:41<07:29,  2.50s/it, avg loss=174.1476]Checkpoint at iteration 821 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 174.1476043701172

Training iteration:  82%|████████▏ | 821/1001 [1:00:43<07:29,  2.50s/it, avg loss=181.9829]
Training iteration:  82%|████████▏ | 822/1001 [1:00:43<07:19,  2.46s/it, avg loss=181.9829]Checkpoint at iteration 822 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 181.98294792175292

Training iteration:  82%|████████▏ | 822/1001 [1:00:45<07:19,  2.46s/it, avg loss=218.7943]
Training iteration:  82%|████████▏ | 823/1001 [1:00:45<07:12,  2.43s/it, avg loss=218.7943]Checkpoint at iteration 823 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 218.79430923461913

Training iteration:  82%|████████▏ | 823/1001 [1:00:48<07:12,  2.43s/it, avg loss=118.6411]
Training iteration:  82%|████████▏ | 824/1001 [1:00:48<07:06,  2.41s/it, avg loss=118.6411]Checkpoint at iteration 824 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 118.64111099243163

Training iteration:  82%|████████▏ | 824/1001 [1:00:50<07:06,  2.41s/it, avg loss=88.0879] 
Training iteration:  82%|████████▏ | 825/1001 [1:00:50<07:01,  2.39s/it, avg loss=88.0879]Checkpoint at iteration 825 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 88.08788146972657

Training iteration:  82%|████████▏ | 825/1001 [1:00:52<07:01,  2.39s/it, avg loss=131.7599]
Training iteration:  83%|████████▎ | 826/1001 [1:00:52<06:57,  2.39s/it, avg loss=131.7599]Checkpoint at iteration 826 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 131.75994300842285

Training iteration:  83%|████████▎ | 826/1001 [1:00:55<06:57,  2.39s/it, avg loss=192.4992]
Training iteration:  83%|████████▎ | 827/1001 [1:00:55<06:54,  2.38s/it, avg loss=192.4992]Checkpoint at iteration 827 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 192.49924354553224

Training iteration:  83%|████████▎ | 827/1001 [1:00:57<06:54,  2.38s/it, avg loss=159.5599]
Training iteration:  83%|████████▎ | 828/1001 [1:00:57<06:50,  2.38s/it, avg loss=159.5599]Checkpoint at iteration 828 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 159.55994911193847

Training iteration:  83%|████████▎ | 828/1001 [1:00:59<06:50,  2.38s/it, avg loss=126.2397]
Training iteration:  83%|████████▎ | 829/1001 [1:00:59<06:47,  2.37s/it, avg loss=126.2397]Checkpoint at iteration 829 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 126.23966369628906

Training iteration:  83%|████████▎ | 829/1001 [1:01:02<06:47,  2.37s/it, avg loss=147.7262]
Training iteration:  83%|████████▎ | 830/1001 [1:01:02<06:45,  2.37s/it, avg loss=147.7262]Checkpoint at iteration 830 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 147.7262050628662

Training iteration:  83%|████████▎ | 830/1001 [1:01:04<06:45,  2.37s/it, avg loss=181.5986]
Training iteration:  83%|████████▎ | 831/1001 [1:01:04<06:42,  2.37s/it, avg loss=181.5986]Checkpoint at iteration 831 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 181.5986312866211

Training iteration:  83%|████████▎ | 831/1001 [1:01:07<06:42,  2.37s/it, avg loss=141.7047]
Training iteration:  83%|████████▎ | 832/1001 [1:01:07<06:40,  2.37s/it, avg loss=141.7047]Checkpoint at iteration 832 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 141.70469589233397

Training iteration:  83%|████████▎ | 832/1001 [1:01:09<06:40,  2.37s/it, avg loss=144.0509]
Training iteration:  83%|████████▎ | 833/1001 [1:01:09<06:37,  2.37s/it, avg loss=144.0509]Checkpoint at iteration 833 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 144.05089530944824

Training iteration:  83%|████████▎ | 833/1001 [1:01:11<06:37,  2.37s/it, avg loss=192.4813]
Training iteration:  83%|████████▎ | 834/1001 [1:01:11<06:35,  2.37s/it, avg loss=192.4813]Checkpoint at iteration 834 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 192.48127326965331

Training iteration:  83%|████████▎ | 834/1001 [1:01:14<06:35,  2.37s/it, avg loss=124.9236]
Training iteration:  83%|████████▎ | 835/1001 [1:01:14<06:32,  2.36s/it, avg loss=124.9236]Checkpoint at iteration 835 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 124.92356300354004

Training iteration:  83%|████████▎ | 835/1001 [1:01:16<06:32,  2.36s/it, avg loss=144.9866]
Training iteration:  84%|████████▎ | 836/1001 [1:01:16<06:29,  2.36s/it, avg loss=144.9866]Checkpoint at iteration 836 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 144.9866008758545

Training iteration:  84%|████████▎ | 836/1001 [1:01:18<06:29,  2.36s/it, avg loss=128.8755]
Training iteration:  84%|████████▎ | 837/1001 [1:01:18<06:27,  2.36s/it, avg loss=128.8755]Checkpoint at iteration 837 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 128.8754669189453

Training iteration:  84%|████████▎ | 837/1001 [1:01:21<06:27,  2.36s/it, avg loss=197.6199]
Training iteration:  84%|████████▎ | 838/1001 [1:01:21<06:25,  2.36s/it, avg loss=197.6199]Checkpoint at iteration 838 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 197.61985206604004

Training iteration:  84%|████████▎ | 838/1001 [1:01:23<06:25,  2.36s/it, avg loss=172.4918]
Training iteration:  84%|████████▍ | 839/1001 [1:01:23<06:22,  2.36s/it, avg loss=172.4918]Checkpoint at iteration 839 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 172.49176216125488

Training iteration:  84%|████████▍ | 839/1001 [1:01:25<06:22,  2.36s/it, avg loss=176.8740]
Training iteration:  84%|████████▍ | 840/1001 [1:01:25<06:20,  2.36s/it, avg loss=176.8740]Checkpoint at iteration 840 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 176.87402801513673

Training iteration:  84%|████████▍ | 840/1001 [1:01:28<06:20,  2.36s/it, avg loss=94.4643] 
Training iteration:  84%|████████▍ | 841/1001 [1:01:28<06:17,  2.36s/it, avg loss=94.4643]Checkpoint at iteration 841 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 94.46427345275879

Training iteration:  84%|████████▍ | 841/1001 [1:01:30<06:17,  2.36s/it, avg loss=179.6051]
Training iteration:  84%|████████▍ | 842/1001 [1:01:30<06:15,  2.36s/it, avg loss=179.6051]Checkpoint at iteration 842 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 179.60507621765137

Training iteration:  84%|████████▍ | 842/1001 [1:01:33<06:15,  2.36s/it, avg loss=214.2429]
Training iteration:  84%|████████▍ | 843/1001 [1:01:33<06:13,  2.36s/it, avg loss=214.2429]Checkpoint at iteration 843 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 214.24287490844728

Training iteration:  84%|████████▍ | 843/1001 [1:01:35<06:13,  2.36s/it, avg loss=125.3715]
Training iteration:  84%|████████▍ | 844/1001 [1:01:35<06:10,  2.36s/it, avg loss=125.3715]Checkpoint at iteration 844 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 125.37149505615234

Training iteration:  84%|████████▍ | 844/1001 [1:01:37<06:10,  2.36s/it, avg loss=168.4445]
Training iteration:  84%|████████▍ | 845/1001 [1:01:37<06:08,  2.36s/it, avg loss=168.4445]Checkpoint at iteration 845 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 168.4445430755615

Training iteration:  84%|████████▍ | 845/1001 [1:01:40<06:08,  2.36s/it, avg loss=175.2591]
Training iteration:  85%|████████▍ | 846/1001 [1:01:40<06:05,  2.36s/it, avg loss=175.2591]Checkpoint at iteration 846 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 175.25909614562988

Training iteration:  85%|████████▍ | 846/1001 [1:01:42<06:05,  2.36s/it, avg loss=157.8780]
Training iteration:  85%|████████▍ | 847/1001 [1:01:42<06:03,  2.36s/it, avg loss=157.8780]Checkpoint at iteration 847 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 157.87803916931153

Training iteration:  85%|████████▍ | 847/1001 [1:01:44<06:03,  2.36s/it, avg loss=221.6439]
Training iteration:  85%|████████▍ | 848/1001 [1:01:44<06:01,  2.36s/it, avg loss=221.6439]Checkpoint at iteration 848 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 221.64394607543946

Training iteration:  85%|████████▍ | 848/1001 [1:01:47<06:01,  2.36s/it, avg loss=229.4567]
Training iteration:  85%|████████▍ | 849/1001 [1:01:47<05:59,  2.36s/it, avg loss=229.4567]Checkpoint at iteration 849 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 229.4566707611084

Training iteration:  85%|████████▍ | 849/1001 [1:01:49<05:59,  2.36s/it, avg loss=134.7155]
Training iteration:  85%|████████▍ | 850/1001 [1:01:49<05:56,  2.36s/it, avg loss=134.7155]Checkpoint at iteration 850 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 134.71554222106934

Training iteration:  85%|████████▍ | 850/1001 [1:01:51<05:56,  2.36s/it, avg loss=157.4392]
Training iteration:  85%|████████▌ | 851/1001 [1:01:51<05:54,  2.36s/it, avg loss=157.4392]Checkpoint at iteration 851 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 157.43915138244628

Training iteration:  85%|████████▌ | 851/1001 [1:01:54<05:54,  2.36s/it, avg loss=112.7009]
Training iteration:  85%|████████▌ | 852/1001 [1:01:54<05:51,  2.36s/it, avg loss=112.7009]Checkpoint at iteration 852 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 112.700883102417

Training iteration:  85%|████████▌ | 852/1001 [1:01:56<05:51,  2.36s/it, avg loss=178.6233]
Training iteration:  85%|████████▌ | 853/1001 [1:01:56<05:49,  2.36s/it, avg loss=178.6233]Checkpoint at iteration 853 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 178.62334060668945

Training iteration:  85%|████████▌ | 853/1001 [1:01:58<05:49,  2.36s/it, avg loss=192.1561]
Training iteration:  85%|████████▌ | 854/1001 [1:01:58<05:47,  2.36s/it, avg loss=192.1561]Checkpoint at iteration 854 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 192.15606079101562

Training iteration:  85%|████████▌ | 854/1001 [1:02:01<05:47,  2.36s/it, avg loss=208.5682]
Training iteration:  85%|████████▌ | 855/1001 [1:02:01<05:44,  2.36s/it, avg loss=208.5682]Checkpoint at iteration 855 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 208.56823844909667

Training iteration:  85%|████████▌ | 855/1001 [1:02:03<05:44,  2.36s/it, avg loss=178.6973]
Training iteration:  86%|████████▌ | 856/1001 [1:02:03<05:42,  2.36s/it, avg loss=178.6973]Checkpoint at iteration 856 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 178.69726524353027

Training iteration:  86%|████████▌ | 856/1001 [1:02:06<05:42,  2.36s/it, avg loss=137.0094]
Training iteration:  86%|████████▌ | 857/1001 [1:02:06<05:40,  2.36s/it, avg loss=137.0094]Checkpoint at iteration 857 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 137.00943870544432

Training iteration:  86%|████████▌ | 857/1001 [1:02:08<05:40,  2.36s/it, avg loss=144.2127]
Training iteration:  86%|████████▌ | 858/1001 [1:02:08<05:37,  2.36s/it, avg loss=144.2127]Checkpoint at iteration 858 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 144.2127197265625

Training iteration:  86%|████████▌ | 858/1001 [1:02:10<05:37,  2.36s/it, avg loss=132.0839]
Training iteration:  86%|████████▌ | 859/1001 [1:02:10<05:35,  2.36s/it, avg loss=132.0839]Checkpoint at iteration 859 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 132.08386192321777

Training iteration:  86%|████████▌ | 859/1001 [1:02:13<05:35,  2.36s/it, avg loss=117.9265]
Training iteration:  86%|████████▌ | 860/1001 [1:02:13<05:33,  2.36s/it, avg loss=117.9265]Checkpoint at iteration 860 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 117.92650871276855

Training iteration:  86%|████████▌ | 860/1001 [1:02:15<05:33,  2.36s/it, avg loss=122.1724]
Training iteration:  86%|████████▌ | 861/1001 [1:02:15<05:31,  2.36s/it, avg loss=122.1724]Checkpoint at iteration 861 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 122.17238655090333

Training iteration:  86%|████████▌ | 861/1001 [1:02:17<05:31,  2.36s/it, avg loss=199.9360]
Training iteration:  86%|████████▌ | 862/1001 [1:02:17<05:28,  2.37s/it, avg loss=199.9360]Checkpoint at iteration 862 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 199.93601760864257

Training iteration:  86%|████████▌ | 862/1001 [1:02:20<05:28,  2.37s/it, avg loss=108.9976]
Training iteration:  86%|████████▌ | 863/1001 [1:02:20<05:26,  2.36s/it, avg loss=108.9976]Checkpoint at iteration 863 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 108.99759483337402

Training iteration:  86%|████████▌ | 863/1001 [1:02:22<05:26,  2.36s/it, avg loss=186.1680]
Training iteration:  86%|████████▋ | 864/1001 [1:02:22<05:23,  2.36s/it, avg loss=186.1680]Checkpoint at iteration 864 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 186.16804428100585

Training iteration:  86%|████████▋ | 864/1001 [1:02:24<05:23,  2.36s/it, avg loss=168.6032]
Training iteration:  86%|████████▋ | 865/1001 [1:02:24<05:21,  2.36s/it, avg loss=168.6032]Checkpoint at iteration 865 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 168.60321273803712

Training iteration:  86%|████████▋ | 865/1001 [1:02:27<05:21,  2.36s/it, avg loss=167.8127]
Training iteration:  87%|████████▋ | 866/1001 [1:02:27<05:19,  2.36s/it, avg loss=167.8127]Checkpoint at iteration 866 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 167.81268997192382

Training iteration:  87%|████████▋ | 866/1001 [1:02:29<05:19,  2.36s/it, avg loss=154.8413]
Training iteration:  87%|████████▋ | 867/1001 [1:02:29<05:16,  2.37s/it, avg loss=154.8413]Checkpoint at iteration 867 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 154.84125785827638

Training iteration:  87%|████████▋ | 867/1001 [1:02:32<05:16,  2.37s/it, avg loss=217.8318]
Training iteration:  87%|████████▋ | 868/1001 [1:02:32<05:14,  2.36s/it, avg loss=217.8318]Checkpoint at iteration 868 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 217.8318099975586

Training iteration:  87%|████████▋ | 868/1001 [1:02:34<05:14,  2.36s/it, avg loss=144.5899]
Training iteration:  87%|████████▋ | 869/1001 [1:02:34<05:12,  2.36s/it, avg loss=144.5899]Checkpoint at iteration 869 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 144.58989295959472

Training iteration:  87%|████████▋ | 869/1001 [1:02:36<05:12,  2.36s/it, avg loss=114.5220]
Training iteration:  87%|████████▋ | 870/1001 [1:02:36<05:09,  2.37s/it, avg loss=114.5220]Checkpoint at iteration 870 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 114.52200431823731

Training iteration:  87%|████████▋ | 870/1001 [1:02:39<05:09,  2.37s/it, avg loss=181.8266]
Training iteration:  87%|████████▋ | 871/1001 [1:02:39<05:07,  2.37s/it, avg loss=181.8266]Checkpoint at iteration 871 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 181.82658615112305

Training iteration:  87%|████████▋ | 871/1001 [1:02:41<05:07,  2.37s/it, avg loss=95.3632] 
Training iteration:  87%|████████▋ | 872/1001 [1:02:41<05:05,  2.36s/it, avg loss=95.3632]Checkpoint at iteration 872 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 95.3632194519043

Training iteration:  87%|████████▋ | 872/1001 [1:02:43<05:05,  2.36s/it, avg loss=147.9538]
Training iteration:  87%|████████▋ | 873/1001 [1:02:43<05:02,  2.36s/it, avg loss=147.9538]Checkpoint at iteration 873 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 147.95381774902344

Training iteration:  87%|████████▋ | 873/1001 [1:02:46<05:02,  2.36s/it, avg loss=125.6309]
Training iteration:  87%|████████▋ | 874/1001 [1:02:46<05:00,  2.36s/it, avg loss=125.6309]Checkpoint at iteration 874 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 125.63092193603515

Training iteration:  87%|████████▋ | 874/1001 [1:02:48<05:00,  2.36s/it, avg loss=148.6398]
Training iteration:  87%|████████▋ | 875/1001 [1:02:48<04:57,  2.36s/it, avg loss=148.6398]Checkpoint at iteration 875 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 148.63982543945312

Training iteration:  87%|████████▋ | 875/1001 [1:02:51<04:57,  2.36s/it, avg loss=155.3438]
Training iteration:  88%|████████▊ | 876/1001 [1:02:51<04:55,  2.36s/it, avg loss=155.3438]Checkpoint at iteration 876 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 155.34381179809571

Training iteration:  88%|████████▊ | 876/1001 [1:02:53<04:55,  2.36s/it, avg loss=136.8436]
Training iteration:  88%|████████▊ | 877/1001 [1:02:53<04:53,  2.36s/it, avg loss=136.8436]Checkpoint at iteration 877 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 136.84364852905273

Training iteration:  88%|████████▊ | 877/1001 [1:02:55<04:53,  2.36s/it, avg loss=111.4944]
Training iteration:  88%|████████▊ | 878/1001 [1:02:55<04:50,  2.36s/it, avg loss=111.4944]Checkpoint at iteration 878 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 111.49440231323243

Training iteration:  88%|████████▊ | 878/1001 [1:02:58<04:50,  2.36s/it, avg loss=181.8730]
Training iteration:  88%|████████▊ | 879/1001 [1:02:58<04:48,  2.37s/it, avg loss=181.8730]Checkpoint at iteration 879 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 181.873042678833

Training iteration:  88%|████████▊ | 879/1001 [1:03:00<04:48,  2.37s/it, avg loss=144.8880]
Training iteration:  88%|████████▊ | 880/1001 [1:03:00<04:46,  2.37s/it, avg loss=144.8880]Checkpoint at iteration 880 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 144.8879810333252

Training iteration:  88%|████████▊ | 880/1001 [1:03:02<04:46,  2.37s/it, avg loss=217.0566]
Training iteration:  88%|████████▊ | 881/1001 [1:03:02<04:43,  2.36s/it, avg loss=217.0566]Checkpoint at iteration 881 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 217.05659866333008

Training iteration:  88%|████████▊ | 881/1001 [1:03:05<04:43,  2.36s/it, avg loss=178.1057]
Training iteration:  88%|████████▊ | 882/1001 [1:03:05<04:41,  2.36s/it, avg loss=178.1057]Checkpoint at iteration 882 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 178.10573654174806

Training iteration:  88%|████████▊ | 882/1001 [1:03:07<04:41,  2.36s/it, avg loss=145.8459]
Training iteration:  88%|████████▊ | 883/1001 [1:03:07<04:38,  2.36s/it, avg loss=145.8459]Checkpoint at iteration 883 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 145.84588890075685

Training iteration:  88%|████████▊ | 883/1001 [1:03:09<04:38,  2.36s/it, avg loss=192.8513]
Training iteration:  88%|████████▊ | 884/1001 [1:03:09<04:36,  2.36s/it, avg loss=192.8513]Checkpoint at iteration 884 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 192.85131034851074

Training iteration:  88%|████████▊ | 884/1001 [1:03:12<04:36,  2.36s/it, avg loss=147.1558]
Training iteration:  88%|████████▊ | 885/1001 [1:03:12<04:34,  2.36s/it, avg loss=147.1558]Checkpoint at iteration 885 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 147.15578651428223

Training iteration:  88%|████████▊ | 885/1001 [1:03:14<04:34,  2.36s/it, avg loss=115.1687]
Training iteration:  89%|████████▊ | 886/1001 [1:03:14<04:31,  2.36s/it, avg loss=115.1687]Checkpoint at iteration 886 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 115.16871490478516

Training iteration:  89%|████████▊ | 886/1001 [1:03:17<04:31,  2.36s/it, avg loss=108.1684]
Training iteration:  89%|████████▊ | 887/1001 [1:03:17<04:29,  2.36s/it, avg loss=108.1684]Checkpoint at iteration 887 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 108.16835746765136

Training iteration:  89%|████████▊ | 887/1001 [1:03:19<04:29,  2.36s/it, avg loss=220.6119]
Training iteration:  89%|████████▊ | 888/1001 [1:03:19<04:26,  2.36s/it, avg loss=220.6119]Checkpoint at iteration 888 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 220.61194381713867

Training iteration:  89%|████████▊ | 888/1001 [1:03:21<04:26,  2.36s/it, avg loss=141.5333]
Training iteration:  89%|████████▉ | 889/1001 [1:03:21<04:24,  2.36s/it, avg loss=141.5333]Checkpoint at iteration 889 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 141.53328628540038

Training iteration:  89%|████████▉ | 889/1001 [1:03:24<04:24,  2.36s/it, avg loss=139.8414]
Training iteration:  89%|████████▉ | 890/1001 [1:03:24<04:22,  2.36s/it, avg loss=139.8414]Checkpoint at iteration 890 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 139.84142951965333

Training iteration:  89%|████████▉ | 890/1001 [1:03:26<04:22,  2.36s/it, avg loss=210.2428]
Training iteration:  89%|████████▉ | 891/1001 [1:03:26<04:19,  2.36s/it, avg loss=210.2428]Checkpoint at iteration 891 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 210.24281883239746

Training iteration:  89%|████████▉ | 891/1001 [1:03:28<04:19,  2.36s/it, avg loss=170.9282]
Training iteration:  89%|████████▉ | 892/1001 [1:03:28<04:17,  2.36s/it, avg loss=170.9282]Checkpoint at iteration 892 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 170.9282299041748

Training iteration:  89%|████████▉ | 892/1001 [1:03:31<04:17,  2.36s/it, avg loss=120.0628]
Training iteration:  89%|████████▉ | 893/1001 [1:03:31<04:14,  2.36s/it, avg loss=120.0628]Checkpoint at iteration 893 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 120.06280059814453

Training iteration:  89%|████████▉ | 893/1001 [1:03:33<04:14,  2.36s/it, avg loss=172.6341]
Training iteration:  89%|████████▉ | 894/1001 [1:03:33<04:12,  2.36s/it, avg loss=172.6341]Checkpoint at iteration 894 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 172.6340534210205

Training iteration:  89%|████████▉ | 894/1001 [1:03:35<04:12,  2.36s/it, avg loss=154.1391]
Training iteration:  89%|████████▉ | 895/1001 [1:03:35<04:10,  2.36s/it, avg loss=154.1391]Checkpoint at iteration 895 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 154.1391357421875

Training iteration:  89%|████████▉ | 895/1001 [1:03:38<04:10,  2.36s/it, avg loss=195.4623]
Training iteration:  90%|████████▉ | 896/1001 [1:03:38<04:07,  2.36s/it, avg loss=195.4623]Checkpoint at iteration 896 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 195.4622890472412

Training iteration:  90%|████████▉ | 896/1001 [1:03:40<04:07,  2.36s/it, avg loss=127.5260]
Training iteration:  90%|████████▉ | 897/1001 [1:03:40<04:05,  2.36s/it, avg loss=127.5260]Checkpoint at iteration 897 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 127.52600784301758

Training iteration:  90%|████████▉ | 897/1001 [1:03:42<04:05,  2.36s/it, avg loss=145.5608]
Training iteration:  90%|████████▉ | 898/1001 [1:03:42<04:03,  2.36s/it, avg loss=145.5608]Checkpoint at iteration 898 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 145.56080169677733

Training iteration:  90%|████████▉ | 898/1001 [1:03:45<04:03,  2.36s/it, avg loss=94.0080] 
Training iteration:  90%|████████▉ | 899/1001 [1:03:45<04:00,  2.36s/it, avg loss=94.0080]Checkpoint at iteration 899 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 94.0079559326172

Training iteration:  90%|████████▉ | 899/1001 [1:03:47<04:00,  2.36s/it, avg loss=260.6238]
Training iteration:  90%|████████▉ | 900/1001 [1:03:47<03:58,  2.36s/it, avg loss=260.6238]Optimization iteration 900 evaluation begins...
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
A new evaluation visualization has been saved: ./saved_data/20240110-081107/it900.png
Training network 0 for evaluation...
Training network 1 for evaluation...
Training network 2 for evaluation...
Training network 3 for evaluation...
Testing network 0 on real datasets for evaluation...
Testing network 1 on real datasets for evaluation...
Testing network 2 on real datasets for evaluation...
Testing network 3 on real datasets for evaluation...
Optimization iteration 900, eval auroc score (train): 19630.9440, eval auroc score (test): 20615.3130
Checkpoint at iteration 900 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 260.62379417419436

Training iteration:  90%|████████▉ | 900/1001 [1:14:24<03:58,  2.36s/it, avg loss=162.7554]
Training iteration:  90%|█████████ | 901/1001 [1:14:24<5:21:11, 192.71s/it, avg loss=162.7554]Checkpoint at iteration 901 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 162.7554138183594

Training iteration:  90%|█████████ | 901/1001 [1:14:27<5:21:11, 192.71s/it, avg loss=204.9388]
Training iteration:  90%|█████████ | 902/1001 [1:14:27<3:43:51, 135.68s/it, avg loss=204.9388]Checkpoint at iteration 902 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 204.93883094787597

Training iteration:  90%|█████████ | 902/1001 [1:14:29<3:43:51, 135.68s/it, avg loss=115.0552]
Training iteration:  90%|█████████ | 903/1001 [1:14:29<2:36:23, 95.75s/it, avg loss=115.0552] Checkpoint at iteration 903 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 115.05521202087402

Training iteration:  90%|█████████ | 903/1001 [1:14:32<2:36:23, 95.75s/it, avg loss=198.1291]
Training iteration:  90%|█████████ | 904/1001 [1:14:32<1:49:36, 67.80s/it, avg loss=198.1291]Checkpoint at iteration 904 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 198.12907791137695

Training iteration:  90%|█████████ | 904/1001 [1:14:34<1:49:36, 67.80s/it, avg loss=167.4751]
Training iteration:  90%|█████████ | 905/1001 [1:14:34<1:17:10, 48.24s/it, avg loss=167.4751]Checkpoint at iteration 905 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 167.47508850097657

Training iteration:  90%|█████████ | 905/1001 [1:14:37<1:17:10, 48.24s/it, avg loss=158.4016]
Training iteration:  91%|█████████ | 906/1001 [1:14:37<54:41, 34.54s/it, avg loss=158.4016]  Checkpoint at iteration 906 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 158.40164642333986

Training iteration:  91%|█████████ | 906/1001 [1:14:40<54:41, 34.54s/it, avg loss=229.1834]
Training iteration:  91%|█████████ | 907/1001 [1:14:40<39:05, 24.95s/it, avg loss=229.1834]Checkpoint at iteration 907 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 229.18342170715331

Training iteration:  91%|█████████ | 907/1001 [1:14:42<39:05, 24.95s/it, avg loss=114.7702]
Training iteration:  91%|█████████ | 908/1001 [1:14:42<28:16, 18.24s/it, avg loss=114.7702]Checkpoint at iteration 908 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 114.77019691467285

Training iteration:  91%|█████████ | 908/1001 [1:14:45<28:16, 18.24s/it, avg loss=130.8326]
Training iteration:  91%|█████████ | 909/1001 [1:14:45<20:46, 13.55s/it, avg loss=130.8326]Checkpoint at iteration 909 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 130.83259086608888

Training iteration:  91%|█████████ | 909/1001 [1:14:47<20:46, 13.55s/it, avg loss=79.7453] 
Training iteration:  91%|█████████ | 910/1001 [1:14:47<15:33, 10.26s/it, avg loss=79.7453]Checkpoint at iteration 910 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 79.74530334472657

Training iteration:  91%|█████████ | 910/1001 [1:14:50<15:33, 10.26s/it, avg loss=153.7607]
Training iteration:  91%|█████████ | 911/1001 [1:14:50<11:55,  7.96s/it, avg loss=153.7607]Checkpoint at iteration 911 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 153.76073608398437

Training iteration:  91%|█████████ | 911/1001 [1:14:52<11:55,  7.96s/it, avg loss=159.4497]
Training iteration:  91%|█████████ | 912/1001 [1:14:52<09:24,  6.34s/it, avg loss=159.4497]Checkpoint at iteration 912 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 159.44966087341308

Training iteration:  91%|█████████ | 912/1001 [1:14:55<09:24,  6.34s/it, avg loss=166.3796]
Training iteration:  91%|█████████ | 913/1001 [1:14:55<07:39,  5.22s/it, avg loss=166.3796]Checkpoint at iteration 913 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 166.37961807250977

Training iteration:  91%|█████████ | 913/1001 [1:14:58<07:39,  5.22s/it, avg loss=125.2744]
Training iteration:  91%|█████████▏| 914/1001 [1:14:58<06:25,  4.43s/it, avg loss=125.2744]Checkpoint at iteration 914 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 125.27439308166504

Training iteration:  91%|█████████▏| 914/1001 [1:15:00<06:25,  4.43s/it, avg loss=142.4796]
Training iteration:  91%|█████████▏| 915/1001 [1:15:00<05:33,  3.88s/it, avg loss=142.4796]Checkpoint at iteration 915 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 142.47959747314454

Training iteration:  91%|█████████▏| 915/1001 [1:15:03<05:33,  3.88s/it, avg loss=120.2812]
Training iteration:  92%|█████████▏| 916/1001 [1:15:03<04:56,  3.49s/it, avg loss=120.2812]Checkpoint at iteration 916 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 120.28124923706055

Training iteration:  92%|█████████▏| 916/1001 [1:15:05<04:56,  3.49s/it, avg loss=179.2371]
Training iteration:  92%|█████████▏| 917/1001 [1:15:05<04:30,  3.22s/it, avg loss=179.2371]Checkpoint at iteration 917 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 179.23709030151366

Training iteration:  92%|█████████▏| 917/1001 [1:15:08<04:30,  3.22s/it, avg loss=172.3721]
Training iteration:  92%|█████████▏| 918/1001 [1:15:08<04:11,  3.03s/it, avg loss=172.3721]Checkpoint at iteration 918 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 172.37205848693847

Training iteration:  92%|█████████▏| 918/1001 [1:15:11<04:11,  3.03s/it, avg loss=143.1692]
Training iteration:  92%|█████████▏| 919/1001 [1:15:11<03:57,  2.90s/it, avg loss=143.1692]Checkpoint at iteration 919 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 143.1691753387451

Training iteration:  92%|█████████▏| 919/1001 [1:15:13<03:57,  2.90s/it, avg loss=167.7566]
Training iteration:  92%|█████████▏| 920/1001 [1:15:13<03:47,  2.80s/it, avg loss=167.7566]Checkpoint at iteration 920 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 167.75657577514647

Training iteration:  92%|█████████▏| 920/1001 [1:15:16<03:47,  2.80s/it, avg loss=144.6860]
Training iteration:  92%|█████████▏| 921/1001 [1:15:16<03:38,  2.74s/it, avg loss=144.6860]Checkpoint at iteration 921 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 144.6860294342041

Training iteration:  92%|█████████▏| 921/1001 [1:15:18<03:38,  2.74s/it, avg loss=110.6668]
Training iteration:  92%|█████████▏| 922/1001 [1:15:18<03:32,  2.69s/it, avg loss=110.6668]Checkpoint at iteration 922 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 110.66679649353027

Training iteration:  92%|█████████▏| 922/1001 [1:15:21<03:32,  2.69s/it, avg loss=164.1873]
Training iteration:  92%|█████████▏| 923/1001 [1:15:21<03:27,  2.66s/it, avg loss=164.1873]Checkpoint at iteration 923 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 164.18732566833495

Training iteration:  92%|█████████▏| 923/1001 [1:15:24<03:27,  2.66s/it, avg loss=168.8937]
Training iteration:  92%|█████████▏| 924/1001 [1:15:24<03:22,  2.64s/it, avg loss=168.8937]Checkpoint at iteration 924 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 168.89368896484376

Training iteration:  92%|█████████▏| 924/1001 [1:15:26<03:22,  2.64s/it, avg loss=193.0028]
Training iteration:  92%|█████████▏| 925/1001 [1:15:26<03:19,  2.62s/it, avg loss=193.0028]Checkpoint at iteration 925 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 193.00282287597656

Training iteration:  92%|█████████▏| 925/1001 [1:15:29<03:19,  2.62s/it, avg loss=142.4420]
Training iteration:  93%|█████████▎| 926/1001 [1:15:29<03:15,  2.61s/it, avg loss=142.4420]Checkpoint at iteration 926 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 142.44203147888183

Training iteration:  93%|█████████▎| 926/1001 [1:15:31<03:15,  2.61s/it, avg loss=149.7699]
Training iteration:  93%|█████████▎| 927/1001 [1:15:31<03:12,  2.60s/it, avg loss=149.7699]Checkpoint at iteration 927 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 149.76994819641112

Training iteration:  93%|█████████▎| 927/1001 [1:15:34<03:12,  2.60s/it, avg loss=162.1597]
Training iteration:  93%|█████████▎| 928/1001 [1:15:34<03:09,  2.60s/it, avg loss=162.1597]Checkpoint at iteration 928 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 162.15973129272462

Training iteration:  93%|█████████▎| 928/1001 [1:15:36<03:09,  2.60s/it, avg loss=152.4125]
Training iteration:  93%|█████████▎| 929/1001 [1:15:36<03:06,  2.59s/it, avg loss=152.4125]Checkpoint at iteration 929 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 152.41246376037597

Training iteration:  93%|█████████▎| 929/1001 [1:15:39<03:06,  2.59s/it, avg loss=99.8753] 
Training iteration:  93%|█████████▎| 930/1001 [1:15:39<03:03,  2.59s/it, avg loss=99.8753]Checkpoint at iteration 930 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 99.8752685546875

Training iteration:  93%|█████████▎| 930/1001 [1:15:42<03:03,  2.59s/it, avg loss=151.9909]
Training iteration:  93%|█████████▎| 931/1001 [1:15:42<03:01,  2.59s/it, avg loss=151.9909]Checkpoint at iteration 931 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 151.99085578918456

Training iteration:  93%|█████████▎| 931/1001 [1:15:44<03:01,  2.59s/it, avg loss=235.7681]
Training iteration:  93%|█████████▎| 932/1001 [1:15:44<02:58,  2.59s/it, avg loss=235.7681]Checkpoint at iteration 932 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 235.7680534362793

Training iteration:  93%|█████████▎| 932/1001 [1:15:47<02:58,  2.59s/it, avg loss=184.5728]
Training iteration:  93%|█████████▎| 933/1001 [1:15:47<02:55,  2.59s/it, avg loss=184.5728]Checkpoint at iteration 933 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 184.57281990051268

Training iteration:  93%|█████████▎| 933/1001 [1:15:49<02:55,  2.59s/it, avg loss=168.1687]
Training iteration:  93%|█████████▎| 934/1001 [1:15:49<02:53,  2.58s/it, avg loss=168.1687]Checkpoint at iteration 934 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 168.16867713928224

Training iteration:  93%|█████████▎| 934/1001 [1:15:52<02:53,  2.58s/it, avg loss=161.8452]
Training iteration:  93%|█████████▎| 935/1001 [1:15:52<02:50,  2.58s/it, avg loss=161.8452]Checkpoint at iteration 935 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 161.84522285461426

Training iteration:  93%|█████████▎| 935/1001 [1:15:55<02:50,  2.58s/it, avg loss=156.8923]
Training iteration:  94%|█████████▎| 936/1001 [1:15:55<02:47,  2.58s/it, avg loss=156.8923]Checkpoint at iteration 936 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 156.89234771728516

Training iteration:  94%|█████████▎| 936/1001 [1:15:57<02:47,  2.58s/it, avg loss=169.8019]
Training iteration:  94%|█████████▎| 937/1001 [1:15:57<02:45,  2.58s/it, avg loss=169.8019]Checkpoint at iteration 937 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 169.801912689209

Training iteration:  94%|█████████▎| 937/1001 [1:16:00<02:45,  2.58s/it, avg loss=178.2177]
Training iteration:  94%|█████████▎| 938/1001 [1:16:00<02:42,  2.58s/it, avg loss=178.2177]Checkpoint at iteration 938 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 178.21766204833983

Training iteration:  94%|█████████▎| 938/1001 [1:16:02<02:42,  2.58s/it, avg loss=103.6825]
Training iteration:  94%|█████████▍| 939/1001 [1:16:02<02:40,  2.58s/it, avg loss=103.6825]Checkpoint at iteration 939 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 103.68251457214356

Training iteration:  94%|█████████▍| 939/1001 [1:16:05<02:40,  2.58s/it, avg loss=145.8130]
Training iteration:  94%|█████████▍| 940/1001 [1:16:05<02:37,  2.58s/it, avg loss=145.8130]Checkpoint at iteration 940 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 145.81302909851075

Training iteration:  94%|█████████▍| 940/1001 [1:16:07<02:37,  2.58s/it, avg loss=205.5065]
Training iteration:  94%|█████████▍| 941/1001 [1:16:07<02:35,  2.59s/it, avg loss=205.5065]Checkpoint at iteration 941 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 205.50645751953124

Training iteration:  94%|█████████▍| 941/1001 [1:16:10<02:35,  2.59s/it, avg loss=192.8178]
Training iteration:  94%|█████████▍| 942/1001 [1:16:10<02:32,  2.59s/it, avg loss=192.8178]Checkpoint at iteration 942 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 192.81778831481932

Training iteration:  94%|█████████▍| 942/1001 [1:16:13<02:32,  2.59s/it, avg loss=169.9750]
Training iteration:  94%|█████████▍| 943/1001 [1:16:13<02:29,  2.58s/it, avg loss=169.9750]Checkpoint at iteration 943 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 169.97502593994142

Training iteration:  94%|█████████▍| 943/1001 [1:16:15<02:29,  2.58s/it, avg loss=196.9729]
Training iteration:  94%|█████████▍| 944/1001 [1:16:15<02:27,  2.59s/it, avg loss=196.9729]Checkpoint at iteration 944 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 196.97288551330567

Training iteration:  94%|█████████▍| 944/1001 [1:16:18<02:27,  2.59s/it, avg loss=191.2647]
Training iteration:  94%|█████████▍| 945/1001 [1:16:18<02:25,  2.60s/it, avg loss=191.2647]Checkpoint at iteration 945 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 191.26469383239746

Training iteration:  94%|█████████▍| 945/1001 [1:16:20<02:25,  2.60s/it, avg loss=146.3463]
Training iteration:  95%|█████████▍| 946/1001 [1:16:20<02:23,  2.61s/it, avg loss=146.3463]Checkpoint at iteration 946 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 146.34628982543944

Training iteration:  95%|█████████▍| 946/1001 [1:16:23<02:23,  2.61s/it, avg loss=121.9920]
Training iteration:  95%|█████████▍| 947/1001 [1:16:23<02:20,  2.61s/it, avg loss=121.9920]Checkpoint at iteration 947 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 121.99195556640625

Training iteration:  95%|█████████▍| 947/1001 [1:16:26<02:20,  2.61s/it, avg loss=185.7462]
Training iteration:  95%|█████████▍| 948/1001 [1:16:26<02:18,  2.62s/it, avg loss=185.7462]Checkpoint at iteration 948 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 185.7461841583252

Training iteration:  95%|█████████▍| 948/1001 [1:16:28<02:18,  2.62s/it, avg loss=193.1935]
Training iteration:  95%|█████████▍| 949/1001 [1:16:28<02:16,  2.62s/it, avg loss=193.1935]Checkpoint at iteration 949 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 193.19353523254395

Training iteration:  95%|█████████▍| 949/1001 [1:16:31<02:16,  2.62s/it, avg loss=212.6281]
Training iteration:  95%|█████████▍| 950/1001 [1:16:31<02:13,  2.62s/it, avg loss=212.6281]Checkpoint at iteration 950 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 212.6280830383301

Training iteration:  95%|█████████▍| 950/1001 [1:16:34<02:13,  2.62s/it, avg loss=137.3280]
Training iteration:  95%|█████████▌| 951/1001 [1:16:34<02:11,  2.62s/it, avg loss=137.3280]Checkpoint at iteration 951 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 137.32796936035157

Training iteration:  95%|█████████▌| 951/1001 [1:16:36<02:11,  2.62s/it, avg loss=107.6984]
Training iteration:  95%|█████████▌| 952/1001 [1:16:36<02:08,  2.62s/it, avg loss=107.6984]Checkpoint at iteration 952 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 107.69843368530273

Training iteration:  95%|█████████▌| 952/1001 [1:16:39<02:08,  2.62s/it, avg loss=234.2655]
Training iteration:  95%|█████████▌| 953/1001 [1:16:39<02:05,  2.61s/it, avg loss=234.2655]Checkpoint at iteration 953 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 234.26552124023436

Training iteration:  95%|█████████▌| 953/1001 [1:16:41<02:05,  2.61s/it, avg loss=182.2201]
Training iteration:  95%|█████████▌| 954/1001 [1:16:41<02:02,  2.61s/it, avg loss=182.2201]Checkpoint at iteration 954 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 182.22010879516603

Training iteration:  95%|█████████▌| 954/1001 [1:16:44<02:02,  2.61s/it, avg loss=157.8889]
Training iteration:  95%|█████████▌| 955/1001 [1:16:44<01:59,  2.61s/it, avg loss=157.8889]Checkpoint at iteration 955 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 157.88885421752929

Training iteration:  95%|█████████▌| 955/1001 [1:16:47<01:59,  2.61s/it, avg loss=96.2944] 
Training iteration:  96%|█████████▌| 956/1001 [1:16:47<01:57,  2.61s/it, avg loss=96.2944]Checkpoint at iteration 956 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 96.29436836242675

Training iteration:  96%|█████████▌| 956/1001 [1:16:49<01:57,  2.61s/it, avg loss=218.6467]
Training iteration:  96%|█████████▌| 957/1001 [1:16:49<01:55,  2.61s/it, avg loss=218.6467]Checkpoint at iteration 957 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 218.64672050476074

Training iteration:  96%|█████████▌| 957/1001 [1:16:52<01:55,  2.61s/it, avg loss=154.1828]
Training iteration:  96%|█████████▌| 958/1001 [1:16:52<01:52,  2.62s/it, avg loss=154.1828]Checkpoint at iteration 958 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 154.18280105590821

Training iteration:  96%|█████████▌| 958/1001 [1:16:54<01:52,  2.62s/it, avg loss=163.8189]
Training iteration:  96%|█████████▌| 959/1001 [1:16:54<01:49,  2.62s/it, avg loss=163.8189]Checkpoint at iteration 959 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 163.8189224243164

Training iteration:  96%|█████████▌| 959/1001 [1:16:57<01:49,  2.62s/it, avg loss=125.7236]
Training iteration:  96%|█████████▌| 960/1001 [1:16:57<01:47,  2.62s/it, avg loss=125.7236]Checkpoint at iteration 960 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 125.72358741760254

Training iteration:  96%|█████████▌| 960/1001 [1:17:00<01:47,  2.62s/it, avg loss=169.2675]
Training iteration:  96%|█████████▌| 961/1001 [1:17:00<01:44,  2.62s/it, avg loss=169.2675]Checkpoint at iteration 961 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 169.2674987792969

Training iteration:  96%|█████████▌| 961/1001 [1:17:02<01:44,  2.62s/it, avg loss=113.7200]
Training iteration:  96%|█████████▌| 962/1001 [1:17:02<01:42,  2.62s/it, avg loss=113.7200]Checkpoint at iteration 962 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 113.72000389099121

Training iteration:  96%|█████████▌| 962/1001 [1:17:05<01:42,  2.62s/it, avg loss=143.2580]
Training iteration:  96%|█████████▌| 963/1001 [1:17:05<01:39,  2.62s/it, avg loss=143.2580]Checkpoint at iteration 963 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 143.2579761505127

Training iteration:  96%|█████████▌| 963/1001 [1:17:08<01:39,  2.62s/it, avg loss=128.6802]
Training iteration:  96%|█████████▋| 964/1001 [1:17:08<01:36,  2.62s/it, avg loss=128.6802]Checkpoint at iteration 964 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 128.68017349243163

Training iteration:  96%|█████████▋| 964/1001 [1:17:10<01:36,  2.62s/it, avg loss=161.3428]
Training iteration:  96%|█████████▋| 965/1001 [1:17:10<01:34,  2.62s/it, avg loss=161.3428]Checkpoint at iteration 965 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 161.3427520751953

Training iteration:  96%|█████████▋| 965/1001 [1:17:13<01:34,  2.62s/it, avg loss=180.5581]
Training iteration:  97%|█████████▋| 966/1001 [1:17:13<01:31,  2.62s/it, avg loss=180.5581]Checkpoint at iteration 966 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 180.55810775756837

Training iteration:  97%|█████████▋| 966/1001 [1:17:15<01:31,  2.62s/it, avg loss=225.8372]
Training iteration:  97%|█████████▋| 967/1001 [1:17:15<01:29,  2.62s/it, avg loss=225.8372]Checkpoint at iteration 967 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 225.83718147277833

Training iteration:  97%|█████████▋| 967/1001 [1:17:18<01:29,  2.62s/it, avg loss=148.1583]
Training iteration:  97%|█████████▋| 968/1001 [1:17:18<01:26,  2.62s/it, avg loss=148.1583]Checkpoint at iteration 968 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 148.158296585083

Training iteration:  97%|█████████▋| 968/1001 [1:17:21<01:26,  2.62s/it, avg loss=106.9541]
Training iteration:  97%|█████████▋| 969/1001 [1:17:21<01:23,  2.62s/it, avg loss=106.9541]Checkpoint at iteration 969 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 106.95407028198242

Training iteration:  97%|█████████▋| 969/1001 [1:17:23<01:23,  2.62s/it, avg loss=168.6545]
Training iteration:  97%|█████████▋| 970/1001 [1:17:23<01:21,  2.62s/it, avg loss=168.6545]Checkpoint at iteration 970 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 168.65447616577148

Training iteration:  97%|█████████▋| 970/1001 [1:17:26<01:21,  2.62s/it, avg loss=102.7757]
Training iteration:  97%|█████████▋| 971/1001 [1:17:26<01:18,  2.62s/it, avg loss=102.7757]Checkpoint at iteration 971 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 102.77570457458496

Training iteration:  97%|█████████▋| 971/1001 [1:17:29<01:18,  2.62s/it, avg loss=90.5634] 
Training iteration:  97%|█████████▋| 972/1001 [1:17:29<01:15,  2.62s/it, avg loss=90.5634]Checkpoint at iteration 972 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 90.5634147644043

Training iteration:  97%|█████████▋| 972/1001 [1:17:31<01:15,  2.62s/it, avg loss=146.8819]
Training iteration:  97%|█████████▋| 973/1001 [1:17:31<01:13,  2.62s/it, avg loss=146.8819]Checkpoint at iteration 973 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 146.88194274902344

Training iteration:  97%|█████████▋| 973/1001 [1:17:34<01:13,  2.62s/it, avg loss=108.4733]
Training iteration:  97%|█████████▋| 974/1001 [1:17:34<01:10,  2.62s/it, avg loss=108.4733]Checkpoint at iteration 974 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 108.47330169677734

Training iteration:  97%|█████████▋| 974/1001 [1:17:36<01:10,  2.62s/it, avg loss=160.6191]
Training iteration:  97%|█████████▋| 975/1001 [1:17:36<01:08,  2.62s/it, avg loss=160.6191]Checkpoint at iteration 975 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 160.61908416748048

Training iteration:  97%|█████████▋| 975/1001 [1:17:39<01:08,  2.62s/it, avg loss=96.8364] 
Training iteration:  98%|█████████▊| 976/1001 [1:17:39<01:05,  2.61s/it, avg loss=96.8364]Checkpoint at iteration 976 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 96.83640632629394

Training iteration:  98%|█████████▊| 976/1001 [1:17:42<01:05,  2.61s/it, avg loss=237.3579]
Training iteration:  98%|█████████▊| 977/1001 [1:17:42<01:02,  2.60s/it, avg loss=237.3579]Checkpoint at iteration 977 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 237.35785980224608

Training iteration:  98%|█████████▊| 977/1001 [1:17:44<01:02,  2.60s/it, avg loss=161.1697]
Training iteration:  98%|█████████▊| 978/1001 [1:17:44<00:59,  2.60s/it, avg loss=161.1697]Checkpoint at iteration 978 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 161.1697032928467

Training iteration:  98%|█████████▊| 978/1001 [1:17:47<00:59,  2.60s/it, avg loss=147.3294]
Training iteration:  98%|█████████▊| 979/1001 [1:17:47<00:57,  2.60s/it, avg loss=147.3294]Checkpoint at iteration 979 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 147.32941131591798

Training iteration:  98%|█████████▊| 979/1001 [1:17:49<00:57,  2.60s/it, avg loss=186.4466]
Training iteration:  98%|█████████▊| 980/1001 [1:17:49<00:54,  2.59s/it, avg loss=186.4466]Checkpoint at iteration 980 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 186.4465587615967

Training iteration:  98%|█████████▊| 980/1001 [1:17:52<00:54,  2.59s/it, avg loss=189.6926]
Training iteration:  98%|█████████▊| 981/1001 [1:17:52<00:51,  2.59s/it, avg loss=189.6926]Checkpoint at iteration 981 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 189.69264221191406

Training iteration:  98%|█████████▊| 981/1001 [1:17:55<00:51,  2.59s/it, avg loss=202.2985]
Training iteration:  98%|█████████▊| 982/1001 [1:17:55<00:49,  2.59s/it, avg loss=202.2985]Checkpoint at iteration 982 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 202.29849548339843

Training iteration:  98%|█████████▊| 982/1001 [1:17:57<00:49,  2.59s/it, avg loss=196.7252]
Training iteration:  98%|█████████▊| 983/1001 [1:17:57<00:46,  2.59s/it, avg loss=196.7252]Checkpoint at iteration 983 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 196.72519226074218

Training iteration:  98%|█████████▊| 983/1001 [1:18:00<00:46,  2.59s/it, avg loss=131.8647]
Training iteration:  98%|█████████▊| 984/1001 [1:18:00<00:43,  2.59s/it, avg loss=131.8647]Checkpoint at iteration 984 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 131.86468429565429

Training iteration:  98%|█████████▊| 984/1001 [1:18:02<00:43,  2.59s/it, avg loss=137.1849]
Training iteration:  98%|█████████▊| 985/1001 [1:18:02<00:41,  2.59s/it, avg loss=137.1849]Checkpoint at iteration 985 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 137.18491439819337

Training iteration:  98%|█████████▊| 985/1001 [1:18:05<00:41,  2.59s/it, avg loss=124.0472]
Training iteration:  99%|█████████▊| 986/1001 [1:18:05<00:38,  2.59s/it, avg loss=124.0472]Checkpoint at iteration 986 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 124.0471908569336

Training iteration:  99%|█████████▊| 986/1001 [1:18:07<00:38,  2.59s/it, avg loss=96.1318] 
Training iteration:  99%|█████████▊| 987/1001 [1:18:07<00:36,  2.59s/it, avg loss=96.1318]Checkpoint at iteration 987 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 96.1318260192871

Training iteration:  99%|█████████▊| 987/1001 [1:18:10<00:36,  2.59s/it, avg loss=166.7465]
Training iteration:  99%|█████████▊| 988/1001 [1:18:10<00:33,  2.59s/it, avg loss=166.7465]Checkpoint at iteration 988 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 166.746496963501

Training iteration:  99%|█████████▊| 988/1001 [1:18:13<00:33,  2.59s/it, avg loss=133.4360]
Training iteration:  99%|█████████▉| 989/1001 [1:18:13<00:31,  2.59s/it, avg loss=133.4360]Checkpoint at iteration 989 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 133.43597145080565

Training iteration:  99%|█████████▉| 989/1001 [1:18:15<00:31,  2.59s/it, avg loss=167.1953]
Training iteration:  99%|█████████▉| 990/1001 [1:18:15<00:28,  2.59s/it, avg loss=167.1953]Checkpoint at iteration 990 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 167.19528045654297

Training iteration:  99%|█████████▉| 990/1001 [1:18:18<00:28,  2.59s/it, avg loss=130.5780]
Training iteration:  99%|█████████▉| 991/1001 [1:18:18<00:25,  2.59s/it, avg loss=130.5780]Checkpoint at iteration 991 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 130.5780117034912

Training iteration:  99%|█████████▉| 991/1001 [1:18:20<00:25,  2.59s/it, avg loss=134.3483]
Training iteration:  99%|█████████▉| 992/1001 [1:18:20<00:23,  2.58s/it, avg loss=134.3483]Checkpoint at iteration 992 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 134.34833068847655

Training iteration:  99%|█████████▉| 992/1001 [1:18:23<00:23,  2.58s/it, avg loss=173.0824]
Training iteration:  99%|█████████▉| 993/1001 [1:18:23<00:20,  2.58s/it, avg loss=173.0824]Checkpoint at iteration 993 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 173.0824172973633

Training iteration:  99%|█████████▉| 993/1001 [1:18:26<00:20,  2.58s/it, avg loss=123.8643]
Training iteration:  99%|█████████▉| 994/1001 [1:18:26<00:18,  2.58s/it, avg loss=123.8643]Checkpoint at iteration 994 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 123.86433563232421

Training iteration:  99%|█████████▉| 994/1001 [1:18:28<00:18,  2.58s/it, avg loss=164.5052]
Training iteration:  99%|█████████▉| 995/1001 [1:18:28<00:15,  2.58s/it, avg loss=164.5052]Checkpoint at iteration 995 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 164.5051570892334

Training iteration:  99%|█████████▉| 995/1001 [1:18:31<00:15,  2.58s/it, avg loss=234.7648]
Training iteration: 100%|█████████▉| 996/1001 [1:18:31<00:12,  2.58s/it, avg loss=234.7648]Checkpoint at iteration 996 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 234.76484336853028

Training iteration: 100%|█████████▉| 996/1001 [1:18:33<00:12,  2.58s/it, avg loss=163.7046]
Training iteration: 100%|█████████▉| 997/1001 [1:18:33<00:10,  2.58s/it, avg loss=163.7046]Checkpoint at iteration 997 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 163.70464897155762

Training iteration: 100%|█████████▉| 997/1001 [1:18:36<00:10,  2.58s/it, avg loss=187.2156]
Training iteration: 100%|█████████▉| 998/1001 [1:18:36<00:07,  2.58s/it, avg loss=187.2156]Checkpoint at iteration 998 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 187.2155590057373

Training iteration: 100%|█████████▉| 998/1001 [1:18:38<00:07,  2.58s/it, avg loss=161.2591]
Training iteration: 100%|█████████▉| 999/1001 [1:18:38<00:05,  2.58s/it, avg loss=161.2591]Checkpoint at iteration 999 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 161.25906372070312

Training iteration: 100%|█████████▉| 999/1001 [1:18:41<00:05,  2.58s/it, avg loss=232.0372]
Training iteration: 100%|█████████▉| 1000/1001 [1:18:41<00:02,  2.58s/it, avg loss=232.0372]Optimization iteration 1000 evaluation begins...
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
A new evaluation visualization has been saved: ./saved_data/20240110-081107/it1000.png
Training network 0 for evaluation...
Training network 1 for evaluation...
Training network 2 for evaluation...
Training network 3 for evaluation...
Testing network 0 on real datasets for evaluation...
Testing network 1 on real datasets for evaluation...
Testing network 2 on real datasets for evaluation...
Testing network 3 on real datasets for evaluation...
Optimization iteration 1000, eval auroc score (train): 19724.8992, eval auroc score (test): 20664.7598
Checkpoint at iteration 1000 saved at ./saved_data/20240110-081107/chckpnt_los_100samples.pth. Loss = 232.03721923828124

Training iteration: 100%|█████████▉| 1000/1001 [1:30:37<00:05,  5.44s/it, avg loss=232.0372]
