==========================================
SLURM_JOB_ID = 18738733
SLURM_JOB_NODELIST = b01-15
TMPDIR = /tmp/SLURM_18738733
==========================================
Restoring modules from user's default
Using device: cuda
Loading dataset from "../data/mimic3/benchmark/multitask/train/saves/20240123-202747.pkl"...
Dataset loaded. Info: {'sr': 1, 'one_hot_encoded': False}
Loading dataset from "../data/mimic3/benchmark/multitask/test/saves/20240123-202427.pkl"...
Dataset loaded. Info: {'sr': 1, 'one_hot_encoded': False}
Datasets loaded.
Train set size: 35571
Test set size: 6273
Epoch 1 training...
Epoch 1 evaluating...
Epoch [1/100], Train Loss: 5706.2274, Eval Loss: 6016.4135
Epoch 2 training...
Epoch 2 evaluating...
Epoch [2/100], Train Loss: 5528.3344, Eval Loss: 8229.5120
Epoch 3 training...
Epoch 3 evaluating...
Epoch [3/100], Train Loss: 5011.3721, Eval Loss: 5223.0922
Epoch 4 training...
Epoch 4 evaluating...
Epoch [4/100], Train Loss: 4978.5438, Eval Loss: 5310.7822
Epoch 5 training...
Epoch 5 evaluating...
Epoch [5/100], Train Loss: 5056.8234, Eval Loss: 5442.8417
Epoch 6 training...
Epoch 6 evaluating...
Epoch [6/100], Train Loss: 5017.2164, Eval Loss: 5276.9157
Epoch 7 training...
Epoch 7 evaluating...
Epoch [7/100], Train Loss: 5080.9355, Eval Loss: 5929.6728
Epoch 8 training...
Epoch 8 evaluating...
Epoch [8/100], Train Loss: 5149.4807, Eval Loss: 5311.3554
Epoch 9 training...
Epoch 9 evaluating...
Epoch [9/100], Train Loss: 5012.8918, Eval Loss: 5258.6096
Epoch 10 training...
Epoch 10 evaluating...
Epoch [10/100], Train Loss: 4981.7504, Eval Loss: 5234.2040
Epoch 11 training...
Epoch 11 evaluating...
Epoch [11/100], Train Loss: 5147.7872, Eval Loss: 5646.8246
Epoch 12 training...
Epoch 12 evaluating...
Epoch [12/100], Train Loss: 5288.3153, Eval Loss: 5902.9205
Epoch 13 training...
Epoch 13 evaluating...
Epoch [13/100], Train Loss: 5334.8042, Eval Loss: 5677.8931
Epoch 14 training...
Epoch 14 evaluating...
Epoch [14/100], Train Loss: 5135.8396, Eval Loss: 5822.7319
Epoch 15 training...
Epoch 15 evaluating...
Epoch [15/100], Train Loss: 5234.6121, Eval Loss: 5516.2190
Epoch 16 training...
Epoch 16 evaluating...
Epoch [16/100], Train Loss: 5158.6419, Eval Loss: 5815.4288
Epoch 17 training...
Epoch 17 evaluating...
Epoch [17/100], Train Loss: 5094.5768, Eval Loss: 5892.1627
Epoch 18 training...
Epoch 18 evaluating...
Epoch [18/100], Train Loss: 5018.5197, Eval Loss: 5616.8940
Epoch 19 training...
Epoch 19 evaluating...
Epoch [19/100], Train Loss: 4989.2930, Eval Loss: 5368.6869
Epoch 20 training...
Epoch 20 evaluating...
Epoch [20/100], Train Loss: 4996.0537, Eval Loss: 5381.2194
Epoch 21 training...
Epoch 21 evaluating...
Epoch [21/100], Train Loss: 4953.7435, Eval Loss: 5380.4486
Epoch 22 training...
Epoch 22 evaluating...
Epoch [22/100], Train Loss: 4938.8122, Eval Loss: 5306.1950
Epoch 23 training...
Epoch 23 evaluating...
Epoch [23/100], Train Loss: 5022.4824, Eval Loss: 5636.5694
Epoch 24 training...
Epoch 24 evaluating...
Epoch [24/100], Train Loss: 5246.4012, Eval Loss: 5517.0845
Epoch 25 training...
Epoch 25 evaluating...
Epoch [25/100], Train Loss: 5119.3306, Eval Loss: 5546.2510
Epoch 26 training...
Epoch 26 evaluating...
Epoch [26/100], Train Loss: 5051.0262, Eval Loss: 5460.5393
Epoch 27 training...
Epoch 27 evaluating...
Epoch [27/100], Train Loss: 5036.3547, Eval Loss: 5550.9383
Epoch 28 training...
Epoch 28 evaluating...
Epoch [28/100], Train Loss: 5083.1592, Eval Loss: 5422.3601
Epoch 29 training...
Epoch 29 evaluating...
Epoch [29/100], Train Loss: 4964.5921, Eval Loss: 5216.7486
Epoch 30 training...
Epoch 30 evaluating...
Epoch [30/100], Train Loss: 5088.1803, Eval Loss: 5642.2942
Epoch 31 training...
Epoch 31 evaluating...
Epoch [31/100], Train Loss: 5131.2025, Eval Loss: 5322.7202
Epoch 32 training...
Epoch 32 evaluating...
Epoch [32/100], Train Loss: 4923.4039, Eval Loss: 5390.7112
Epoch 33 training...
Epoch 33 evaluating...
Epoch [33/100], Train Loss: 4949.4602, Eval Loss: 5330.9414
Epoch 34 training...
Epoch 34 evaluating...
Epoch [34/100], Train Loss: 5065.7779, Eval Loss: 5485.0341
Epoch 35 training...
Epoch 35 evaluating...
Epoch [35/100], Train Loss: 5124.3398, Eval Loss: 5346.7372
Epoch 36 training...
Epoch 36 evaluating...
Epoch [36/100], Train Loss: 4966.9627, Eval Loss: 5306.9446
Epoch 37 training...
Epoch 37 evaluating...
Epoch [37/100], Train Loss: 4983.7802, Eval Loss: 5335.0486
Epoch 38 training...
Epoch 38 evaluating...
Epoch [38/100], Train Loss: 4936.5383, Eval Loss: 5505.0829
Epoch 39 training...
Epoch 39 evaluating...
Epoch [39/100], Train Loss: 4932.5573, Eval Loss: 5322.7565
Epoch 40 training...
Epoch 40 evaluating...
Epoch [40/100], Train Loss: 4966.7584, Eval Loss: 5695.6825
Epoch 41 training...
Epoch 41 evaluating...
Epoch [41/100], Train Loss: 5001.9917, Eval Loss: 5489.1782
Epoch 42 training...
Epoch 42 evaluating...
Epoch [42/100], Train Loss: 4982.7118, Eval Loss: 5569.1995
Epoch 43 training...
Epoch 43 evaluating...
Epoch [43/100], Train Loss: 5011.4193, Eval Loss: 5552.4671
Epoch 44 training...
Epoch 44 evaluating...
Epoch [44/100], Train Loss: 4987.6050, Eval Loss: 5876.5813
Epoch 45 training...
Epoch 45 evaluating...
Epoch [45/100], Train Loss: 4976.4175, Eval Loss: 5872.0364
Epoch 46 training...
Epoch 46 evaluating...
Epoch [46/100], Train Loss: 4997.8392, Eval Loss: 6018.1553
Epoch 47 training...
Epoch 47 evaluating...
Epoch [47/100], Train Loss: 4992.1073, Eval Loss: 5856.6197
Epoch 48 training...
Epoch 48 evaluating...
Epoch [48/100], Train Loss: 5059.4683, Eval Loss: 5699.3435
Epoch 49 training...
Epoch 49 evaluating...
Epoch [49/100], Train Loss: 5107.5716, Eval Loss: 5794.2262
Epoch 50 training...
Epoch 50 evaluating...
Epoch [50/100], Train Loss: 5025.9440, Eval Loss: 6025.6591
Epoch 51 training...
Epoch 51 evaluating...
Epoch [51/100], Train Loss: 4987.9801, Eval Loss: 5647.3704
Epoch 52 training...
Epoch 52 evaluating...
Epoch [52/100], Train Loss: 4968.0417, Eval Loss: 5354.6794
Epoch 53 training...
Epoch 53 evaluating...
Epoch [53/100], Train Loss: 4923.6920, Eval Loss: 5383.9259
Epoch 54 training...
Epoch 54 evaluating...
Epoch [54/100], Train Loss: 4975.8082, Eval Loss: 5496.1418
Epoch 55 training...
Epoch 55 evaluating...
Epoch [55/100], Train Loss: 4968.0862, Eval Loss: 5470.6183
Epoch 56 training...
Epoch 56 evaluating...
Epoch [56/100], Train Loss: 5032.6464, Eval Loss: 5409.0432
Epoch 57 training...
Epoch 57 evaluating...
Epoch [57/100], Train Loss: 4986.8480, Eval Loss: 5566.7756
Epoch 58 training...
Epoch 58 evaluating...
Epoch [58/100], Train Loss: 5073.1227, Eval Loss: 5619.5437
Epoch 59 training...
Epoch 59 evaluating...
Epoch [59/100], Train Loss: 5134.7397, Eval Loss: 5625.5634
Epoch 60 training...
Epoch 60 evaluating...
Epoch [60/100], Train Loss: 5138.2179, Eval Loss: 5608.2217
Epoch 61 training...
Epoch 61 evaluating...
Epoch [61/100], Train Loss: 5124.9200, Eval Loss: 5677.9070
Epoch 62 training...
Epoch 62 evaluating...
Epoch [62/100], Train Loss: 5134.2702, Eval Loss: 5657.6735
Epoch 63 training...
Epoch 63 evaluating...
Epoch [63/100], Train Loss: 5122.0723, Eval Loss: 5708.0412
Epoch 64 training...
Epoch 64 evaluating...
Epoch [64/100], Train Loss: 5129.7763, Eval Loss: 5750.0398
Epoch 65 training...
Epoch 65 evaluating...
Epoch [65/100], Train Loss: 5132.3306, Eval Loss: 5619.5152
Epoch 66 training...
Epoch 66 evaluating...
Epoch [66/100], Train Loss: 5126.9321, Eval Loss: 5750.4042
Epoch 67 training...
Epoch 67 evaluating...
Epoch [67/100], Train Loss: 5127.5640, Eval Loss: 5806.6913
Epoch 68 training...
Epoch 68 evaluating...
Epoch [68/100], Train Loss: 5126.7180, Eval Loss: 5800.8912
Epoch 69 training...
Epoch 69 evaluating...
Epoch [69/100], Train Loss: 5125.1953, Eval Loss: 5795.5315
Epoch 70 training...
Epoch 70 evaluating...
Epoch [70/100], Train Loss: 5138.6875, Eval Loss: 5705.3053
Epoch 71 training...
Epoch 71 evaluating...
Epoch [71/100], Train Loss: 5133.2853, Eval Loss: 5655.8283
Epoch 72 training...
Epoch 72 evaluating...
Epoch [72/100], Train Loss: 5126.9793, Eval Loss: 5612.1174
Epoch 73 training...
Epoch 73 evaluating...
Epoch [73/100], Train Loss: 5119.7092, Eval Loss: 5760.9919
Epoch 74 training...
Epoch 74 evaluating...
Epoch [74/100], Train Loss: 5118.8614, Eval Loss: 5652.5554
Epoch 75 training...
Epoch 75 evaluating...
Epoch [75/100], Train Loss: 5120.0795, Eval Loss: 5828.0447
Epoch 76 training...
Epoch 76 evaluating...
Epoch [76/100], Train Loss: 5123.4368, Eval Loss: 5858.2976
Epoch 77 training...
Epoch 77 evaluating...
Epoch [77/100], Train Loss: 5125.2914, Eval Loss: 5606.1386
Epoch 78 training...
Epoch 78 evaluating...
Epoch [78/100], Train Loss: 5121.0725, Eval Loss: 5693.3252
Epoch 79 training...
Epoch 79 evaluating...
Epoch [79/100], Train Loss: 5109.9338, Eval Loss: 5732.2135
Epoch 80 training...
Epoch 80 evaluating...
Epoch [80/100], Train Loss: 5115.3430, Eval Loss: 5731.1389
Epoch 81 training...
Epoch 81 evaluating...
Epoch [81/100], Train Loss: 5116.5988, Eval Loss: 5590.6219
Epoch 82 training...
Epoch 82 evaluating...
Epoch [82/100], Train Loss: 5113.1342, Eval Loss: 5648.1143
Epoch 83 training...
Epoch 83 evaluating...
Epoch [83/100], Train Loss: 5111.5742, Eval Loss: 5637.9091
Epoch 84 training...
Epoch 84 evaluating...
Epoch [84/100], Train Loss: 5107.7583, Eval Loss: 5665.1170
Epoch 85 training...
Epoch 85 evaluating...
Epoch [85/100], Train Loss: 5119.2537, Eval Loss: 5729.0769
Epoch 86 training...
Epoch 86 evaluating...
Epoch [86/100], Train Loss: 5110.5058, Eval Loss: 5571.7765
Epoch 87 training...
Epoch 87 evaluating...
Epoch [87/100], Train Loss: 5099.8106, Eval Loss: 5547.1757
Epoch 88 training...
Epoch 88 evaluating...
Epoch [88/100], Train Loss: 5098.9731, Eval Loss: 5536.6782
Epoch 89 training...
Epoch 89 evaluating...
Epoch [89/100], Train Loss: 5107.1762, Eval Loss: 5588.3188
Epoch 90 training...
Epoch 90 evaluating...
Epoch [90/100], Train Loss: 5105.4174, Eval Loss: 5620.4218
Epoch 91 training...
Epoch 91 evaluating...
Epoch [91/100], Train Loss: 5099.0983, Eval Loss: 5572.2546
Epoch 92 training...
Epoch 92 evaluating...
Epoch [92/100], Train Loss: 5099.5981, Eval Loss: 5694.7833
Epoch 93 training...
Epoch 93 evaluating...
Epoch [93/100], Train Loss: 5128.6251, Eval Loss: 5784.5021
Epoch 94 training...
Epoch 94 evaluating...
Epoch [94/100], Train Loss: 5107.9043, Eval Loss: 5687.3460
Epoch 95 training...
Epoch 95 evaluating...
Epoch [95/100], Train Loss: 5119.9009, Eval Loss: 5622.5799
Epoch 96 training...
Epoch 96 evaluating...
Epoch [96/100], Train Loss: 5117.1013, Eval Loss: 5772.7243
Epoch 97 training...
Epoch 97 evaluating...
Epoch [97/100], Train Loss: 5109.4541, Eval Loss: 5639.5487
Epoch 98 training...
Epoch 98 evaluating...
Epoch [98/100], Train Loss: 5113.5348, Eval Loss: 5642.7753
Epoch 99 training...
Epoch 99 evaluating...
Epoch [99/100], Train Loss: 5127.5555, Eval Loss: 5598.6904
Epoch 100 training...
Epoch 100 evaluating...
Epoch [100/100], Train Loss: 5127.6572, Eval Loss: 5702.2603
Training done, all data saved to "../saved_data/20240124-133003".
