{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary experiment - distilled dataset for in-hospital mortality prediction task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“– Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âœ… Dependencies.\n",
    "\n",
    "For cuda, define `device` that'll be used throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import importlib\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import copy\n",
    "import os\n",
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âœ… Custom libs. **Always re-run the following code block after modifying `utils`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.report' from '/project/ruishanl_1185/EHR-Distillation/utils/report.py'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import preprocess, dataset, network, train, report\n",
    "importlib.reload(preprocess)\n",
    "importlib.reload(dataset)\n",
    "importlib.reload(network)\n",
    "importlib.reload(train)\n",
    "importlib.reload(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âœ… Compute statistics that'll be used for imputation and dataloading.\n",
    "\n",
    "Statistics can be load from saved pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_FROM_SAVED = True\n",
    "STAT_PKL_DIR = \"./saved_data/stats/\"\n",
    "if not os.path.exists(STAT_PKL_DIR):\n",
    "    os.makedirs(STAT_PKL_DIR)\n",
    "\n",
    "categorical_numcls = {  # how many classes are there for categorical classes\n",
    "    \"capillary_refill_rate\": 2,\n",
    "    \"glascow_coma_scale_eye_opening\": 4,\n",
    "    \"glascow_coma_scale_motor_response\": 6,\n",
    "    \"glascow_coma_scale_total\": 13,\n",
    "    \"glascow_coma_scale_verbal_response\": 5,\n",
    "}\n",
    "\n",
    "pkl_path = os.path.join(STAT_PKL_DIR, \"ihm_preliminary.pkl\")\n",
    "if os.path.exists(pkl_path) and LOAD_FROM_SAVED:\n",
    "    with open(pkl_path, 'rb') as f:\n",
    "        continuous_avgs_train, continuous_stds_train, categorical_modes_train = pickle.load(f)\n",
    "else:\n",
    "    continuous_avgs_train, continuous_stds_train, categorical_modes_train =  preprocess.compute_feature_statistics(\n",
    "        ts_dir=\"./data/mimic3/benchmark/in-hospital-mortality/train/\",\n",
    "        feature_dict=preprocess.mimic3_benchmark_variable_dict\n",
    "        )\n",
    "    with open(pkl_path, 'wb') as f:\n",
    "        pickle.dump((continuous_avgs_train, continuous_stds_train, categorical_modes_train), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean all data by resampling, imputating and masking.\n",
    "\n",
    "**Running this block once is enough.**\n",
    "(Cleaned data will be saved at ./data/mimic3/ihm_preliminary/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess.preprocess_ihm_timeseries_files(\n",
    "    ts_dir=\"./data/mimic3/benchmark/in-hospital-mortality/train/\",\n",
    "    output_dir=\"./data/mimic3/ihm_preliminary/train/\",\n",
    "    feature_dict=preprocess.mimic3_benchmark_variable_dict,\n",
    "    normal_value_dict=continuous_avgs_train|categorical_modes_train\n",
    "    )\n",
    "preprocess.preprocess_ihm_timeseries_files(\n",
    "    ts_dir=\"./data/mimic3/benchmark/in-hospital-mortality/test/\",\n",
    "    output_dir=\"./data/mimic3/ihm_preliminary/test/\",\n",
    "    feature_dict=preprocess.mimic3_benchmark_variable_dict,\n",
    "    normal_value_dict=continuous_avgs_train|categorical_modes_train\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âœ… Define original mimic3 benchmark training and evaluation datasets for IHM objective.\n",
    "\n",
    "Apply mask / balance to the dataset here.\n",
    "\n",
    "You may have to re-run this block after modifying dataloader-related codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First item in the dataset: \n",
      "(tensor([[ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0668,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0489,  ...,  0.0220,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 1.0000,  0.0000,  0.0980,  ..., -0.0870,  4.1913,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.1293,  ..., -0.0870,  4.1913,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0176,  ..., -0.0870,  4.1913,  0.0000]]), tensor(0))\n",
      "Feature tensor shape: torch.Size([48, 42])\n",
      "First item in the dataset: \n",
      "(tensor([[ 1.0000,  0.0000,  0.0310,  ..., -0.1730, -0.8523,  0.0391],\n",
      "        [ 1.0000,  0.0000,  0.0578,  ..., -0.1615, -0.8523,  0.0391],\n",
      "        [ 1.0000,  0.0000,  0.0623,  ..., -0.1615, -0.8523,  0.0391],\n",
      "        ...,\n",
      "        [ 1.0000,  0.0000,  0.0132,  ...,  0.0335, -0.5163,  0.0521],\n",
      "        [ 1.0000,  0.0000,  0.0087,  ...,  0.0335, -0.5163,  0.0521],\n",
      "        [ 1.0000,  0.0000,  0.0400,  ...,  0.0335, -0.5163,  0.0521]]), tensor(0))\n",
      "Feature tensor shape: torch.Size([48, 42])\n",
      "Input tensor shape: torch.Size([48, 42])\n"
     ]
    }
   ],
   "source": [
    "# Pay attention to balance and mask settings\n",
    "\n",
    "BALANCE = False\n",
    "MASK = False\n",
    "\n",
    "train_set = dataset.IHMPreliminaryDatasetReal(\n",
    "    dir=\"./data/mimic3/ihm_preliminary/train/\",\n",
    "    dstype=\"train\",\n",
    "    avg_dict=continuous_avgs_train,\n",
    "    std_dict=continuous_stds_train,\n",
    "    numcls_dict=categorical_numcls,\n",
    "    balance=BALANCE,\n",
    "    mask=MASK,\n",
    "    )\n",
    "print(f\"First item in the dataset: \\n{train_set[0]}\")\n",
    "print(f\"Feature tensor shape: {train_set[0][0].shape}\")\n",
    "\n",
    "test_set = dataset.IHMPreliminaryDatasetReal(\n",
    "    dir=\"./data/mimic3/ihm_preliminary/test/\",\n",
    "    dstype=\"test\",\n",
    "    avg_dict=continuous_avgs_train,\n",
    "    std_dict=continuous_stds_train,\n",
    "    numcls_dict=categorical_numcls,\n",
    "    balance=BALANCE,\n",
    "    mask=MASK,\n",
    "    )\n",
    "print(f\"First item in the dataset: \\n{test_set[0]}\")\n",
    "print(f\"Feature tensor shape: {test_set[0][0].shape}\")\n",
    "\n",
    "input_shape = train_set[0][0].shape\n",
    "print(f\"Input tensor shape: {input_shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the label distribution in the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total datapoints: 17904\n",
      "Label 0 ratio: 0.8646112600536193\n",
      "Label 1 ratio: 0.1353887399463807\n"
     ]
    }
   ],
   "source": [
    "label_0_cnt = 0\n",
    "label_1_cnt = 1\n",
    "for _, label in test_set:\n",
    "    if label > 0.5:\n",
    "        label_1_cnt += 1\n",
    "    else:\n",
    "        label_0_cnt += 1\n",
    "print(f\"Total datapoints: {label_0_cnt + label_1_cnt}\")\n",
    "print(f\"Label 0 ratio: {label_0_cnt / (label_0_cnt + label_1_cnt)}\")\n",
    "print(f\"Label 1 ratio: {label_1_cnt / (label_0_cnt + label_1_cnt)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’­ Evaluating model capacity on training objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train an 1D CNN and save the best performing weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyper params\n",
    "ihm_epoch = 100\n",
    "ihm_batch_size = 256\n",
    "ihm_lr = 1e-3\n",
    "ihm_wd = 1e-3\n",
    "\n",
    "# train 1D CNN\n",
    "\n",
    "PT_SAVE_DIR = \"./saved_data/ihm_model/\"\n",
    "if not os.path.exists(PT_SAVE_DIR):\n",
    "    os.makedirs(PT_SAVE_DIR)\n",
    "\n",
    "NUM_WORKERS = 8\n",
    "\n",
    "train_loader = DataLoader(train_set, ihm_batch_size, shuffle=True, num_workers=NUM_WORKERS)\n",
    "test_loader = DataLoader(test_set, ihm_batch_size, num_workers=NUM_WORKERS)\n",
    "\n",
    "model = network.IHMPreliminary1DCNN(input_shape=input_shape).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=ihm_lr, weight_decay=ihm_wd)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "pbar = tqdm(range(ihm_epoch), desc=\"Training on original task\")\n",
    "min_loss = float(\"inf\")\n",
    "for e in pbar:\n",
    "    train_loss, train_acc = train.epoch(\"train\", train_loader, model, criterion, optimizer, device=DEVICE)\n",
    "    test_loss, test_acc = train.epoch(\"test\", test_loader, model, criterion, device=DEVICE)\n",
    "    if train_loss < min_loss:\n",
    "        filename = f'ihm_1dcnn_e{e}_trl{train_loss:.4f}_tel{test_loss:.4f}.pt'\n",
    "        file_path = os.path.join(PT_SAVE_DIR, filename)\n",
    "\n",
    "        # Remove the previous checkpoint if it exists\n",
    "        existing_pts = [f for f in os.listdir(PT_SAVE_DIR) if f.startswith(f'ihm_1dcnn_e{e}_') and f.endswith('.pt')]\n",
    "        for f in existing_pts:\n",
    "            os.remove(os.path.join(PT_SAVE_DIR, f))\n",
    "        torch.save({\n",
    "                'epoch': e,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': train_loss,\n",
    "            }, file_path)\n",
    "    \n",
    "    pbar.set_description(f\"Training on original task, epoch {e}\\ntrain loss = {train_loss}, train acc = {train_acc}\\ntest loss = {test_loss}, test acc = {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train an MLP and save the best performing weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyper params\n",
    "ihm_epoch = 100\n",
    "ihm_batch_size = 256\n",
    "ihm_lr = 1e-3\n",
    "ihm_wd = 1e-3\n",
    "\n",
    "# train MLP\n",
    "\n",
    "PT_SAVE_DIR = \"./saved_data/ihm_model/\"\n",
    "if not os.path.exists(PT_SAVE_DIR):\n",
    "    os.makedirs(PT_SAVE_DIR)\n",
    "\n",
    "NUM_WORKERS = 8\n",
    "\n",
    "train_loader = DataLoader(train_set, ihm_batch_size, shuffle=True, num_workers=NUM_WORKERS)\n",
    "test_loader = DataLoader(test_set, ihm_batch_size, num_workers=NUM_WORKERS)\n",
    "\n",
    "model = network.IHMPreliminaryMLP(input_shape=input_shape).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=ihm_lr, weight_decay=ihm_wd)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "pbar = tqdm(range(ihm_epoch), desc=\"Training on original task\")\n",
    "min_loss = float(\"inf\")\n",
    "for e in pbar:\n",
    "    train_loss, train_acc = train.epoch(\"train\", train_loader, model, criterion, optimizer, device=DEVICE)\n",
    "    test_loss, test_acc = train.epoch(\"test\", test_loader, model, criterion, device=DEVICE)\n",
    "    if train_loss < min_loss:\n",
    "        filename = f'ihm_mlp_e{e}_trl{train_loss:.4f}_tel{test_loss:.4f}.pt'\n",
    "        file_path = os.path.join(PT_SAVE_DIR, filename)\n",
    "\n",
    "        # Remove the previous checkpoint if it exists\n",
    "        existing_pts = [f for f in os.listdir(PT_SAVE_DIR) if f.startswith(f'ihm_mlp_e{e}_') and f.endswith('.pt')]\n",
    "        for f in existing_pts:\n",
    "            os.remove(os.path.join(PT_SAVE_DIR, f))\n",
    "        torch.save({\n",
    "                'epoch': e,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': train_loss,\n",
    "            }, file_path)\n",
    "    \n",
    "    pbar.set_description(f\"Training on original task, epoch {e}\\ntrain loss = {train_loss}, train acc = {train_acc}\\ntest loss = {test_loss}, test acc = {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baselines: train the model with randomly sampled subset of datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose model\n",
    "MODEL = [\"1dcnn\", \"mlp\"][1]\n",
    "\n",
    "# define hyper params\n",
    "EPOCH = 100\n",
    "BATCH_SIZE = 256\n",
    "LR = 1e-3\n",
    "WD = 1e-3\n",
    "\n",
    "PT_SAVE_DIR = \"./saved_data/ihm_model/\"\n",
    "if not os.path.exists(PT_SAVE_DIR):\n",
    "    os.makedirs(PT_SAVE_DIR)\n",
    "\n",
    "# define num sampled datapoints\n",
    "N_SAMPLES_PER_CLS = 10\n",
    "\n",
    "# Sample from class 0\n",
    "ts_class_0, lab_class_0 = train_set.random_sample_from_class(n_samples=N_SAMPLES_PER_CLS, cls=0, no_duplicate=True)\n",
    "# Sample from class 1\n",
    "ts_class_1, lab_class_1 = train_set.random_sample_from_class(n_samples=N_SAMPLES_PER_CLS, cls=1, no_duplicate=True)\n",
    "# Concatenate the time series data along the first dimension (batch size)\n",
    "ts_real = torch.cat((ts_class_0, ts_class_1), dim=0).to(DEVICE)\n",
    "# Concatenate the labels along the 0th dimension\n",
    "lab_real = torch.cat((lab_class_0, lab_class_1), dim=0).to(DEVICE)\n",
    "# print(ts_real.shape, lab_real.shape) # batch_size * num_time_steps * num_features\n",
    "\n",
    "sample_set = dataset.TensorDataset(ts_real, lab_real)\n",
    "\n",
    "# define dataloaders\n",
    "NUM_WORKERS = 8\n",
    "sample_loader = DataLoader(sample_set, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "\n",
    "if MODEL == \"1dcnn\":\n",
    "    model = network.IHMPreliminary1DCNN(input_shape=input_shape).to(DEVICE)\n",
    "else:\n",
    "    model = network.IHMPreliminaryMLP(input_shape=input_shape).to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WD)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "pbar = tqdm(range(EPOCH), desc=f\"Training on sampled dataset (size={2*N_SAMPLES_PER_CLS})\")\n",
    "min_loss = float(\"inf\")\n",
    "for e in pbar:\n",
    "    train_loss, train_acc = train.epoch(\"train\", sample_loader, model, loss_fn, optimizer, device=DEVICE) # attention: using sampled dataset\n",
    "    test_loss, test_acc = train.epoch(\"test\", test_loader, model, loss_fn, device=DEVICE)\n",
    "    if train_loss < min_loss:\n",
    "        filename = f'ihm_{MODEL}_spc{N_SAMPLES_PER_CLS}_e{e}_trl{train_loss:.4f}_tel{test_loss:.4f}.pt'\n",
    "        file_path = os.path.join(PT_SAVE_DIR, filename)\n",
    "\n",
    "        # Remove the previous checkpoint if it exists\n",
    "        existing_pts = [f for f in os.listdir(PT_SAVE_DIR) if f.startswith(f'ihm_{MODEL}_spc{N_SAMPLES_PER_CLS}_e{e}_') and f.endswith('.pt')]\n",
    "        for f in existing_pts:\n",
    "            os.remove(os.path.join(PT_SAVE_DIR, f))\n",
    "        torch.save({\n",
    "                'epoch': e,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': train_loss,\n",
    "            }, file_path)\n",
    "    \n",
    "    pbar.set_postfix({\"train loss\": f\"{train_loss:.4f}\",\n",
    "                      \"train acc\": f\"{train_acc*100:.2f}%\",\n",
    "                      \"test loss\": f\"{test_loss:.4f}\",\n",
    "                      \"test acc\": f\"{test_acc*100:.2f}%\",\n",
    "                      })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a saved model and evaluate on evaluation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro AUC-ROC score: 0.7190892461425202\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[1903,  959],\n",
       "        [ 109,  265]]),\n",
       " {'0': {'precision': 0.9458250497017893,\n",
       "   'recall': 0.6649196366177498,\n",
       "   'f1-score': 0.780878128846943,\n",
       "   'support': 2862},\n",
       "  '1': {'precision': 0.21650326797385622,\n",
       "   'recall': 0.7085561497326203,\n",
       "   'f1-score': 0.3316645807259074,\n",
       "   'support': 374},\n",
       "  'accuracy': 0.6699629171817059,\n",
       "  'macro avg': {'precision': 0.5811641588378227,\n",
       "   'recall': 0.6867378931751851,\n",
       "   'f1-score': 0.5562713547864252,\n",
       "   'support': 3236},\n",
       "  'weighted avg': {'precision': 0.8615338425428749,\n",
       "   'recall': 0.6699629171817059,\n",
       "   'f1-score': 0.7289603701951297,\n",
       "   'support': 3236}},\n",
       " 0.7190892461425202)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate saved model\n",
    "PT_SAVE_DIR = \"./saved_data/ihm_model/\"\n",
    "PT_NAME_GLOB = \"ihm_mlp_spc10_e2_*.pt\"\n",
    "eval_model = network.IHMPreliminaryMLP(input_shape=(48, 42))\n",
    "\n",
    "model_pt = glob(os.path.join(PT_SAVE_DIR, PT_NAME_GLOB))[0]\n",
    "model_data = torch.load(model_pt, map_location=torch.device(DEVICE))\n",
    "\n",
    "eval_model.load_state_dict(model_data[\"model_state_dict\"])\n",
    "eval_model.to(DEVICE)\n",
    "eval_model.eval()\n",
    "\n",
    "# load eval set\n",
    "NUM_WORKERS = 8\n",
    "BATCH_SIZE = 256\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS) # pay attention to the test set used here\n",
    "\n",
    "report.run_classificatoin_report(eval_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§ª EHR Distillation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŒ¿ Vanilla dataset distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla Dataset Distillation intends to get dataset that is able to train a model within only 1 epoch\n",
    "\n",
    "# define hyper params\n",
    "NUM_OPTIM_IT = 1000\n",
    "EVAL_EVERY_NUM_IT = 10\n",
    "\n",
    "INIT_LR = 0.001\n",
    "STEP_SIZE = 0.001\n",
    "INIT_WEIGHTS_DISTR = \"kaiming\"\n",
    "BATCH_SIZE = 256\n",
    "NUM_SAMPLED_MODELS_TRAIN = 16\n",
    "NUM_SAMPLED_MODELS_EVAL = 4\n",
    "N_SAMPLES_PER_CLS = 10\n",
    "\n",
    "# checkpoints saving\n",
    "CHCKPNT_SAVE_DIR = \"./saved_data\"\n",
    "if not os.path.exists(CHCKPNT_SAVE_DIR):\n",
    "    os.makedirs(CHCKPNT_SAVE_DIR)\n",
    "\n",
    "# prepare dataloaders\n",
    "NUM_WORKERS = 8\n",
    "train_loader = DataLoader(train_set, BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "test_loader = DataLoader(test_set, BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "\n",
    "# initialize random synth dataset\n",
    "ts_syn = torch.randn(size=(2*N_SAMPLES_PER_CLS, input_shape[0], input_shape[1]), dtype=torch.float, requires_grad=True, device=DEVICE) # device is ignored by far\n",
    "lab_syn = torch.tensor(np.array([np.ones(N_SAMPLES_PER_CLS)*i for i in (0, 1)]), dtype=torch.long, requires_grad=False, device=DEVICE).view(-1) # 1-D, length = episodes_per_cls * 2\n",
    "\n",
    "# initialize learning rate\n",
    "lr = torch.tensor([INIT_LR], dtype=torch.float, requires_grad=True, device=DEVICE) # make it learnable\n",
    "\n",
    "optimizer_ts = torch.optim.Adam([ts_syn], lr=STEP_SIZE)\n",
    "optimizer_lr = torch.optim.Adam([lr], lr=STEP_SIZE)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# data used for plotting curves\n",
    "optim_losses = [] # optimization objective loss each iteration\n",
    "min_optim_loss = float('inf')\n",
    "syn_lrs = [] # synthetic lr\n",
    "eval_scores_train = [] # evaluation avg roc-auc score on train set\n",
    "eval_scores_test = [] # evaluation avg roc-auc score on test set\n",
    "\n",
    "# begin training steps\n",
    "pbar = tqdm(range(NUM_OPTIM_IT), desc=\"Distilling dataset using vanilla DD\")\n",
    "for it in pbar:\n",
    "    # get a minibatch of real training data\n",
    "    # Sample from class 0\n",
    "    ts_class_0, lab_class_0 = train_set.random_sample_from_class(n_samples=BATCH_SIZE//2, cls=0)\n",
    "    # ts_class_0, lab_class_0 = train_set.first_n_samples_from_class(n_samples=BATCH_SIZE//2, cls=0)\n",
    "    # Sample from class 1\n",
    "    ts_class_1, lab_class_1 = train_set.random_sample_from_class(n_samples=BATCH_SIZE//2, cls=1)\n",
    "    # ts_class_1, lab_class_1 = train_set.first_n_samples_from_class(n_samples=BATCH_SIZE//2, cls=1)\n",
    "    # Concatenate the time series data along the first dimension (batch size)\n",
    "    ts_real = torch.cat((ts_class_0, ts_class_1), dim=0).to(DEVICE)\n",
    "    # Concatenate the labels along the 0th dimension\n",
    "    lab_real = torch.cat((lab_class_0, lab_class_1), dim=0).to(DEVICE)\n",
    "    # print(ts_real.shape, lab_real.shape) # batch_size * num_time_steps * num_features\n",
    "\n",
    "    # evaluate the distilled data every `EVAL_EVERY_NUM_IT` iterations\n",
    "    if it % EVAL_EVERY_NUM_IT == 0:\n",
    "        print(f\"Optimization iteration {it} evaluation begins...\")\n",
    "        ts_syn_chckpnt = ts_syn.detach().clone()\n",
    "        # lab_syn are not learning objectives so just use it in-place\n",
    "        lr_chckpnt = lr.detach().clone()\n",
    "        # sample a batch of models\n",
    "        sampled_models = []\n",
    "        local_train_scores = []\n",
    "        local_test_scores = []\n",
    "        for j in range(NUM_SAMPLED_MODELS_EVAL):\n",
    "            torch.random.manual_seed(int(time.time() * 1000) % 100000) # random seed\n",
    "            # torch.random.manual_seed(42) # fixed seed\n",
    "            model = network.IHMPreliminary1DCNN(input_shape=input_shape, init_distr=INIT_WEIGHTS_DISTR).to(DEVICE)\n",
    "            sampled_models.append(model)\n",
    "        for model in sampled_models:\n",
    "            model.train()\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=lr_chckpnt.item())\n",
    "            # train the models on synthetic set\n",
    "            pred_syn = model(ts_syn_chckpnt)\n",
    "            loss_syn = loss_fn(pred_syn, lab_syn)\n",
    "            optimizer.zero_grad()\n",
    "            loss_syn.backward()\n",
    "            optimizer.step()\n",
    "        for model in sampled_models:\n",
    "            # evaluate the models on both full train set and test set\n",
    "            train_auc_roc = report.compute_roc_auc_score(model, train_loader)\n",
    "            test_auc_roc = report.compute_roc_auc_score(model, test_loader)\n",
    "            local_train_scores.append(train_auc_roc)\n",
    "            local_test_scores.append(test_auc_roc)\n",
    "        eval_scores_train.append(sum(local_train_scores) / len(local_train_scores))\n",
    "        eval_scores_test.append(sum(local_test_scores) / len(local_test_scores))\n",
    "        print(f\"Optimization iteration {it}, eval score (train): {eval_scores_train[-1]:.4f}, eval score (test): {eval_scores_test[-1]:.4f}\")\n",
    "    \n",
    "    # sample a batch of models\n",
    "    sampled_models = []\n",
    "    for j in range(NUM_SAMPLED_MODELS_TRAIN):\n",
    "        torch.random.manual_seed(int(time.time() * 1000) % 100000) # random seed\n",
    "        # torch.random.manual_seed(42) # fixed seed\n",
    "        model = network.IHMPreliminary1DCNN(input_shape=input_shape, init_distr=INIT_WEIGHTS_DISTR).to(DEVICE)\n",
    "        sampled_models.append(model)\n",
    "        \n",
    "    optimizer_ts.zero_grad()\n",
    "    optimizer_lr.zero_grad()\n",
    "\n",
    "    losses = []\n",
    "    for model in sampled_models:\n",
    "        # Step 1: Train each sampled model on synthetic dataset\n",
    "        model.train()\n",
    "        pred_syn = model(ts_syn)\n",
    "        loss_syn = loss_fn(pred_syn, lab_syn)\n",
    "        \n",
    "        for m in model.modules():\n",
    "            param_names = []\n",
    "            new_params = []\n",
    "            for n, p in m.named_parameters(recurse=False): # n is the param's name alone instead of \"module.name\"\n",
    "                gp, = torch.autograd.grad(loss_syn, p, create_graph=True) # enabling higher-order derivatives\n",
    "                new_p = p - lr * gp\n",
    "                new_p.to(DEVICE)\n",
    "                param_names.append(n) # save them, to delete leaf params later in another enumeration\n",
    "                new_params.append(new_p) # save them, to reset non-leaf params later in another enumeration\n",
    "            for i, n in enumerate(param_names):\n",
    "                delattr(m, n)\n",
    "                setattr(m, n, new_params[i])\n",
    "\n",
    "        # Step 2: Evaluate the objective function on real training data\n",
    "        pred_real = model(ts_real)\n",
    "        loss_real = loss_fn(pred_real, lab_real)\n",
    "        losses.append(loss_real)\n",
    "\n",
    "        # Clear gradients for the next model\n",
    "        model.zero_grad()\n",
    "\n",
    "    # Check if params are swapped as non-leaves\n",
    "    # for model in sampled_models:\n",
    "    #     for m in model.modules():\n",
    "    #         for n, p in m.named_parameters(recurse=False): # name is the param's name alone instead of module.name\n",
    "    #             print(p.grad_fn)\n",
    "    \n",
    "    # Step 3: Update synthetic data and learnable learning rate\n",
    "    total_loss = sum(losses)\n",
    "    total_loss.backward()  # Compute gradients based on real data losses\n",
    "\n",
    "    # Update synthetic data and learning rate\n",
    "    # print(lr.grad) # shouldn't be none\n",
    "    # print(ts_syn.grad) # shouldn't be none\n",
    "    optimizer_ts.step()\n",
    "    optimizer_lr.step()\n",
    "\n",
    "    # Logging the progress\n",
    "    pbar.set_postfix({\"loss\": f\"{total_loss.item():.4f}\",\n",
    "                      \"learnable lr\": f\"{lr.item()}\",\n",
    "                      })\n",
    "    optim_losses.append(total_loss.item())\n",
    "    syn_lrs.append(lr.item())\n",
    "\n",
    "    if total_loss.item() < min_optim_loss or it >= NUM_OPTIM_IT - 1: # save checkpoint\n",
    "        min_optim_loss = total_loss.item()\n",
    "        print(f\"New best! Saving checkpoint iteration {it}...\")\n",
    "        checkpoint = {\n",
    "            \"it\": it,\n",
    "            \"ts_syn\": ts_syn.detach().clone(),\n",
    "            \"lab_syn\": lab_syn.detach().clone(),\n",
    "            'optim_losses': optim_losses,\n",
    "            'syn_lrs': syn_lrs,\n",
    "            'eval_scores_train': eval_scores_train,\n",
    "            'eval_scores_test': eval_scores_test,\n",
    "        }\n",
    "        # Save checkpoint\n",
    "        torch.save(checkpoint, os.path.join(CHCKPNT_SAVE_DIR, 'distillation_checkpoint.pth'))\n",
    "        print(f\"Checkpoint at iteration {it} saved\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŒˆ Distill by matching gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready for training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef945399d3a746d499f8a619d3665207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training iteration:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distillation iteration 0 evaluation begins...\n",
      "Training 4 models for evaluation done. Generating classification reports...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ceacf984ff14e9288508aa2a2485e17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating classification reports for each model...:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization iteration 0, eval score (train): 0.4979, eval score (test): 0.4794\n",
      "Distillation iteration 10 evaluation begins...\n",
      "Training 4 models for evaluation done. Generating classification reports...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b24e44e73ccb4650ae5eb0d373ab216c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating classification reports for each model...:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization iteration 10, eval score (train): 0.4948, eval score (test): 0.5009\n",
      "Distillation iteration 20 evaluation begins...\n",
      "Training 4 models for evaluation done. Generating classification reports...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e07ff5effb424dc6b6876d6b86ab2de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating classification reports for each model...:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization iteration 20, eval score (train): 0.4986, eval score (test): 0.4995\n",
      "Distillation iteration 30 evaluation begins...\n",
      "Training 4 models for evaluation done. Generating classification reports...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "956d82e0d9d948d18579019705eae605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating classification reports for each model...:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization iteration 30, eval score (train): 0.5496, eval score (test): 0.5577\n",
      "Distillation iteration 40 evaluation begins...\n",
      "Training 4 models for evaluation done. Generating classification reports...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bd3c7a4bc2e463ead1867bf1543e0f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating classification reports for each model...:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization iteration 40, eval score (train): 0.4955, eval score (test): 0.5106\n",
      "Distillation iteration 50 evaluation begins...\n",
      "Training 4 models for evaluation done. Generating classification reports...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b479805c2a574d66bbc332a63c813633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating classification reports for each model...:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization iteration 50, eval score (train): 0.5499, eval score (test): 0.5464\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 93\u001b[0m\n\u001b[1;32m     91\u001b[0m loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(\u001b[39m0.0\u001b[39m)\u001b[39m.\u001b[39mto(DEVICE)\n\u001b[1;32m     92\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39min\u001b[39;00m (\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m):\n\u001b[0;32m---> 93\u001b[0m     ts_real, lab_real \u001b[39m=\u001b[39m train_set\u001b[39m.\u001b[39;49mrandom_sample_from_class(n_samples\u001b[39m=\u001b[39;49mREAL_BATCH_SIZE, \u001b[39mcls\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mcls\u001b[39;49m, no_duplicate\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     94\u001b[0m     ts_real, lab_real \u001b[39m=\u001b[39m ts_real\u001b[39m.\u001b[39mto(DEVICE), lab_real\u001b[39m.\u001b[39mto(DEVICE)\n\u001b[1;32m     95\u001b[0m     ts_syn \u001b[39m=\u001b[39m episodes_syn[\u001b[39mcls\u001b[39m\u001b[39m*\u001b[39mN_SAMPLES_PER_CLS: (\u001b[39mcls\u001b[39m\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m*\u001b[39mN_SAMPLES_PER_CLS]\n",
      "File \u001b[0;32m/project/ruishanl_1185/EHR-Distillation/utils/dataset.py:116\u001b[0m, in \u001b[0;36mIHMPreliminaryDatasetReal.random_sample_from_class\u001b[0;34m(self, n_samples, cls, no_duplicate)\u001b[0m\n\u001b[1;32m    114\u001b[0m label_tensors \u001b[39m=\u001b[39m []\n\u001b[1;32m    115\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m sampled_indices:\n\u001b[0;32m--> 116\u001b[0m     data_tensor, label_tensor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m(i)\n\u001b[1;32m    117\u001b[0m     data_tensors\u001b[39m.\u001b[39mappend(data_tensor)\n\u001b[1;32m    118\u001b[0m     label_tensors\u001b[39m.\u001b[39mappend(label_tensor)\n",
      "File \u001b[0;32m/project/ruishanl_1185/EHR-Distillation/utils/dataset.py:88\u001b[0m, in \u001b[0;36mIHMPreliminaryDatasetReal.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     85\u001b[0m file_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepisode_paths[idx]\n\u001b[1;32m     87\u001b[0m \u001b[39m# read csv, normalize, expand categorical features to one-hot, and form a tensor sized num_features * num_time_steps\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(file_path, index_col\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     89\u001b[0m processed_data \u001b[39m=\u001b[39m []\n\u001b[1;32m     90\u001b[0m \u001b[39mfor\u001b[39;00m col_name, col_data \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/.conda/envs/playground/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/.conda/envs/playground/lib/python3.11/site-packages/pandas/io/parsers/readers.py:617\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[1;32m    616\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[0;32m--> 617\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[0;32m~/.conda/envs/playground/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1748\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1741\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[1;32m   1742\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1743\u001b[0m     \u001b[39m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m     (\n\u001b[1;32m   1745\u001b[0m         index,\n\u001b[1;32m   1746\u001b[0m         columns,\n\u001b[1;32m   1747\u001b[0m         col_dict,\n\u001b[0;32m-> 1748\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(  \u001b[39m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1749\u001b[0m         nrows\n\u001b[1;32m   1750\u001b[0m     )\n\u001b[1;32m   1751\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1752\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.conda/envs/playground/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mread_low_memory(nrows)\n\u001b[1;32m    235\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Distill with matching loss\n",
    "# TODO: device\n",
    "\n",
    "# define hyper params\n",
    "TRAIN_IT = 100\n",
    "EVAL_EVERY_NUM_IT = 10\n",
    "EVAL_NUM_EPOCHS = 50\n",
    "NUM_SAMPLED_MODELS_EVAL = 4\n",
    "LR_DATA = 0.01\n",
    "LR_NET = 0.01\n",
    "NUM_OUTER_LOOP = 10\n",
    "NUM_INNER_LOOP = 50\n",
    "REAL_BATCH_SIZE = 2048\n",
    "SYN_BATCH_SIZE = 256\n",
    "\n",
    "N_SAMPLES_PER_CLS = 50\n",
    "INIT_WEIGHTS_DISTR = None\n",
    "\n",
    "# prepare dataloaders\n",
    "NUM_WORKERS = 8\n",
    "train_loader = DataLoader(train_set, REAL_BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "test_loader = DataLoader(test_set, REAL_BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "\n",
    "# initialize synthetic data\n",
    "episodes_syn = torch.randn(size=(2*N_SAMPLES_PER_CLS, input_shape[0], input_shape[1]), dtype=torch.float, requires_grad=True, device=DEVICE)\n",
    "labels_syn = torch.tensor(np.array([np.ones(N_SAMPLES_PER_CLS)*i for i in (0, 1)]), dtype=torch.long, requires_grad=False, device=DEVICE).view(-1) # 1D, length = episodes_per_cls * 2\n",
    "\n",
    "# define training optimizers and criterion\n",
    "optimizer_ts = torch.optim.SGD([episodes_syn,], lr=LR_DATA, momentum=0.5) # optimizer for synthetic data\n",
    "optimizer_ts.zero_grad()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(\"Ready for training\")\n",
    "\n",
    "eval_scores_train = [] # evaluation avg roc-auc score on train set\n",
    "eval_scores_test = [] # evaluation avg roc-auc score on test set\n",
    "\n",
    "PT_SAVE_DIR = \"./saved_data\"\n",
    "if not os.path.exists(PT_SAVE_DIR):\n",
    "    os.makedirs(PT_SAVE_DIR)\n",
    "pbar = tqdm(range(TRAIN_IT), desc=\"Training iteration\")\n",
    "for it in pbar:\n",
    "\n",
    "    # evaluate the distilled data every `EVAL_EVERY_NUM_IT` iterations\n",
    "    if it % EVAL_EVERY_NUM_IT == 0:\n",
    "        print(f\"Distillation iteration {it} evaluation begins...\")\n",
    "        episodes_syn_chckpnt = copy.deepcopy(episodes_syn.detach())\n",
    "        syn_dataset = dataset.TensorDataset(episodes_syn_chckpnt, copy.deepcopy(labels_syn)) # lab_syn are not learning objectives so just use it in-place\n",
    "        syn_loader = DataLoader(syn_dataset, SYN_BATCH_SIZE, shuffle=True)\n",
    "        \n",
    "        # sample a batch of models\n",
    "        sampled_models = []\n",
    "        local_train_scores = []\n",
    "        local_test_scores = []\n",
    "        for j in range(NUM_SAMPLED_MODELS_EVAL):\n",
    "            torch.random.manual_seed(int(time.time() * 1000) % 100000) # random seed\n",
    "            # torch.random.manual_seed(42) # fixed seed\n",
    "            model = network.IHMPreliminary1DCNN(input_shape=input_shape, init_distr=INIT_WEIGHTS_DISTR).to(DEVICE)\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=LR_NET)\n",
    "            sampled_models.append(model)\n",
    "        for model in sampled_models:\n",
    "            # update network\n",
    "            for e in range(EVAL_NUM_EPOCHS):\n",
    "                train.epoch(\"train\", syn_loader, model, criterion, optimizer=optimizer)\n",
    "        \n",
    "        print(f\"Training {NUM_SAMPLED_MODELS_EVAL} models for evaluation done. Generating classification reports...\")\n",
    "        sub_pbar = tqdm(range(NUM_SAMPLED_MODELS_EVAL), desc=\"Generating classification reports for each model...\",leave=False)\n",
    "        for idx in sub_pbar:\n",
    "            model = sampled_models[idx]\n",
    "            # evaluate the models on both full train set and test set\n",
    "            train_auc_roc = report.compute_roc_auc_score(model, train_loader)\n",
    "            test_auc_roc = report.compute_roc_auc_score(model, test_loader)\n",
    "            local_train_scores.append(train_auc_roc)\n",
    "            local_test_scores.append(test_auc_roc)\n",
    "        eval_scores_train.append(sum(local_train_scores) / len(local_train_scores))\n",
    "        eval_scores_test.append(sum(local_test_scores) / len(local_test_scores))\n",
    "        print(f\"Optimization iteration {it}, eval score (train): {eval_scores_train[-1]:.4f}, eval score (test): {eval_scores_test[-1]:.4f}\")\n",
    "    \n",
    "\n",
    "    # Train synthetic data\n",
    "    torch.random.manual_seed(int(time.time() * 1000) % 100000) # random init network\n",
    "    net = network.IHMPreliminary1DCNN(input_shape=input_shape, init_distr=INIT_WEIGHTS_DISTR).to(DEVICE)\n",
    "    net.train()\n",
    "    net_params = list(net.parameters())\n",
    "\n",
    "    optimizer_net = torch.optim.SGD(net.parameters(), lr=LR_NET)\n",
    "    optimizer_net.zero_grad()\n",
    "    loss_avg = 0\n",
    "\n",
    "    for ol in range(NUM_OUTER_LOOP):\n",
    "        # update synthetic data\n",
    "        loss = torch.tensor(0.0).to(DEVICE)\n",
    "        for cls in (0, 1):\n",
    "            ts_real, lab_real = train_set.random_sample_from_class(n_samples=REAL_BATCH_SIZE, cls=cls, no_duplicate=True)\n",
    "            ts_real, lab_real = ts_real.to(DEVICE), lab_real.to(DEVICE)\n",
    "            ts_syn = episodes_syn[cls*N_SAMPLES_PER_CLS: (cls+1)*N_SAMPLES_PER_CLS]\n",
    "            lab_syn = labels_syn[cls*N_SAMPLES_PER_CLS: (cls+1)*N_SAMPLES_PER_CLS]\n",
    "\n",
    "            out_real = net(ts_real)\n",
    "            loss_real = criterion(out_real, lab_real)\n",
    "            grad_real = torch.autograd.grad(loss_real, net_params)\n",
    "            grad_real = [_.detach().clone() for _ in grad_real]\n",
    "\n",
    "            out_syn = net(ts_syn)\n",
    "            loss_syn = criterion(out_syn, lab_syn)\n",
    "            grad_syn = torch.autograd.grad(loss_syn, net_params, create_graph=True) # create_graph: will be used to compute higher-order derivatives\n",
    "\n",
    "            # compute gradient matching loss, here using MSE, instead of the one proposed in DCwMG because it's too complicated\n",
    "            # dis = torch.tensor(0.0).to(DEVICE)\n",
    "            grad_real_vec = []\n",
    "            grad_syn_vec = []\n",
    "            for ig in range(len(grad_real)):\n",
    "                grad_real_vec.append(grad_real[ig].reshape((-1)))\n",
    "                grad_syn_vec.append(grad_syn[ig].reshape((-1)))\n",
    "            grad_real_vec = torch.cat(grad_real_vec, dim=0)\n",
    "            grad_syn_vec = torch.cat(grad_syn_vec, dim=0)\n",
    "            dis = torch.sum((grad_syn_vec - grad_real_vec)**2)\n",
    "\n",
    "            loss += dis\n",
    "        \n",
    "        optimizer_ts.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_ts.step()\n",
    "        loss_avg += loss.item()\n",
    "\n",
    "        if ol == NUM_OUTER_LOOP - 1:\n",
    "            break\n",
    "\n",
    "        # update network\n",
    "        episodes_syn_train, labels_syn_train = copy.deepcopy(episodes_syn.detach()), copy.deepcopy(labels_syn.detach())  # avoid any unaware modification\n",
    "        syn_dataset = dataset.TensorDataset(episodes_syn_train, labels_syn_train)\n",
    "        syn_loader = DataLoader(syn_dataset, SYN_BATCH_SIZE, shuffle=True)\n",
    "        for il in range(NUM_INNER_LOOP):\n",
    "            train.epoch(\"train\", syn_loader, net, criterion, optimizer=optimizer_net)\n",
    "\n",
    "    loss_avg /= (2 * NUM_OUTER_LOOP)\n",
    "    pbar.set_postfix({\"avg loss\": f\"{loss_avg:.4f}\",\n",
    "                      })\n",
    "\n",
    "torch.save({\"data\": (copy.deepcopy(episodes_syn.detach().cpu()), copy.deepcopy(labels_syn.detach().cpu()))},\n",
    "           os.path.join(PT_SAVE_DIR, \"distilled_dataset.pt\")\n",
    "           )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ¤”ï¸ Evaluate distilled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simultaneously train 2 models on distilled dataset and original dataset, compare performance\n",
    "N_SAMPLES_PER_CLS = 10\n",
    "\n",
    "REAL_BATCH_SIZE = 256\n",
    "SYN_BATCH_SIZE = 2*N_SAMPLES_PER_CLS\n",
    "\n",
    "pt_save_dir = \"./saved_data\"\n",
    "syn_pt = \"distilled_dataset.pt\"\n",
    "syn_pt_path = glob(os.path.join(pt_save_dir, syn_pt))[0]\n",
    "syn_data = torch.load(syn_pt_path, map_location=torch.device(DEVICE))\n",
    "syn_ts, syn_lab = syn_data[\"data\"]\n",
    "syn_ts = syn_ts.to(DEVICE)\n",
    "syn_lab = syn_lab.to(DEVICE)\n",
    "syn_set = dataset.TensorDataset(syn_ts, syn_lab)\n",
    "syn_loader = DataLoader(syn_set, 2*N_SAMPLES_PER_CLS)\n",
    "\n",
    "NUM_WORKERS = 8\n",
    "real_set = dataset.IHMPreliminaryDatasetReal(\n",
    "    dir=\"./data/mimic3/ihm_preliminary/train/\",\n",
    "    dstype=\"train\",\n",
    "    avg_dict=continuous_avgs_train,\n",
    "    std_dict=continuous_stds_train,\n",
    "    numcls_dict=categorical_numcls,\n",
    "    balance=True,\n",
    "    mask=True,\n",
    "    )\n",
    "real_loader = DataLoader(real_set, REAL_BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "\n",
    "model_syn = network.IHMPreliminary1DCNN().to(DEVICE)\n",
    "model_real = network.IHMPreliminary1DCNN().to(DEVICE)\n",
    "\n",
    "train_epoch = 100\n",
    "lr = 0.01\n",
    "\n",
    "optimizer_syn = torch.optim.SGD(model_syn.parameters(), lr)\n",
    "optimizer_syn.zero_grad()\n",
    "optimizer_real = torch.optim.SGD(model_real.parameters(), lr)\n",
    "optimizer_real.zero_grad()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model_syn.train()\n",
    "model_real.train()\n",
    "\n",
    "pbar = tqdm(range(train_epoch), desc=\"Evaluating synthetic dataset\")\n",
    "for e in pbar:\n",
    "    train.epoch(\"train\", syn_loader, model_syn, criterion, optimizer_syn, DEVICE)\n",
    "    syn_loss, syn_acc = train.epoch(\"test\", real_loader, model_syn, criterion, optimizer_syn, DEVICE)\n",
    "    real_loss, real_acc = train.epoch(\"train\", real_loader, model_real, criterion, optimizer_real, DEVICE)\n",
    "    \n",
    "    pbar.set_description(f\"Evaluating epoch {e}\\nsyn loss = {syn_loss}, syn acc = {syn_acc}\\nreal loss = {real_loss}, real acc = {real_acc}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
