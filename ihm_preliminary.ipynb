{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary experiment - distilled dataset for in-hospital mortality prediction task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“– Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âœ… Dependencies.\n",
    "\n",
    "For cuda, define `device` that'll be used throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import importlib\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import copy\n",
    "import os\n",
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âœ… Custom libs. **Always re-run the following code block after modifying `utils`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.report' from '/project/ruishanl_1185/EHR-Distillation/utils/report.py'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import preprocess, dataset, network, train, report\n",
    "importlib.reload(preprocess)\n",
    "importlib.reload(dataset)\n",
    "importlib.reload(network)\n",
    "importlib.reload(train)\n",
    "importlib.reload(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âœ… Compute statistics that'll be used for imputation and dataloading.\n",
    "\n",
    "Statistics can be load from saved pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from_saved = True\n",
    "stat_pkl_dir = \"./saved_data/stats/\"\n",
    "if not os.path.exists(stat_pkl_dir):\n",
    "    os.makedirs(stat_pkl_dir)\n",
    "\n",
    "categorical_numcls = {  # how many classes are there for categorical classes\n",
    "    \"capillary_refill_rate\": 2,\n",
    "    \"glascow_coma_scale_eye_opening\": 4,\n",
    "    \"glascow_coma_scale_motor_response\": 6,\n",
    "    \"glascow_coma_scale_total\": 13,\n",
    "    \"glascow_coma_scale_verbal_response\": 5,\n",
    "}\n",
    "\n",
    "pkl_path = os.path.join(stat_pkl_dir, \"ihm_preliminary.pkl\")\n",
    "if os.path.exists(pkl_path) and load_from_saved:\n",
    "    with open(pkl_path, 'rb') as f:\n",
    "        continuous_avgs_train, continuous_stds_train, categorical_modes_train = pickle.load(f)\n",
    "else:\n",
    "    continuous_avgs_train, continuous_stds_train, categorical_modes_train =  preprocess.compute_feature_statistics(\n",
    "        ts_dir=\"./data/mimic3/benchmark/in-hospital-mortality/train/\",\n",
    "        feature_dict=preprocess.mimic3_benchmark_variable_dict\n",
    "        )\n",
    "    with open(pkl_path, 'wb') as f:\n",
    "        pickle.dump((continuous_avgs_train, continuous_stds_train, categorical_modes_train), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean all data by resampling, imputating and masking.\n",
    "\n",
    "**Running this block once is enough.**\n",
    "(Cleaned data will be saved at ./data/mimic3/ihm_preliminary/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess.preprocess_ihm_timeseries_files(\n",
    "    ts_dir=\"./data/mimic3/benchmark/in-hospital-mortality/train/\",\n",
    "    output_dir=\"./data/mimic3/ihm_preliminary/train/\",\n",
    "    feature_dict=preprocess.mimic3_benchmark_variable_dict,\n",
    "    normal_value_dict=continuous_avgs_train|categorical_modes_train\n",
    "    )\n",
    "preprocess.preprocess_ihm_timeseries_files(\n",
    "    ts_dir=\"./data/mimic3/benchmark/in-hospital-mortality/test/\",\n",
    "    output_dir=\"./data/mimic3/ihm_preliminary/test/\",\n",
    "    feature_dict=preprocess.mimic3_benchmark_variable_dict,\n",
    "    normal_value_dict=continuous_avgs_train|categorical_modes_train\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’­ Evaluating model capacity on training objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define training and evaluation set for IHM objective.\n",
    "\n",
    "Apply mask / balance to the dataset here.\n",
    "\n",
    "You may have to re-run this block after modifying dataloader-related codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First item in the dataset: \n",
      "(tensor([[ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0668,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0489,  ...,  0.0220,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 1.0000,  0.0000,  0.0980,  ..., -0.0870,  4.1913,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.1293,  ..., -0.0870,  4.1913,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0176,  ..., -0.0870,  4.1913,  0.0000]]), tensor(0))\n",
      "Feature tensor shape: torch.Size([48, 42])\n",
      "First item in the dataset: \n",
      "(tensor([[ 1.0000,  0.0000,  0.0310,  ..., -0.1730, -0.8523,  0.0391],\n",
      "        [ 1.0000,  0.0000,  0.0578,  ..., -0.1615, -0.8523,  0.0391],\n",
      "        [ 1.0000,  0.0000,  0.0623,  ..., -0.1615, -0.8523,  0.0391],\n",
      "        ...,\n",
      "        [ 1.0000,  0.0000,  0.0132,  ...,  0.0335, -0.5163,  0.0521],\n",
      "        [ 1.0000,  0.0000,  0.0087,  ...,  0.0335, -0.5163,  0.0521],\n",
      "        [ 1.0000,  0.0000,  0.0400,  ...,  0.0335, -0.5163,  0.0521]]), tensor(0))\n",
      "Feature tensor shape: torch.Size([48, 42])\n",
      "Input tensor shape: torch.Size([48, 42])\n"
     ]
    }
   ],
   "source": [
    "# Pay attention to balance and mask settings\n",
    "\n",
    "train_set = dataset.IHMPreliminaryDatasetReal(\n",
    "    dir=\"./data/mimic3/ihm_preliminary/train/\",\n",
    "    dstype=\"train\",\n",
    "    avg_dict=continuous_avgs_train,\n",
    "    std_dict=continuous_stds_train,\n",
    "    numcls_dict=categorical_numcls,\n",
    "    balance=False,\n",
    "    mask=False,\n",
    "    )\n",
    "print(f\"First item in the dataset: \\n{train_set[0]}\")\n",
    "print(f\"Feature tensor shape: {train_set[0][0].shape}\")\n",
    "\n",
    "test_set = dataset.IHMPreliminaryDatasetReal(\n",
    "    dir=\"./data/mimic3/ihm_preliminary/test/\",\n",
    "    dstype=\"test\",\n",
    "    avg_dict=continuous_avgs_train,\n",
    "    std_dict=continuous_stds_train,\n",
    "    numcls_dict=categorical_numcls,\n",
    "    balance=False,\n",
    "    mask=False,\n",
    "    )\n",
    "print(f\"First item in the dataset: \\n{test_set[0]}\")\n",
    "print(f\"Feature tensor shape: {test_set[0][0].shape}\")\n",
    "\n",
    "input_shape = train_set[0][0].shape\n",
    "print(f\"Input tensor shape: {input_shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the label distribution in training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_0_cnt = 0\n",
    "label_1_cnt = 1\n",
    "for _, label in train_set:\n",
    "    if label > 0.5:\n",
    "        label_1_cnt += 1\n",
    "    else:\n",
    "        label_0_cnt += 1\n",
    "print(f\"Label 0 ratio: {label_0_cnt / (label_0_cnt + label_1_cnt)}\")\n",
    "print(f\"Label 1 ratio: {label_1_cnt / (label_0_cnt + label_1_cnt)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define hyper parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyper params\n",
    "ihm_epoch = 100\n",
    "ihm_batch_size = 256\n",
    "ihm_lr = 1e-3\n",
    "ihm_wd = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train an 1D CNN and save the best performing weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 1D CNN\n",
    "num_workers = 8\n",
    "pkl_save_dir = \"./saved_data/ihm_model/\"\n",
    "if not os.path.exists(pkl_save_dir):\n",
    "    os.makedirs(pkl_save_dir)\n",
    "\n",
    "train_loader = DataLoader(train_set, ihm_batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_set, ihm_batch_size, num_workers=num_workers)\n",
    "\n",
    "model = network.IHMPreliminary1DCNN(input_shape=input_shape).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=ihm_lr, weight_decay=ihm_wd)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "pbar = tqdm(range(ihm_epoch), desc=\"Training on original task\")\n",
    "min_loss = float(\"inf\")\n",
    "for e in pbar:\n",
    "    train_loss, train_acc = train.epoch(\"train\", train_loader, model, criterion, optimizer, device=device)\n",
    "    test_loss, test_acc = train.epoch(\"test\", test_loader, model, criterion, device=device)\n",
    "    if train_loss < min_loss:\n",
    "        filename = f'ihm_1dcnn_e{e}_trl{train_loss:.4f}_tel{test_loss:.4f}.pt'\n",
    "        file_path = os.path.join(pkl_save_dir, filename)\n",
    "\n",
    "        # Remove the previous checkpoint if it exists\n",
    "        existing_pts = [f for f in os.listdir(pkl_save_dir) if f.startswith(f'ihm_1dcnn_e{e}_') and f.endswith('.pt')]\n",
    "        for f in existing_pts:\n",
    "            os.remove(os.path.join(pkl_save_dir, f))\n",
    "        torch.save({\n",
    "                'epoch': e,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': train_loss,\n",
    "            }, file_path)\n",
    "    \n",
    "    pbar.set_description(f\"Training on original task, epoch {e}\\ntrain loss = {train_loss}, train acc = {train_acc}\\ntest loss = {test_loss}, test acc = {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train an MLP and save the best performing weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train MLP\n",
    "num_workers = 8\n",
    "pkl_save_dir = \"./saved_data/ihm_model/\"\n",
    "if not os.path.exists(pkl_save_dir):\n",
    "    os.makedirs(pkl_save_dir)\n",
    "\n",
    "train_loader = DataLoader(train_set, ihm_batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_set, ihm_batch_size, num_workers=num_workers)\n",
    "\n",
    "model = network.IHMPreliminaryMLP(input_shape=input_shape).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=ihm_lr, weight_decay=ihm_wd)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "pbar = tqdm(range(ihm_epoch), desc=\"Training on original task\")\n",
    "min_loss = float(\"inf\")\n",
    "for e in pbar:\n",
    "    train_loss, train_acc = train.epoch(\"train\", train_loader, model, criterion, optimizer, device)\n",
    "    test_loss, test_acc = train.epoch(\"test\", test_loader, model, criterion, device=device)\n",
    "    if train_loss < min_loss:\n",
    "        filename = f'ihm_mlp_e{e}_trl{train_loss:.4f}_tel{test_loss:.4f}.pt'\n",
    "        file_path = os.path.join(pkl_save_dir, filename)\n",
    "\n",
    "        # Remove the previous checkpoint if it exists\n",
    "        existing_pts = [f for f in os.listdir(pkl_save_dir) if f.startswith(f'ihm_mlp_e{e}_') and f.endswith('.pt')]\n",
    "        for f in existing_pts:\n",
    "            os.remove(os.path.join(pkl_save_dir, f))\n",
    "        torch.save({\n",
    "                'epoch': e,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': train_loss,\n",
    "            }, file_path)\n",
    "    \n",
    "    pbar.set_description(f\"Training on original task, epoch {e}\\ntrain loss = {train_loss}, train acc = {train_acc}\\ntest loss = {test_loss}, test acc = {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a saved model and evaluate on evaluation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro AUC-ROC score: 0.8296290690852289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[2778,   84],\n",
       "        [ 264,  110]]),\n",
       " {'0': {'precision': 0.9132149901380671,\n",
       "   'recall': 0.9706498951781971,\n",
       "   'f1-score': 0.9410569105691057,\n",
       "   'support': 2862},\n",
       "  '1': {'precision': 0.5670103092783505,\n",
       "   'recall': 0.29411764705882354,\n",
       "   'f1-score': 0.38732394366197176,\n",
       "   'support': 374},\n",
       "  'accuracy': 0.892459826946848,\n",
       "  'macro avg': {'precision': 0.7401126497082088,\n",
       "   'recall': 0.6323837711185103,\n",
       "   'f1-score': 0.6641904271155388,\n",
       "   'support': 3236},\n",
       "  'weighted avg': {'precision': 0.8732024590374693,\n",
       "   'recall': 0.892459826946848,\n",
       "   'f1-score': 0.8770593427003579,\n",
       "   'support': 3236}},\n",
       " 0.8296290690852289)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate saved model\n",
    "pt_save_dir = \"./saved_data/ihm_model/\"\n",
    "model_name = \"ihm_mlp_e3_*.pt\"\n",
    "eval_model = network.IHMPreliminaryMLP(input_shape=(48, 42))\n",
    "\n",
    "model_pt = glob(os.path.join(pt_save_dir, model_name))[0]\n",
    "model_data = torch.load(model_pt, map_location=torch.device(device))\n",
    "\n",
    "eval_model.load_state_dict(model_data[\"model_state_dict\"])\n",
    "eval_model.to(device)\n",
    "eval_model.eval()\n",
    "\n",
    "num_workers = 8\n",
    "balanced_test_set = dataset.IHMPreliminaryDatasetReal(\n",
    "    dir=\"./data/mimic3/ihm_preliminary/test/\",\n",
    "    dstype=\"test\",\n",
    "    avg_dict=continuous_avgs_train,\n",
    "    std_dict=continuous_stds_train,\n",
    "    numcls_dict=categorical_numcls,\n",
    "    balance=True,\n",
    "    mask=False,\n",
    "    )\n",
    "test_loader = DataLoader(test_set, ihm_batch_size, num_workers=num_workers) # pay attention to the test set used here\n",
    "\n",
    "report.run_classificatoin_report(eval_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline: train the model with randomly sampled subset of datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 1D CNN with random sampled 20 datapoints\n",
    "# TODO\n",
    "num_workers = 8\n",
    "pkl_save_dir = \"./saved_data/ihm_model/\"\n",
    "if not os.path.exists(pkl_save_dir):\n",
    "    os.makedirs(pkl_save_dir)\n",
    "\n",
    "num_workers = 8\n",
    "# define real train and test set\n",
    "# adjust balance and mask settings for datasets here\n",
    "train_set = dataset.IHMPreliminaryDatasetReal(\n",
    "    dir=\"./data/mimic3/ihm_preliminary/train/\",\n",
    "    dstype=\"train\",\n",
    "    avg_dict=continuous_avgs_train,\n",
    "    std_dict=continuous_stds_train,\n",
    "    numcls_dict=categorical_numcls,\n",
    "    balance=False,\n",
    "    mask=False,\n",
    "    )\n",
    "input_shape = train_set[0][0].shape\n",
    "# prepare loaders\n",
    "train_loader = DataLoader(train_set, 256, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "# Sample from class 0\n",
    "ts_class_0, lab_class_0 = train_set.random_sample_from_class(n_samples=10, cls=0)\n",
    "# ts_class_0, lab_class_0 = train_set.first_n_samples_from_class(n_samples=batch_size//2, cls=0)\n",
    "# Sample from class 1\n",
    "ts_class_1, lab_class_1 = train_set.random_sample_from_class(n_samples=10, cls=1)\n",
    "# ts_class_1, lab_class_1 = train_set.first_n_samples_from_class(n_samples=batch_size//2, cls=1)\n",
    "# Concatenate the time series data along the first dimension (batch size)\n",
    "ts_real = torch.cat((ts_class_0, ts_class_1), dim=0).to(device)\n",
    "# Concatenate the labels along the 0th dimension\n",
    "lab_real = torch.cat((lab_class_0, lab_class_1), dim=0).to(device)\n",
    "# print(ts_real.shape, lab_real.shape) # batch_size * num_time_steps * num_features\n",
    "\n",
    "model = network.IHMPreliminary1DCNN(input_shape=input_shape).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=ihm_lr, weight_decay=ihm_wd)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "pbar = tqdm(range(100), desc=\"Training on original task\")\n",
    "min_loss = float(\"inf\")\n",
    "for e in pbar:\n",
    "    model.train()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "    # train the models on synthetic set\n",
    "    pred_real = model(ts_real)\n",
    "    loss_real = loss_fn(pred_real, lab_real)\n",
    "    optimizer.zero_grad()\n",
    "    loss_real.backward()\n",
    "    optimizer.step()\n",
    "    if e % 10 == 0:\n",
    "        train_auc_roc = report.compute_roc_auc_score(model, train_loader)\n",
    "        print(train_auc_roc)\n",
    "    # if train_loss < min_loss:\n",
    "    #     filename = f'ihm_1dcnn_e{e}_trl{train_loss:.4f}_tel{test_loss:.4f}.pt'\n",
    "    #     file_path = os.path.join(pkl_save_dir, filename)\n",
    "\n",
    "    #     # Remove the previous checkpoint if it exists\n",
    "    #     existing_pts = [f for f in os.listdir(pkl_save_dir) if f.startswith(f'ihm_1dcnn_e{e}_') and f.endswith('.pt')]\n",
    "    #     for f in existing_pts:\n",
    "    #         os.remove(os.path.join(pkl_save_dir, f))\n",
    "    #     torch.save({\n",
    "    #             'epoch': e,\n",
    "    #             'model_state_dict': model.state_dict(),\n",
    "    #             'optimizer_state_dict': optimizer.state_dict(),\n",
    "    #             'loss': train_loss,\n",
    "    #         }, file_path)\n",
    "    \n",
    "    pbar.set_postfix({\"loss\": f\"{total_loss.item():.4f}\",\n",
    "                      \"learnable lr\": f\"{lr.item()}\",\n",
    "                      })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 EHR Distillation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Vanilla dataset distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c4f01265cbd4d5882a1b13bea19c742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training iteration:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization iteration 0 evaluation begins...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/delphynium/Documents/research projects/EHR-Distillation/ihm_preliminary.ipynb Cell 27\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/delphynium/Documents/research%20projects/EHR-Distillation/ihm_preliminary.ipynb#X32sZmlsZQ%3D%3D?line=103'>104</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/delphynium/Documents/research%20projects/EHR-Distillation/ihm_preliminary.ipynb#X32sZmlsZQ%3D%3D?line=104'>105</a>\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m sampled_models:\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/delphynium/Documents/research%20projects/EHR-Distillation/ihm_preliminary.ipynb#X32sZmlsZQ%3D%3D?line=105'>106</a>\u001b[0m     \u001b[39m# evaluate the models on both full train set and test set\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/delphynium/Documents/research%20projects/EHR-Distillation/ihm_preliminary.ipynb#X32sZmlsZQ%3D%3D?line=106'>107</a>\u001b[0m     train_auc_roc \u001b[39m=\u001b[39m report\u001b[39m.\u001b[39mcompute_roc_auc_score(model, train_loader)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/delphynium/Documents/research%20projects/EHR-Distillation/ihm_preliminary.ipynb#X32sZmlsZQ%3D%3D?line=107'>108</a>\u001b[0m     test_auc_roc \u001b[39m=\u001b[39m report\u001b[39m.\u001b[39mcompute_roc_auc_score(model, test_loader)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/delphynium/Documents/research%20projects/EHR-Distillation/ihm_preliminary.ipynb#X32sZmlsZQ%3D%3D?line=108'>109</a>\u001b[0m     local_train_scores\u001b[39m.\u001b[39mappend(train_auc_roc)\n",
      "File \u001b[0;32m~/Documents/research projects/EHR-Distillation/utils/report.py:23\u001b[0m, in \u001b[0;36mcompute_roc_auc_score\u001b[0;34m(model, loader)\u001b[0m\n\u001b[1;32m     20\u001b[0m model_scores \u001b[39m=\u001b[39m []  \u001b[39m# To store the softmax scores for each class\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> 23\u001b[0m     \u001b[39mfor\u001b[39;00m inputs, labels \u001b[39min\u001b[39;00m loader:\n\u001b[1;32m     24\u001b[0m         outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m     25\u001b[0m         softmax_scores \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39msoftmax(outputs, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)  \u001b[39m# Apply softmax to convert logits to probabilities\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/playground/lib/python3.11/site-packages/torch/utils/data/dataloader.py:438\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[1;32m    437\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 438\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_iterator()\n",
      "File \u001b[0;32m~/miniconda3/envs/playground/lib/python3.11/site-packages/torch/utils/data/dataloader.py:386\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 386\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/playground/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1039\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1032\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1033\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1039\u001b[0m w\u001b[39m.\u001b[39mstart()\n\u001b[1;32m   1040\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1041\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m~/miniconda3/envs/playground/lib/python3.11/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Popen(\u001b[39mself\u001b[39m)\n\u001b[1;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/playground/lib/python3.11/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39mget_context()\u001b[39m.\u001b[39mProcess\u001b[39m.\u001b[39m_Popen(process_obj)\n",
      "File \u001b[0;32m~/miniconda3/envs/playground/lib/python3.11/multiprocessing/context.py:288\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    286\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    287\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_posix\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[0;32m--> 288\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[0;32m~/miniconda3/envs/playground/lib/python3.11/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fds \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(process_obj)\n",
      "File \u001b[0;32m~/miniconda3/envs/playground/lib/python3.11/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturncode \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinalizer \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_launch(process_obj)\n",
      "File \u001b[0;32m~/miniconda3/envs/playground/lib/python3.11/multiprocessing/popen_spawn_posix.py:62\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msentinel \u001b[39m=\u001b[39m parent_r\n\u001b[1;32m     61\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(parent_w, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m, closefd\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m---> 62\u001b[0m         f\u001b[39m.\u001b[39mwrite(fp\u001b[39m.\u001b[39mgetbuffer())\n\u001b[1;32m     63\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     fds_to_close \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Vanilla Dataset Distillation intends to get dataset that is able to train a model within only 1 epoch\n",
    "\n",
    "# define hyper params\n",
    "num_optim_it = 1000\n",
    "eval_every_num_it = 10\n",
    "\n",
    "init_lr = 0.001\n",
    "step_size = 0.001\n",
    "init_weights_distr = \"kaiming\"\n",
    "batch_size = 256\n",
    "num_sampled_models_train = 16\n",
    "num_sampled_models_eval = 4\n",
    "ts_per_cls = 10\n",
    "\n",
    "# checkpoints saving\n",
    "chckpnt_save_dir = \"./saved_data\"\n",
    "if not os.path.exists(chckpnt_save_dir):\n",
    "    os.makedirs(chckpnt_save_dir)\n",
    "\n",
    "num_workers = 8\n",
    "# define real train and test set\n",
    "# adjust balance and mask settings for datasets here\n",
    "train_set = dataset.IHMPreliminaryDatasetReal(\n",
    "    dir=\"./data/mimic3/ihm_preliminary/train/\",\n",
    "    dstype=\"train\",\n",
    "    avg_dict=continuous_avgs_train,\n",
    "    std_dict=continuous_stds_train,\n",
    "    numcls_dict=categorical_numcls,\n",
    "    balance=False,\n",
    "    mask=False,\n",
    "    )\n",
    "test_set = dataset.IHMPreliminaryDatasetReal(\n",
    "    dir=\"./data/mimic3/ihm_preliminary/test/\",\n",
    "    dstype=\"test\",\n",
    "    avg_dict=continuous_avgs_train,\n",
    "    std_dict=continuous_stds_train,\n",
    "    numcls_dict=categorical_numcls,\n",
    "    balance=False,\n",
    "    mask=False,\n",
    "    )\n",
    "input_shape = train_set[0][0].shape\n",
    "# prepare loaders\n",
    "train_loader = DataLoader(train_set, batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_set, batch_size, num_workers=num_workers)\n",
    "\n",
    "# initialize random synth dataset\n",
    "ts_syn = torch.randn(size=(2*ts_per_cls, input_shape[0], input_shape[1]), dtype=torch.float, requires_grad=True, device=device) # device is ignored by far\n",
    "lab_syn = torch.tensor(np.array([np.ones(ts_per_cls)*i for i in (0, 1)]), dtype=torch.long, requires_grad=False, device=device).view(-1) # 1-D, length = episodes_per_cls * 2\n",
    "\n",
    "# initialize learning rate\n",
    "lr = torch.tensor([init_lr], dtype=torch.float, requires_grad=True, device=device) # make it learnable\n",
    "\n",
    "optimizer_ts = torch.optim.Adam([ts_syn], lr=step_size)\n",
    "optimizer_lr = torch.optim.Adam([lr], lr=step_size)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# data used for plotting curves\n",
    "optim_losses = [] # optimization objective loss each iteration\n",
    "min_optim_loss = float('inf')\n",
    "syn_lrs = [] # synthetic lr\n",
    "eval_scores_train = [] # evaluation avg roc-auc score on train set\n",
    "eval_scores_test = [] # evaluation avg roc-auc score on test set\n",
    "\n",
    "# begin training steps\n",
    "pbar = tqdm(range(num_optim_it), desc=\"Training iteration\")\n",
    "for it in pbar:\n",
    "    # get a minibatch of real training data\n",
    "    # Sample from class 0\n",
    "    ts_class_0, lab_class_0 = train_set.random_sample_from_class(n_samples=batch_size//2, cls=0)\n",
    "    # ts_class_0, lab_class_0 = train_set.first_n_samples_from_class(n_samples=batch_size//2, cls=0)\n",
    "    # Sample from class 1\n",
    "    ts_class_1, lab_class_1 = train_set.random_sample_from_class(n_samples=batch_size//2, cls=1)\n",
    "    # ts_class_1, lab_class_1 = train_set.first_n_samples_from_class(n_samples=batch_size//2, cls=1)\n",
    "    # Concatenate the time series data along the first dimension (batch size)\n",
    "    ts_real = torch.cat((ts_class_0, ts_class_1), dim=0).to(device)\n",
    "    # Concatenate the labels along the 0th dimension\n",
    "    lab_real = torch.cat((lab_class_0, lab_class_1), dim=0).to(device)\n",
    "    # print(ts_real.shape, lab_real.shape) # batch_size * num_time_steps * num_features\n",
    "\n",
    "    # evaluate the distilled data every eval_every_num_it iterations\n",
    "    if it % eval_every_num_it == 0:\n",
    "        print(f\"Optimization iteration {it} evaluation begins...\")\n",
    "        ts_syn_chckpnt = ts_syn.detach().clone()\n",
    "        # lab_syn are not learning objectives so just use it in-place\n",
    "        lr_chckpnt = lr.detach().clone()\n",
    "        # sample a batch of models\n",
    "        sampled_models = []\n",
    "        local_train_scores = []\n",
    "        local_test_scores = []\n",
    "        for j in range(num_sampled_models_eval):\n",
    "            torch.random.manual_seed(int(time.time() * 1000) % 100000) # random seed\n",
    "            # torch.random.manual_seed(42) # fixed seed\n",
    "            model = network.IHMPreliminary1DCNN(input_shape=input_shape, init_distr=init_weights_distr).to(device)\n",
    "            sampled_models.append(model)\n",
    "        for model in sampled_models:\n",
    "            model.train()\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=lr_chckpnt.item())\n",
    "            # train the models on synthetic set\n",
    "            pred_syn = model(ts_syn_chckpnt)\n",
    "            loss_syn = loss_fn(pred_syn, lab_syn)\n",
    "            optimizer.zero_grad()\n",
    "            loss_syn.backward()\n",
    "            optimizer.step()\n",
    "        for model in sampled_models:\n",
    "            # evaluate the models on both full train set and test set\n",
    "            train_auc_roc = report.compute_roc_auc_score(model, train_loader)\n",
    "            test_auc_roc = report.compute_roc_auc_score(model, test_loader)\n",
    "            local_train_scores.append(train_auc_roc)\n",
    "            local_test_scores.append(test_auc_roc)\n",
    "        eval_scores_train.append(sum(local_train_scores) / len(local_train_scores))\n",
    "        eval_scores_test.append(sum(local_test_scores) / len(local_test_scores))\n",
    "        print(f\"Optimization iteration {it}, eval score (train): {eval_scores_train[-1]:.4f}, eval score (test): {eval_scores_test[-1]:.4f}\")\n",
    "    # sample a batch of models\n",
    "    sampled_models = []\n",
    "    for j in range(num_sampled_models_train):\n",
    "        torch.random.manual_seed(int(time.time() * 1000) % 100000) # random seed\n",
    "        # torch.random.manual_seed(42) # fixed seed\n",
    "        model = network.IHMPreliminary1DCNN(input_shape=input_shape, init_distr=init_weights_distr).to(device)\n",
    "        sampled_models.append(model)\n",
    "        \n",
    "    optimizer_ts.zero_grad()\n",
    "    optimizer_lr.zero_grad()\n",
    "\n",
    "    losses = []\n",
    "    for model in sampled_models:\n",
    "        # Step 1: Train each sampled model on synthetic dataset\n",
    "        model.train()\n",
    "        pred_syn = model(ts_syn)\n",
    "        loss_syn = loss_fn(pred_syn, lab_syn)\n",
    "        \n",
    "        for m in model.modules():\n",
    "            param_names = []\n",
    "            new_params = []\n",
    "            for n, p in m.named_parameters(recurse=False): # n is the param's name alone instead of \"module.name\"\n",
    "                gp, = torch.autograd.grad(loss_syn, p, create_graph=True) # enabling higher-order derivatives\n",
    "                new_p = p - lr * gp\n",
    "                new_p.to(device)\n",
    "                param_names.append(n) # save them, to delete leaf params later in another enumeration\n",
    "                new_params.append(new_p) # save them, to reset non-leaf params later in another enumeration\n",
    "            for i, n in enumerate(param_names):\n",
    "                delattr(m, n)\n",
    "                setattr(m, n, new_params[i])\n",
    "\n",
    "        # Step 2: Evaluate the objective function on real training data\n",
    "        pred_real = model(ts_real)\n",
    "        loss_real = loss_fn(pred_real, lab_real)\n",
    "        losses.append(loss_real)\n",
    "\n",
    "        # Clear gradients for the next model\n",
    "        model.zero_grad()\n",
    "\n",
    "    # Check if params are swapped as non-leaves\n",
    "    for model in sampled_models:\n",
    "        for m in model.modules():\n",
    "            for n, p in m.named_parameters(recurse=False): # name is the param's name alone instead of module.name\n",
    "                print(p.grad_fn)\n",
    "    \n",
    "    # Step 3: Update synthetic data and learnable learning rate\n",
    "    total_loss = sum(losses)\n",
    "    total_loss.backward()  # Compute gradients based on real data losses\n",
    "\n",
    "    # Update synthetic data and learning rate\n",
    "    # print(lr.grad) # shouldn't be none\n",
    "    # print(ts_syn.grad) # shouldn't be none\n",
    "    optimizer_ts.step()\n",
    "    optimizer_lr.step()\n",
    "\n",
    "    # Logging the progress\n",
    "    pbar.set_postfix({\"loss\": f\"{total_loss.item():.4f}\",\n",
    "                      \"learnable lr\": f\"{lr.item()}\",\n",
    "                      })\n",
    "    optim_losses.append(total_loss.item())\n",
    "    syn_lrs.append(lr.item())\n",
    "\n",
    "    if total_loss.item() < min_optim_loss or it >= num_optim_it - 1: # save checkpoint\n",
    "        min_optim_loss = total_loss.item()\n",
    "        print(f\"New best! Saving checkpoint iteration {it}...\")\n",
    "        checkpoint = {\n",
    "            \"it\": it,\n",
    "            \"ts_syn\": ts_syn.detach().clone(),\n",
    "            \"lab_syn\": lab_syn.detach().clone(),\n",
    "            'optim_losses': optim_losses,\n",
    "            'syn_lrs': syn_lrs,\n",
    "            'eval_scores_train': eval_scores_train,\n",
    "            'eval_scores_test': eval_scores_test,\n",
    "        }\n",
    "        # Save checkpoint\n",
    "        torch.save(checkpoint, os.path.join(chckpnt_save_dir, 'distillation_checkpoint.pth'))\n",
    "        print(f\"Checkpoint at iteration {it} saved\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Distill by matching gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyper params\n",
    "\n",
    "train_it = 100\n",
    "lr_data = 0.01\n",
    "lr_net = 0.01\n",
    "episodes_per_cls = 10\n",
    "num_outer_loop = 10\n",
    "num_inner_loop = 50\n",
    "real_batch_size = 256\n",
    "syn_batch_size = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize synthetic data\n",
    "\n",
    "episodes_syn = torch.randn(size=(2*episodes_per_cls, input_shape[0], input_shape[1]), dtype=torch.float, requires_grad=True) # device is ignored by far\n",
    "labels_syn = torch.tensor(np.array([np.ones(episodes_per_cls)*i for i in (0, 1)]), dtype=torch.long, requires_grad=False).view(-1) # 1-D, length = episodes_per_cls * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training optimizers and criterion\n",
    "optimizer_ts = torch.optim.SGD([episodes_syn,], lr=lr_data, momentum=0.5) # optimizer for synthetic data\n",
    "optimizer_ts.zero_grad()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(\"Ready for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with matching loss\n",
    "# TODO: device\n",
    "\n",
    "pkl_save_dir = \"./saved_data\"\n",
    "if not os.path.exists(pkl_save_dir):\n",
    "    os.makedirs(pkl_save_dir)\n",
    "pbar = tqdm(range(train_it), desc=\"Training iteration\")\n",
    "for it in pbar:\n",
    "\n",
    "    # Evaluate synthetic data\n",
    "    # TODO\n",
    "\n",
    "    # Train synthetic data\n",
    "    torch.random.manual_seed(int(time.time() * 1000) % 100000) # random init network\n",
    "    net = network.IHMPreliminary1DCNN(input_shape=input_shape)\n",
    "    net.train()\n",
    "    net_params = list(net.parameters())\n",
    "\n",
    "    optimizer_net = torch.optim.SGD(net.parameters(), lr=lr_net)\n",
    "    optimizer_net.zero_grad()\n",
    "    loss_avg = 0\n",
    "\n",
    "    for ol in range(num_outer_loop):\n",
    "        # update synthetic data\n",
    "        loss = torch.tensor(0.0)\n",
    "        for cls in (0, 1):\n",
    "            ts_real, lab_real = train_set.random_sample_from_class(n_samples=real_batch_size, cls=cls)\n",
    "            ts_syn = episodes_syn[cls*episodes_per_cls: (cls+1)*episodes_per_cls]\n",
    "            lab_syn = labels_syn[cls*episodes_per_cls: (cls+1)*episodes_per_cls]\n",
    "\n",
    "            out_real = net(ts_real)\n",
    "            loss_real = criterion(out_real, lab_real)\n",
    "            grad_real = torch.autograd.grad(loss_real, net_params)\n",
    "            grad_real = [_.detach().clone() for _ in grad_real]\n",
    "\n",
    "            out_syn = net(ts_syn)\n",
    "            loss_syn = criterion(out_syn, lab_syn)\n",
    "            grad_syn = torch.autograd.grad(loss_syn, net_params, create_graph=True) # create_graph: will be used to compute higher-order derivatives\n",
    "\n",
    "            # compute gradient matching loss, here using MSE, instead of the one proposed in DCwMG because it's too complicated\n",
    "            dis = torch.tensor(0.0)\n",
    "            grad_real_vec = []\n",
    "            grad_syn_vec = []\n",
    "            for ig in range(len(grad_real)):\n",
    "                grad_real_vec.append(grad_real[ig].reshape((-1)))\n",
    "                grad_syn_vec.append(grad_syn[ig].reshape((-1)))\n",
    "            grad_real_vec = torch.cat(grad_real_vec, dim=0)\n",
    "            grad_syn_vec = torch.cat(grad_syn_vec, dim=0)\n",
    "            dis = torch.sum((grad_syn_vec - grad_real_vec)**2)\n",
    "\n",
    "            loss += dis\n",
    "        \n",
    "        optimizer_ts.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_ts.step()\n",
    "        loss_avg += loss.item()\n",
    "\n",
    "        if ol == num_outer_loop - 1:\n",
    "            break\n",
    "\n",
    "        # update network\n",
    "        episodes_syn_train, labels_syn_train = copy.deepcopy(episodes_syn.detach()), copy.deepcopy(labels_syn.detach())  # avoid any unaware modification\n",
    "        syn_dataset = dataset.TensorDataset(episodes_syn_train, labels_syn_train)\n",
    "        train_loader = DataLoader(syn_dataset, syn_batch_size, shuffle=True)\n",
    "        for il in range(num_inner_loop):\n",
    "            train.epoch(\"train\", train_loader, net, optimizer_net, criterion)\n",
    "\n",
    "    loss_avg /= (2 * num_outer_loop)\n",
    "    pbar.set_description(f\"Training iteration, average loss = {loss_avg}\")\n",
    "\n",
    "torch.save({\"data\": (copy.deepcopy(episodes_syn.detach()), copy.deepcopy(labels_syn.detach()))},\n",
    "           os.path.join(pkl_save_dir, \"distilled_dataset.pt\")\n",
    "           )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Evaluate distilled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simultaneously train 2 models on distilled dataset and original dataset, compare performance\n",
    "episodes_per_cls = 10\n",
    "\n",
    "real_batch_size = 256\n",
    "syn_batch_size = 2*episodes_per_cls\n",
    "\n",
    "pt_save_dir = \"./saved_data\"\n",
    "syn_pt = \"distilled_dataset.pt\"\n",
    "syn_pt_path = glob(os.path.join(pt_save_dir, syn_pt))[0]\n",
    "syn_data = torch.load(syn_pt_path, map_location=torch.device(device))\n",
    "syn_ts, syn_lab = syn_data[\"data\"]\n",
    "syn_ts = syn_ts.to(device)\n",
    "syn_lab = syn_lab.to(device)\n",
    "syn_set = dataset.TensorDataset(syn_ts, syn_lab)\n",
    "syn_loader = DataLoader(syn_set, 2*episodes_per_cls)\n",
    "\n",
    "num_workers = 8\n",
    "real_set = dataset.IHMPreliminaryDatasetReal(\n",
    "    dir=\"./data/mimic3/ihm_preliminary/train/\",\n",
    "    dstype=\"train\",\n",
    "    avg_dict=continuous_avgs_train,\n",
    "    std_dict=continuous_stds_train,\n",
    "    numcls_dict=categorical_numcls,\n",
    "    balance=True,\n",
    "    mask=True,\n",
    "    )\n",
    "real_loader = DataLoader(real_set, real_batch_size, num_workers=num_workers)\n",
    "\n",
    "model_syn = network.IHMPreliminary1DCNN().to(device)\n",
    "model_real = network.IHMPreliminary1DCNN().to(device)\n",
    "\n",
    "train_epoch = 100\n",
    "lr = 0.01\n",
    "\n",
    "optimizer_syn = torch.optim.SGD(model_syn.parameters(), lr)\n",
    "optimizer_syn.zero_grad()\n",
    "optimizer_real = torch.optim.SGD(model_real.parameters(), lr)\n",
    "optimizer_real.zero_grad()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model_syn.train()\n",
    "model_real.train()\n",
    "\n",
    "pbar = tqdm(range(train_epoch), desc=\"Evaluating synthetic dataset\")\n",
    "for e in pbar:\n",
    "    train.epoch(\"train\", syn_loader, model_syn, criterion, optimizer_syn, device)\n",
    "    syn_loss, syn_acc = train.epoch(\"test\", real_loader, model_syn, criterion, optimizer_syn, device)\n",
    "    real_loss, real_acc = train.epoch(\"train\", real_loader, model_real, criterion, optimizer_real, device)\n",
    "    \n",
    "    pbar.set_description(f\"Evaluating epoch {e}\\nsyn loss = {syn_loss}, syn acc = {syn_acc}\\nreal loss = {real_loss}, real acc = {real_acc}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
