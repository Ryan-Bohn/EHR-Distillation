{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: CPU\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, model_selection\n",
    "import copy\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from glob import glob\n",
    "from collections import defaultdict\n",
    "\n",
    "import importlib\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device:\", DEVICE.upper())\n",
    "\n",
    "# manual random seed is used for dataset partitioning\n",
    "# to ensure reproducible results across runs\n",
    "RNG = torch.Generator().manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.report' from '/Users/d9sus4/Documents/research projects/EHR-Distillation/utils/report.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import custom libraries\n",
    "\n",
    "from utils import preprocess, dataset, network, train, report\n",
    "importlib.reload(preprocess)\n",
    "importlib.reload(dataset)\n",
    "importlib.reload(network)\n",
    "importlib.reload(train)\n",
    "importlib.reload(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute (or load from saved pickel) data statistics\n",
    "\n",
    "LOAD_FROM_SAVED = True\n",
    "STAT_PKL_DIR = \"./saved_data/stats/\"\n",
    "if not os.path.exists(STAT_PKL_DIR):\n",
    "    os.makedirs(STAT_PKL_DIR)\n",
    "\n",
    "CATEGORICAL_NUM_CLS_DICT = {  # how many classes are there for categorical classes\n",
    "    \"capillary_refill_rate\": 2,\n",
    "    \"glascow_coma_scale_eye_opening\": 4,\n",
    "    \"glascow_coma_scale_motor_response\": 6,\n",
    "    \"glascow_coma_scale_total\": 13,\n",
    "    \"glascow_coma_scale_verbal_response\": 5,\n",
    "}\n",
    "\n",
    "stat_pkl_path = os.path.join(STAT_PKL_DIR, \"ihm_preliminary.pkl\")\n",
    "if os.path.exists(stat_pkl_path) and LOAD_FROM_SAVED:\n",
    "    with open(stat_pkl_path, 'rb') as f:\n",
    "        continuous_avgs_train, continuous_stds_train, categorical_modes_train = pickle.load(f)\n",
    "else: # compute and save\n",
    "    continuous_avgs_train, continuous_stds_train, categorical_modes_train =  preprocess.compute_feature_statistics(\n",
    "        ts_dir=\"./data/mimic3/benchmark/in-hospital-mortality/train/\",\n",
    "        feature_dict=preprocess.mimic3_benchmark_variable_dict\n",
    "        )\n",
    "    with open(stat_pkl_path, 'wb') as f:\n",
    "        pickle.dump((continuous_avgs_train, continuous_stds_train, categorical_modes_train), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining timeseries episodes with label...\n",
      "Loading dataset to RAM...\n",
      "Found unified episodes file at ./data/mimic3/ihm_preliminary/train/all_episodes.pkl, skipping individuals...\n",
      "First item in the dataset: \n",
      "(tensor([[ 1.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00, -3.8303e-16],\n",
      "        [ 1.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00, -3.8303e-16],\n",
      "        [ 1.0000e+00,  0.0000e+00,  3.9972e-02,  ...,  5.6418e-02,\n",
      "          1.4145e+00,  4.7770e-02],\n",
      "        ...,\n",
      "        [ 1.0000e+00,  0.0000e+00,  2.6577e-02,  ...,  8.5097e-02,\n",
      "          1.4145e+00,  9.9521e-02],\n",
      "        [ 1.0000e+00,  0.0000e+00,  1.0695e-01,  ..., -1.8149e-02,\n",
      "          1.4145e+00,  9.9521e-02],\n",
      "        [ 1.0000e+00,  0.0000e+00,  2.2111e-02,  ..., -1.8149e-02,\n",
      "          1.4145e+00,  9.9521e-02]]), tensor(0))\n",
      "Feature tensor shape: torch.Size([48, 42])\n",
      "Joining timeseries episodes with label...\n",
      "Loading dataset to RAM...\n",
      "Found unified episodes file at ./data/mimic3/ihm_preliminary/test/all_episodes.pkl, skipping individuals...\n",
      "First item in the dataset: \n",
      "(tensor([[ 1.0000,  0.0000, -0.0583,  ..., -0.0835,  0.0000,  0.0607],\n",
      "        [ 1.0000,  0.0000, -0.0449,  ...,  0.0197,  0.0000,  0.0607],\n",
      "        [ 1.0000,  0.0000, -0.0806,  ...,  0.0507,  0.0000,  0.0564],\n",
      "        ...,\n",
      "        [ 1.0000,  0.0000, -0.0404,  ..., -0.0698,  0.4754,  0.0693],\n",
      "        [ 1.0000,  0.0000, -0.0315,  ..., -0.0698,  0.4754,  0.0693],\n",
      "        [ 1.0000,  0.0000, -0.0315,  ..., -0.0698,  0.4754,  0.0693]]), tensor(0))\n",
      "Feature tensor shape: torch.Size([48, 42])\n",
      "Input tensor shape: torch.Size([48, 42])\n"
     ]
    }
   ],
   "source": [
    "# define ihm objective datasets and dataloaders\n",
    "\n",
    "ihm_num_cls = 2 # this is a binary classification objective\n",
    "\n",
    "IHM_BALANCE = False\n",
    "IHM_MASK = False\n",
    "\n",
    "LOAD_TO_RAM = True\n",
    "\n",
    "ihm_train_set = dataset.IHMPreliminaryDatasetReal(\n",
    "    dir=\"./data/mimic3/ihm_preliminary/train/\",\n",
    "    dstype=\"train\",\n",
    "    avg_dict=continuous_avgs_train,\n",
    "    std_dict=continuous_stds_train,\n",
    "    numcls_dict=CATEGORICAL_NUM_CLS_DICT,\n",
    "    balance=IHM_BALANCE,\n",
    "    mask=IHM_MASK,\n",
    "    load_to_ram=LOAD_TO_RAM,\n",
    "    )\n",
    "print(f\"First item in the dataset: \\n{ihm_train_set[0]}\")\n",
    "print(f\"Feature tensor shape: {ihm_train_set[0][0].shape}\")\n",
    "\n",
    "ihm_test_set = dataset.IHMPreliminaryDatasetReal(\n",
    "    dir=\"./data/mimic3/ihm_preliminary/test/\",\n",
    "    dstype=\"test\",\n",
    "    avg_dict=continuous_avgs_train,\n",
    "    std_dict=continuous_stds_train,\n",
    "    numcls_dict=CATEGORICAL_NUM_CLS_DICT,\n",
    "    balance=IHM_BALANCE,\n",
    "    mask=IHM_MASK,\n",
    "    load_to_ram=LOAD_TO_RAM,\n",
    "    )\n",
    "print(f\"First item in the dataset: \\n{ihm_test_set[0]}\")\n",
    "print(f\"Feature tensor shape: {ihm_test_set[0][0].shape}\")\n",
    "\n",
    "ihm_feat_shape = ihm_train_set[0][0].shape\n",
    "print(f\"Input tensor shape: {ihm_feat_shape}\")\n",
    "\n",
    "# prepare dataloaders\n",
    "\n",
    "NUM_WORKERS = 8 if not LOAD_TO_RAM else 0\n",
    "IHM_BATCH_SIZE = 256\n",
    "\n",
    "ihm_train_loader = DataLoader(ihm_train_set, IHM_BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "ihm_test_loader = DataLoader(ihm_test_set, IHM_BATCH_SIZE, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBJECTIVE = [\"ihm\"][0]\n",
    "\n",
    "if OBJECTIVE == \"ihm\":\n",
    "    train_set = ihm_train_set\n",
    "    test_set = ihm_test_set\n",
    "    num_cls = ihm_num_cls\n",
    "    feat_shape = ihm_feat_shape\n",
    "    train_set = ihm_train_set\n",
    "    test_set = ihm_test_set\n",
    "    train_loader = ihm_train_loader\n",
    "    test_loader = ihm_test_loader\n",
    "    net_name = \"1dcnn\"\n",
    "    continuous_avgs_train, continuous_stds_train, categorical_modes_train = continuous_avgs_train, continuous_stds_train, categorical_modes_train\n",
    "    comment = \"\"\n",
    "    train_it = 1000\n",
    "    lr = 1e-2\n",
    "else:\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coreset size = 2\n"
     ]
    }
   ],
   "source": [
    "# get the coreset\n",
    "\n",
    "CORESET = [\"random\", ][0]\n",
    "# define num sampled datapoints\n",
    "NPC = 1\n",
    "\n",
    "CORESET_BATCH_SIZE = 256\n",
    "\n",
    "feats = []\n",
    "labs = []\n",
    "for cls in range(num_cls):\n",
    "    feat, lab = train_set.random_sample_from_class(n_samples=NPC, cls=cls, no_duplicate=True, return_as_tensor=True)\n",
    "    feats.append(feat)\n",
    "    labs.append(lab)\n",
    "feats = torch.cat(feats, dim=0).to(DEVICE)\n",
    "labs = torch.cat(labs, dim=0).to(DEVICE)\n",
    "coreset = dataset.TensorDataset(feats, labs)\n",
    "print(f\"Coreset size = {len(coreset)}\")\n",
    "coreset_loader = DataLoader(coreset, batch_size=CORESET_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define get_net\n",
    "\n",
    "def get_net(name, feat_shape):\n",
    "    if name == \"1dcnn\":\n",
    "        net = network.IHMPreliminary1DCNN(input_shape=feat_shape)\n",
    "    elif name == \"mlp\":\n",
    "        net = network.IHMPreliminaryMLP(input_shape=feat_shape)\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training:\n"
     ]
    }
   ],
   "source": [
    "# train and evaluate model on coreset\n",
    "\n",
    "# evaluate distilled dataset on both training set and test set\n",
    "\n",
    "NUM_SAMPLED_NETS_EVAL = 4\n",
    "\n",
    "# sample a batch of models to eval on\n",
    "sampled_nets = []\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "for j in range(NUM_SAMPLED_NETS_EVAL):\n",
    "    net = get_net(net_name, feat_shape=feat_shape).to(DEVICE)\n",
    "    sampled_nets.append(net)\n",
    "\n",
    "# eval the sampled models without any training\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "print(\"Before training:\")\n",
    "for net in sampled_nets:\n",
    "    # evaluate the models on both full train set and test set before training\n",
    "    train_score = report.compute_roc_auc_score(net, train_loader)\n",
    "    test_score = report.compute_roc_auc_score(net, test_loader)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "print(f\"Eval score (train): {sum(train_scores) / len(train_scores):.4f}\")\n",
    "print(f\"Eval score (test): {sum(test_scores) / len(test_scores):.4f}\")\n",
    "\n",
    "# train the models and plot curves (if exist)\n",
    "train_loss_curves = []\n",
    "for net in sampled_nets:\n",
    "    train_losses = []\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    for s in range(train_it):\n",
    "        loss, _ = train.epoch(mode=\"train\", dataloader=coreset_loader, net=net, criterion=loss_fn, optimizer=optimizer, device=DEVICE)\n",
    "        train_losses.append(loss)\n",
    "    train_loss_curves.append(train_losses)\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Iterate over each set of loss values and plot them\n",
    "for i, losses in enumerate(train_loss_curves):\n",
    "    plt.plot(losses, label=f'Training Run {i+1}')\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curves')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# eval the trained result models\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "print(\"After training:\")\n",
    "for net in sampled_nets:\n",
    "    # evaluate the models on both full train set and test set after training\n",
    "    train_score = report.compute_roc_auc_score(net, train_loader)\n",
    "    test_score = report.compute_roc_auc_score(net, test_loader)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "print(f\"Eval score (train): {sum(train_scores) / len(train_scores):.4f}\")\n",
    "print(f\"Eval score (test): {sum(test_scores) / len(test_scores):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
