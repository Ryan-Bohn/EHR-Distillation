import os
import sys
import time
import requests
import random
import numpy as np
import matplotlib.pyplot as plt
from sklearn import linear_model, model_selection
import copy
import pickle
import itertools
from datetime import datetime

import torch
from torch import nn
from torch import optim
from torch.utils.data import DataLoader, Subset
import torch.nn.functional as F

import torchvision
from torchvision import transforms
from torchvision.utils import make_grid
from torchvision.models import resnet18

from tqdm import tqdm

from glob import glob
from collections import defaultdict

import argparse

from utils import preprocess, dataset, network, train, report


def parse_args():
    parser = argparse.ArgumentParser(description='Parse command line arguments.')
    
    parser.add_argument('--n', type=int, required=True, help='Number of synthetic samples in total')
    parser.add_argument('--obj', type=str, required=True, help="Objective")
    timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
    default_outdir = os.path.join("./saved_data", timestamp)
    parser.add_argument('--outdir', type=str, default=None, help='Output directory for data')
    parser.add_argument('--testflag', action='store_true', help='Set a test flag, so the program returns immediately, for shell scripts testing')

    args = parser.parse_args()
    if args.testflag:
        # Print the entire list of command-line arguments
        print("All arguments:", sys.argv)
        # Access individual arguments (excluding the script name)
        for i, arg in enumerate(sys.argv[1:], start=1):
            print(f"Argument {i}: {arg}")

        exit(0)
    
    if args.obj not in ["ihm", "los",]:
        raise NotImplementedError()
        
    return args


def get_net(name, feat_shape, init=None):
        if name == "1dcnn":
            net = network.IHMPreliminary1DCNN(input_shape=feat_shape, init_distr=init)
        elif name == "mlp":
            net = network.IHMPreliminaryMLP(input_shape=feat_shape, init_distr=init)
        elif name == "1dcnnregr":
            net = network.Preliminary1DCNNRegressor(input_shape=feat_shape, init_distr=init, output_dim=1)
        else:
            raise NotImplementedError()
        return net


def main():

    # parse arguments
    args = parse_args()

    OUT_DIR = args.outdir
    if OUT_DIR is None:
        timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
        OUT_DIR = os.path.join("./saved_data", timestamp)
        os.makedirs(OUT_DIR, exist_ok=True)
    elif not os.path.exists(OUT_DIR):
        raise ValueError("Not a valid output dir")
    print(f"All data will be output to {OUT_DIR}")

    DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
    print("Running on device:", DEVICE.upper())

    # manual random seed is used for dataset partitioning
    # to ensure reproducible results across runs
    RNG = torch.Generator().manual_seed(42)


    # compute (or load from saved pickel) data statistics

    LOAD_FROM_SAVED = True
    STAT_PKL_DIR = "./saved_data/stats/"
    if not os.path.exists(STAT_PKL_DIR):
        os.makedirs(STAT_PKL_DIR)

    CATEGORICAL_NUM_CLS_DICT = {  # how many classes are there for categorical classes
        "capillary_refill_rate": 2,
        "glascow_coma_scale_eye_opening": 4,
        "glascow_coma_scale_motor_response": 6,
        "glascow_coma_scale_total": 13,
        "glascow_coma_scale_verbal_response": 5,
    }

    stat_pkl_path = os.path.join(STAT_PKL_DIR, "ihm_preliminary.pkl")
    if os.path.exists(stat_pkl_path) and LOAD_FROM_SAVED:
        with open(stat_pkl_path, 'rb') as f:
            continuous_avgs_train, continuous_stds_train, categorical_modes_train = pickle.load(f)
    else: # compute and save
        continuous_avgs_train, continuous_stds_train, categorical_modes_train =  preprocess.compute_feature_statistics(
            ts_dir="./data/mimic3/benchmark/in-hospital-mortality/train/",
            feature_dict=preprocess.mimic3_benchmark_variable_dict
            )
        with open(stat_pkl_path, 'wb') as f:
            pickle.dump((continuous_avgs_train, continuous_stds_train, categorical_modes_train), f)


    # preprocess data generated by mimic3 benchmarks, based on ihm objective constraints (stay length > 48h)
    # this step does resampling, imputing, excluding anomalies, and save new csvs as cleaned ones
    # skip if ./data/mimic3/ihm_preliminary/test/ is not empty
    if not os.listdir("./data/mimic3/ihm_preliminary/test/"):
        preprocess.preprocess_ihm_timeseries_files(
            ts_dir="./data/mimic3/benchmark/in-hospital-mortality/train/",
            output_dir="./data/mimic3/ihm_preliminary/train/",
            feature_dict=preprocess.mimic3_benchmark_variable_dict,
            normal_value_dict=continuous_avgs_train|categorical_modes_train
            )
        preprocess.preprocess_ihm_timeseries_files(
            ts_dir="./data/mimic3/benchmark/in-hospital-mortality/test/",
            output_dir="./data/mimic3/ihm_preliminary/test/",
            feature_dict=preprocess.mimic3_benchmark_variable_dict,
            normal_value_dict=continuous_avgs_train|categorical_modes_train
            )
        

    # unify episodes into a whole, for faster data loading
    # skip if ./data/mimic3/ihm_preliminary/test/all_episodes.pkl already exists
    if not os.path.exists(os.path.join("./data/mimic3/ihm_preliminary/test/", "all_episodes.pkl")):
        preprocess.unify_ihm_episodes(dir="./data/mimic3/ihm_preliminary/train/")
        preprocess.unify_ihm_episodes(dir="./data/mimic3/ihm_preliminary/test/")

    # join other tasks (lof, phenotyping) into the fully preprocessed and unified ihm data
    # skip if ./data/mimic3/multitask_preliminary/test/all.pkl already exists
    if not os.path.exists(os.path.join("./data/mimic3/multitask_preliminary/test/", "all.pkl")):
        preprocess.join_multitask_labels(
            cleaned_ihm_ts_dir="./data/mimic3/ihm_preliminary/train/",
            raw_multitask_ts_dir="./data/mimic3/benchmark/multitask/train/",
            output_dir="./data/mimic3/multitask_preliminary/train/",
            )
        preprocess.join_multitask_labels(
            cleaned_ihm_ts_dir="./data/mimic3/ihm_preliminary/test/",
            raw_multitask_ts_dir="./data/mimic3/benchmark/multitask/test/",
            output_dir="./data/mimic3/multitask_preliminary/test/",
            )


    # define multi objective datasets and dataloaders

    train_set = dataset.Mimic3BenchmarkDataset(
        dir="./data/mimic3/multitask_preliminary/train/",
        avg_dict=continuous_avgs_train,
        std_dict=continuous_stds_train,
        numcls_dict=CATEGORICAL_NUM_CLS_DICT,
        dstype="train",
        objective="ihm"
        )
    print(f"First item in the dataset: \n{train_set[0]}")
    print(f"Feature tensor shape: {train_set[0][0].shape}")
    train_set_stats = train_set.get_stats()

    test_set = dataset.Mimic3BenchmarkDataset(
        dir="./data/mimic3/multitask_preliminary/test/",
        avg_dict=continuous_avgs_train,
        std_dict=continuous_stds_train,
        numcls_dict=CATEGORICAL_NUM_CLS_DICT,
        dstype="test",
        objective="ihm"
        )
    print(f"First item in the dataset: \n{test_set[0]}")
    print(f"Feature tensor shape: {test_set[0][0].shape}")

    feat_shape = train_set[0][0].shape
    print(f"Input tensor shape: {feat_shape}")

    # prepare dataloaders

    NUM_WORKERS = 0
    DS_BATCH_SIZE = 256

    train_loader = DataLoader(train_set, DS_BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)
    test_loader = DataLoader(test_set, DS_BATCH_SIZE, num_workers=NUM_WORKERS)

    # define synthetic dataset
    NUM_SAMPLES_TOTAL = args.n
    print(f"Initializing synthetic dataset. Number of samples in total = {NUM_SAMPLES_TOTAL}")

    OBJECTIVE = args.obj

    train_set.set_objective(objective=OBJECTIVE)
    test_set.set_objective(objective=OBJECTIVE)

    # initialize random synth dataset
    if OBJECTIVE == "ihm":
        feat_syn = torch.randn(size=(NUM_SAMPLES_TOTAL), dtype=torch.float, requires_grad=True, device=DEVICE)
        lab_syn = torch.tensor(np.array([np.ones(NUM_SAMPLES_TOTAL//2)*i for i in range(2)]), dtype=torch.long, requires_grad=False, device=DEVICE).view(-1)
    elif OBJECTIVE == "los":
        feat_syn = torch.randn(size=(NUM_SAMPLES_TOTAL, *feat_shape), dtype=torch.float, requires_grad=True, device=DEVICE)
        lab_samples = np.random.normal(loc=train_set_stats["los_mean"], scale=train_set_stats["los_std"], size=NUM_SAMPLES_TOTAL)
        lab_syn = torch.tensor(lab_samples, dtype=torch.float, device=DEVICE).view(-1)
        lab_syn.requires_grad_()
    print(f"Synthetic feature shape: {feat_syn.shape}")
    print(f"Synthetic label shape: {lab_syn.shape}")
    # print some of the feature tensors
    feats = feat_syn.clone().cpu()
    fig, ax = plt.subplots(figsize=(12, 6))
    plt.title("Random initialized features for IHM distillation")
    ax.set_xticks([])
    ax.set_yticks([])
    ax.imshow(make_grid(feats.unsqueeze(1), nrow=10).permute(1, 2, 0))
    plt.savefig(os.path.join(OUT_DIR, "syn_data_init_vis.png"))
    plt.clf()

    # plot tensor element value distributions
    # Convert feat_syn to a numpy array if it's not already
    feat_syn_np = feat_syn.detach().cpu().numpy()
    # Reshape the array to a 1D array for histogram plotting
    pixels = feat_syn_np.reshape(-1)
    # Plotting the histogram
    plt.figure(figsize=(10, 6))
    plt.hist(pixels, bins=50, color='gray', alpha=0.7)
    plt.title('Tensor Element Value Distribution')
    plt.xlabel('Element Value')
    plt.ylabel('Frequency')
    # Show the plot
    plt.savefig(os.path.join(OUT_DIR, "syn_data_init_distr.png"))
    plt.clf()

    # distill with gradient matching

    # define local variables
    if OBJECTIVE == "ihm":
        net_name = "1dcnn"
        comment = ""
    elif OBJECTIVE == "los":
        net_name = "1dcnnregr"
        comment = ""
    else:
        raise NotImplementedError()

    # define hyper params
    NUM_OUTER_LOOPS = 1000
    EVAL_INTERVAL = 100
    NUM_EVAL_EPOCHS = 1000
    NUM_SAMPLED_NETS_EVAL = 4
    LR_DATA = 0.1 # original: 0.1
    LR_NET = 0.01 # original: 0.01
    NUM_INNER_LOOPS = 10
    NUM_UPDT_STEPS_DATA = 1 # s_S
    NUM_UPDT_STEPS_NET = 50 # s_theta
    BATCH_SIZE_REAL = 256
    BATCH_SIZE_SYN = 256

    MAX_NORM = 5

    INIT_WEIGHTS_DISTR = [None, "kaiming"][0]
    FIX_INIT_WEIGHTS = False

    CLAMP_AFTER_EACH_IT = False

    MATCH_LOSS = ["gmatch", "mse", "cos"][0]

    # define training optimizers and criterion
    if OBJECTIVE == "ihm":
        optimizer_feat = torch.optim.SGD([feat_syn,], lr=LR_DATA, momentum=0.5) # optimizer for synthetic data
    elif OBJECTIVE == "los":
        optimizer_feat = torch.optim.SGD([feat_syn, lab_syn,], lr=LR_DATA, momentum=0.5) # optimizer for synthetic data
    optimizer_feat.zero_grad()
    criterion = {
        "ihm": nn.CrossEntropyLoss(),
        "los": nn.MSELoss(),
    }[OBJECTIVE]
    print("Ready for training")

    # data for plotting curves
    eval_its = [] # iterations of evaluation
    eval_scores_train = [] # evaluation accuracy on train set
    eval_scores_test = [] # evaluation accuracy on test set
    avg_losses = []
    min_avg_loss = float('inf')

    # checkpoints saving
    # CHECKPOINT_SAVE_DIR = "./saved_data/ihmdd/"
    # if not os.path.exists(CHECKPOINT_SAVE_DIR):
    #     os.makedirs(CHECKPOINT_SAVE_DIR)
    CHECKPOINT_SAVE_DIR = OUT_DIR

    # snapshots of synthetic data evaluated
    feat_syn_snapshots = []

    # proposed match loss distance
    def distance_wb(gwr, gws):
        shape = gwr.shape
        if len(shape) == 4: # conv, out*in*h*w
            gwr = gwr.reshape(shape[0], shape[1] * shape[2] * shape[3])
            gws = gws.reshape(shape[0], shape[1] * shape[2] * shape[3])
        elif len(shape) == 3:  # layernorm, C*h*w
            gwr = gwr.reshape(shape[0], shape[1] * shape[2])
            gws = gws.reshape(shape[0], shape[1] * shape[2])
        elif len(shape) == 2: # linear, out*in
            tmp = 'do nothing'
        elif len(shape) == 1: # batchnorm/instancenorm, C; groupnorm x, bias
            gwr = gwr.reshape(1, shape[0])
            gws = gws.reshape(1, shape[0])
            return torch.tensor(0, dtype=torch.float, device=gwr.device)

        dis_weight = torch.sum(1 - torch.sum(gwr * gws, dim=-1) / (torch.norm(gwr, dim=-1) * torch.norm(gws, dim=-1) + 0.000001))
        dis = dis_weight
        return dis
        
    pbar = tqdm(range(NUM_OUTER_LOOPS+1), desc="Training iteration")
    for it in pbar:

        # evaluate the distilled data every `EVAL_INTERVAL` iterations
        if EVAL_INTERVAL > 0 and it % EVAL_INTERVAL == 0:
            eval_its.append(it)

            print(f"Optimization iteration {it} evaluation begins...")
            feat_syn_snapshot = feat_syn.detach().clone()
            feat_syn_snapshots.append(feat_syn_snapshot)
            fig, ax = plt.subplots(figsize=(12, 6))
            plt.title(f"Synthetic dataset (optimization iteration {it})")
            ax.set_xticks([])
            ax.set_yticks([])
            ax.imshow(make_grid(feat_syn_snapshot.cpu().unsqueeze(1), nrow=10).permute(1, 2, 0))
            eval_vis_path = os.path.join(OUT_DIR, f"it{it}.png")
            plt.savefig(eval_vis_path)
            plt.clf()
            print(f"A new evaluation visualization has been saved: {eval_vis_path}")

            # sample a batch of models to eval on
            sampled_nets = []
            local_train_scores = []
            local_test_scores = []
            for j in range(NUM_SAMPLED_NETS_EVAL if not FIX_INIT_WEIGHTS else 1):
                if FIX_INIT_WEIGHTS:
                    torch.random.manual_seed(42) # fixed seed
                else:
                    torch.random.manual_seed(int(time.time() * 1000) % 100000) # random seed
                net = get_net(net_name, feat_shape=feat_shape, init=INIT_WEIGHTS_DISTR).to(DEVICE)
                sampled_nets.append(net)
            for j, net in enumerate(sampled_nets):
                print(f"Training network {j} for evaluation...")
                net.train()
                optimizer = torch.optim.SGD(net.parameters(), lr=LR_NET)
                # train the models on synthetic set
                for s in range(NUM_EVAL_EPOCHS):
                    pred_syn = net(feat_syn_snapshot)
                    if isinstance(criterion, nn.MSELoss):
                        lab_syn = lab_syn.view(-1, 1)
                    loss_syn = criterion(pred_syn, lab_syn)
                    optimizer.zero_grad()
                    loss_syn.backward()
                    if MAX_NORM > 0:
                        torch.nn.utils.clip_grad_norm_(net.parameters(), MAX_NORM)  # clip gradients
                    optimizer.step()
            for j, net in enumerate(sampled_nets):
                print(f"Testing network {j} on real datasets for evaluation...")
                # evaluate the models on both full train set and test set
                if OBJECTIVE == "ihm":
                    train_score = report.compute_roc_auc_score(net, train_loader)
                    test_score = report.compute_roc_auc_score(net, test_loader)
                elif OBJECTIVE == "los":
                    train_score, _ = train.epoch(mode="test", dataloader=train_loader, net=net, criterion=criterion, device=DEVICE)
                    test_score, _ = train.epoch(mode="test", dataloader=test_loader, net=net, criterion=criterion, device=DEVICE)
                local_train_scores.append(train_score)
                local_test_scores.append(test_score)
            eval_scores_train.append(sum(local_train_scores) / len(local_train_scores))
            eval_scores_test.append(sum(local_test_scores) / len(local_test_scores))
            print(f"Optimization iteration {it}, eval auroc score (train): {eval_scores_train[-1]:.4f}, eval auroc score (test): {eval_scores_test[-1]:.4f}")
        
        checkpoint = {
            "objective": OBJECTIVE,
            "method": "gmatch",
            "net_name": net_name,
            "it": it,
            "num_cls": {"ihm": 2, "los": None}[OBJECTIVE],
            "feat_syn": feat_syn.detach().clone(),
            "lab_syn": lab_syn.detach().clone(),
            'optim_losses': avg_losses,
            "eval_its": eval_its,
            "feat_syn_snapshots": feat_syn_snapshots,
            'eval_scores_train': eval_scores_train,
            'eval_scores_test': eval_scores_test,
            'init_weight_distr': INIT_WEIGHTS_DISTR,
            'fix_init_weights': FIX_INIT_WEIGHTS,
            "comment": comment
        }
        
        # Save checkpoint
        filepath = os.path.join(CHECKPOINT_SAVE_DIR, f'chckpnt_{OBJECTIVE}_{NUM_SAMPLES_TOTAL}samples.pth')
        torch.save(checkpoint, filepath)
        print(f"Checkpoint at iteration {it} saved at {filepath}. Loss = {'None' if len(avg_losses) == 0 else avg_losses[-1]}")
        
        if it >= NUM_OUTER_LOOPS: # last epoch only evaluate, no training
            break

        # Train synthetic data
        if FIX_INIT_WEIGHTS:
            torch.random.manual_seed(42) # fixed seed
        else:
            torch.random.manual_seed(int(time.time() * 1000) % 100000) # random seed
        net = get_net(net_name, feat_shape=feat_shape, init=INIT_WEIGHTS_DISTR).to(DEVICE)
        net.train()
        net_params = list(net.parameters())

        optimizer_net = torch.optim.SGD(net.parameters(), lr=LR_NET)
        optimizer_net.zero_grad()
        loss_avg = 0

        for l in range(NUM_INNER_LOOPS):
            # update synthetic data
            loss = torch.tensor(0.0).to(DEVICE)
            if OBJECTIVE in ["ihm",]:
                for cls in range(2):
                    sampled_real_feats, _ = train_set.random_sample(n_samples=BATCH_SIZE_REAL, match_label=cls)
                    cls_feat_real = torch.stack(sampled_real_feats).to(DEVICE)
                    cls_lab_real = torch.full((len(sampled_real_feats),), cls, dtype=torch.long).to(DEVICE)
                    cls_feat_syn = feat_syn[cls*NUM_SAMPLES_TOTAL//2: (cls+1)*NUM_SAMPLES_TOTAL//2]
                    cls_lab_syn = lab_syn[cls*NUM_SAMPLES_TOTAL//2: (cls+1)*NUM_SAMPLES_TOTAL//2]

                    out_real = net(cls_feat_real)
                    loss_real = criterion(out_real, cls_lab_real)
                    grad_real = torch.autograd.grad(loss_real, net_params)
                    grad_real = list((_.detach().clone() for _ in grad_real))

                    out_syn = net(cls_feat_syn)
                    loss_syn = criterion(out_syn, cls_lab_syn)
                    grad_syn = torch.autograd.grad(loss_syn, net_params, create_graph=True) # create_graph: will be used to compute higher-order derivatives

                    dis = torch.tensor(0.0).to(DEVICE)

                    if MATCH_LOSS == "gmatch":
                        for gidx in range(len(grad_real)):
                            gr = grad_real[gidx]
                            gs = grad_syn[gidx]
                            dis += distance_wb(gr, gs)
                    elif MATCH_LOSS == "mse":
                        # compute gradient matching loss, here using MSE, instead of the one proposed in DCwMG because it's too complicated
                        # dis = torch.tensor(0.0).to(DEVICE)
                        grad_real_vec = []
                        grad_syn_vec = []
                        for gidx in range(len(grad_real)):
                            grad_real_vec.append(grad_real[gidx].reshape((-1)))
                            grad_syn_vec.append(grad_syn[gidx].reshape((-1)))
                        grad_real_vec = torch.cat(grad_real_vec, dim=0)
                        grad_syn_vec = torch.cat(grad_syn_vec, dim=0)
                        dis = torch.sum((grad_syn_vec - grad_real_vec)**2)
                    else:
                        raise NotImplementedError()

                    loss += dis
            elif OBJECTIVE in ["los"]:
                sampled_real_feats, sampled_real_labs = train_set.random_sample(n_samples=BATCH_SIZE_REAL)
                feat_real = torch.stack(sampled_real_feats).to(DEVICE)
                lab_real = torch.stack(sampled_real_labs).view(-1, 1).to(DEVICE)

                out_real = net(feat_real)
                loss_real = criterion(out_real, lab_real)
                grad_real = torch.autograd.grad(loss_real, net_params)
                grad_real = list((_.detach().clone() for _ in grad_real))

                out_syn = net(feat_syn)
                loss_syn = criterion(out_syn, lab_syn.view(-1, 1))
                grad_syn = torch.autograd.grad(loss_syn, net_params, create_graph=True) # create_graph: will be used to compute higher-order derivatives


                dis = torch.tensor(0.0).to(DEVICE)

                if MATCH_LOSS == "gmatch":
                    for gidx in range(len(grad_real)):
                        gr = grad_real[gidx]
                        gs = grad_syn[gidx]
                        # contains_nan = torch.isnan(gr).any() or torch.isnan(gs).any()
                        # print(f"Does the tensor contain NaN values? {contains_nan}")
                        dis += distance_wb(gr, gs)
                        # print("I'm dis", dis)
                elif MATCH_LOSS == "mse":
                    # compute gradient matching loss, here using MSE, instead of the one proposed in DCwMG because it's too complicated
                    # dis = torch.tensor(0.0).to(DEVICE)
                    grad_real_vec = []
                    grad_syn_vec = []
                    for gidx in range(len(grad_real)):
                        grad_real_vec.append(grad_real[gidx].reshape((-1)))
                        grad_syn_vec.append(grad_syn[gidx].reshape((-1)))
                    grad_real_vec = torch.cat(grad_real_vec, dim=0)
                    grad_syn_vec = torch.cat(grad_syn_vec, dim=0)
                    dis = torch.sum((grad_syn_vec - grad_real_vec)**2)
                else:
                    raise NotImplementedError()
                loss += dis
            optimizer_feat.zero_grad()
            loss.backward()
            if MAX_NORM > 0:
                torch.nn.utils.clip_grad_norm_([feat_syn, lab_syn], MAX_NORM)  # clip gradients
            optimizer_feat.step()
            loss_avg += loss.item()
            # print(f"It = {it}, synthetic image pixels are now distributed within [{torch.min(feat_syn)}, {torch.max(feat_syn)}]")
            
            if CLAMP_AFTER_EACH_IT:
                with torch.no_grad():
                    # Clamp the values of the tensor to the range [-1, 1]
                    feat_syn.clamp_(-1, 1) # this is not in the original paper, where the image is only clamped before visualized

            # update network
            feat_syn_train, lab_syn_train = copy.deepcopy(feat_syn.detach()), copy.deepcopy(lab_syn.detach())  # avoid any unaware modification
            for s in range(NUM_UPDT_STEPS_NET):
                pred_syn_train = net(feat_syn_train)
                if isinstance(criterion, nn.MSELoss):
                    lab_syn_train = lab_syn_train.view(-1, 1)
                train_loss = criterion(pred_syn_train, lab_syn_train)
                optimizer_net.zero_grad()
                train_loss.backward()
                if MAX_NORM > 0:
                    torch.nn.utils.clip_grad_norm_(net.parameters(), MAX_NORM)  # clip gradients
                optimizer_net.step()
            for name, param in net.named_parameters():
                if torch.isnan(param).any():
                    print(f"NaN found in {name}")

        loss_avg /= (2 * NUM_INNER_LOOPS)
        pbar.set_postfix({"avg loss": f"{loss_avg:.4f}",
                        })
        avg_losses.append(loss_avg)
        if loss_avg < min_avg_loss:
            min_avg_loss = loss_avg
            print(f"New best at iteratoin {it}!")



if __name__ == "__main__":
    main()